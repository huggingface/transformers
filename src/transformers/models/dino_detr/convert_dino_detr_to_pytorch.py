"""Convert Dino DETR checkpoints."""

import argparse
import json
from pathlib import Path

import requests
import torch
from huggingface_hub import hf_hub_download
from PIL import Image

from transformers import (
    DinoDetrConfig,
    DinoDetrForObjectDetection,
    DinoDetrImageProcessor,
)
from transformers.utils import logging


torch.manual_seed(42)


logging.set_verbosity_info()
logger = logging.get_logger(__name__)

layers = [
    "model.backbone.conv_encoder.model.bn1.bias",
    "model.backbone.conv_encoder.model.bn1.running_mean",
    "model.backbone.conv_encoder.model.bn1.running_var",
    "model.backbone.conv_encoder.model.bn1.weight",
    "model.backbone.conv_encoder.model.conv1.weight",
    "model.backbone.conv_encoder.model.layer1.0.bn1.bias",
    "model.backbone.conv_encoder.model.layer1.0.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer1.0.bn1.running_var",
    "model.backbone.conv_encoder.model.layer1.0.bn1.weight",
    "model.backbone.conv_encoder.model.layer1.0.bn2.bias",
    "model.backbone.conv_encoder.model.layer1.0.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer1.0.bn2.running_var",
    "model.backbone.conv_encoder.model.layer1.0.bn2.weight",
    "model.backbone.conv_encoder.model.layer1.0.bn3.bias",
    "model.backbone.conv_encoder.model.layer1.0.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer1.0.bn3.running_var",
    "model.backbone.conv_encoder.model.layer1.0.bn3.weight",
    "model.backbone.conv_encoder.model.layer1.0.conv1.weight",
    "model.backbone.conv_encoder.model.layer1.0.conv2.weight",
    "model.backbone.conv_encoder.model.layer1.0.conv3.weight",
    "model.backbone.conv_encoder.model.layer1.0.downsample.0.weight",
    "model.backbone.conv_encoder.model.layer1.0.downsample.1.bias",
    "model.backbone.conv_encoder.model.layer1.0.downsample.1.running_mean",
    "model.backbone.conv_encoder.model.layer1.0.downsample.1.running_var",
    "model.backbone.conv_encoder.model.layer1.0.downsample.1.weight",
    "model.backbone.conv_encoder.model.layer1.1.bn1.bias",
    "model.backbone.conv_encoder.model.layer1.1.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer1.1.bn1.running_var",
    "model.backbone.conv_encoder.model.layer1.1.bn1.weight",
    "model.backbone.conv_encoder.model.layer1.1.bn2.bias",
    "model.backbone.conv_encoder.model.layer1.1.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer1.1.bn2.running_var",
    "model.backbone.conv_encoder.model.layer1.1.bn2.weight",
    "model.backbone.conv_encoder.model.layer1.1.bn3.bias",
    "model.backbone.conv_encoder.model.layer1.1.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer1.1.bn3.running_var",
    "model.backbone.conv_encoder.model.layer1.1.bn3.weight",
    "model.backbone.conv_encoder.model.layer1.1.conv1.weight",
    "model.backbone.conv_encoder.model.layer1.1.conv2.weight",
    "model.backbone.conv_encoder.model.layer1.1.conv3.weight",
    "model.backbone.conv_encoder.model.layer1.2.bn1.bias",
    "model.backbone.conv_encoder.model.layer1.2.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer1.2.bn1.running_var",
    "model.backbone.conv_encoder.model.layer1.2.bn1.weight",
    "model.backbone.conv_encoder.model.layer1.2.bn2.bias",
    "model.backbone.conv_encoder.model.layer1.2.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer1.2.bn2.running_var",
    "model.backbone.conv_encoder.model.layer1.2.bn2.weight",
    "model.backbone.conv_encoder.model.layer1.2.bn3.bias",
    "model.backbone.conv_encoder.model.layer1.2.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer1.2.bn3.running_var",
    "model.backbone.conv_encoder.model.layer1.2.bn3.weight",
    "model.backbone.conv_encoder.model.layer1.2.conv1.weight",
    "model.backbone.conv_encoder.model.layer1.2.conv2.weight",
    "model.backbone.conv_encoder.model.layer1.2.conv3.weight",
    "model.backbone.conv_encoder.model.layer2.0.bn1.bias",
    "model.backbone.conv_encoder.model.layer2.0.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer2.0.bn1.running_var",
    "model.backbone.conv_encoder.model.layer2.0.bn1.weight",
    "model.backbone.conv_encoder.model.layer2.0.bn2.bias",
    "model.backbone.conv_encoder.model.layer2.0.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer2.0.bn2.running_var",
    "model.backbone.conv_encoder.model.layer2.0.bn2.weight",
    "model.backbone.conv_encoder.model.layer2.0.bn3.bias",
    "model.backbone.conv_encoder.model.layer2.0.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer2.0.bn3.running_var",
    "model.backbone.conv_encoder.model.layer2.0.bn3.weight",
    "model.backbone.conv_encoder.model.layer2.0.conv1.weight",
    "model.backbone.conv_encoder.model.layer2.0.conv2.weight",
    "model.backbone.conv_encoder.model.layer2.0.conv3.weight",
    "model.backbone.conv_encoder.model.layer2.0.downsample.0.weight",
    "model.backbone.conv_encoder.model.layer2.0.downsample.1.bias",
    "model.backbone.conv_encoder.model.layer2.0.downsample.1.running_mean",
    "model.backbone.conv_encoder.model.layer2.0.downsample.1.running_var",
    "model.backbone.conv_encoder.model.layer2.0.downsample.1.weight",
    "model.backbone.conv_encoder.model.layer2.1.bn1.bias",
    "model.backbone.conv_encoder.model.layer2.1.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer2.1.bn1.running_var",
    "model.backbone.conv_encoder.model.layer2.1.bn1.weight",
    "model.backbone.conv_encoder.model.layer2.1.bn2.bias",
    "model.backbone.conv_encoder.model.layer2.1.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer2.1.bn2.running_var",
    "model.backbone.conv_encoder.model.layer2.1.bn2.weight",
    "model.backbone.conv_encoder.model.layer2.1.bn3.bias",
    "model.backbone.conv_encoder.model.layer2.1.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer2.1.bn3.running_var",
    "model.backbone.conv_encoder.model.layer2.1.bn3.weight",
    "model.backbone.conv_encoder.model.layer2.1.conv1.weight",
    "model.backbone.conv_encoder.model.layer2.1.conv2.weight",
    "model.backbone.conv_encoder.model.layer2.1.conv3.weight",
    "model.backbone.conv_encoder.model.layer2.2.bn1.bias",
    "model.backbone.conv_encoder.model.layer2.2.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer2.2.bn1.running_var",
    "model.backbone.conv_encoder.model.layer2.2.bn1.weight",
    "model.backbone.conv_encoder.model.layer2.2.bn2.bias",
    "model.backbone.conv_encoder.model.layer2.2.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer2.2.bn2.running_var",
    "model.backbone.conv_encoder.model.layer2.2.bn2.weight",
    "model.backbone.conv_encoder.model.layer2.2.bn3.bias",
    "model.backbone.conv_encoder.model.layer2.2.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer2.2.bn3.running_var",
    "model.backbone.conv_encoder.model.layer2.2.bn3.weight",
    "model.backbone.conv_encoder.model.layer2.2.conv1.weight",
    "model.backbone.conv_encoder.model.layer2.2.conv2.weight",
    "model.backbone.conv_encoder.model.layer2.2.conv3.weight",
    "model.backbone.conv_encoder.model.layer2.3.bn1.bias",
    "model.backbone.conv_encoder.model.layer2.3.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer2.3.bn1.running_var",
    "model.backbone.conv_encoder.model.layer2.3.bn1.weight",
    "model.backbone.conv_encoder.model.layer2.3.bn2.bias",
    "model.backbone.conv_encoder.model.layer2.3.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer2.3.bn2.running_var",
    "model.backbone.conv_encoder.model.layer2.3.bn2.weight",
    "model.backbone.conv_encoder.model.layer2.3.bn3.bias",
    "model.backbone.conv_encoder.model.layer2.3.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer2.3.bn3.running_var",
    "model.backbone.conv_encoder.model.layer2.3.bn3.weight",
    "model.backbone.conv_encoder.model.layer2.3.conv1.weight",
    "model.backbone.conv_encoder.model.layer2.3.conv2.weight",
    "model.backbone.conv_encoder.model.layer2.3.conv3.weight",
    "model.backbone.conv_encoder.model.layer3.0.bn1.bias",
    "model.backbone.conv_encoder.model.layer3.0.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer3.0.bn1.running_var",
    "model.backbone.conv_encoder.model.layer3.0.bn1.weight",
    "model.backbone.conv_encoder.model.layer3.0.bn2.bias",
    "model.backbone.conv_encoder.model.layer3.0.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer3.0.bn2.running_var",
    "model.backbone.conv_encoder.model.layer3.0.bn2.weight",
    "model.backbone.conv_encoder.model.layer3.0.bn3.bias",
    "model.backbone.conv_encoder.model.layer3.0.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer3.0.bn3.running_var",
    "model.backbone.conv_encoder.model.layer3.0.bn3.weight",
    "model.backbone.conv_encoder.model.layer3.0.conv1.weight",
    "model.backbone.conv_encoder.model.layer3.0.conv2.weight",
    "model.backbone.conv_encoder.model.layer3.0.conv3.weight",
    "model.backbone.conv_encoder.model.layer3.0.downsample.0.weight",
    "model.backbone.conv_encoder.model.layer3.0.downsample.1.bias",
    "model.backbone.conv_encoder.model.layer3.0.downsample.1.running_mean",
    "model.backbone.conv_encoder.model.layer3.0.downsample.1.running_var",
    "model.backbone.conv_encoder.model.layer3.0.downsample.1.weight",
    "model.backbone.conv_encoder.model.layer3.1.bn1.bias",
    "model.backbone.conv_encoder.model.layer3.1.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer3.1.bn1.running_var",
    "model.backbone.conv_encoder.model.layer3.1.bn1.weight",
    "model.backbone.conv_encoder.model.layer3.1.bn2.bias",
    "model.backbone.conv_encoder.model.layer3.1.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer3.1.bn2.running_var",
    "model.backbone.conv_encoder.model.layer3.1.bn2.weight",
    "model.backbone.conv_encoder.model.layer3.1.bn3.bias",
    "model.backbone.conv_encoder.model.layer3.1.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer3.1.bn3.running_var",
    "model.backbone.conv_encoder.model.layer3.1.bn3.weight",
    "model.backbone.conv_encoder.model.layer3.1.conv1.weight",
    "model.backbone.conv_encoder.model.layer3.1.conv2.weight",
    "model.backbone.conv_encoder.model.layer3.1.conv3.weight",
    "model.backbone.conv_encoder.model.layer3.2.bn1.bias",
    "model.backbone.conv_encoder.model.layer3.2.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer3.2.bn1.running_var",
    "model.backbone.conv_encoder.model.layer3.2.bn1.weight",
    "model.backbone.conv_encoder.model.layer3.2.bn2.bias",
    "model.backbone.conv_encoder.model.layer3.2.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer3.2.bn2.running_var",
    "model.backbone.conv_encoder.model.layer3.2.bn2.weight",
    "model.backbone.conv_encoder.model.layer3.2.bn3.bias",
    "model.backbone.conv_encoder.model.layer3.2.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer3.2.bn3.running_var",
    "model.backbone.conv_encoder.model.layer3.2.bn3.weight",
    "model.backbone.conv_encoder.model.layer3.2.conv1.weight",
    "model.backbone.conv_encoder.model.layer3.2.conv2.weight",
    "model.backbone.conv_encoder.model.layer3.2.conv3.weight",
    "model.backbone.conv_encoder.model.layer3.3.bn1.bias",
    "model.backbone.conv_encoder.model.layer3.3.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer3.3.bn1.running_var",
    "model.backbone.conv_encoder.model.layer3.3.bn1.weight",
    "model.backbone.conv_encoder.model.layer3.3.bn2.bias",
    "model.backbone.conv_encoder.model.layer3.3.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer3.3.bn2.running_var",
    "model.backbone.conv_encoder.model.layer3.3.bn2.weight",
    "model.backbone.conv_encoder.model.layer3.3.bn3.bias",
    "model.backbone.conv_encoder.model.layer3.3.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer3.3.bn3.running_var",
    "model.backbone.conv_encoder.model.layer3.3.bn3.weight",
    "model.backbone.conv_encoder.model.layer3.3.conv1.weight",
    "model.backbone.conv_encoder.model.layer3.3.conv2.weight",
    "model.backbone.conv_encoder.model.layer3.3.conv3.weight",
    "model.backbone.conv_encoder.model.layer3.4.bn1.bias",
    "model.backbone.conv_encoder.model.layer3.4.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer3.4.bn1.running_var",
    "model.backbone.conv_encoder.model.layer3.4.bn1.weight",
    "model.backbone.conv_encoder.model.layer3.4.bn2.bias",
    "model.backbone.conv_encoder.model.layer3.4.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer3.4.bn2.running_var",
    "model.backbone.conv_encoder.model.layer3.4.bn2.weight",
    "model.backbone.conv_encoder.model.layer3.4.bn3.bias",
    "model.backbone.conv_encoder.model.layer3.4.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer3.4.bn3.running_var",
    "model.backbone.conv_encoder.model.layer3.4.bn3.weight",
    "model.backbone.conv_encoder.model.layer3.4.conv1.weight",
    "model.backbone.conv_encoder.model.layer3.4.conv2.weight",
    "model.backbone.conv_encoder.model.layer3.4.conv3.weight",
    "model.backbone.conv_encoder.model.layer3.5.bn1.bias",
    "model.backbone.conv_encoder.model.layer3.5.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer3.5.bn1.running_var",
    "model.backbone.conv_encoder.model.layer3.5.bn1.weight",
    "model.backbone.conv_encoder.model.layer3.5.bn2.bias",
    "model.backbone.conv_encoder.model.layer3.5.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer3.5.bn2.running_var",
    "model.backbone.conv_encoder.model.layer3.5.bn2.weight",
    "model.backbone.conv_encoder.model.layer3.5.bn3.bias",
    "model.backbone.conv_encoder.model.layer3.5.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer3.5.bn3.running_var",
    "model.backbone.conv_encoder.model.layer3.5.bn3.weight",
    "model.backbone.conv_encoder.model.layer3.5.conv1.weight",
    "model.backbone.conv_encoder.model.layer3.5.conv2.weight",
    "model.backbone.conv_encoder.model.layer3.5.conv3.weight",
    "model.backbone.conv_encoder.model.layer4.0.bn1.bias",
    "model.backbone.conv_encoder.model.layer4.0.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer4.0.bn1.running_var",
    "model.backbone.conv_encoder.model.layer4.0.bn1.weight",
    "model.backbone.conv_encoder.model.layer4.0.bn2.bias",
    "model.backbone.conv_encoder.model.layer4.0.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer4.0.bn2.running_var",
    "model.backbone.conv_encoder.model.layer4.0.bn2.weight",
    "model.backbone.conv_encoder.model.layer4.0.bn3.bias",
    "model.backbone.conv_encoder.model.layer4.0.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer4.0.bn3.running_var",
    "model.backbone.conv_encoder.model.layer4.0.bn3.weight",
    "model.backbone.conv_encoder.model.layer4.0.conv1.weight",
    "model.backbone.conv_encoder.model.layer4.0.conv2.weight",
    "model.backbone.conv_encoder.model.layer4.0.conv3.weight",
    "model.backbone.conv_encoder.model.layer4.0.downsample.0.weight",
    "model.backbone.conv_encoder.model.layer4.0.downsample.1.bias",
    "model.backbone.conv_encoder.model.layer4.0.downsample.1.running_mean",
    "model.backbone.conv_encoder.model.layer4.0.downsample.1.running_var",
    "model.backbone.conv_encoder.model.layer4.0.downsample.1.weight",
    "model.backbone.conv_encoder.model.layer4.1.bn1.bias",
    "model.backbone.conv_encoder.model.layer4.1.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer4.1.bn1.running_var",
    "model.backbone.conv_encoder.model.layer4.1.bn1.weight",
    "model.backbone.conv_encoder.model.layer4.1.bn2.bias",
    "model.backbone.conv_encoder.model.layer4.1.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer4.1.bn2.running_var",
    "model.backbone.conv_encoder.model.layer4.1.bn2.weight",
    "model.backbone.conv_encoder.model.layer4.1.bn3.bias",
    "model.backbone.conv_encoder.model.layer4.1.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer4.1.bn3.running_var",
    "model.backbone.conv_encoder.model.layer4.1.bn3.weight",
    "model.backbone.conv_encoder.model.layer4.1.conv1.weight",
    "model.backbone.conv_encoder.model.layer4.1.conv2.weight",
    "model.backbone.conv_encoder.model.layer4.1.conv3.weight",
    "model.backbone.conv_encoder.model.layer4.2.bn1.bias",
    "model.backbone.conv_encoder.model.layer4.2.bn1.running_mean",
    "model.backbone.conv_encoder.model.layer4.2.bn1.running_var",
    "model.backbone.conv_encoder.model.layer4.2.bn1.weight",
    "model.backbone.conv_encoder.model.layer4.2.bn2.bias",
    "model.backbone.conv_encoder.model.layer4.2.bn2.running_mean",
    "model.backbone.conv_encoder.model.layer4.2.bn2.running_var",
    "model.backbone.conv_encoder.model.layer4.2.bn2.weight",
    "model.backbone.conv_encoder.model.layer4.2.bn3.bias",
    "model.backbone.conv_encoder.model.layer4.2.bn3.running_mean",
    "model.backbone.conv_encoder.model.layer4.2.bn3.running_var",
    "model.backbone.conv_encoder.model.layer4.2.bn3.weight",
    "model.backbone.conv_encoder.model.layer4.2.conv1.weight",
    "model.backbone.conv_encoder.model.layer4.2.conv2.weight",
    "model.backbone.conv_encoder.model.layer4.2.conv3.weight",
    "model.input_proj.0.0.bias",
    "model.input_proj.0.0.weight",
    "model.input_proj.0.1.bias",
    "model.input_proj.0.1.weight",
    "model.input_proj.1.0.bias",
    "model.input_proj.1.0.weight",
    "model.input_proj.1.1.bias",
    "model.input_proj.1.1.weight",
    "model.input_proj.2.0.bias",
    "model.input_proj.2.0.weight",
    "model.input_proj.2.1.bias",
    "model.input_proj.2.1.weight",
    "model.input_proj.3.0.bias",
    "model.input_proj.3.0.weight",
    "model.input_proj.3.1.bias",
    "model.input_proj.3.1.weight",
    "model.label_enc.weight",
    "model.transformer.decoder.bbox_embed.0.layers.0.bias",
    "model.transformer.decoder.bbox_embed.0.layers.0.weight",
    "model.transformer.decoder.bbox_embed.0.layers.1.bias",
    "model.transformer.decoder.bbox_embed.0.layers.1.weight",
    "model.transformer.decoder.bbox_embed.0.layers.2.bias",
    "model.transformer.decoder.bbox_embed.0.layers.2.weight",
    "model.transformer.decoder.class_embed.0.bias",
    "model.transformer.decoder.class_embed.0.weight",
    "model.transformer.decoder.layers.0.cross_attn.attention_weights.bias",
    "model.transformer.decoder.layers.0.cross_attn.attention_weights.weight",
    "model.transformer.decoder.layers.0.cross_attn.output_proj.bias",
    "model.transformer.decoder.layers.0.cross_attn.output_proj.weight",
    "model.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias",
    "model.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight",
    "model.transformer.decoder.layers.0.cross_attn.value_proj.bias",
    "model.transformer.decoder.layers.0.cross_attn.value_proj.weight",
    "model.transformer.decoder.layers.0.linear1.bias",
    "model.transformer.decoder.layers.0.linear1.weight",
    "model.transformer.decoder.layers.0.linear2.bias",
    "model.transformer.decoder.layers.0.linear2.weight",
    "model.transformer.decoder.layers.0.norm1.bias",
    "model.transformer.decoder.layers.0.norm1.weight",
    "model.transformer.decoder.layers.0.norm2.bias",
    "model.transformer.decoder.layers.0.norm2.weight",
    "model.transformer.decoder.layers.0.norm3.bias",
    "model.transformer.decoder.layers.0.norm3.weight",
    "model.transformer.decoder.layers.0.self_attn.in_proj_bias",
    "model.transformer.decoder.layers.0.self_attn.in_proj_weight",
    "model.transformer.decoder.layers.0.self_attn.out_proj.bias",
    "model.transformer.decoder.layers.0.self_attn.out_proj.weight",
    "model.transformer.decoder.layers.1.cross_attn.attention_weights.bias",
    "model.transformer.decoder.layers.1.cross_attn.attention_weights.weight",
    "model.transformer.decoder.layers.1.cross_attn.output_proj.bias",
    "model.transformer.decoder.layers.1.cross_attn.output_proj.weight",
    "model.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias",
    "model.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight",
    "model.transformer.decoder.layers.1.cross_attn.value_proj.bias",
    "model.transformer.decoder.layers.1.cross_attn.value_proj.weight",
    "model.transformer.decoder.layers.1.linear1.bias",
    "model.transformer.decoder.layers.1.linear1.weight",
    "model.transformer.decoder.layers.1.linear2.bias",
    "model.transformer.decoder.layers.1.linear2.weight",
    "model.transformer.decoder.layers.1.norm1.bias",
    "model.transformer.decoder.layers.1.norm1.weight",
    "model.transformer.decoder.layers.1.norm2.bias",
    "model.transformer.decoder.layers.1.norm2.weight",
    "model.transformer.decoder.layers.1.norm3.bias",
    "model.transformer.decoder.layers.1.norm3.weight",
    "model.transformer.decoder.layers.1.self_attn.in_proj_bias",
    "model.transformer.decoder.layers.1.self_attn.in_proj_weight",
    "model.transformer.decoder.layers.1.self_attn.out_proj.bias",
    "model.transformer.decoder.layers.1.self_attn.out_proj.weight",
    "model.transformer.decoder.layers.2.cross_attn.attention_weights.bias",
    "model.transformer.decoder.layers.2.cross_attn.attention_weights.weight",
    "model.transformer.decoder.layers.2.cross_attn.output_proj.bias",
    "model.transformer.decoder.layers.2.cross_attn.output_proj.weight",
    "model.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias",
    "model.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight",
    "model.transformer.decoder.layers.2.cross_attn.value_proj.bias",
    "model.transformer.decoder.layers.2.cross_attn.value_proj.weight",
    "model.transformer.decoder.layers.2.linear1.bias",
    "model.transformer.decoder.layers.2.linear1.weight",
    "model.transformer.decoder.layers.2.linear2.bias",
    "model.transformer.decoder.layers.2.linear2.weight",
    "model.transformer.decoder.layers.2.norm1.bias",
    "model.transformer.decoder.layers.2.norm1.weight",
    "model.transformer.decoder.layers.2.norm2.bias",
    "model.transformer.decoder.layers.2.norm2.weight",
    "model.transformer.decoder.layers.2.norm3.bias",
    "model.transformer.decoder.layers.2.norm3.weight",
    "model.transformer.decoder.layers.2.self_attn.in_proj_bias",
    "model.transformer.decoder.layers.2.self_attn.in_proj_weight",
    "model.transformer.decoder.layers.2.self_attn.out_proj.bias",
    "model.transformer.decoder.layers.2.self_attn.out_proj.weight",
    "model.transformer.decoder.layers.3.cross_attn.attention_weights.bias",
    "model.transformer.decoder.layers.3.cross_attn.attention_weights.weight",
    "model.transformer.decoder.layers.3.cross_attn.output_proj.bias",
    "model.transformer.decoder.layers.3.cross_attn.output_proj.weight",
    "model.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias",
    "model.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight",
    "model.transformer.decoder.layers.3.cross_attn.value_proj.bias",
    "model.transformer.decoder.layers.3.cross_attn.value_proj.weight",
    "model.transformer.decoder.layers.3.linear1.bias",
    "model.transformer.decoder.layers.3.linear1.weight",
    "model.transformer.decoder.layers.3.linear2.bias",
    "model.transformer.decoder.layers.3.linear2.weight",
    "model.transformer.decoder.layers.3.norm1.bias",
    "model.transformer.decoder.layers.3.norm1.weight",
    "model.transformer.decoder.layers.3.norm2.bias",
    "model.transformer.decoder.layers.3.norm2.weight",
    "model.transformer.decoder.layers.3.norm3.bias",
    "model.transformer.decoder.layers.3.norm3.weight",
    "model.transformer.decoder.layers.3.self_attn.in_proj_bias",
    "model.transformer.decoder.layers.3.self_attn.in_proj_weight",
    "model.transformer.decoder.layers.3.self_attn.out_proj.bias",
    "model.transformer.decoder.layers.3.self_attn.out_proj.weight",
    "model.transformer.decoder.layers.4.cross_attn.attention_weights.bias",
    "model.transformer.decoder.layers.4.cross_attn.attention_weights.weight",
    "model.transformer.decoder.layers.4.cross_attn.output_proj.bias",
    "model.transformer.decoder.layers.4.cross_attn.output_proj.weight",
    "model.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias",
    "model.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight",
    "model.transformer.decoder.layers.4.cross_attn.value_proj.bias",
    "model.transformer.decoder.layers.4.cross_attn.value_proj.weight",
    "model.transformer.decoder.layers.4.linear1.bias",
    "model.transformer.decoder.layers.4.linear1.weight",
    "model.transformer.decoder.layers.4.linear2.bias",
    "model.transformer.decoder.layers.4.linear2.weight",
    "model.transformer.decoder.layers.4.norm1.bias",
    "model.transformer.decoder.layers.4.norm1.weight",
    "model.transformer.decoder.layers.4.norm2.bias",
    "model.transformer.decoder.layers.4.norm2.weight",
    "model.transformer.decoder.layers.4.norm3.bias",
    "model.transformer.decoder.layers.4.norm3.weight",
    "model.transformer.decoder.layers.4.self_attn.in_proj_bias",
    "model.transformer.decoder.layers.4.self_attn.in_proj_weight",
    "model.transformer.decoder.layers.4.self_attn.out_proj.bias",
    "model.transformer.decoder.layers.4.self_attn.out_proj.weight",
    "model.transformer.decoder.layers.5.cross_attn.attention_weights.bias",
    "model.transformer.decoder.layers.5.cross_attn.attention_weights.weight",
    "model.transformer.decoder.layers.5.cross_attn.output_proj.bias",
    "model.transformer.decoder.layers.5.cross_attn.output_proj.weight",
    "model.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias",
    "model.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight",
    "model.transformer.decoder.layers.5.cross_attn.value_proj.bias",
    "model.transformer.decoder.layers.5.cross_attn.value_proj.weight",
    "model.transformer.decoder.layers.5.linear1.bias",
    "model.transformer.decoder.layers.5.linear1.weight",
    "model.transformer.decoder.layers.5.linear2.bias",
    "model.transformer.decoder.layers.5.linear2.weight",
    "model.transformer.decoder.layers.5.norm1.bias",
    "model.transformer.decoder.layers.5.norm1.weight",
    "model.transformer.decoder.layers.5.norm2.bias",
    "model.transformer.decoder.layers.5.norm2.weight",
    "model.transformer.decoder.layers.5.norm3.bias",
    "model.transformer.decoder.layers.5.norm3.weight",
    "model.transformer.decoder.layers.5.self_attn.in_proj_bias",
    "model.transformer.decoder.layers.5.self_attn.in_proj_weight",
    "model.transformer.decoder.layers.5.self_attn.out_proj.bias",
    "model.transformer.decoder.layers.5.self_attn.out_proj.weight",
    "model.transformer.decoder.norm.bias",
    "model.transformer.decoder.norm.weight",
    "model.transformer.decoder.ref_point_head.layers.0.bias",
    "model.transformer.decoder.ref_point_head.layers.0.weight",
    "model.transformer.decoder.ref_point_head.layers.1.bias",
    "model.transformer.decoder.ref_point_head.layers.1.weight",
    "model.transformer.enc_output.bias",
    "model.transformer.enc_output.weight",
    "model.transformer.enc_output_norm.bias",
    "model.transformer.enc_output_norm.weight",
    "model.transformer.enc_out_bbox_embed.layers.0.bias",
    "model.transformer.enc_out_bbox_embed.layers.0.weight",
    "model.transformer.enc_out_bbox_embed.layers.1.bias",
    "model.transformer.enc_out_bbox_embed.layers.1.weight",
    "model.transformer.enc_out_bbox_embed.layers.2.bias",
    "model.transformer.enc_out_bbox_embed.layers.2.weight",
    "model.transformer.enc_out_class_embed.bias",
    "model.transformer.enc_out_class_embed.weight",
    "model.transformer.encoder.layers.0.fc1.bias",
    "model.transformer.encoder.layers.0.fc1.weight",
    "model.transformer.encoder.layers.0.fc2.bias",
    "model.transformer.encoder.layers.0.fc2.weight",
    "model.transformer.encoder.layers.0.final_layer_norm.bias",
    "model.transformer.encoder.layers.0.final_layer_norm.weight",
    "model.transformer.encoder.layers.0.self_attn.attention_weights.bias",
    "model.transformer.encoder.layers.0.self_attn.attention_weights.weight",
    "model.transformer.encoder.layers.0.self_attn.output_proj.bias",
    "model.transformer.encoder.layers.0.self_attn.output_proj.weight",
    "model.transformer.encoder.layers.0.self_attn.sampling_offsets.bias",
    "model.transformer.encoder.layers.0.self_attn.sampling_offsets.weight",
    "model.transformer.encoder.layers.0.self_attn.value_proj.bias",
    "model.transformer.encoder.layers.0.self_attn.value_proj.weight",
    "model.transformer.encoder.layers.0.self_attn_layer_norm.bias",
    "model.transformer.encoder.layers.0.self_attn_layer_norm.weight",
    "model.transformer.encoder.layers.1.fc1.bias",
    "model.transformer.encoder.layers.1.fc1.weight",
    "model.transformer.encoder.layers.1.fc2.bias",
    "model.transformer.encoder.layers.1.fc2.weight",
    "model.transformer.encoder.layers.1.final_layer_norm.bias",
    "model.transformer.encoder.layers.1.final_layer_norm.weight",
    "model.transformer.encoder.layers.1.self_attn.attention_weights.bias",
    "model.transformer.encoder.layers.1.self_attn.attention_weights.weight",
    "model.transformer.encoder.layers.1.self_attn.output_proj.bias",
    "model.transformer.encoder.layers.1.self_attn.output_proj.weight",
    "model.transformer.encoder.layers.1.self_attn.sampling_offsets.bias",
    "model.transformer.encoder.layers.1.self_attn.sampling_offsets.weight",
    "model.transformer.encoder.layers.1.self_attn.value_proj.bias",
    "model.transformer.encoder.layers.1.self_attn.value_proj.weight",
    "model.transformer.encoder.layers.1.self_attn_layer_norm.bias",
    "model.transformer.encoder.layers.1.self_attn_layer_norm.weight",
    "model.transformer.encoder.layers.2.fc1.bias",
    "model.transformer.encoder.layers.2.fc1.weight",
    "model.transformer.encoder.layers.2.fc2.bias",
    "model.transformer.encoder.layers.2.fc2.weight",
    "model.transformer.encoder.layers.2.final_layer_norm.bias",
    "model.transformer.encoder.layers.2.final_layer_norm.weight",
    "model.transformer.encoder.layers.2.self_attn.attention_weights.bias",
    "model.transformer.encoder.layers.2.self_attn.attention_weights.weight",
    "model.transformer.encoder.layers.2.self_attn.output_proj.bias",
    "model.transformer.encoder.layers.2.self_attn.output_proj.weight",
    "model.transformer.encoder.layers.2.self_attn.sampling_offsets.bias",
    "model.transformer.encoder.layers.2.self_attn.sampling_offsets.weight",
    "model.transformer.encoder.layers.2.self_attn.value_proj.bias",
    "model.transformer.encoder.layers.2.self_attn.value_proj.weight",
    "model.transformer.encoder.layers.2.self_attn_layer_norm.bias",
    "model.transformer.encoder.layers.2.self_attn_layer_norm.weight",
    "model.transformer.encoder.layers.3.fc1.bias",
    "model.transformer.encoder.layers.3.fc1.weight",
    "model.transformer.encoder.layers.3.fc2.bias",
    "model.transformer.encoder.layers.3.fc2.weight",
    "model.transformer.encoder.layers.3.final_layer_norm.bias",
    "model.transformer.encoder.layers.3.final_layer_norm.weight",
    "model.transformer.encoder.layers.3.self_attn.attention_weights.bias",
    "model.transformer.encoder.layers.3.self_attn.attention_weights.weight",
    "model.transformer.encoder.layers.3.self_attn.output_proj.bias",
    "model.transformer.encoder.layers.3.self_attn.output_proj.weight",
    "model.transformer.encoder.layers.3.self_attn.sampling_offsets.bias",
    "model.transformer.encoder.layers.3.self_attn.sampling_offsets.weight",
    "model.transformer.encoder.layers.3.self_attn.value_proj.bias",
    "model.transformer.encoder.layers.3.self_attn.value_proj.weight",
    "model.transformer.encoder.layers.3.self_attn_layer_norm.bias",
    "model.transformer.encoder.layers.3.self_attn_layer_norm.weight",
    "model.transformer.encoder.layers.4.fc1.bias",
    "model.transformer.encoder.layers.4.fc1.weight",
    "model.transformer.encoder.layers.4.fc2.bias",
    "model.transformer.encoder.layers.4.fc2.weight",
    "model.transformer.encoder.layers.4.final_layer_norm.bias",
    "model.transformer.encoder.layers.4.final_layer_norm.weight",
    "model.transformer.encoder.layers.4.self_attn.attention_weights.bias",
    "model.transformer.encoder.layers.4.self_attn.attention_weights.weight",
    "model.transformer.encoder.layers.4.self_attn.output_proj.bias",
    "model.transformer.encoder.layers.4.self_attn.output_proj.weight",
    "model.transformer.encoder.layers.4.self_attn.sampling_offsets.bias",
    "model.transformer.encoder.layers.4.self_attn.sampling_offsets.weight",
    "model.transformer.encoder.layers.4.self_attn.value_proj.bias",
    "model.transformer.encoder.layers.4.self_attn.value_proj.weight",
    "model.transformer.encoder.layers.4.self_attn_layer_norm.bias",
    "model.transformer.encoder.layers.4.self_attn_layer_norm.weight",
    "model.transformer.encoder.layers.5.fc1.bias",
    "model.transformer.encoder.layers.5.fc1.weight",
    "model.transformer.encoder.layers.5.fc2.bias",
    "model.transformer.encoder.layers.5.fc2.weight",
    "model.transformer.encoder.layers.5.final_layer_norm.bias",
    "model.transformer.encoder.layers.5.final_layer_norm.weight",
    "model.transformer.encoder.layers.5.self_attn.attention_weights.bias",
    "model.transformer.encoder.layers.5.self_attn.attention_weights.weight",
    "model.transformer.encoder.layers.5.self_attn.output_proj.bias",
    "model.transformer.encoder.layers.5.self_attn.output_proj.weight",
    "model.transformer.encoder.layers.5.self_attn.sampling_offsets.bias",
    "model.transformer.encoder.layers.5.self_attn.sampling_offsets.weight",
    "model.transformer.encoder.layers.5.self_attn.value_proj.bias",
    "model.transformer.encoder.layers.5.self_attn.value_proj.weight",
    "model.transformer.encoder.layers.5.self_attn_layer_norm.bias",
    "model.transformer.encoder.layers.5.self_attn_layer_norm.weight",
    "model.transformer.level_embed",
    "model.transformer.tgt_embed.weight",
    "model.transformer.two_stage_wh_embedding.weight",
]

class_embed_list_weight = [
    "model.transformer.decoder.class_embed.1.weight",
    "model.transformer.decoder.class_embed.2.weight",
    "model.transformer.decoder.class_embed.3.weight",
    "model.transformer.decoder.class_embed.4.weight",
    "model.transformer.decoder.class_embed.5.weight",
]
class_embed_list_bias = [
    "model.transformer.decoder.class_embed.1.bias",
    "model.transformer.decoder.class_embed.2.bias",
    "model.transformer.decoder.class_embed.3.bias",
    "model.transformer.decoder.class_embed.4.bias",
    "model.transformer.decoder.class_embed.5.bias",
]


bbox_embed_list_weight = [
    (
        f"model.transformer.decoder.bbox_embed.{i}.layers.{j}.weight",
        f"model.transformer.decoder.bbox_embed.0.layers.{j}.weight",
    )
    for i in range(0, 6)
    for j in range(0, 3)
]

bbox_embed_list_bias = [
    (
        f"model.transformer.decoder.bbox_embed.{i}.layers.{j}.bias",
        f"model.transformer.decoder.bbox_embed.0.layers.{j}.bias",
    )
    for i in range(0, 6)
    for j in range(0, 3)
]


def rename_key(orig_key):
    if "backbone.0.body" in orig_key:
        orig_key = orig_key.replace("backbone.0.body", "backbone.conv_encoder.model")
    if "encoder" in orig_key:
        if "norm1" in orig_key:
            orig_key = orig_key.replace("norm1", "self_attn_layer_norm")
        if "norm2" in orig_key:
            orig_key = orig_key.replace("norm2", "final_layer_norm")
        if "norm3" in orig_key:
            orig_key = orig_key.replace("norm3", "final_layer_norm")
        if "linear1" in orig_key:
            orig_key = orig_key.replace("linear1", "fc1")
        if "linear2" in orig_key:
            orig_key = orig_key.replace("linear2", "fc2")

    return orig_key


@torch.no_grad()
def convert_dino_detr_checkpoint(
    checkpoint_path,
    pytorch_dump_folder_path,
    push_to_hub,
):
    """
    Copy/paste/tweak model's weights to our Deformable DETR structure.
    """

    # load default config
    config = DinoDetrConfig()
    # set labels
    config.num_labels = 91
    repo_id = "huggingface/label-files"
    filename = "coco-detection-id2label.json"
    id2label = json.loads(Path(hf_hub_download(repo_id, filename, repo_type="dataset")).read_text())
    id2label = {int(k): v for k, v in id2label.items()}
    config.id2label = id2label
    config.label2id = {v: k for k, v in id2label.items()}

    # load original state dict
    state_dict = torch.load(checkpoint_path, map_location="cpu", weights_only=False)["model"]
    # rename keys
    for key in state_dict.copy().keys():
        val = state_dict.pop(key)
        state_dict[rename_key(key)] = val

    prefix = "model."
    for key in state_dict.copy().keys():
        if not key.startswith("class_embed") and not key.startswith("bbox_embed"):
            val = state_dict.pop(key)
            state_dict[prefix + key] = val

    for key in state_dict.copy().keys():
        if key not in layers:
            val = state_dict.pop(key)

    for tgt, src in bbox_embed_list_weight:
        state_dict[tgt] = state_dict[src]
    # for tgt, src in bbox_embed_list_weight:
    #    if src in state_dict:
    #        val = state_dict.pop(src)

    for tgt, src in bbox_embed_list_bias:
        state_dict[tgt] = state_dict[src]
    # for tgt, src in bbox_embed_list_bias:
    #    if src in state_dict:
    #        val = state_dict.pop(src)

    val = state_dict["model.transformer.decoder.class_embed.0.weight"]
    for key in class_embed_list_weight:
        state_dict[key] = val

    val = state_dict["model.transformer.decoder.class_embed.0.bias"]
    for key in class_embed_list_bias:
        state_dict[key] = val

    # state_dict["model.transformer.two_stage_wh_embedding.weight"] = torch.empty((1, 2))

    url = "http://images.cocodataset.org/val2017/000000039769.jpg"
    image = Image.open(requests.get(url, stream=True).raw)

    processor = DinoDetrImageProcessor()
    model = DinoDetrForObjectDetection(config)
    model.load_state_dict(state_dict)
    model.eval()

    inputs = processor(images=image, return_tensors="pt")
    outputs = model(**inputs)

    # convert outputs (bounding boxes and class logits) to COCO API
    # let's only keep detections with score > 0.9
    target_sizes = torch.tensor([image.size[::-1]])
    results = processor.post_process_object_detection(
        outputs, target_sizes=target_sizes, nms_iou_threshold=10, conf_threshold=0
    )[0]

    """
        [
            0.7476,
            0.7341,
            0.7231,
            0.4700,
            0.4449,
            0.3087,
            0.1926,
            0.1795,
            0.1335,
            0.1254,
            0.1113,
            0.1111,
            0.1110,
            0.1097,
            0.1038,
            0.1034,
            0.1015,
            0.0964,
            0.0962,
            0.0921,
            0.0877,
            0.0822,
            0.0776,
            0.0768,
            0.0762,
            0.0756,
            0.0749,
            0.0728,
            0.0707,
            0.0692,
            0.0659,
            0.0652,
            0.0626,
            0.0613,
            0.0609,
            0.0603,
            0.0600,
            0.0591,
            0.0591,
            0.0568,
            0.0566,
            0.0564,
            0.0559,
            0.0559,
            0.0559,
            0.0546,
            0.0541,
            0.0538,
            0.0537,
            0.0535,
            0.0519,
            0.0518,
            0.0504,
            0.0490,
            0.0486,
            0.0479,
            0.0477,
            0.0466,
            0.0465,
            0.0465,
            0.0463,
            0.0462,
            0.0459,
            0.0456,
            0.0453,
            0.0451,
            0.0450,
            0.0450,
            0.0449,
            0.0448,
            0.0447,
            0.0445,
            0.0441,
            0.0440,
            0.0431,
            0.0429,
            0.0427,
            0.0425,
            0.0424,
            0.0423,
            0.0416,
            0.0407,
            0.0398,
            0.0389,
            0.0388,
            0.0386,
            0.0385,
            0.0382,
            0.0378,
            0.0376,
            0.0375,
            0.0368,
            0.0360,
            0.0356,
            0.0354,
            0.0353,
            0.0353,
            0.0352,
            0.0347,
            0.0341,
            0.0337,
            0.0336,
            0.0336,
            0.0333,
            0.0332,
            0.0332,
            0.0332,
            0.0331,
            0.0329,
            0.0326,
            0.0324,
            0.0324,
            0.0324,
            0.0324,
            0.0323,
            0.0320,
            0.0318,
            0.0318,
            0.0317,
            0.0316,
            0.0315,
            0.0314,
            0.0312,
            0.0312,
            0.0310,
            0.0307,
            0.0307,
            0.0304,
            0.0303,
            0.0303,
            0.0302,
            0.0301,
            0.0298,
            0.0297,
            0.0295,
            0.0295,
            0.0293,
            0.0292,
            0.0292,
            0.0290,
            0.0290,
            0.0289,
            0.0289,
            0.0289,
            0.0288,
            0.0288,
            0.0286,
            0.0286,
            0.0286,
            0.0283,
            0.0282,
            0.0280,
            0.0279,
            0.0279,
            0.0278,
            0.0278,
            0.0277,
            0.0277,
            0.0277,
            0.0277,
            0.0276,
            0.0276,
            0.0275,
            0.0274,
            0.0274,
            0.0270,
            0.0269,
            0.0269,
            0.0268,
            0.0268,
            0.0267,
            0.0264,
            0.0263,
            0.0262,
            0.0259,
            0.0257,
            0.0254,
            0.0254,
            0.0252,
            0.0252,
            0.0251,
            0.0251,
            0.0250,
            0.0250,
            0.0250,
            0.0249,
            0.0246,
            0.0246,
            0.0245,
            0.0244,
            0.0244,
            0.0243,
            0.0242,
            0.0241,
            0.0240,
            0.0239,
            0.0237,
            0.0237,
            0.0237,
            0.0236,
            0.0236,
            0.0236,
            0.0235,
            0.0234,
            0.0234,
            0.0233,
            0.0233,
            0.0231,
            0.0231,
            0.0231,
            0.0231,
            0.0230,
            0.0230,
            0.0229,
            0.0229,
            0.0228,
            0.0228,
            0.0228,
            0.0227,
            0.0227,
            0.0225,
            0.0225,
            0.0224,
            0.0223,
            0.0221,
            0.0220,
            0.0220,
            0.0219,
            0.0219,
            0.0219,
            0.0219,
            0.0218,
            0.0218,
            0.0218,
            0.0218,
            0.0218,
            0.0218,
            0.0218,
            0.0217,
            0.0216,
            0.0216,
            0.0215,
            0.0215,
            0.0214,
            0.0214,
            0.0214,
            0.0214,
            0.0214,
            0.0213,
            0.0213,
            0.0213,
            0.0212,
            0.0211,
            0.0211,
            0.0210,
            0.0210,
            0.0210,
            0.0209,
            0.0209,
            0.0208,
            0.0208,
            0.0207,
            0.0206,
            0.0206,
            0.0206,
            0.0206,
            0.0206,
            0.0206,
            0.0205,
            0.0204,
            0.0204,
            0.0204,
            0.0204,
            0.0204,
            0.0204,
            0.0204,
            0.0203,
            0.0203,
            0.0202,
            0.0202,
            0.0200,
            0.0200,
            0.0199,
            0.0199,
            0.0198,
            0.0198,
            0.0197,
            0.0197,
            0.0197,
            0.0196,
            0.0194,
            0.0194,
            0.0194,
            0.0193,
            0.0193,
            0.0193,
            0.0193,
            0.0192,
            0.0192,
            0.0192,
        ]
        """
    expected_scores = torch.tensor(
        [
            0.7475,
            0.7341,
            0.7229,
            0.4707,
            0.4449,
            0.3086,
            0.1927,
            0.1794,
            0.1334,
            0.1251,
            0.1113,
            0.1111,
            0.1110,
            0.1097,
            0.1039,
            0.1038,
            0.1015,
            0.0963,
            0.0962,
            0.0921,
            0.0877,
            0.0823,
            0.0776,
            0.0768,
            0.0763,
            0.0755,
            0.0749,
            0.0729,
            0.0707,
            0.0693,
            0.0659,
            0.0653,
            0.0626,
            0.0613,
            0.0609,
            0.0604,
            0.0601,
            0.0592,
            0.0591,
            0.0568,
            0.0566,
            0.0564,
            0.0560,
            0.0559,
            0.0558,
            0.0546,
            0.0538,
            0.0538,
            0.0535,
            0.0529,
            0.0519,
            0.0518,
            0.0504,
            0.0489,
            0.0486,
            0.0479,
            0.0476,
            0.0466,
            0.0465,
            0.0465,
            0.0462,
            0.0462,
            0.0458,
            0.0456,
            0.0453,
            0.0451,
            0.0450,
            0.0450,
            0.0450,
            0.0448,
            0.0447,
            0.0445,
            0.0441,
            0.0440,
            0.0431,
            0.0429,
            0.0428,
            0.0425,
            0.0424,
            0.0423,
            0.0416,
            0.0407,
            0.0398,
            0.0388,
            0.0388,
            0.0386,
            0.0386,
            0.0383,
            0.0379,
            0.0376,
            0.0374,
            0.0368,
            0.0361,
            0.0355,
            0.0354,
            0.0353,
            0.0352,
            0.0352,
            0.0347,
            0.0341,
            0.0336,
            0.0336,
            0.0336,
            0.0333,
            0.0332,
            0.0332,
            0.0332,
            0.0331,
            0.0329,
            0.0325,
            0.0324,
            0.0324,
            0.0324,
            0.0323,
            0.0323,
            0.0320,
            0.0318,
            0.0317,
            0.0317,
            0.0317,
            0.0315,
            0.0314,
            0.0312,
            0.0312,
            0.0310,
            0.0308,
            0.0307,
            0.0304,
            0.0303,
            0.0302,
            0.0302,
            0.0302,
            0.0298,
            0.0297,
            0.0295,
            0.0295,
            0.0293,
            0.0292,
            0.0292,
            0.0290,
            0.0290,
            0.0290,
            0.0289,
            0.0289,
            0.0288,
            0.0288,
            0.0286,
            0.0286,
            0.0286,
            0.0283,
            0.0282,
            0.0280,
            0.0279,
            0.0279,
            0.0278,
            0.0278,
            0.0278,
            0.0277,
            0.0277,
            0.0277,
            0.0276,
            0.0276,
            0.0275,
            0.0275,
            0.0274,
            0.0270,
            0.0270,
            0.0269,
            0.0268,
            0.0268,
            0.0267,
            0.0264,
            0.0263,
            0.0262,
            0.0259,
            0.0257,
            0.0254,
            0.0254,
            0.0252,
            0.0252,
            0.0251,
            0.0251,
            0.0250,
            0.0250,
            0.0250,
            0.0249,
            0.0247,
            0.0246,
            0.0245,
            0.0244,
            0.0244,
            0.0243,
            0.0242,
            0.0241,
            0.0240,
            0.0239,
            0.0238,
            0.0237,
            0.0237,
            0.0236,
            0.0236,
            0.0235,
            0.0235,
            0.0234,
            0.0234,
            0.0233,
            0.0233,
            0.0232,
            0.0231,
            0.0231,
            0.0231,
            0.0230,
            0.0229,
            0.0229,
            0.0228,
            0.0228,
            0.0228,
            0.0228,
            0.0227,
            0.0226,
            0.0225,
            0.0225,
            0.0224,
            0.0223,
            0.0221,
            0.0220,
            0.0220,
            0.0219,
            0.0219,
            0.0219,
            0.0219,
            0.0219,
            0.0218,
            0.0218,
            0.0218,
            0.0218,
            0.0218,
            0.0218,
            0.0217,
            0.0216,
            0.0216,
            0.0216,
            0.0215,
            0.0215,
            0.0214,
            0.0214,
            0.0214,
            0.0213,
            0.0213,
            0.0213,
            0.0212,
            0.0212,
            0.0211,
            0.0211,
            0.0210,
            0.0210,
            0.0209,
            0.0209,
            0.0209,
            0.0208,
            0.0208,
            0.0207,
            0.0207,
            0.0206,
            0.0206,
            0.0206,
            0.0206,
            0.0206,
            0.0205,
            0.0204,
            0.0204,
            0.0204,
            0.0204,
            0.0204,
            0.0203,
            0.0203,
            0.0203,
            0.0203,
            0.0202,
            0.0202,
            0.0200,
            0.0200,
            0.0199,
            0.0199,
            0.0198,
            0.0198,
            0.0197,
            0.0197,
            0.0197,
            0.0196,
            0.0194,
            0.0194,
            0.0194,
            0.0194,
            0.0193,
            0.0193,
            0.0193,
            0.0192,
            0.0192,
            0.0192,
        ]
    )

    print("Scores:", results["scores"])
    print("Expected Scores:", expected_scores)

    assert torch.allclose(results["scores"], expected_scores, atol=1e-4)

    print("Everything ok!")

    # Save model and image processor
    logger.info(f"Saving PyTorch model and image processor to {pytorch_dump_folder_path}...")
    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)
    model.save_pretrained(pytorch_dump_folder_path)
    processor.save_pretrained(pytorch_dump_folder_path)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--checkpoint_path",
        type=str,
        default="/home/niels/checkpoints/deformable_detr/r50_deformable_detr-checkpoint.pth",
        help="Path to Pytorch checkpoint (.pth file) you'd like to convert.",
    )
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default=None,
        type=str,
        required=True,
        help="Path to the folder to output PyTorch model.",
    )
    parser.add_argument(
        "--push_to_hub",
        action="store_true",
        help="Whether or not to push the converted model to the 🤗 hub.",
    )
    args = parser.parse_args()
    convert_dino_detr_checkpoint(
        args.checkpoint_path,
        args.pytorch_dump_folder_path,
        args.push_to_hub,
    )
