#                ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨
#           This file was automatically generated from src/transformers/models/minicpm_v_4/modular_minicpm_v_4.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_minicpm_v_4.py file directly. One of our CI enforces this.
#                ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨
# coding=utf-8
# Copyright 2025 The OpenBMB Team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ...configuration_utils import PretrainedConfig
from ...models.siglip.configuration_siglip import SiglipVisionConfig
from ...utils import logging
from ..llama.configuration_llama import LlamaConfig


logger = logging.get_logger(__name__)


class MiniCPMVisionConfig(SiglipVisionConfig):
    model_type = "minicpm_vision_encoder"

    def __init__(
        self,
        max_slice_nums=9,
        scale_resolution=448,
        drop_vision_last_layer=True,
        batch_vision_input=True,
        use_image_id=True,
        vision_batch_size=16,
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.max_slice_nums = max_slice_nums
        self.scale_resolution = scale_resolution
        self.drop_vision_last_layer = drop_vision_last_layer
        self.batch_vision_input = batch_vision_input
        self.use_image_id = use_image_id
        self.vision_batch_size = vision_batch_size


class MiniCPM_V_4Config(PretrainedConfig):
    model_type = "minicpm_v_4"
    is_composition = True

    def __init__(
        self,
        vision_config=None,
        text_config=None,
        query_num=64,
        use_cache=True,
        **kwargs,
    ):
        super().__init__(**kwargs)

        if vision_config is None:
            logger.info("vision_config is None, using default MiniCPMVisionConfig.")
            vision_config = {}

        if isinstance(vision_config, dict):
            self.vision_config = MiniCPMVisionConfig(**vision_config)
        else:
            self.vision_config = vision_config

        if text_config is None:
            logger.info("text_config is None, using default LlamaConfig.")
            text_config = {}

        if isinstance(text_config, dict):
            self.text_config = LlamaConfig(**text_config)
        else:
            self.text_config = text_config

        self.query_num = query_num

        self.text_config.use_cache = use_cache

        if getattr(self, "hidden_size", None) is None:
            self.hidden_size = self.text_config.hidden_size
        if getattr(self, "vocab_size", None) is None:
            self.vocab_size = self.text_config.vocab_size
        if getattr(self, "num_hidden_layers", None) is None:
            self.num_hidden_layers = self.text_config.num_hidden_layers
        if getattr(self, "num_attention_heads", None) is None:
            self.num_attention_heads = self.text_config.num_attention_heads
        if getattr(self, "num_key_value_heads", None) is None:
            self.num_key_value_heads = self.text_config.num_key_value_heads
        if getattr(self, "intermediate_size", None) is None:
            self.intermediate_size = self.text_config.intermediate_size

__all__ = ["MiniCPM_V_4Config"]
