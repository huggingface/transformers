#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
#           This file was automatically generated from src/transformers/models/uvdoc/modular_uvdoc.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_uvdoc.py file directly. One of our CI enforces this.
#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
from typing import Optional, Union

import torch
from torchvision.transforms.v2.functional import InterpolationMode

from ...feature_extraction_utils import BatchFeature
from ...image_processing_utils_fast import BaseImageProcessorFast
from ...image_utils import PILImageResampling
from ...utils.generic import TensorType


class UVDocImageProcessorFast(BaseImageProcessorFast):
    """
    Fast image processor for UVDoc models (PyTorch-optimized, inherits from `BaseImageProcessorFast`).
    Optimized for speed with torch tensor operations, skipping numpy conversions for low-latency inference.
    """

    resample = 2
    image_mean = [0, 0, 0]
    image_std = [1, 1, 1]
    size = {"height": 256, "width": 256}
    do_resize = True
    do_rescale = True
    do_normalize = True

    def __init__(self, **kwargs) -> None:
        """Initialize the fast UVDoc image processor (inherits class-level defaults)."""
        super().__init__(**kwargs)

    def _preprocess(
        self,
        images: list[torch.Tensor],
        size: Optional[list[dict[str, int]]],
        do_resize: bool,
        do_rescale: bool,
        rescale_factor: float,
        do_normalize: bool,
        image_mean: Optional[Union[float, list[float]]],
        image_std: Optional[Union[float, list[float]]],
        return_tensors: Optional[Union[str, TensorType]],
        interpolation: Optional[InterpolationMode] = None,
        resample: Optional[PILImageResampling] = None,
        **kwargs,
    ) -> BatchFeature:
        """
        Fast preprocessing for UVDoc model (pure PyTorch tensor operations).
        Optimized for GPU inference with minimal data conversion overhead.

        Args:
            images (`List[torch.Tensor]`):
                List of input images (PyTorch tensors, [C, H, W] format).
            size (`List[Dict[str, int]]`, *optional*):
                Ignored (class-level size is used for fast processing).
            do_resize (`bool`):
                Whether to resize images (ignored in fast implementation).
            do_rescale (`bool`):
                Whether to rescale pixel values from 0-255 to 0-1.
            rescale_factor (`float`):
                Factor to scale pixel values by (1/255 for 0-255 â†’ 0-1).
            do_normalize (`bool`):
                Whether to normalize images with mean/std.
            image_mean (`Union[float, List[float]]`, *optional*):
                Override normalization mean (defaults to class-level image_mean).
            image_std (`Union[float, List[float]]`, *optional*):
                Override normalization std (defaults to class-level image_std).
            return_tensors (`Union[str, TensorType]`, *optional*):
                Type of tensors to return (only "pt" is supported for fast processing).
            interpolation (`InterpolationMode`, *optional*):
                Ignored (class-level resample is used).
            resample (`PILImageResampling`, *optional*):
                Ignored (class-level resample is used).

        Returns:
            `BatchFeature`: BatchFeature containing processed "pixel_values" (PyTorch tensor, [B, C, H, W]).
        """
        data = {}

        processed_images = []
        for image in images:
            image = self.rescale_and_normalize(image, do_rescale, rescale_factor, do_normalize, image_mean, image_std)
            processed_images.append(image)
        images = processed_images

        images = [image[[2, 1, 0], :, :] for image in images]
        data.update({"pixel_values": torch.stack(images, dim=0)})
        encoded_inputs = BatchFeature(data, tensor_type=return_tensors)

        return encoded_inputs

    def post_process_document_rectification(self, images, scale=None):
        """
        Fast postprocessing for UVDoc model outputs (pure PyTorch tensor operations).
        GPU-optimized conversion of model outputs to rectified document images (uint8).

        Args:
            images (`Union[torch.Tensor, Tuple[torch.Tensor, ...], List[torch.Tensor]]`):
                Raw model outputs (logits) to postprocess (batch of images, GPU tensors).
            scale (`Union[str, float, int]`, *optional*, defaults to 255.0):
                Scaling factor to convert normalized outputs back to 0-255 pixel values.

        Returns:
            `List[torch.Tensor]`: List of rectified document images (uint8, [H, W, C], RGB, same device as input).
        """
        if isinstance(scale, (str, float, int)):
            scale = torch.tensor(float(scale), device=images.device)
        else:
            scale = torch.tensor(255.0, device=images.device)

        return [self.doctr(img, scale) for img in images]

    def doctr(self, pred: Union[torch.Tensor, tuple[torch.Tensor, ...]], scale: torch.Tensor) -> torch.Tensor:
        """
        Core fast postprocessing logic for a single document image (pure PyTorch).
        Converts model output tensor to a valid RGB image (uint8, [H, W, C]) without CPU conversion.

        Args:
            pred (`Union[torch.Tensor, Tuple[torch.Tensor, ...]]`):
                Raw model output for a single image (or tuple containing the output, GPU tensor).
            scale (`torch.Tensor`):
                Scaling factor tensor (same device as input) to convert normalized values to 0-255.

        Returns:
            `torch.Tensor`: Rectified document image (uint8, [H, W, C], RGB, same device as input).

        Raises:
            AssertionError: If input is not a PyTorch tensor.
        """
        if isinstance(pred, tuple):
            im = pred[0]
        else:
            im = pred

        assert isinstance(im, torch.Tensor), "Invalid input 'im' in DocTrPostProcess. Expected a torch tensor."

        im = im.squeeze()
        im = im.permute(1, 2, 0)
        im = im * scale
        im = im.flip(dims=[-1])
        im = im.to(dtype=torch.uint8, non_blocking=True, copy=False)

        return im


__all__ = ["UVDocImageProcessorFast"]
