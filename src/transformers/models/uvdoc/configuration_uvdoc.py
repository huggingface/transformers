#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
#           This file was automatically generated from src/transformers/models/uvdoc/modular_uvdoc.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_uvdoc.py file directly. One of our CI enforces this.
#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨

from ...configuration_utils import PreTrainedConfig


class UVDocConfig(PreTrainedConfig):
    model_type = "uvdoc"

    """
    This is the configuration class to store the configuration of a [`UVDocModel`]. It is used to instantiate a
    UVDoc model according to the specified arguments, defining the model architecture for document rectification
    (correcting perspective distortion, tilt, and geometric deformation of document images).
    Instantiating a configuration with the defaults will yield a similar configuration to that of the UVDoc
    [PaddlePaddle/UVDoc](https://huggingface.co/PaddlePaddle/UVDoc) baseline architecture for document rectification tasks.
    Configuration objects inherit from [`PreTrainedConfig`] and can be used to control the model outputs. Read the
    documentation from [`PreTrainedConfig`] for more information.
    Args:
        num_filter (`int`, *optional*, defaults to 32):
            The number of convolutional filters (output channels) in the initial convolutional layers of the model,
            controlling the depth of feature maps extracted from input document images. Larger values increase
            model capacity but also computational cost.
        in_channels (`int`, *optional*, defaults to 3):
            The number of input channels of the model. Defaults to 3 for RGB document images; set to 1 for grayscale
            document images.
        kernel_size (`int`, *optional*, defaults to 5):
            The size of convolutional kernels used in the backbone network, typically an odd integer to ensure
            symmetric padding and preserve spatial dimensions of feature maps.
        stride (`List[int]`, *optional*, defaults to `[1, 2, 2, 2]`):
            The list of stride values for convolutional layers in the model, controlling the downsampling rate of
            feature maps at each stage. Stride=1 retains spatial resolution, while stride=2 halves the resolution
            to capture larger receptive fields.
        map_num (`List[int]`, *optional*, defaults to `[1, 2, 4, 8, 16]`):
            The scaling factors for feature map dimensions in multi-scale feature fusion modules, used to align
            feature maps of different resolutions for document structure restoration.
        block_nums (`List[int]`, *optional*, defaults to `[3, 4, 6, 3]`):
            The number of residual blocks in each stage of the model backbone, determining the depth of the network.
            More blocks enhance feature extraction capability but increase inference time.
        dilation_values (`Dict[str, Union[int, List[int]]]`, *optional*, defaults to `None`):
            A dictionary of dilation rates for dilated convolutional layers in bridge modules (e.g., "bridge_1": 1,
            "bridge_4": [8, 3, 2]). Dilated convolution expands the receptive field without increasing kernel size,
            critical for capturing long-range geometric dependencies in distorted documents. If `None`, default values
            will be used:{
                "bridge_1": 1,
                "bridge_2": 2,
                "bridge_3": 5,
                "bridge_4": [8, 3, 2],
                "bridge_5": [12, 7, 4],
                "bridge_6": [18, 12, 6]
            }
        padding_mode (`str`, *optional*, defaults to `"reflect"`):
        The padding mode for convolutional layers, used to handle boundary pixels of document images. Supported
        modes include `"reflect"` (recommended for document rectification to avoid edge artifacts), `"constant"`,
        and `"replicate"`.
        upsample_size (`List[int]`, *optional*, defaults to `[712, 488]`):
        The target spatial size (width, height) of the upsampled output image, matching the desired resolution
        of the rectified document. Adjust based on your input document size and task requirements.
        upsample_mode (`str`, *optional*, defaults to `"bilinear"`):
        The interpolation mode for upsampling layers to restore the original image resolution. Supported modes
        include `"bilinear"` (smooth upsampling, recommended for document images), `"nearest"`, and `"bicubic"`.
        Examples:
        ```python
        >>> from transformers import UVDocConfig, UVDocModelForImageToImage
        >>> # Initializing a UVDoc configuration
        >>> configuration = UVDocConfig()
        >>> # Customize configuration for grayscale document images
        >>> configuration = UVDocConfig(in_channels=1, upsample_size=[800, 600])
        >>> # Initializing a model (with random weights) from the configuration
        >>> model = UVDocModelForImageToImage(configuration)
        >>> # Accessing the model configuration
        >>> configuration = model.config
    """

    def __init__(
        self,
        num_filter: int = 32,
        in_channels: int = 3,
        kernel_size: int = 5,
        stride: list = [1, 2, 2, 2],
        map_num: list = [1, 2, 4, 8, 16],
        block_nums: list = [3, 4, 6, 3],
        dilation_values: dict | None = None,
        padding_mode: str = "reflect",
        upsample_size: list = [712, 488],
        upsample_mode: str = "bilinear",
        **kwargs,
    ):
        self.num_filter = num_filter
        self.in_channels = in_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.map_num = map_num
        self.block_nums = block_nums
        self.dilation_values = dilation_values
        self.padding_mode = padding_mode
        self.upsample_size = upsample_size
        self.upsample_mode = upsample_mode

        super().__init__(**kwargs)


__all__ = ["UVDocConfig"]
