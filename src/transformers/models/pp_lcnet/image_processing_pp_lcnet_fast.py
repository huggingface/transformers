#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
#           This file was automatically generated from src/transformers/models/pp_lcnet/modular_pp_lcnet.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_pp_lcnet.py file directly. One of our CI enforces this.
#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
import math
from typing import Optional, Union

import torch
from torchvision.transforms.v2.functional import InterpolationMode

from ...feature_extraction_utils import BatchFeature
from ...image_processing_utils_fast import BaseImageProcessorFast
from ...image_utils import PILImageResampling, SizeDict
from ...utils.generic import TensorType


class PPLCNetImageProcessorFast(BaseImageProcessorFast):
    """
    Fast image processor for PP-LCNet models (PyTorch-optimized, inherits from `BaseImageProcessorFast`).
    Optimized for speed with torch tensor operations, skipping numpy conversions for low-latency inference.
    """

    resample = 2
    image_mean = [0.406, 0.456, 0.485]
    image_std = [0.225, 0.224, 0.229]
    size = {"height": 256, "width": 256}
    do_resize = True
    do_rescale = True
    do_normalize = True
    do_center_crop = True
    crop_size = 224
    resize_short = None
    size_divisor = None

    def __init__(self, **kwargs) -> None:
        """
        Initialize the PPLCNetImageProcessorFast.

        Args:
            **kwargs: Additional keyword arguments passed to `BaseImageProcessorFast`.
        """
        super().__init__(**kwargs)

    def _preprocess(
        self,
        images: list[torch.Tensor],
        size: Optional[list[dict[str, int]]],
        do_resize: bool,
        do_center_crop: bool,
        crop_size: SizeDict,
        do_rescale: bool,
        rescale_factor: float,
        do_normalize: bool,
        image_mean: Optional[Union[float, list[float]]],
        image_std: Optional[Union[float, list[float]]],
        return_tensors: Optional[Union[str, TensorType]],
        interpolation: Optional[InterpolationMode] = None,
        resample: Optional[PILImageResampling] = None,
        **kwargs,
    ) -> BatchFeature:
        """
        Fast preprocessing pipeline for PyTorch tensors (optimized for low latency): resize â†’ center crop â†’ rescale â†’ normalize â†’ channel flip.

        Args:
            images (List[torch.Tensor]): List of input PyTorch tensors (shape [C, H, W]).
            size (Optional[List[Dict[str, int]]]): List of target sizes for each image (one per image). Defaults to None.
            do_resize (bool): Whether to resize the input images.
            do_center_crop (bool): Whether to perform center cropping after resizing.
            crop_size (SizeDict): Target size for center cropping ({"height": H, "width": W}).
            do_rescale (bool): Whether to rescale pixel values from [0, 255] to [0, 1].
            rescale_factor (float): Factor to rescale pixel values (1/255 for [0,255] â†’ [0,1]).
            do_normalize (bool): Whether to normalize pixel values with mean and std.
            image_mean (Optional[Union[float, List[float]]]): Mean values for image normalization (BGR order).
            image_std (Optional[Union[float, List[float]]]): Standard deviation values for image normalization (BGR order).
            return_tensors (Optional[Union[str, TensorType]]): Type of tensors to return (e.g., "pt" for PyTorch).
                Defaults to None (returns PyTorch tensors).
            interpolation (Optional[InterpolationMode]): TorchVision interpolation mode for resizing. Defaults to None.
            resample (Optional[PILImageResampling]): Unused (for compatibility with base class). Defaults to None.
            **kwargs: Additional unused keyword arguments (for compatibility).

        Returns:
            BatchFeature: Preprocessed image batch with key "pixel_values" containing the processed PyTorch tensors.
        """
        data = {}
        resize_imgs = []
        if do_resize:
            for image in images:
                if self.resize_short is not None:
                    size = self.get_image_size(
                        image, target_short_edge=self.resize_short, size_divisor=self.size_divisor
                    )

                img = self.resize(image, size=size, interpolation=interpolation)
                resize_imgs.append(img)
            images = resize_imgs

        crop_images = []
        if do_center_crop:
            for image in images:
                image = self.center_crop(image, crop_size)
                crop_images.append(image)
            images = crop_images

        processed_images = []
        for image in images:
            image = self.rescale_and_normalize(image, do_rescale, rescale_factor, do_normalize, image_mean, image_std)
            processed_images.append(image)
        images = processed_images

        images = [image[[2, 1, 0], :, :] for image in images]
        data.update({"pixel_values": torch.stack(images, dim=0)})
        encoded_inputs = BatchFeature(data, tensor_type=return_tensors)

        return encoded_inputs

    def get_image_size(
        self,
        img: torch.Tensor,
        target_short_edge: Union[int, None],
        size_divisor: Optional[int] = None,
    ) -> tuple[SizeDict, torch.Tensor]:
        """
        Calculate target image size for PyTorch tensors (preserve aspect ratio + align with size_divisor).

        Args:
            img (torch.Tensor): Input PyTorch tensor (shape [C, H, W]).
            target_short_edge (Union[int, None]): Desired length for the shorter edge of the image.
            size_divisor (Optional[int]): Divisor to align image dimensions (for hardware optimization). Defaults to None.

        Returns:
            SizeDict: Target size ({"height": resize_h, "width": resize_w}) with preserved aspect ratio.
        """
        c, h, w = img.shape
        scale = target_short_edge / min(h, w)
        resize_h = round(h * scale)
        resize_w = round(w * scale)
        if self.size_divisor is not None:
            resize_h = math.ceil(resize_h / size_divisor) * size_divisor
            resize_h = math.ceil(resize_h / size_divisor) * size_divisor

        return SizeDict(height=resize_h, width=resize_w)


__all__ = ["PPLCNetImageProcessorFast"]
