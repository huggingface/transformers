#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
#           This file was automatically generated from src/transformers/models/pp_lcnet/modular_pp_lcnet.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_pp_lcnet.py file directly. One of our CI enforces this.
#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
import math
from typing import Optional, Union

import numpy as np

from ...feature_extraction_utils import BatchFeature
from ...image_processing_utils import BaseImageProcessor
from ...image_transforms import flip_channel_order, resize, to_channel_dimension_format
from ...image_utils import (
    ChannelDimension,
    ImageInput,
    PILImageResampling,
    infer_channel_dimension_format,
    make_flat_list_of_images,
    to_numpy_array,
    valid_images,
    validate_preprocess_arguments,
)
from ...utils import filter_out_non_signature_kwargs
from ...utils.generic import TensorType


class PPLCNetImageProcessor(BaseImageProcessor):
    """
    Image processor for PP-LCNet models, handling all preprocessing steps required for image classification:
    resizing, center cropping, rescaling, normalization, and channel order flipping (RGB â†’ BGR).
    Inherits from Hugging Face `BaseImageProcessor` and follows the standard preprocessing pipeline for lightweight
    CNN models in document/image classification tasks.
    """

    model_input_names = ["pixel_values"]

    def __init__(
        self,
        resize_short: Optional[int] = None,
        size_divisor: Optional[int] = None,
        do_resize: bool = True,
        size: Optional[dict[str, int]] = None,
        resample: Optional[PILImageResampling] = PILImageResampling.BICUBIC,
        do_center_crop: bool = True,
        crop_size: int = 224,
        do_rescale: bool = True,
        rescale_factor: Union[int, float] = 1 / 255,
        do_normalize: bool = True,
        image_mean: Optional[Union[float, list[float]]] = [0.406, 0.456, 0.485],
        image_std: Optional[Union[float, list[float]]] = [0.225, 0.224, 0.229],
        **kwargs,
    ) -> None:
        """
        Initialize the PPLCNetImageProcessor with preprocessing configuration.

        Args:
            resize_short (Optional[int]): Target length for the shorter edge of the image (overrides `size` if set).
                Defaults to None.
            size_divisor (Optional[int]): Divisor to align image dimensions (for hardware optimization, e.g., 32).
                Defaults to None.
            do_resize (bool): Whether to resize the input image. Defaults to True.
            size (Optional[Dict[str, int]]): Target size for resizing ({"height": H, "width": W}). Defaults to
                {"height": 256, "width": 256} if None.
            resample (Optional[PILImageResampling]): PIL resampling mode for resizing. Defaults to BICUBIC (high quality).
            do_center_crop (bool): Whether to perform center cropping after resizing. Defaults to True.
            crop_size (int): Target size for center cropping (square crop, H=Crop_size, W=Crop_size). Defaults to 224.
            do_rescale (bool): Whether to rescale pixel values from [0, 255] to [0, 1]. Defaults to True.
            rescale_factor (Union[int, float]): Factor to rescale pixel values (1/255 for [0,255] â†’ [0,1]). Defaults to 1/255.
            do_normalize (bool): Whether to normalize pixel values with mean and std. Defaults to True.
            image_mean (Optional[Union[float, List[float]]]): Mean values for image normalization (BGR order, matching PP-LCNet defaults).
                Defaults to [0.406, 0.456, 0.485].
            image_std (Optional[Union[float, List[float]]]): Standard deviation values for image normalization (BGR order, matching PP-LCNet defaults).
                Defaults to [0.225, 0.224, 0.229].
            **kwargs: Additional keyword arguments passed to `BaseImageProcessor`.
        """
        super().__init__(**kwargs)
        size = size if size is not None else {"height": 256, "width": 256}

        self.resize_short = resize_short
        self.size_divisor = size_divisor

        self.do_resize = do_resize
        self.size = size
        self.do_center_crop = do_center_crop
        self.crop_size = crop_size
        self.do_rescale = do_rescale
        self.rescale_factor = rescale_factor
        self.do_normalize = do_normalize
        self.image_mean = image_mean
        self.image_std = image_std
        self.resample = resample

    @filter_out_non_signature_kwargs()
    def preprocess(
        self,
        images: ImageInput,
        resize_short: Optional[int] = None,
        size_divisor: Optional[int] = None,
        size: Optional[dict[str, int]] = None,
        do_resize: Optional[bool] = None,
        resample: Optional[PILImageResampling] = None,
        do_rescale: Optional[bool] = None,
        rescale_factor: Optional[Union[int, float]] = None,
        do_center_crop: Optional[bool] = None,
        crop_size: int = 224,
        do_normalize: Optional[bool] = None,
        image_mean: Optional[Union[float, list[float]]] = None,
        image_std: Optional[Union[float, list[float]]] = None,
        return_tensors: Optional[Union[TensorType, str]] = None,
        data_format: Union[str, ChannelDimension] = ChannelDimension.FIRST,
        input_data_format: Optional[Union[str, ChannelDimension]] = None,
    ) -> BatchFeature:
        """
        Main preprocessing pipeline for input images: applies resize â†’ center crop â†’ rescale â†’ normalize â†’ channel flip.

        Args:
            images (ImageInput): Input images to preprocess (single image or list of images; supports PIL, numpy, or torch tensor).
            resize_short (Optional[int]): Override for the class-level `resize_short`. Defaults to None.
            size_divisor (Optional[int]): Override for the class-level `size_divisor`. Defaults to None.
            size (Optional[Dict[str, int]]): Override for the class-level `size`. Defaults to None.
            do_resize (Optional[bool]): Override for the class-level `do_resize`. Defaults to None.
            resample (Optional[PILImageResampling]): Override for the class-level `resample`. Defaults to None.
            do_rescale (Optional[bool]): Override for the class-level `do_rescale`. Defaults to None.
            rescale_factor (Optional[Union[int, float]]): Override for the class-level `rescale_factor`. Defaults to None.
            do_center_crop (Optional[bool]): Override for the class-level `do_center_crop`. Defaults to None.
            crop_size (int): Override for the class-level `crop_size` (only if `do_center_crop` is True). Defaults to 224.
            do_normalize (Optional[bool]): Override for the class-level `do_normalize`. Defaults to None.
            image_mean (Optional[Union[float, List[float]]]): Override for the class-level `image_mean`. Defaults to None.
            image_std (Optional[Union[float, List[float]]]): Override for the class-level `image_std`. Defaults to None.
            return_tensors (Optional[Union[TensorType, str]]): Type of tensors to return (e.g., "pt" for PyTorch, "np" for numpy).
                Defaults to None (returns raw numpy arrays).
            data_format (Union[str, ChannelDimension]): Output channel dimension format (FIRST = [C, H, W], LAST = [H, W, C]).
                Defaults to ChannelDimension.FIRST (compatible with PyTorch).
            input_data_format (Optional[Union[str, ChannelDimension]]): Channel dimension format of the input images.
                Defaults to None (auto-infer from input).

        Returns:
            BatchFeature: Preprocessed image batch with key "pixel_values" containing the processed tensors/arrays.

        Raises:
            ValueError: If input images are of an invalid type (not PIL, numpy array, or torch tensor).
            RuntimeError: If resizing fails for any input image.
        """
        size = self.size if size is None else size
        resize_short = self.resize_short if resize_short is None else resize_short
        size_divisor = self.size_divisor if size_divisor is None else size_divisor
        do_resize = self.do_resize if do_resize is None else do_resize
        resample = self.resample if resample is None else resample
        do_center_crop = self.do_center_crop if do_center_crop is None else do_center_crop
        crop_size = self.crop_size if crop_size is None else crop_size
        do_rescale = self.do_rescale if do_rescale is None else do_rescale
        rescale_factor = self.rescale_factor if rescale_factor is None else rescale_factor
        do_normalize = self.do_normalize if do_normalize is None else do_normalize
        image_mean = self.image_mean if image_mean is None else image_mean
        image_std = self.image_std if image_std is None else image_std

        images = make_flat_list_of_images(images)

        validate_preprocess_arguments(
            do_rescale=do_rescale,
            rescale_factor=rescale_factor,
            do_normalize=do_normalize,
            image_mean=image_mean,
            image_std=image_std,
            size=size,
            do_resize=do_resize,
            resample=resample,
            do_center_crop=do_center_crop,
            crop_size=crop_size,
        )

        if not valid_images(images):
            raise ValueError("Invalid image type. Must be of type PIL.Image.Image, numpy.ndarray, or torch.Tensor")

        # All transformations expect numpy arrays
        images = [to_numpy_array(image) for image in images]

        if input_data_format is None:
            input_data_format = infer_channel_dimension_format(images[0])

        # transformations
        resize_imgs = []
        if do_resize:
            for image in images:
                if resize_short is not None:
                    size = self.get_image_size(image, target_short_edge=resize_short, size_divisor=size_divisor)
                try:
                    img = resize(
                        image,
                        size=(size["height"], size["width"]),
                        resample=resample,
                        input_data_format=input_data_format,
                    )
                except Exception as e:
                    print(size)
                    raise RuntimeError(f"Failed to resize image: {e}") from e
                resize_imgs.append(img)
            images = resize_imgs

        if do_center_crop:
            images = [
                self.center_crop(image=image, size=crop_size, input_data_format=input_data_format) for image in images
            ]

        if do_rescale:
            images = [self.rescale(image, rescale_factor, input_data_format=input_data_format) for image in images]

        if do_normalize:
            images = [
                self.normalize(image, image_mean, image_std, input_data_format=input_data_format) for image in images
            ]
        # flip color channels from RGB to BGR
        images = [flip_channel_order(image, input_data_format=input_data_format) for image in images]
        images = [
            to_channel_dimension_format(image, data_format, input_channel_dim=input_data_format) for image in images
        ]

        encoded_inputs = BatchFeature(data={"pixel_values": images}, tensor_type=return_tensors)

        return encoded_inputs

    def get_image_size(
        self,
        img: np.ndarray,
        target_short_edge: Union[int, None],
        size_divisor: Optional[int] = None,
    ) -> tuple[dict, np.ndarray]:
        """
        Calculate target image size while preserving aspect ratio (based on shorter edge) and aligning with size_divisor.

        Args:
            img (np.ndarray): Input image array (shape [H, W, C] or [C, H, W]).
            target_short_edge (Union[int, None]): Desired length for the shorter edge of the image.
            size_divisor (Optional[int]): Divisor to align image dimensions (for hardware optimization). Defaults to None.

        Returns:
            Dict[str, int]: Target size {"height": resize_h, "width": resize_w} with preserved aspect ratio.
        """
        h, w = img.shape[:2]
        scale = target_short_edge / min(h, w)
        resize_h = round(h * scale)
        resize_w = round(w * scale)
        if self.size_divisor is not None:
            resize_h = math.ceil(resize_h / size_divisor) * size_divisor
            resize_h = math.ceil(resize_h / size_divisor) * size_divisor

        return {"height": resize_h, "width": resize_w}


__all__ = ["PPLCNetImageProcessor"]
