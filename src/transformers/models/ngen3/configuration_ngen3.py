#!/usr/bin/env python3
# coding=utf-8
# --------------------------------------------------------------------------------
# This file was automatically generated from the NGEN3 modular configuration.
# Do NOT edit this file manually as any edits will be overwritten.
# --------------------------------------------------------------------------------
"""
Configuration file for the NGEN3 model.

This file defines the NGEN3Config class (a subclass of PretrainedConfig),
which supports options such as instruct mode, Mixture-of-Experts (MoE) and other
architectural hyperparameters.

The design and docstring style mirror that of the Gemma3 configuration files.
"""

from transformers.configuration_utils import PretrainedConfig

class NGEN3Config(PretrainedConfig):
    model_type = "ngen3"

    def __init__(
        self,
        vocab_size=50257,
        n_embd=768,
        n_layer=12,
        n_head=12,
        block_size=1024,
        dropout=0.1,
        instruct=False,
        use_moe=False,
        num_experts=4,
        grad_clip=1.0,
        grad_accum_steps=1,
        learning_rate=6e-4,
        weight_decay=0.1,
        max_iters=2000,
        log_interval=50,
        eval_interval=200,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.vocab_size = vocab_size
        self.n_embd = n_embd
        self.n_layer = n_layer
        self.n_head = n_head
        self.block_size = block_size
        self.dropout = dropout
        self.instruct = instruct
        self.use_moe = use_moe
        self.num_experts = num_experts
        self.grad_clip = grad_clip
        self.grad_accum_steps = grad_accum_steps
        self.learning_rate = learning_rate
        self.weight_decay = weight_decay
        self.max_iters = max_iters
        self.log_interval = log_interval
        self.eval_interval = eval_interval
