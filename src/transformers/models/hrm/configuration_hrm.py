#                ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨
#           This file was automatically generated from src/transformers/models/hrm/modular_hrm.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_hrm.py file directly. One of our CI enforces this.
#                ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨
# coding=utf-8
# Copyright 2025 The HRM Team and The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ...configuration_utils import PretrainedConfig


class HrmConfig(PretrainedConfig):
    r"""
    This is the configuration class to store the configuration of a [`HrmModel`]. It is used to instantiate a HRM
    model according to the specified arguments, defining the model architecture. Instantiating a configuration with the
    defaults will yield a similar configuration to that of the HRM base model.

    The Hierarchical Reasoning Model (HRM) is a novel recurrent neural network architecture for sequential reasoning
    tasks featuring:
    - Two-level hierarchical processing inspired by human cognition
    - High-level (H) module: Slow, abstract planning and reasoning
    - Low-level (L) module: Fast, detailed computations
    - Adaptive Computation Time (ACT) mechanism with Q-learning based halting

    This model was introduced in the paper "Hierarchical Reasoning Model" by Guan Wang, Jin Li, Yuhao Sun,
    Xing Chen, Changling Liu, Yue Wu, Meng Lu, Sen Song, and Yasin Abbasi Yadkori.
    For more details, see: https://arxiv.org/abs/2506.21734

    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the
    documentation from [`PretrainedConfig`] for more information.

    Args:
            vocab_size (`<fill_type>`, *optional*, defaults to 11): <fill_docstring>
            hidden_size (`<fill_type>`, *optional*, defaults to 512): <fill_docstring>
            num_hidden_layers (`<fill_type>`, *optional*, defaults to 4): <fill_docstring>
            h_layers (`<fill_type>`, *optional*): <fill_docstring>
            l_layers (`<fill_type>`, *optional*): <fill_docstring>
            num_attention_heads (`<fill_type>`, *optional*, defaults to 8): <fill_docstring>
            intermediate_size (`<fill_type>`, *optional*): <fill_docstring>
            expansion (`<fill_type>`, *optional*, defaults to 4.0): <fill_docstring>
            max_position_embeddings (`<fill_type>`, *optional*, defaults to 81): <fill_docstring>
            h_cycles (`<fill_type>`, *optional*, defaults to 2): <fill_docstring>
            l_cycles (`<fill_type>`, *optional*, defaults to 2): <fill_docstring>
            pos_encodings (`<fill_type>`, *optional*, defaults to `"rope"`): <fill_docstring>
            rope_theta (`<fill_type>`, *optional*, defaults to 10000.0): <fill_docstring>
            rms_norm_eps (`<fill_type>`, *optional*, defaults to 1e-05): <fill_docstring>
            puzzle_emb_ndim (`<fill_type>`, *optional*, defaults to 0): <fill_docstring>
            num_puzzle_identifiers (`<fill_type>`, *optional*, defaults to 1): <fill_docstring>
            halt_max_steps (`<fill_type>`, *optional*, defaults to 16): <fill_docstring>
            halt_exploration_prob (`<fill_type>`, *optional*, defaults to 0.1): <fill_docstring>
            dtype (`<fill_type>`, *optional*, defaults to `"bfloat16"`): <fill_docstring>
            initializer_range (`<fill_type>`, *optional*, defaults to 0.02): <fill_docstring>
            use_cache (`<fill_type>`, *optional*, defaults to `False`): <fill_docstring>

    Example:
    ```python
    >>> from transformers import HrmConfig, HrmModel

    >>> # Initializing a HRM configuration for Sudoku solving
    >>> configuration = HrmConfig(
    ...     vocab_size=11,  # 0-9 digits + padding
    ...     hidden_size=512,
    ...     num_hidden_layers=4,
    ...     max_position_embeddings=81,  # 9x9 grid
    ...     h_cycles=2,
    ...     l_cycles=2,
    ... )

    >>> # Initializing a model from the configuration
    >>> model = HrmModel(configuration)

    >>> # Accessing the model configuration
    >>> configuration = model.config
    ```
    """

    model_type = "hrm"

    def __init__(
        self,
        vocab_size=11,
        hidden_size=512,
        num_hidden_layers=4,
        h_layers=None,
        l_layers=None,
        num_attention_heads=8,
        intermediate_size=None,
        expansion=4.0,
        max_position_embeddings=81,
        h_cycles=2,
        l_cycles=2,
        pos_encodings="rope",
        rope_theta=10000.0,
        rms_norm_eps=1e-5,
        puzzle_emb_ndim=0,
        num_puzzle_identifiers=1,
        halt_max_steps=16,
        halt_exploration_prob=0.1,
        dtype="bfloat16",
        initializer_range=0.02,
        use_cache=False,
        **kwargs,
    ):
        self.vocab_size = vocab_size
        self.hidden_size = hidden_size
        self.num_hidden_layers = num_hidden_layers
        self.h_layers = h_layers if h_layers is not None else num_hidden_layers
        self.l_layers = l_layers if l_layers is not None else num_hidden_layers
        self.num_attention_heads = num_attention_heads
        self.expansion = expansion
        self.intermediate_size = intermediate_size if intermediate_size is not None else int(hidden_size * expansion)
        self.max_position_embeddings = max_position_embeddings
        self.h_cycles = h_cycles
        self.l_cycles = l_cycles
        self.pos_encodings = pos_encodings
        self.rope_theta = rope_theta
        self.rms_norm_eps = rms_norm_eps
        self.puzzle_emb_ndim = puzzle_emb_ndim
        self.num_puzzle_identifiers = num_puzzle_identifiers
        self.halt_max_steps = halt_max_steps
        self.halt_exploration_prob = halt_exploration_prob
        self.initializer_range = initializer_range
        self.use_cache = use_cache

        super().__init__(dtype=dtype, **kwargs)


__all__ = ["HrmConfig"]
