#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
#           This file was automatically generated from src/transformers/models/modernvbert/modular_modernvbert.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_modernvbert.py file directly. One of our CI enforces this.
#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
from typing import Any, Literal, Optional

from ...configuration_utils import PretrainedConfig
from ..modernbert import ModernBertConfig
from ..siglip import SiglipVisionConfig


class ModernVBertConfig(PretrainedConfig):
    r"""
    This is the configuration class to store the configuration of a `ModernVBert` model. It is used to
    instantiate a ModernVBert model according to the specified arguments and defines the model architecture.
    e.g. [ModernVBERT/modernvbert](https://huggingface.co/ModernVBERT/modernvbert).

    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs.
    See the documentation for [`PretrainedConfig`] for more details.

    Args:
            text_config ([`ModernBertConfig`], *optional*): [`ModernBertModel`] config to build the text encoder.
            vision_config ([`SiglipVisionConfig`], *optional*): [`SiglipVisionModel`] config to build the vision encoder.
            image_token_id (`Optional`, *optional*, defaults to 50407): The token id reserved for image tokens inserted into the text stream.
            pixel_shuffle_factor (`Optional`, *optional*, defaults to 4): Scale factor used by any pixel-shuffle / upsampling operations in the vision head.
            vocab_size (`Optional`, *optional*): Vocabulary size of the text model. Defines the number of different tokens that can be represented
                by the `inputs_ids` passed when calling [`ModernVBertModel`]. If not provided, will be taken from
                the `text_config`.
            hidden_size (`Optional`, *optional*): Dimensionality of the encoder layers and the pooler layer. If not provided, will be taken from
                the `text_config`.
            num_hidden_layers (`Optional`, *optional*): Number of hidden layers in the Transformer encoder. If not provided, will be taken from
                the `text_config`.
            initializer_range (`Optional`, *optional*, defaults to 0.02): The standard deviation of the truncated_normal_initializer for initializing all weight matrices.
            initializer_cutoff_factor (`Optional`, *optional*, defaults to 2.0): The cutoff factor for the truncated_normal_initializer for initializing all weight matrices.
            classifier_pooling (`Literal`, *optional*, defaults to `"cls"`): The pooling strategy to use for classification tasks. Can be either `"cls"` or `"mean"`.
            classifier_dropout (`Optional`, *optional*, defaults to 0.0): The dropout probability for the classification head.
            classifier_bias (`Optional`, *optional*, defaults to `False`): Whether to add a bias term to the classification head.

    Example:
    ```python
    >>> from modernvbert import ModernVBertConfig

    >>> # Initializing configuration
    >>> configuration = ModernVBertConfig()

    >>> # Initializing a model from the configuration (model class is implemented in
    >>> # `modernvbert.modeling_modernvbert`)

    >>> from modernvbert import ModernVBertModel
    >>> model = ModernVBertModel(configuration)

    >>> # Accessing the model configuration
    >>> cfg = model.config
    ```"""

    model_type = "modernvbert"
    sub_configs: dict[str, Any] = {"text_config": ModernBertConfig, "vision_config": SiglipVisionConfig}

    def __init__(
        self,
        text_config=None,
        vision_config=None,
        image_token_id: Optional[int] = 50407,
        pixel_shuffle_factor: Optional[int] = 4,
        initializer_range: Optional[float] = 0.02,
        initializer_cutoff_factor: Optional[float] = 2.0,
        classifier_pooling: Literal["cls", "mean"] = "cls",
        classifier_dropout: Optional[float] = 0.0,
        classifier_bias: Optional[bool] = False,
        vocab_size: Optional[int] = None,
        **kwargs,
    ):
        if classifier_pooling not in ["cls", "mean"]:
            raise ValueError(
                f'Invalid value for `classifier_pooling`, should be either "cls" or "mean", but is {classifier_pooling}.'
            )

        if text_config is None:
            text_config = self.sub_configs["text_config"]()
        elif isinstance(text_config, dict):
            text_config = self.sub_configs["text_config"](**text_config)
        self.text_config = text_config

        if vision_config is None:
            vision_config = self.sub_configs["vision_config"]()
        elif isinstance(vision_config, dict):
            vision_config = self.sub_configs["vision_config"](**vision_config)
        self.vision_config = vision_config

        self.pixel_shuffle_factor = pixel_shuffle_factor
        self.initializer_range = initializer_range
        self.initializer_cutoff_factor = initializer_cutoff_factor
        self.classifier_pooling = classifier_pooling
        self.classifier_dropout = classifier_dropout
        self.classifier_bias = classifier_bias

        if vocab_size is not None:
            self.text_config.vocab_size = vocab_size
        self.vocab_size = self.text_config.vocab_size

        super().__init__(image_token_id=image_token_id, **kwargs)


__all__ = ["ModernVBertConfig"]
