{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessor_config.json: 100%|██████████| 523/523 [00:00<00:00, 3.03MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import FastImageProcessor, FastForSceneTextRecognition, AutoConfig, AutoBackbone\n",
    "from transformers import TextNetConfig\n",
    "from transformers import TextNetBackbone\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://huggingface.co/datasets/Raghavan/fast_model_samples/resolve/main/img657.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "processor = FastImageProcessor.from_pretrained(\"jadechoghari/fast-tiny\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 4.83k/4.83k [00:00<00:00, 11.1MB/s]\n",
      "model.safetensors: 100%|█████████▉| 54.3M/54.3M [00:00<00:00, 87.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = FastForSceneTextRecognition.from_pretrained(\"jadechoghari/fast-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/app/transformers/src/transformers/models/fast/modeling_fast.py:294: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  return F.upsample(layer_out, size=(height, width), mode=\"bilinear\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(pixel_values=inputs[\"pixel_values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size (640, 864)\n"
     ]
    }
   ],
   "source": [
    "target_sizes = [image.size]\n",
    "target_sizes = [(300, 400)]\n",
    "threshold = 0.88\n",
    "text_locations = processor.post_process_text_detection(outputs, target_sizes, threshold, bbox_type=\"rect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(300, 400)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bboxes': [[151, 151, 160, 56, 355, 74, 346, 169],\n",
       "   [181, 205, 328, 192, 332, 249, 186, 261]],\n",
       "  'scores': [0.918617844581604, 0.9378566741943359]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "def generate_bbox(keys, label, score, scales, cfg):\n",
    "    label_num = len(keys)\n",
    "    bboxes = []\n",
    "    scores = []\n",
    "    for index in range(1, label_num):\n",
    "        i = keys[index]\n",
    "        ind = (label == i)\n",
    "        ind_np = ind.data.cpu().numpy()\n",
    "        points = np.array(np.where(ind_np)).transpose((1, 0))\n",
    "        if points.shape[0] < cfg.test_cfg.min_area:\n",
    "            label[ind] = 0\n",
    "            continue\n",
    "        score_i = score[ind].mean().item()\n",
    "        if score_i < cfg.test_cfg.min_score:\n",
    "            label[ind] = 0\n",
    "            continue\n",
    "\n",
    "        if cfg.test_cfg.bbox_type == 'rect':\n",
    "            rect = cv2.minAreaRect(points[:, ::-1])\n",
    "            alpha = math.sqrt(math.sqrt(points.shape[0] / (rect[1][0] * rect[1][1])))\n",
    "            rect = (rect[0], (rect[1][0] * alpha, rect[1][1] * alpha), rect[2])\n",
    "            bbox = cv2.boxPoints(rect) * scales\n",
    "\n",
    "        elif cfg.test_cfg.bbox_type == 'poly':\n",
    "            binary = np.zeros(label.shape, dtype='uint8')\n",
    "            binary[ind_np] = 1\n",
    "            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            bbox = contours[0] * scales\n",
    "        bbox = bbox.astype('int32')\n",
    "        bboxes.append(bbox.reshape(-1).tolist())\n",
    "        scores.append(score_i)\n",
    "    return bboxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bbox()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
