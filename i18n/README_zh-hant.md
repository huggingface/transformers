<!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <a href="https://github.com/huggingface/transformers/blob/main/README.md">English</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">ç®€ä½“ä¸­æ–‡</a> |
        <b>ç¹é«”ä¸­æ–‡</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">í•œêµ­ì–´</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">EspaÃ±ol</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">æ—¥æœ¬èª</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">PortuguÃªs</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">à°¤à±†à°²à±à°—à±</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">FranÃ§ais</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_it.md">Italiano</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiáº¿ng Viá»‡t</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">Ø§Ø±Ø¯Ùˆ</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_bn.md">à¦¬à¦¾à¦‚à¦²à¦¾</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/ReADME_id.md">Bahasa Indonesia</a> |
    </p>
</h4>

<h3 align="center">
    <p>æœ€å…ˆé€²çš„é è¨“ç·´æ¨¡å‹ï¼Œå°ˆç‚ºæ¨ç†èˆ‡è¨“ç·´è€Œç”Ÿ</p>
</h3>

<h3 align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/transformers_as_a_model_definition.png"/>
</h3>

Transformers æ˜¯ä¸€å€‹ç‚ºæœ€å…ˆé€²çš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ï¼ˆæ¶µè“‹æ–‡å­—ã€é›»è…¦è¦–è¦ºã€éŸ³è¨Šã€å½±ç‰‡åŠå¤šæ¨¡æ…‹ï¼‰æä¾›æ¨ç†å’Œè¨“ç·´æ”¯æ´çš„æ¨¡å‹å®šç¾©æ¡†æ¶ã€‚

å®ƒå°‡æ¨¡å‹å®šç¾©é›†ä¸­åŒ–ï¼Œä½¿å¾—è©²å®šç¾©åœ¨æ•´å€‹ç”Ÿæ…‹ç³»ä¸­èƒ½å¤ é”æˆå…±è­˜ã€‚`transformers` æ˜¯è²«ç©¿å„å€‹æ¡†æ¶çš„æ¨ç´ï¼šå¦‚æœä¸€å€‹æ¨¡å‹å®šç¾©å—åˆ°æ”¯æ´ï¼Œå®ƒå°‡èˆ‡å¤§å¤šæ•¸è¨“ç·´æ¡†æ¶ï¼ˆå¦‚ Axolotlã€Unslothã€DeepSpeedã€FSDPã€PyTorch-Lightning ç­‰ï¼‰ã€æ¨ç†å¼•æ“ï¼ˆå¦‚ vLLMã€SGLangã€TGI ç­‰ï¼‰ä»¥åŠåˆ©ç”¨ `transformers` æ¨¡å‹å®šç¾©çš„å‘¨é‚Šå»ºæ¨¡å‡½å¼åº«ï¼ˆå¦‚ llama.cppã€mlx ç­‰ï¼‰ç›¸å®¹ã€‚

æˆ‘å€‘è‡´åŠ›æ–¼æ”¯æ´æœ€æ–°çš„é ‚å°–æ¨¡å‹ï¼Œä¸¦é€éä½¿å…¶æ¨¡å‹å®šç¾©è®Šå¾—ç°¡å–®ã€å¯å®¢è£½åŒ–ä¸”é«˜æ•ˆï¼Œä¾†æ™®åŠå®ƒå€‘çš„æ‡‰ç”¨ã€‚

åœ¨ [Hugging Face Hub](https://huggingface.com/models) ä¸Šï¼Œæœ‰è¶…é 100 è¬å€‹ Transformers [æ¨¡å‹æª¢æŸ¥é»](https://huggingface.co/models?library=transformers&sort=trending) ä¾›æ‚¨ä½¿ç”¨ã€‚

ç«‹å³æ¢ç´¢ [Hub](https://huggingface.com/)ï¼Œå°‹æ‰¾åˆé©çš„æ¨¡å‹ï¼Œä¸¦ä½¿ç”¨ Transformers å¹«åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ã€‚

## å®‰è£

Transformers æ”¯æ´ Python 3.9+ å’Œ [PyTorch](https://pytorch.org/get-started/locally/) 2.1+ã€‚

ä½¿ç”¨ [venv](https://docs.python.org/3/library/venv.html) æˆ–åŸºæ–¼ Rust çš„é«˜é€Ÿ Python å¥—ä»¶åŠå°ˆæ¡ˆç®¡ç†å™¨ [uv](https://docs.astral.sh/uv/) ä¾†å»ºç«‹ä¸¦å•Ÿç”¨è™›æ“¬ç’°å¢ƒã€‚

```py
# venv
python -m venv .my-env
source .my-env/bin/activate
# uv
uv venv .my-env
source .my-env/bin/activate
```

åœ¨æ‚¨çš„è™›æ“¬ç’°å¢ƒä¸­å®‰è£ Transformersã€‚

```py
# pip
pip install "transformers[torch]"

# uv
uv pip install "transformers[torch]"
```

å¦‚æœæ‚¨æƒ³ä½¿ç”¨å‡½å¼åº«çš„æœ€æ–°è®Šæ›´æˆ–æœ‰èˆˆè¶£åƒèˆ‡è²¢ç»ï¼Œå¯ä»¥å¾åŸå§‹ç¢¼å®‰è£ Transformersã€‚ç„¶è€Œï¼Œ*æœ€æ–°*ç‰ˆæœ¬å¯èƒ½ä¸ç©©å®šã€‚å¦‚æœæ‚¨é‡åˆ°ä»»ä½•éŒ¯èª¤ï¼Œæ­¡è¿éš¨æ™‚æäº¤ä¸€å€‹ [issue](https://github.com/huggingface/transformers/issues)ã€‚

```shell
git clone https://github.com/huggingface/transformers.git
cd transformers

# pip
pip install '.[torch]'

# uv
uv pip install '.[torch]'
```

## å¿«é€Ÿå…¥é–€

é€é [Pipeline](https://huggingface.co/docs/transformers/pipeline_tutorial) API å¿«é€Ÿé–‹å§‹ä½¿ç”¨ Transformersã€‚`Pipeline` æ˜¯ä¸€å€‹é«˜éšçš„æ¨ç†é¡åˆ¥ï¼Œæ”¯æ´æ–‡å­—ã€éŸ³è¨Šã€è¦–è¦ºå’Œå¤šæ¨¡æ…‹ä»»å‹™ã€‚å®ƒè² è²¬è™•ç†è¼¸å…¥è³‡æ–™çš„é è™•ç†ï¼Œä¸¦å›å‚³é©ç•¶çš„è¼¸å‡ºã€‚

å¯¦ä¾‹åŒ–ä¸€å€‹ pipeline ä¸¦æŒ‡å®šç”¨æ–¼æ–‡å­—ç”Ÿæˆçš„æ¨¡å‹ã€‚è©²æ¨¡å‹æœƒè¢«ä¸‹è¼‰ä¸¦å¿«å–ï¼Œæ–¹ä¾¿æ‚¨ä¹‹å¾Œè¼•é¬†è¤‡ç”¨ã€‚æœ€å¾Œï¼Œå‚³å…¥ä¸€äº›æ–‡å­—ä¾†æç¤ºæ¨¡å‹ã€‚

```py
from transformers import pipeline

pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]
```

èˆ‡æ¨¡å‹é€²è¡ŒèŠå¤©ï¼Œä½¿ç”¨æ¨¡å¼æ˜¯ç›¸åŒçš„ã€‚å”¯ä¸€çš„å€åˆ¥æ˜¯æ‚¨éœ€è¦å»ºæ§‹ä¸€å€‹æ‚¨èˆ‡ç³»çµ±ä¹‹é–“çš„èŠå¤©æ­·å²ï¼ˆä½œç‚º `Pipeline` çš„è¼¸å…¥ï¼‰ã€‚

> [!TIP]
> ä½ ä¹Ÿå¯ä»¥ç›´æ¥åœ¨å‘½ä»¤åˆ—ä¸­èˆ‡æ¨¡å‹èŠå¤©ã€‚
> ```shell
> transformers chat Qwen/Qwen2.5-0.5B-Instruct
> ```

```py
import torch
from transformers import pipeline

chat = [
    {"role": "system", "content": "You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986."},
    {"role": "user", "content": "Hey, can you tell me any fun things to do in New York?"}
]

pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
```

å±•é–‹ä¸‹é¢çš„ç¯„ä¾‹ï¼ŒæŸ¥çœ‹ `Pipeline` å¦‚ä½•åœ¨ä¸åŒæ¨¡æ…‹å’Œä»»å‹™ä¸Šé‹ä½œã€‚

<details>
<summary>è‡ªå‹•èªéŸ³è¾¨è­˜</summary>

```py
from transformers import pipeline

pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

</details>

<details>
<summary>å½±åƒåˆ†é¡</summary>

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>

```py
from transformers import pipeline

pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
```

</details>

<details>
<summary>è¦–è¦ºå•ç­”</summary>

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>

```py
from transformers import pipeline

pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
```

</details>

## ç‚ºä»€éº¼æˆ‘æ‡‰è©²ä½¿ç”¨ Transformersï¼Ÿ

1.  æ˜“æ–¼ä½¿ç”¨çš„æœ€å…ˆé€²æ¨¡å‹ï¼š
    *   åœ¨è‡ªç„¶èªè¨€ç†è§£èˆ‡ç”Ÿæˆã€é›»è…¦è¦–è¦ºã€éŸ³è¨Šã€å½±ç‰‡å’Œå¤šæ¨¡æ…‹ä»»å‹™ä¸Šè¡¨ç¾å“è¶Šã€‚
    *   ç‚ºç ”ç©¶äººå“¡ã€å·¥ç¨‹å¸«èˆ‡é–‹ç™¼è€…æä¾›äº†ä½é–€æª»çš„å…¥é–€é€”å¾‘ã€‚
    *   é¢å‘ä½¿ç”¨è€…çš„æŠ½è±¡å±¤ç´šå°‘ï¼Œåªéœ€å­¸ç¿’ä¸‰å€‹æ ¸å¿ƒé¡åˆ¥ã€‚
    *   ç‚ºæ‰€æœ‰é è¨“ç·´æ¨¡å‹æä¾›äº†çµ±ä¸€çš„ API ä»‹é¢ã€‚

2.  æ›´ä½çš„é‹ç®—æˆæœ¬ï¼Œæ›´å°çš„ç¢³è¶³è·¡ï¼š
    *   åˆ†äº«è¨“ç·´å¥½çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯å¾é›¶é–‹å§‹è¨“ç·´ã€‚
    *   æ¸›å°‘é‹ç®—æ™‚é–“å’Œç”Ÿç”¢æˆæœ¬ã€‚
    *   æ“æœ‰æ•¸åç¨®æ¨¡å‹æ¶æ§‹å’Œè¶…é100è¬å€‹æ©«è·¨æ‰€æœ‰æ¨¡æ…‹çš„é è¨“ç·´æª¢æŸ¥é»ã€‚

3.  ç‚ºæ¨¡å‹çš„æ¯å€‹ç”Ÿå‘½é€±æœŸéšæ®µé¸æ“‡åˆé©çš„æ¡†æ¶ï¼š
    *   åƒ…ç”¨3è¡Œç¨‹å¼ç¢¼å³å¯è¨“ç·´æœ€å…ˆé€²çš„æ¨¡å‹ã€‚
    *   åœ¨PyTorch/JAX/TF2.0æ¡†æ¶ä¹‹é–“è¼•é¬†åˆ‡æ›å–®ä¸€æ¨¡å‹ã€‚
    *   ç‚ºè¨“ç·´ã€è©•ä¼°å’Œç”Ÿç”¢é¸æ“‡æœ€åˆé©çš„æ¡†æ¶ã€‚

4.  è¼•é¬†æ ¹æ“šæ‚¨çš„éœ€æ±‚å®¢è£½åŒ–æ¨¡å‹æˆ–ç¯„ä¾‹ï¼š
    *   æˆ‘å€‘ç‚ºæ¯å€‹æ¶æ§‹æä¾›äº†ç¯„ä¾‹ï¼Œä»¥é‡ç¾å…¶åŸä½œè€…ç™¼è¡¨çš„çµæœã€‚
    *   æ¨¡å‹å…§éƒ¨çµæ§‹ç›¡å¯èƒ½ä¿æŒä¸€è‡´åœ°æš´éœ²çµ¦ä½¿ç”¨è€…ã€‚
    *   æ¨¡å‹æª”æ¡ˆå¯ä»¥ç¨ç«‹æ–¼å‡½å¼åº«ä½¿ç”¨ï¼Œä¾¿æ–¼å¿«é€Ÿå¯¦é©—ã€‚

<a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br>

## ç‚ºä»€éº¼æˆ‘ä¸æ‡‰è©²ä½¿ç”¨ Transformersï¼Ÿ

-   æœ¬å‡½å¼åº«ä¸¦éä¸€å€‹ç”¨æ–¼å»ºæ§‹ç¥ç¶“ç¶²è·¯çš„æ¨¡çµ„åŒ–å·¥å…·ç®±ã€‚æ¨¡å‹æª”æ¡ˆä¸­çš„ç¨‹å¼ç¢¼ç‚ºäº†è®“ç ”ç©¶äººå“¡èƒ½å¿«é€Ÿåœ¨æ¨¡å‹ä¸Šè¿­ä»£ï¼Œè€Œæ²’æœ‰é€²è¡Œéåº¦çš„æŠ½è±¡é‡æ§‹ï¼Œé¿å…äº†æ·±å…¥é¡å¤–çš„æŠ½è±¡å±¤/æª”æ¡ˆã€‚
-   è¨“ç·´ API é‡å° Transformers æä¾›çš„ PyTorch æ¨¡å‹é€²è¡Œäº†æœ€ä½³åŒ–ã€‚å°æ–¼é€šç”¨çš„æ©Ÿå™¨å­¸ç¿’è¿´åœˆï¼Œæ‚¨æ‡‰è©²ä½¿ç”¨åƒ [Accelerate](https://huggingface.co/docs/accelerate) é€™æ¨£çš„å…¶ä»–å‡½å¼åº«ã€‚
-   [ç¯„ä¾‹æŒ‡ä»¤ç¨¿](https://github.com/huggingface/transformers/tree/main/examples)åƒ…åƒ…æ˜¯*ç¯„ä¾‹*ã€‚å®ƒå€‘ä¸ä¸€å®šèƒ½åœ¨æ‚¨çš„ç‰¹å®šç”¨ä¾‹ä¸Šé–‹ç®±å³ç”¨ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¿®æ”¹ç¨‹å¼ç¢¼æ‰èƒ½ä½¿å…¶æ­£å¸¸é‹ä½œã€‚

## 100å€‹ä½¿ç”¨ Transformers çš„å°ˆæ¡ˆ

Transformers ä¸åƒ…åƒ…æ˜¯ä¸€å€‹ä½¿ç”¨é è¨“ç·´æ¨¡å‹çš„å·¥å…·åŒ…ï¼Œå®ƒé‚„æ˜¯ä¸€å€‹åœç¹å®ƒå’Œ Hugging Face Hub å»ºæ§‹çš„å°ˆæ¡ˆç¤¾ç¾¤ã€‚æˆ‘å€‘å¸Œæœ› Transformers èƒ½å¤ è³¦èƒ½é–‹ç™¼è€…ã€ç ”ç©¶äººå“¡ã€å­¸ç”Ÿã€æ•™æˆã€å·¥ç¨‹å¸«ä»¥åŠå…¶ä»–ä»»ä½•äººï¼Œå»å»ºæ§‹ä»–å€‘å¤¢æƒ³ä¸­çš„å°ˆæ¡ˆã€‚

ç‚ºäº†æ…¶ç¥ Transformers ç²å¾— 10 è¬é¡†æ˜Ÿæ¨™ï¼Œæˆ‘å€‘å¸Œæœ›é€é [awesome-transformers](./awesome-transformers.md) é é¢ä¾†èšç„¦ç¤¾ç¾¤ï¼Œè©²é é¢åˆ—å‡ºäº†100å€‹åŸºæ–¼ Transformers å»ºæ§‹çš„ç²¾å½©å°ˆæ¡ˆã€‚

å¦‚æœæ‚¨æ“æœ‰æˆ–ä½¿ç”¨ä¸€å€‹æ‚¨èªç‚ºæ‡‰è©²è¢«åˆ—å…¥å…¶ä¸­çš„å°ˆæ¡ˆï¼Œè«‹éš¨æ™‚æäº¤ PR å°‡å…¶åŠ å…¥ï¼

## ç¯„ä¾‹æ¨¡å‹

æ‚¨å¯ä»¥åœ¨æˆ‘å€‘å¤§å¤šæ•¸æ¨¡å‹çš„ [Hub æ¨¡å‹é é¢](https://huggingface.co/models) ä¸Šç›´æ¥é€²è¡Œæ¸¬è©¦ã€‚

å±•é–‹ä¸‹é¢çš„æ¯å€‹æ¨¡æ…‹ï¼ŒæŸ¥çœ‹ä¸€äº›ç”¨æ–¼ä¸åŒç”¨ä¾‹çš„ç¯„ä¾‹æ¨¡å‹ã€‚

<details>
<summary>éŸ³è¨Š</summary>

-   Audio classification with [Whisper](https://huggingface.co/openai/whisper-large-v3-turbo)
-   Automatic speech recognition with [Moonshine](https://huggingface.co/UsefulSensors/moonshine)
-   Keyword spotting with [Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks)
-   Speech to speech generation with [Moshi](https://huggingface.co/kyutai/moshiko-pytorch-bf16)
-   Text to audio with [MusicGen](https://huggingface.co/facebook/musicgen-large)
-   Text to speech with [Bark](https://huggingface.co/suno/bark)

</details>

<details>
<summary>é›»è…¦è¦–è¦º</summary>

-   Automatic mask generation with [SAM](https://huggingface.co/facebook/sam-vit-base)
-   Depth estimation with [DepthPro](https://huggingface.co/apple/DepthPro-hf)
-   Image classification with [DINO v2](https://huggingface.co/facebook/dinov2-base)
-   Keypoint detection with [SuperPoint](https://huggingface.co/magic-leap-community/superpoint)
-   Keypoint matching with [SuperGlue](https://huggingface.co/magic-leap-community/superglue_outdoor)
-   Object detection with [RT-DETRv2](https://huggingface.co/PekingU/rtdetr_v2_r50vd)
-   Pose Estimation with [VitPose](https://huggingface.co/usyd-community/vitpose-base-simple)
-   Universal segmentation with [OneFormer](https://huggingface.co/shi-labs/oneformer_ade20k_swin_large)
-   Video classification with [VideoMAE](https://huggingface.co/MCG-NJU/videomae-large)

</details>

<details>
<summary>å¤šæ¨¡æ…‹</summary>

-   Audio or text to text with [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B)
-   Document question answering with [LayoutLMv3](https://huggingface.co/microsoft/layoutlmv3-base)
-   Image or text to text with [Qwen-VL](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)
-   Image captioning [BLIP-2](https://huggingface.co/Salesforce/blip2-opt-2.7b)
-   OCR-based document understanding with [GOT-OCR2](https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf)
-   Table question answering with [TAPAS](https://huggingface.co/google/tapas-base)
-   Unified multimodal understanding and generation with [Emu3](https://huggingface.co/BAAI/Emu3-Gen)
-   Vision to text with [Llava-OneVision](https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf)
-   Visual question answering with [Llava](https://huggingface.co/llava-hf/llava-1.5-7b-hf)
-   Visual referring expression segmentation with [Kosmos-2](https://huggingface.co/microsoft/kosmos-2-patch14-224)

</details>

<details>
<summary>è‡ªç„¶èªè¨€è™•ç† (NLP)</summary>

-   Masked word completion with [ModernBERT](https://huggingface.co/answerdotai/ModernBERT-base)
-   Named entity recognition with [Gemma](https://huggingface.co/google/gemma-2-2b)
-   Question answering with [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)
-   Summarization with [BART](https://huggingface.co/facebook/bart-large-cnn)
-   Translation with [T5](https://huggingface.co/google-t5/t5-base)
-   Text generation with [Llama](https://huggingface.co/meta-llama/Llama-3.2-1B)
-   Text classification with [Qwen](https://huggingface.co/Qwen/Qwen2.5-0.5B)

</details>

## å¼•ç”¨

ç¾åœ¨æˆ‘å€‘æœ‰ä¸€ç¯‡å¯ä¾›æ‚¨å¼•ç”¨çš„é—œæ–¼ ğŸ¤— Transformers å‡½å¼åº«çš„ [è«–æ–‡](https://www.aclweb.org/anthology/2020.emnlp-demos.6/)ï¼š
```bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
```