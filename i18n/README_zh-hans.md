<!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<!---
A useful guide for English-Chinese translation of Hugging Face documentation
- Add space around English words and numbers when they appear between Chinese characters. E.g., å…± 100 å¤šç§è¯­è¨€; ä½¿ç”¨ transformers åº“ã€‚
- Use square quotes, e.g.,ã€Œå¼•ç”¨ã€

Dictionary

Hugging Face: æŠ±æŠ±è„¸
token: è¯ç¬¦ï¼ˆå¹¶ç”¨æ‹¬å·æ ‡æ³¨åŸè‹±æ–‡ï¼‰
tokenize: è¯ç¬¦åŒ–ï¼ˆå¹¶ç”¨æ‹¬å·æ ‡æ³¨åŸè‹±æ–‡ï¼‰
tokenizer: è¯ç¬¦åŒ–å™¨ï¼ˆå¹¶ç”¨æ‹¬å·æ ‡æ³¨åŸè‹±æ–‡ï¼‰
transformer: transformerï¼ˆä¸ç¿»è¯‘ï¼‰
pipeline: æµæ°´çº¿
API: API (ä¸ç¿»è¯‘ï¼‰
inference: æ¨ç†
Trainer: è®­ç»ƒå™¨ã€‚å½“ä½œä¸ºç±»åå‡ºç°æ—¶ä¸ç¿»è¯‘ã€‚
pretrained/pretrain: é¢„è®­ç»ƒ
finetune: å¾®è°ƒ
community: ç¤¾åŒº
example: å½“ç‰¹æŒ‡ä»“åº“ä¸­ example ç›®å½•æ—¶ç¿»è¯‘ä¸ºã€Œç”¨ä¾‹ã€
Python data structures (e.g., list, set, dict): ç¿»è¯‘ä¸ºåˆ—è¡¨ï¼Œé›†åˆï¼Œè¯å…¸ï¼Œå¹¶ç”¨æ‹¬å·æ ‡æ³¨åŸè‹±æ–‡
NLP/Natural Language Processing: ä»¥ NLP å‡ºç°æ—¶ä¸ç¿»è¯‘ï¼Œä»¥ Natural Language Processing å‡ºç°æ—¶ç¿»è¯‘ä¸ºè‡ªç„¶è¯­è¨€å¤„ç†
checkpoint: æ£€æŸ¥ç‚¹
modality æ¨¡æ€
-->

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<p align="center">
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <a href="https://github.com/huggingface/transformers/">English</a> |
        <b>ç®€ä½“ä¸­æ–‡</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">ç¹é«”ä¸­æ–‡</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">í•œêµ­ì–´</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">EspaÃ±ol</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">æ—¥æœ¬èª</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Ğ ortuguÃªs</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">à°¤à±†à°²à±à°—à±</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">FranÃ§ais</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiáº¿ng Viá»‡t</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">Ø§Ø±Ø¯Ùˆ</a> |
    </p>
</h4>

<h3 align="center">
    <p>ä¸º Jaxã€PyTorch å’Œ TensorFlow ç¤¾åŒºæä¾›æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹</p>
</h3>

<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>

ğŸ¤— Transformers æä¾›äº†æ•°ä»¥åƒè®¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥ç”¨äºæ‰§è¡Œæ–‡æœ¬ã€è§†è§‰å’ŒéŸ³é¢‘ç­‰ä¸åŒæ¨¡æ€ï¼ˆmodalityï¼‰ä¸Šçš„ä»»åŠ¡ã€‚

è¿™äº›æ¨¡å‹å¯ä»¥åº”ç”¨åœ¨ï¼š

- ğŸ“ æ–‡æœ¬ï¼Œç”¨äºæ–‡æœ¬åˆ†ç±»ã€ä¿¡æ¯æå–ã€é—®ç­”ã€æ‘˜è¦ã€ç¿»è¯‘å’Œæ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ï¼Œæ”¯æŒè¶…è¿‡100ç§è¯­è¨€

- ğŸ–¼ï¸ å›¾åƒï¼Œç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ç­‰ä»»åŠ¡

- ğŸ—£ï¸ éŸ³é¢‘ï¼Œç”¨äºè¯­éŸ³è¯†åˆ«å’ŒéŸ³é¢‘åˆ†ç±»ç­‰ä»»åŠ¡

Transformer æ¨¡å‹è¿˜å¯ä»¥åœ¨å¤šç§æ¨¡æ€ç»„åˆä¸Šæ‰§è¡Œä»»åŠ¡ï¼Œä¾‹å¦‚è¡¨æ ¼é—®ç­”ã€è§†è§‰å­—ç¬¦è¯†åˆ«ï¼ˆoptical character recognitionï¼‰ã€æ–‡æ¡£æ‘˜è¦ã€è§†é¢‘åˆ†ç±»å’Œè§†è§‰é—®ç­”ã€‚

ğŸ¤— Transformers æä¾›äº†ä¾¿äºå¿«é€Ÿä¸‹è½½å’Œä½¿ç”¨çš„ APIï¼Œå¯ä»¥å¿«é€Ÿä¸‹è½½å¹¶åœ¨ç»™å®šæ–‡æœ¬ä¸Šä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹ï¼Œåœ¨ä½ è‡ªå·±çš„æ•°æ®åº“ä¸Šå¯¹å®ƒä»¬è¿›è¡Œå¾®è°ƒï¼Œç„¶åé€šè¿‡ [model hub](https://huggingface.co/models) ä¸ç¤¾åŒºå…±äº«ã€‚åŒæ—¶ï¼Œæ¯ä¸ªå®šä¹‰çš„ Python æ¨¡å—å‡å®Œå…¨ç‹¬ç«‹ï¼Œå¯ä»¥è¿›è¡Œä¿®æ”¹ï¼Œç”¨äºå¿«é€Ÿç ”ç©¶å®éªŒã€‚

ğŸ¤— Transformers ä¸ºä¸‰ä¸ªæœ€çƒ­é—¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶æä¾›æ”¯æŒ â€” [Jax](https://jax.readthedocs.io/en/latest/), [PyTorch](https://pytorch.org/) ä»¥åŠ [TensorFlow](https://www.tensorflow.org/) â€” å¹¶åœ¨å®ƒä»¬ä¹‹é—´æ— ç¼é›†æˆã€‚ä½ å¯ä»¥è½»æ¾åœ°å…ˆç”¨ä¸€ä¸ªè®­ç»ƒä½ çš„æ¨¡å‹ï¼Œç„¶åå†ç”¨å¦ä¸€ä¸ªæ¡†æ¶åŠ è½½å®ƒä»¬è¿›è¡Œæ¨ç†ã€‚

## åœ¨çº¿æ¼”ç¤º

ä½ å¯ä»¥ç›´æ¥åœ¨ [model hub](https://huggingface.co/models) ä¸Šæµ‹è¯•æˆ‘ä»¬çš„å¤§éƒ¨åˆ†æ¨¡å‹ã€‚ æˆ‘ä»¬è¿˜æä¾›äº† [ç§æœ‰æ¨¡å‹æ‰˜ç®¡ã€æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ä»¥åŠæ¨ç†API](https://huggingface.co/pricing) æœåŠ¡ã€‚

è¿™é‡Œæœ‰ä¸€äº›ä¾‹å­ï¼š

è‡ªç„¶è¯­è¨€å¤„ç†ï¼š
- [ç”¨ BERT åšæ©ç å¡«è¯](https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)
- [ç”¨ Electra åšå‘½åå®ä½“è¯†åˆ«](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)
- [ç”¨ Mistral åšæ–‡æœ¬ç”Ÿæˆ](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)
- [ç”¨ RoBERTa åšè‡ªç„¶è¯­è¨€æ¨ç†](https://huggingface.co/FacebookAI/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal)
- [ç”¨ BART åšæ–‡æœ¬æ‘˜è¦](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)
- [ç”¨ DistilBERT åšé—®ç­”](https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species)
- [ç”¨ T5 åšç¿»è¯‘](https://huggingface.co/google-t5/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin)

è®¡ç®—æœºè§†è§‰ï¼š
- [ç”¨ ViT åšå›¾åƒåˆ†ç±»](https://huggingface.co/google/vit-base-patch16-224)
- [ç”¨ DETR åšç›®æ ‡æ£€æµ‹](https://huggingface.co/facebook/detr-resnet-50)
- [ç”¨ SegFormer åšè¯­ä¹‰åˆ†å‰²](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512)
- [ç”¨ Mask2Former åšå…¨æ™¯åˆ†å‰²](https://huggingface.co/facebook/mask2former-swin-large-coco-panoptic)
- [ç”¨ Depth Anything åšæ·±åº¦ä¼°è®¡](https://huggingface.co/docs/transformers/main/model_doc/depth_anything)
- [ç”¨ VideoMAE åšè§†é¢‘åˆ†ç±»](https://huggingface.co/docs/transformers/model_doc/videomae)
- [ç”¨ OneFormer åšé€šç”¨åˆ†å‰²ï¼ˆUniversal Segmentationï¼‰](https://huggingface.co/shi-labs/oneformer_ade20k_dinat_large)

éŸ³é¢‘å¤„ç†ï¼š

- [ç”¨ Whisper åšè‡ªåŠ¨è¯­éŸ³è¯†åˆ«](https://huggingface.co/openai/whisper-large-v3)
- [ç”¨ Wav2Vec2 åšå…³é”®è¯æ£€æµ‹](https://huggingface.co/superb/wav2vec2-base-superb-ks)
- [ç”¨ Audio Spectrogram Transformer åšéŸ³é¢‘åˆ†ç±»](https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593)

å¤šæ¨¡æ€ä»»åŠ¡ï¼š

- [Table Question Answering with TAPAS](https://huggingface.co/google/tapas-base-finetuned-wtq)
- [Visual Question Answering with ViLT](https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)
- [Image captioning with LLaVa](https://huggingface.co/llava-hf/llava-1.5-7b-hf)
- [Zero-shot Image Classification with SigLIP](https://huggingface.co/google/siglip-so400m-patch14-384)
- [Document Question Answering with LayoutLM](https://huggingface.co/impira/layoutlm-document-qa)
- [Zero-shot Video Classification with X-CLIP](https://huggingface.co/docs/transformers/model_doc/xclip)
- [Zero-shot Object Detection with OWLv2](https://huggingface.co/docs/transformers/en/model_doc/owlv2)
- [Zero-shot Image Segmentation with CLIPSeg](https://huggingface.co/docs/transformers/model_doc/clipseg)
- [Automatic Mask Generation with SAM](https://huggingface.co/docs/transformers/model_doc/sam)

## 100 ä¸ªä½¿ç”¨ Transformers çš„é¡¹ç›®

Transformers ä¸åªæ˜¯ä¸€ä¸ªé›†æˆäº†é¢„è®­ç»ƒæ¨¡å‹çš„å·¥å…·åŒ…ï¼šå®ƒè¿˜æ˜¯ä¸€ä¸ªå›´ç»• Hugging Face Hub æ‰€æ„å»ºçš„ç¤¾åŒºã€‚
æˆ‘ä»¬å¸Œæœ› Transformers èƒ½è®©å¼€å‘è€…ã€ç ”ç©¶äººå‘˜ã€å­¦ç”Ÿã€æ•™æˆã€å·¥ç¨‹å¸ˆä»¥åŠæ¯ä¸€ä¸ªäººèƒ½å¤Ÿæ„å»ºä»–ä»¬ç†æƒ³ä¸­çš„é¡¹ç›®ã€‚

ä¸ºäº†åº†ç¥ transformers è·å¾— 100,000 ä¸ª starï¼Œæˆ‘ä»¬å†³å®šèšç„¦ç¤¾åŒºï¼Œå¹¶åˆ›å»ºäº† [awesome-transformers](./awesome-transformers.md) é¡µé¢ï¼Œ
é¡µé¢åˆ—å‡ºäº† 100 ä¸ªä½¿ç”¨ transformers æ„å»ºçš„ä¸å¯æ€è®®çš„é¡¹ç›®ï¼Œå¦‚æœä½ æ‹¥æœ‰æˆ–æ­£åœ¨ä½¿ç”¨ä¸€ä¸ªä½ è®¤ä¸ºåº”è¯¥è¢«åˆ—å…¥åˆ—è¡¨çš„é¡¹ç›®ï¼Œè¯·æäº¤ä¸€ä¸ª PRï¼ˆpull requestï¼‰æ·»åŠ å®ƒï¼

## å¦‚æœä½ åœ¨å¯»æ‰¾ç”±æŠ±æŠ±è„¸å›¢é˜Ÿæä¾›çš„å®šåˆ¶åŒ–æ”¯æŒæœåŠ¡

<a target="_blank" href="https://huggingface.co/support">
    <img alt="HuggingFace Expert Acceleration Program" src="https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png" style="max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);">
</a><br>

## å¿«é€Ÿä¸Šæ‰‹

ä¸ºäº†ç«‹å³åœ¨ç»™å®šè¾“å…¥ï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰ï¼‰ä¸Šä½¿ç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬æä¾›äº† `pipeline`ï¼ˆæµæ°´çº¿ï¼‰ APIã€‚Pipeline å°†é¢„è®­ç»ƒæ¨¡å‹ä¸è¯¥æ¨¡å‹è®­ç»ƒæœŸé—´ä½¿ç”¨çš„é¢„å¤„ç†æ­¥éª¤ç»„åˆåœ¨ä¸€èµ·ã€‚
ä»¥ä¸‹æ˜¯å¦‚ä½•å¿«é€Ÿä½¿ç”¨ `pipeline` å¯¹æ­£é¢æ–‡æœ¬å’Œè´Ÿé¢æ–‡æœ¬è¿›è¡Œåˆ†ç±»

```python
>>> from transformers import pipeline

# ä½¿ç”¨æƒ…ç»ªåˆ†ææµæ°´çº¿
>>> classifier = pipeline('sentiment-analysis')
>>> classifier('We are very happy to introduce pipeline to the transformers repository.')
[{'label': 'POSITIVE', 'score': 0.9996980428695679}]
```

ç¬¬äºŒè¡Œä»£ç ä¸‹è½½å¹¶ç¼“å­˜äº†æµæ°´çº¿ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œç¬¬ä¸‰è¡Œä»£ç åˆ™åœ¨ç»™å®šçš„æ–‡æœ¬ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚è¿™é‡Œçš„ç­”æ¡ˆâ€œæ­£é¢â€ (positive) å…·æœ‰ 99 çš„ç½®ä¿¡åº¦ã€‚

è®¸å¤šä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªå¼€ç®±å³ç”¨çš„ `pipeline` å¯ä¾›ä½¿ç”¨ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€è®¡ç®—æœºè§†è§‰ä»»åŠ¡å’Œè¯­éŸ³è¯†åˆ«ä»»åŠ¡ã€‚
ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°æå–å›¾åƒä¸­æ£€æµ‹åˆ°çš„ç‰©ä½“ï¼š
``` python
>>> import requests
>>> from PIL import Image
>>> from transformers import pipeline

# Download an image with cute cats
>>> url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png"
>>> image_data = requests.get(url, stream=True).raw
>>> image = Image.open(image_data)

# Allocate a pipeline for object detection
>>> object_detector = pipeline('object-detection')
>>> object_detector(image)
[{'score': 0.9982201457023621,
  'label': 'remote',
  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},
 {'score': 0.9960021376609802,
  'label': 'remote',
  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},
 {'score': 0.9954745173454285,
  'label': 'couch',
  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},
 {'score': 0.9988006353378296,
  'label': 'cat',
  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},
 {'score': 0.9986783862113953,
  'label': 'cat',
  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]
```

å¦‚ä¸Šï¼Œæˆ‘ä»¬åˆ—å‡ºäº†å›¾åƒä¸­æ£€æµ‹åˆ°çš„ç‰©ä½“ï¼Œå¹¶ç”¨æ–¹æ¡†æ ‡æ³¨å‡ºäº†å›¾åƒå¹¶åˆ†åˆ«æ ‡å‡ºäº†ç½®ä¿¡åº¦åˆ†æ•°ã€‚

ä»¥ä¸‹åˆ†åˆ«å±•ç¤ºäº†åŸå§‹å›¾åƒå’Œé¢„æµ‹ç»“æœ

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png" width="400"></a>
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample_post_processed.png" width="400"></a>
</h3>

ä½ å¯ä»¥åœ¨[è¿™ä¸ªæ•™ç¨‹](https://huggingface.co/docs/transformers/task_summary)ä¸­äº†è§£æ›´å¤šå…³äº `pipeline` API çš„çŸ¥è¯†ï¼Œä»¥åŠèƒ½å¤Ÿæ”¯æŒçš„ä»»åŠ¡ã€‚

è¦åœ¨ä½ çš„ä»»åŠ¡ä¸Šä¸‹è½½å’Œä½¿ç”¨ä»»æ„é¢„è®­ç»ƒæ¨¡å‹ä¹Ÿå¾ˆç®€å•ï¼Œåªéœ€ä¸‰è¡Œä»£ç ã€‚ä»¥ä¸‹æ˜¯åŸºäº PyTorch çš„ç¤ºä¾‹ï¼š

```python
>>> from transformers import AutoTokenizer, AutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = AutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("Hello world!", return_tensors="pt")
>>> outputs = model(**inputs)
```

ä»¥ä¸‹æ˜¯å¯¹åº”çš„ TensorFlow ä»£ç ï¼š

```python
>>> from transformers import AutoTokenizer, TFAutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = TFAutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("Hello world!", return_tensors="tf")
>>> outputs = model(**inputs)
```

è¯ç¬¦åŒ–å™¨ (tokenizer) ä¸ºæ‰€æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹æä¾›äº†é¢„å¤„ç†ï¼Œå¹¶å¯ä»¥ç›´æ¥å¯¹å•ä¸ªå­—ç¬¦ä¸²è¿›è¡Œè°ƒç”¨ï¼ˆæ¯”å¦‚ä¸Šé¢çš„ä¾‹å­ï¼‰æˆ–å¯¹åˆ—è¡¨ (list) è°ƒç”¨ã€‚å®ƒä¼šè¾“å‡ºä¸€ä¸ªä½ å¯ä»¥åœ¨ä¸‹æ¸¸ä»£ç é‡Œä½¿ç”¨æˆ–ç›´æ¥é€šè¿‡ `**` è§£åŒ…è¡¨è¾¾å¼ä¼ ç»™æ¨¡å‹çš„è¯å…¸ (dict)ã€‚

æ¨¡å‹æœ¬èº«æ˜¯ä¸€ä¸ªå¸¸è§„çš„ [Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) æˆ– [TensorFlow `tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)ï¼ˆå–å†³äºä½ çš„åç«¯ï¼‰ï¼Œå¯ä»¥å¸¸è§„æ–¹å¼ä½¿ç”¨ã€‚ [è¿™ä¸ªæ•™ç¨‹](https://huggingface.co/transformers/training.html)è§£é‡Šäº†å¦‚ä½•å°†è¿™æ ·çš„æ¨¡å‹æ•´åˆåˆ°ç»å…¸çš„ PyTorch æˆ– TensorFlow è®­ç»ƒå¾ªç¯ä¸­ï¼Œæˆ–æ˜¯å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„ `Trainer` è®­ç»ƒå™¨ï¼‰API æ¥åœ¨ä¸€ä¸ªæ–°çš„æ•°æ®é›†ä¸Šå¿«é€Ÿå¾®è°ƒã€‚

## ä¸ºä»€ä¹ˆä½¿ç”¨ transformersï¼Ÿ

1. æ˜“äºä½¿ç”¨çš„ Sotaï¼ˆæœ€å…ˆè¿›ï¼‰æ¨¡å‹ï¼š

    - åœ¨è‡ªç„¶è¯­è¨€ç†è§£ä¸ç”Ÿæˆã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘ä»»åŠ¡ä¸Šè¡¨ç°å“è¶Š
   
    - å¯¹äºæ•™è‚²å·¥ä½œè€…å’Œå®è·µè€…çš„å…¥é—¨é—¨æ§›ä½
   
    - é«˜çº§æŠ½è±¡ï¼Œåªéœ€äº†è§£ä¸‰ä¸ªç±»
   
    - å¯¹æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€çš„ API

2. æ›´ä½è®¡ç®—å¼€é”€ï¼Œæ›´å°‘çš„ç¢³æ’æ”¾ï¼š

    - ç ”ç©¶äººå‘˜å¯ä»¥å…±äº«é¢„è®­ç»ƒæ¨¡å‹è€Œéæ€»æ˜¯ä»0å¼€å§‹è®­ç»ƒæ¨¡å‹
   
    - å·¥ç¨‹å¸ˆèƒ½å¤Ÿé™ä½è®¡ç®—ç”¨æ—¶å’Œç”Ÿäº§æˆæœ¬
   
    - æ•°åç§æ¨¡å‹æ¶æ„ã€æ¶µç›–æ‰€æœ‰æ¨¡æ€çš„è¶…è¿‡ 400,000 ä¸ªé¢„è®­ç»ƒæ¨¡å‹

3. å¯¹äºæ¨¡å‹ç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸€ä¸ªéƒ¨åˆ†éƒ½é¢é¢ä¿±åˆ°ï¼š

    - è®­ç»ƒ Sotaï¼ˆæœ€å…ˆè¿›ï¼‰æ¨¡å‹ï¼Œåªéœ€ 3 è¡Œä»£ç 
   
    - æ¨¡å‹å¯ä»¥åœ¨ä¸åŒæ·±åº¦å­¦ä¹ æ¡†æ¶é—´ä»»æ„è¿ç§»ï¼Œéšä½ å¿ƒæ„
   
    - ä¸ºè®­ç»ƒã€è¯„ä¼°å’Œç”Ÿäº§é€‰æ‹©æœ€é€‚åˆçš„æ¡†æ¶ï¼Œå®ƒä»¬å¯ä»¥æ— ç¼è¡”æ¥

4. ä¸ºä½ çš„éœ€æ±‚è½»æ¾å®šåˆ¶ä¸“å±æ¨¡å‹å’Œç”¨ä¾‹ï¼š

    - æˆ‘ä»¬ä¸ºæ¯ç§æ¨¡å‹æ¶æ„æä¾›äº†å¤šä¸ªç”¨ä¾‹æ¥å¤ç°åŸè®ºæ–‡ç»“æœ
   
    - æ¨¡å‹å†…éƒ¨ç»“æ„å°½å¯èƒ½ä¸€è‡´åœ°è¢«å…¬å¼€
   
    - æ¨¡å‹æ–‡ä»¶å¯å•ç‹¬ä½¿ç”¨ï¼Œæ–¹ä¾¿è¿›è¡Œå¿«é€Ÿå®éªŒ

## ä»€ä¹ˆæƒ…å†µä¸‹ transformers å¹¶ä¸é€‚ç”¨ï¼Ÿ

- æœ¬åº“å¹¶ä¸æ˜¯æ¨¡å—åŒ–çš„ç¥ç»ç½‘ç»œå·¥å…·ç®±ã€‚æ¨¡å‹æ–‡ä»¶ä¸­çš„ä»£ç ç‰¹æ„å‘ˆè‹¥ç’ç‰ï¼Œæœªç»é¢å¤–æŠ½è±¡å°è£…ï¼Œä»¥ä¾¿ç ”ç©¶äººå‘˜å¿«é€Ÿè¿­ä»£é­”æ”¹è€Œä¸è‡´æººäºæŠ½è±¡å’Œæ–‡ä»¶è·³è½¬ä¹‹ä¸­ã€‚

- `Trainer` API å¹¶éå…¼å®¹ä»»ä½•æ¨¡å‹ï¼Œåªä¸ºæœ¬åº“ä¹‹æ¨¡å‹ä¼˜åŒ–ã€‚è‹¥æ˜¯åœ¨å¯»æ‰¾é€‚ç”¨äºé€šç”¨æœºå™¨å­¦ä¹ çš„è®­ç»ƒå¾ªç¯å®ç°ï¼Œè¯·å¦å¯»ä»–åº“ã€‚

- å°½ç®¡æˆ‘ä»¬å·²å°½åŠ›è€Œä¸ºï¼Œ[examples ç›®å½•](https://github.com/huggingface/transformers/tree/main/examples)ä¸­çš„è„šæœ¬ä¹Ÿä»…ä¸ºç”¨ä¾‹è€Œå·²ã€‚å¯¹äºä½ çš„ç‰¹å®šé—®é¢˜ï¼Œå®ƒä»¬å¹¶ä¸ä¸€å®šå¼€ç®±å³ç”¨ï¼Œå¯èƒ½éœ€è¦æ”¹å‡ è¡Œä»£ç ä»¥é€‚é…ä½ çš„éœ€æ±‚ã€‚

## å®‰è£…

### ä½¿ç”¨ pip

è¿™ä¸ªä»“åº“å·²åœ¨ Python 3.9+ã€Flax 0.4.1+ã€PyTorch 2.0+ å’Œ TensorFlow 2.6+ ä¸‹ç»è¿‡æµ‹è¯•ã€‚

ä½ å¯ä»¥åœ¨[è™šæ‹Ÿç¯å¢ƒ](https://docs.python.org/3/library/venv.html)ä¸­å®‰è£… ğŸ¤— Transformersã€‚å¦‚æœä½ è¿˜ä¸ç†Ÿæ‚‰ Python çš„è™šæ‹Ÿç¯å¢ƒï¼Œè¯·é˜…æ­¤[ç”¨æˆ·è¯´æ˜](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã€‚

é¦–å…ˆï¼Œç”¨ä½ æ‰“ç®—ä½¿ç”¨çš„ Python ç‰ˆæœ¬åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒå¹¶æ¿€æ´»ã€‚

ç„¶åï¼Œä½ éœ€è¦å®‰è£… Flaxã€PyTorch æˆ– TensorFlow å…¶ä¸­ä¹‹ä¸€ã€‚å…³äºåœ¨ä½ ä½¿ç”¨çš„å¹³å°ä¸Šå®‰è£…è¿™äº›æ¡†æ¶ï¼Œè¯·å‚é˜… [TensorFlow å®‰è£…é¡µé¢](https://www.tensorflow.org/install/), [PyTorch å®‰è£…é¡µé¢](https://pytorch.org/get-started/locally/#start-locally) æˆ– [Flax å®‰è£…é¡µé¢](https://github.com/google/flax#quick-install)ã€‚

å½“è¿™äº›åç«¯ä¹‹ä¸€å®‰è£…æˆåŠŸåï¼Œ ğŸ¤— Transformers å¯ä¾æ­¤å®‰è£…ï¼š

```bash
pip install transformers
```

å¦‚æœä½ æƒ³è¦è¯•è¯•è¿™äº›ç”¨ä¾‹æˆ–è€…æƒ³åœ¨æ­£å¼å‘å¸ƒå‰è¯•ç”¨æœ€æ–°ç‰ˆæœ¬ï¼Œå¹¶ä¸”ä¸æƒ³ç­‰å¾…æœ€æ–°ç‰ˆæœ¬çš„å‘å¸ƒï¼Œä½ å¯ä»¥[ä»æºä»£ç å®‰è£…](https://huggingface.co/docs/transformers/installation#installing-from-source)ã€‚

### ä½¿ç”¨ conda

ğŸ¤— Transformers å¯ä»¥é€šè¿‡ conda ä¾æ­¤å®‰è£…ï¼š

```shell script
conda install conda-forge::transformers
```

> **_æ³¨æ„:_** ä» `huggingface` æ¸ é“å®‰è£… `transformers` çš„æ–¹å¼å·²è¢«å¼ƒç”¨ã€‚

è¦é€šè¿‡ conda å®‰è£… Flaxã€PyTorch æˆ– TensorFlow å…¶ä¸­ä¹‹ä¸€ï¼Œè¯·å‚é˜…å®ƒä»¬å„è‡ªå®‰è£…é¡µçš„è¯´æ˜ã€‚

> **_æ³¨æ„:_** åœ¨ Windows ç³»ç»Ÿä¸Šï¼Œä½ å¯èƒ½ä¼šè¢«æç¤ºå¯ç”¨å¼€å‘è€…æ¨¡å¼ä»¥ä¾¿äºåˆ©ç”¨ç¼“å­˜ä¼˜åŒ–å®‰è£…ã€‚å¦‚æœè¿™ä¸ªé€‰é¡¹å¯¹ä½ ä¸å¯ç”¨ï¼Œè¯·åœ¨[é—®é¢˜](https://github.com/huggingface/huggingface_hub/issues/1062)ä¸­å‘ŠçŸ¥æˆ‘ä»¬

## æ¨¡å‹æ¶æ„

ğŸ¤— Transformers æ”¯æŒçš„[**æ‰€æœ‰çš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆcheckpointsï¼‰**](https://huggingface.co/models)ç”±[ç”¨æˆ·](https://huggingface.co/users)å’Œ[ç»„ç»‡](https://huggingface.co/organizations)ä¸Šä¼ ï¼Œå‡ä¸ huggingface.co [model hub](https://huggingface.co) æ— ç¼æ•´åˆã€‚

ç›®å‰çš„æ£€æŸ¥ç‚¹æ•°é‡ï¼š ![](https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen)

ğŸ¤— Transformers ç›®å‰æ”¯æŒå¦‚ä¸‹çš„æ¶æ„: å…³äºå®ƒä»¬çš„ç®€è¦æ¦‚è¿°è¯·æŸ¥é˜…[è¿™é‡Œ](https://huggingface.co/docs/transformers/model_summary).

è¦æ£€æŸ¥æŸä¸ªæ¨¡å‹æ˜¯å¦å·²æœ‰ Flaxã€PyTorch æˆ– TensorFlow çš„å®ç°ï¼Œæˆ–å…¶æ˜¯å¦åœ¨ ğŸ¤— Tokenizers åº“ä¸­æœ‰å¯¹åº”è¯ç¬¦åŒ–å™¨ï¼ˆtokenizerï¼‰ï¼Œæ•¬è¯·å‚é˜…[æ­¤è¡¨](https://huggingface.co/docs/transformers/index#supported-frameworks)ã€‚

è¿™äº›å®ç°å·²ç»åœ¨è‹¥å¹²ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼ˆå‚è§ç¤ºä¾‹è„šæœ¬ï¼‰ï¼Œå¹¶ä¸”åº”è¯¥ä¸åŸå§‹å®ç°çš„æ€§èƒ½ç›¸åŒ¹é…ã€‚ä½ å¯ä»¥åœ¨[è¯¥æ–‡æ¡£]((https://github.com/huggingface/transformers/tree/main/examples))çš„ç”¨ä¾‹éƒ¨åˆ†æ‰¾åˆ°æ›´å¤šå…³äºæ€§èƒ½çš„è¯¦ç»†ä¿¡æ¯

## äº†è§£æ›´å¤š

| ç« èŠ‚                                                                             | æè¿° |
|--------------------------------------------------------------------------------|-|
| [æ–‡æ¡£](https://huggingface.co/docs/transformers/)                                | å®Œæ•´çš„ API æ–‡æ¡£å’Œæ•™ç¨‹ |
| [ä»»åŠ¡æ¦‚è§ˆ](https://huggingface.co/docs/transformers/task_summary)                  | ğŸ¤— Transformers æ”¯æŒçš„ä»»åŠ¡ |
| [é¢„å¤„ç†æ•™ç¨‹](https://huggingface.co/docs/transformers/preprocessing)                | ä½¿ç”¨ `Tokenizer` æ¥ä¸ºæ¨¡å‹å‡†å¤‡æ•°æ® |
| [è®­ç»ƒå’Œå¾®è°ƒ](https://huggingface.co/docs/transformers/training)                     | åœ¨ PyTorch/TensorFlow çš„è®­ç»ƒå¾ªç¯æˆ– `Trainer` API ä¸­ä½¿ç”¨ ğŸ¤— Transformers æä¾›çš„æ¨¡å‹ |
| [å¿«é€Ÿä¸Šæ‰‹ï¼šå¾®è°ƒå’Œç”¨ä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples) | ä¸ºå„ç§ä»»åŠ¡æä¾›çš„ç”¨ä¾‹è„šæœ¬ |
| [æ¨¡å‹å…±äº«å’Œä¸Šä¼ ](https://huggingface.co/docs/transformers/model_sharing)              | å’Œç¤¾åŒºä¸Šä¼ å’Œåˆ†äº«ä½ å¾®è°ƒçš„æ¨¡å‹ |

## å¼•ç”¨

æˆ‘ä»¬å·²å°†è¯¥åº“å¯¹åº”çš„[è®ºæ–‡](https://www.aclweb.org/anthology/2020.emnlp-demos.6/)æ­£å¼å‘è¡¨ï¼Œå¦‚æœä½ ä½¿ç”¨äº† ğŸ¤— Transformers åº“ï¼Œè¯·å¼•ç”¨:

```bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
```
