<!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<p align="center">
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <a href="https://github.com/huggingface/transformers/">English</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_zh-hans.md">ç®€ä½“ä¸­æ–‡</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_zh-hant.md">ç¹é«”ä¸­æ–‡</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_ko.md">í•œêµ­ì–´</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_es.md">EspaÃ±ol</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_ja.md">æ—¥æœ¬èª</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_hd.md">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_ru.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_pt-br.md">Ğ ortuguÃªs</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_te.md">à°¤à±†à°²à±à°—à±</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_fr.md">FranÃ§ais</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_de.md">Deutsch</a> |
        <b>TÃ¼rkÃ§e</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/README_vi.md">Tiáº¿ng Viá»‡t</a> |
    </p>
</h4>

<h3 align="center">
    <p>JAX, PyTorch ve TensorFlow iÃ§in son teknoloji Makine Ã–ÄŸrenimi</p>
</h3>

<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>

ğŸ¤— Transformers, metin, gÃ¶rÃ¼ntÃ¼ ve ses gibi farklÄ± yÃ¶ntemler Ã¼zerinde gÃ¶revleri gerÃ§ekleÅŸtirmek iÃ§in binlerce Ã¶nceden eÄŸitilmiÅŸ model saÄŸlar.

Bu modeller aÅŸaÄŸÄ±dakilere uygulanabilir:

* ğŸ“ Metin sÄ±nÄ±flandÄ±rma, bilgi Ã§Ä±karma, soru yanÄ±tlama, Ã¶zetleme, Ã§eviri ve metin oluÅŸturma gibi gÃ¶revler iÃ§in 100'den fazla dilde metin.
* ğŸ–¼ï¸ GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, nesne algÄ±lama ve segmentasyon gibi gÃ¶revler iÃ§in gÃ¶rÃ¼ntÃ¼ler.
* ğŸ—£ï¸ KonuÅŸma tanÄ±ma ve ses sÄ±nÄ±flandÄ±rmasÄ± gibi gÃ¶revler iÃ§in ses.

TransformatÃ¶r modelleri ayrÄ±ca aÅŸaÄŸÄ±daki gÃ¶revleri de yerine getirebilir: **birkaÃ§ yÃ¶ntemin bir araya getirilmesi**, tablo soru cevaplama, optik karakter tanÄ±ma, taranan belgelerden bilgi Ã§Ä±karma, video sÄ±nÄ±flandÄ±rma ve gÃ¶rsel soru cevaplama gibi.

ğŸ¤— Transformers, bu Ã¶nceden eÄŸitilmiÅŸ modelleri belirli bir metin Ã¼zerinde hÄ±zlÄ± bir ÅŸekilde indirip kullanmanÄ±z, bunlara kendi veri kÃ¼melerinizde ince ayar yapmanÄ±z ve ardÄ±ndan bunlarÄ± topluluÄŸumuzla paylaÅŸmanÄ±z iÃ§in API'ler saÄŸlar [model hub](https://huggingface.co/models). AynÄ± zamanda, bir mimariyi tanÄ±mlayan her python modÃ¼lÃ¼ tamamen baÄŸÄ±msÄ±zdÄ±r ve hÄ±zlÄ± araÅŸtÄ±rma deneylerine olanak saÄŸlayacak ÅŸekilde deÄŸiÅŸtirilebilir.

ğŸ¤— Transformers en popÃ¼ler Ã¼Ã§ derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi tarafÄ±ndan desteklenmektedir â€” [Jax](https://jax.readthedocs.io/en/latest/), [PyTorch](https://pytorch.org/) ve [TensorFlow](https://www.tensorflow.org/)â€” aralarÄ±nda kusursuz bir entegrasyonla. Ã‡Ä±karÄ±m yapmak iÃ§in diÄŸeriyle yÃ¼klemeden Ã¶nce modellerinizi biriyle eÄŸitmek kolaydÄ±r.

## Ã‡evrimiÃ§i demolar

Modellerimizin Ã§oÄŸunu doÄŸrudan sayfalarÄ±nda test edebilirsiniz. [model hub](https://huggingface.co/models). Biz bunu da [private model hosting, versioning, & an inference API](https://huggingface.co/pricing) kamu ve Ã¶zel modeller iÃ§in sunuyoruz.

Ä°ÅŸte birkaÃ§ Ã¶rnek:

DoÄŸal Dil Ä°ÅŸlemede:
- [Masked word completion with BERT](https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)
- [Named Entity Recognition with Electra](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)
- [Text generation with Mistral](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)
- [Natural Language Inference with RoBERTa](https://huggingface.co/FacebookAI/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal)
- [Summarization with BART](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)
- [Question answering with DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species)
- [Translation with T5](https://huggingface.co/google-t5/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin)

Bilgisayar GÃ¶rÃ¼ÅŸÃ¼nde:
- [Image classification with ViT](https://huggingface.co/google/vit-base-patch16-224)
- [Object Detection with DETR](https://huggingface.co/facebook/detr-resnet-50)
- [Semantic Segmentation with SegFormer](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512)
- [Panoptic Segmentation with Mask2Former](https://huggingface.co/facebook/mask2former-swin-large-coco-panoptic)
- [Depth Estimation with Depth Anything](https://huggingface.co/docs/transformers/main/model_doc/depth_anything)
- [Video Classification with VideoMAE](https://huggingface.co/docs/transformers/model_doc/videomae)
- [Universal Segmentation with OneFormer](https://huggingface.co/shi-labs/oneformer_ade20k_dinat_large)

Seste:
- [Automatic Speech Recognition with Whisper](https://huggingface.co/openai/whisper-large-v3)
- [Keyword Spotting with Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks)
- [Audio Classification with Audio Spectrogram Transformer](https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593)

Ã‡ok modlu gÃ¶revlerde:
- [Table Question Answering with TAPAS](https://huggingface.co/google/tapas-base-finetuned-wtq)
- [Visual Question Answering with ViLT](https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)
- [Image captioning with LLaVa](https://huggingface.co/llava-hf/llava-1.5-7b-hf)
- [Zero-shot Image Classification with SigLIP](https://huggingface.co/google/siglip-so400m-patch14-384)
- [Document Question Answering with LayoutLM](https://huggingface.co/impira/layoutlm-document-qa)
- [Zero-shot Video Classification with X-CLIP](https://huggingface.co/docs/transformers/model_doc/xclip)
- [Zero-shot Object Detection with OWLv2](https://huggingface.co/docs/transformers/en/model_doc/owlv2)
- [Zero-shot Image Segmentation with CLIPSeg](https://huggingface.co/docs/transformers/model_doc/clipseg)
- [Automatic Mask Generation with SAM](https://huggingface.co/docs/transformers/model_doc/sam)


## Transformers'Ä± kullanan 100 proje

Transformers, Ã¶nceden eÄŸitilmiÅŸ modellerin kullanÄ±mÄ±na yÃ¶nelik bir araÃ§ setinden daha fazlasÄ±dÄ±r: kendisi ve Hugging Face Hub etrafÄ±nda inÅŸa edilen bir proje topluluÄŸudur. Transformers'Ä±n geliÅŸtiricilerin, araÅŸtÄ±rmacÄ±larÄ±n, Ã¶ÄŸrencilerin, profesÃ¶rlerin, mÃ¼hendislerin ve herkesin hayallerindeki projeleri inÅŸa etmelerine olanak saÄŸlamasÄ±nÄ± istiyoruz.

Transformers'Ä±n 100.000 yÄ±ldÄ±zÄ±nÄ± kutlamak iÃ§in dikkatleri topluluÄŸa yÃ¶neltmeye karar verdik ve [awesome-transformers](./awesome-transformers.md) 100'Ã¼ listeleyen sayfa
trafolarÄ±n yakÄ±nÄ±nda inÅŸa edilen inanÄ±lmaz projeler.

Listede yer almasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z bir projeye sahipseniz veya onu kullanÄ±yorsanÄ±z, lÃ¼tfen eklemek iÃ§in bir PR aÃ§Ä±n!

## Hugging Face ekibinden Ã¶zel destek arÄ±yorsanÄ±z

<a target="_blank" href="https://huggingface.co/support">
    <img alt="HuggingFace Expert Acceleration Program" src="https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png" style="max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);">
</a><br>

## HÄ±zlÄ± tur

Belirli bir girdide (metin, resim, ses, ...) bir modeli hemen kullanmak iÃ§in `pipeline` API'sini saÄŸlÄ±yoruz. Pipelines, Ã¶nceden eÄŸitilmiÅŸ bir modeli, o modelin eÄŸitimi sÄ±rasÄ±nda kullanÄ±lan Ã¶n iÅŸlemeyle birlikte gruplandÄ±rÄ±r. Olumlu ve olumsuz metinleri sÄ±nÄ±flandÄ±rmak iÃ§in pipeline'Ä± hÄ±zlÄ± bir ÅŸekilde nasÄ±l kullanacaÄŸÄ±nÄ±z aÅŸaÄŸÄ±da aÃ§Ä±klanmÄ±ÅŸtÄ±r:

```python
>>> from transformers import pipeline

# Allocate a pipeline for sentiment-analysis
>>> classifier = pipeline('sentiment-analysis')
>>> classifier('TransformatÃ¶r deposuna boru hattÄ±nÄ± tanÄ±tmaktan Ã§ok mutluyuz.')
[{'label': 'POSITIVE', 'score': 0.9996980428695679}]
```

Ä°kinci kod satÄ±rÄ±, iÅŸlem hattÄ± tarafÄ±ndan kullanÄ±lan Ã¶nceden eÄŸitilmiÅŸ modeli indirir ve Ã¶nbelleÄŸe alÄ±rken, Ã¼Ã§Ã¼ncÃ¼sÃ¼ onu verilen metin Ã¼zerinde deÄŸerlendirir. Burada cevap %99,97 gÃ¼venle "olumlu"dur.

NLP'de ve aynÄ± zamanda bilgisayarla gÃ¶rme ve konuÅŸmada birÃ§ok gÃ¶revin Ã¶nceden eÄŸitilmiÅŸ, kullanÄ±ma hazÄ±r bir `pipeline` vardÄ±r. Ã–rneÄŸin bir gÃ¶rÃ¼ntÃ¼de tespit edilen nesneleri kolaylÄ±kla Ã§Ä±kartabiliriz:

``` python
>>> import requests
>>> from PIL import Image
>>> from transformers import pipeline

# Download an image with cute cats
>>> url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png"
>>> image_data = requests.get(url, stream=True).raw
>>> image = Image.open(image_data)

# Allocate a pipeline for object detection
>>> object_detector = pipeline('object-detection')
>>> object_detector(image)
[{'score': 0.9982201457023621,
  'label': 'remote',
  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},
 {'score': 0.9960021376609802,
  'label': 'remote',
  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},
 {'score': 0.9954745173454285,
  'label': 'couch',
  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},
 {'score': 0.9988006353378296,
  'label': 'cat',
  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},
 {'score': 0.9986783862113953,
  'label': 'cat',
  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]
```

Burada, gÃ¶rÃ¼ntÃ¼de tespit edilen nesnelerin bir listesini, nesneyi Ã§evreleyen bir kutu ve bir gÃ¼ven puanÄ±yla birlikte alÄ±yoruz. Soldaki orijinal gÃ¶rÃ¼ntÃ¼, saÄŸda ise tahminler gÃ¶steriliyor:

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png" width="400"></a>
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample_post_processed.png" width="400"></a>
</h3>

`pipeline` API'si tarafÄ±ndan desteklenen gÃ¶revler hakkÄ±nda daha fazla bilgiyi ÅŸu adreste bulabilirsiniz: [this tutorial](https://huggingface.co/docs/transformers/task_summary).

Ek olarak `pipeline`, Ã–nceden eÄŸitilmiÅŸ modellerden herhangi birini size verilen gÃ¶revde indirmek ve kullanmak iÃ§in tek yapmanÄ±z gereken Ã¼Ã§ satÄ±r koddur. Ä°ÅŸte PyTorch sÃ¼rÃ¼mÃ¼:
```python
>>> from transformers import AutoTokenizer, AutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = AutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("Hello world!", return_tensors="pt")
>>> outputs = model(**inputs)
```

Ve iÅŸte TensorFlow'un eÅŸdeÄŸer (muadil) kodu:
```python
>>> from transformers import AutoTokenizer, TFAutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = TFAutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("Hello world!", return_tensors="tf")
>>> outputs = model(**inputs)
```

Tokenizer, Ã¶nceden eÄŸitilmiÅŸ modelin beklediÄŸi tÃ¼m Ã¶n iÅŸlemlerden sorumludur ve doÄŸrudan tek bir dize (yukarÄ±daki Ã¶rneklerde olduÄŸu gibi) veya bir liste Ã¼zerinden Ã§aÄŸrÄ±labilir. AÅŸaÄŸÄ± akÄ±ÅŸ kodunda kullanabileceÄŸiniz veya ** argÃ¼man aÃ§ma operatÃ¶rÃ¼nÃ¼ kullanarak doÄŸrudan modelinize aktarabileceÄŸiniz bir sÃ¶zlÃ¼k Ã§Ä±ktÄ±sÄ± alacaktÄ±r.

Modelin kendisi dÃ¼zenli [Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) veya bir [TensorFlow `tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) (arka ucunuza baÄŸlÄ± olarak) her zamanki gibi kullanabilirsiniz. [This tutorial](https://huggingface.co/docs/transformers/training) bÃ¶yle bir modelin klasik bir PyTorch veya TensorFlow eÄŸitim dÃ¶ngÃ¼sÃ¼ne nasÄ±l entegre edileceÄŸini veya yeni bir veri kÃ¼mesinde hÄ±zlÄ± bir ÅŸekilde ince ayar yapmak iÃ§in `Trainer` API'mizin nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± aÃ§Ä±klÄ±yor.

## Neden Transformers kullanmalÄ±yÄ±m?

1. KullanÄ±mÄ± kolay son teknoloji modeller:
    - DoÄŸal dil anlama ve oluÅŸturma, bilgisayarlÄ± gÃ¶rme ve ses gÃ¶revlerinde yÃ¼ksek performans.
    - EÄŸitimciler ve uygulayÄ±cÄ±lar iÃ§in giriÅŸ engeli dÃ¼ÅŸÃ¼ktÃ¼r.
    - Ã–ÄŸrenilecek yalnÄ±zca Ã¼Ã§ sÄ±nÄ±fla kullanÄ±cÄ±ya yÃ¶nelik az sayÄ±da soyutlama.
    - Ã–nceden eÄŸitilmiÅŸ tÃ¼m modellerimizi kullanmaya yÃ¶nelik birleÅŸik bir API.

1. Daha dÃ¼ÅŸÃ¼k bilgi iÅŸlem maliyetleri, daha kÃ¼Ã§Ã¼k karbon ayak izi:
    - AraÅŸtÄ±rmacÄ±lar her zaman yeniden eÄŸitmek yerine eÄŸitilmiÅŸ modelleri paylaÅŸabilirler.
    - UygulayÄ±cÄ±lar hesaplama sÃ¼resini ve Ã¼retim maliyetlerini azaltabilir.
    - TÃ¼m yÃ¶ntemlerde 400.000'den fazla Ã¶nceden eÄŸitilmiÅŸ model iÃ§eren dÃ¼zinelerce mimari.

1. Bir modelin kullanÄ±m Ã¶mrÃ¼nÃ¼n her bÃ¶lÃ¼mÃ¼ iÃ§in doÄŸru Ã§erÃ§eveyi seÃ§in:
    - En son teknolojiye sahip modelleri 3 satÄ±r kodla eÄŸitin.
    - Tek bir modeli dilediÄŸiniz gibi TF2.0/PyTorch/JAX Ã§erÃ§eveleri arasÄ±nda taÅŸÄ±yÄ±n.
    - EÄŸitim, deÄŸerlendirme ve Ã¼retim iÃ§in doÄŸru Ã§erÃ§eveyi sorunsuz bir ÅŸekilde seÃ§in.

1. Bir modeli veya Ã¶rneÄŸi ihtiyaÃ§larÄ±nÄ±za gÃ¶re kolayca Ã¶zelleÅŸtirin:
    - Orijinal yazarlarÄ± tarafÄ±ndan yayÄ±nlanan sonuÃ§larÄ± yeniden Ã¼retmek iÃ§in her mimariye Ã¶rnekler sunuyoruz.
    - Modelin iÃ§ kÄ±sÄ±mlarÄ± mÃ¼mkÃ¼n olduÄŸunca tutarlÄ± bir ÅŸekilde ortaya Ã§Ä±kar.
    - Model dosyalarÄ± hÄ±zlÄ± deneyler iÃ§in kÃ¼tÃ¼phaneden baÄŸÄ±msÄ±z olarak kullanÄ±labilir.

## Neden Transformers'Ä± kullanmamalÄ±yÄ±m?

- Bu kÃ¼tÃ¼phane, sinir aÄŸlarÄ± iÃ§in yapÄ± taÅŸlarÄ±ndan oluÅŸan modÃ¼ler bir araÃ§ kutusu deÄŸildir. Model dosyalarÄ±ndaki kod, ek soyutlamalarla bilerek yeniden dÃ¼zenlenmez; bÃ¶ylece araÅŸtÄ±rmacÄ±lar, ek soyutlamalara/dosyalara dalmadan her model Ã¼zerinde hÄ±zlÄ± bir ÅŸekilde yineleme yapabilir.
- EÄŸitim API'sinin herhangi bir model Ã¼zerinde Ã§alÄ±ÅŸmasÄ± amaÃ§lanmamÄ±ÅŸtÄ±r ancak kitaplÄ±k tarafÄ±ndan saÄŸlanan modellerle Ã§alÄ±ÅŸacak ÅŸekilde optimize edilmiÅŸtir. Genel makine Ã¶ÄŸrenimi dÃ¶ngÃ¼leri iÃ§in baÅŸka bir kitaplÄ±k kullanmalÄ±sÄ±nÄ±z (muhtemel olarak, [Accelerate](https://huggingface.co/docs/accelerate)).
- MÃ¼mkÃ¼n olduÄŸu kadar Ã§ok kullanÄ±m senaryosu sunmaya Ã§alÄ±ÅŸÄ±rken, senaryolarÄ±mÄ±zdaki komut dosyalarÄ± [examples folder](https://github.com/huggingface/transformers/tree/main/examples) sadece bu: Ã¶rnekler. Ã–zel sorununuz Ã¼zerinde kullanÄ±ma hazÄ±r bir ÅŸekilde Ã§alÄ±ÅŸmamalarÄ± ve bunlarÄ± ihtiyaÃ§larÄ±nÄ±za uyarlamak iÃ§in birkaÃ§ kod satÄ±rÄ±nÄ± deÄŸiÅŸtirmeniz gerekmesi beklenir.

## Kurulum

### pip Kullanarak

Bu depo Python 3.8+, Flax 0.4.1+, PyTorch 1.11+ ve TensorFlow 2.6+ Ã¼zerinde test edilmiÅŸtir.

ğŸ¤— Transformers uygulamasÄ±nÄ± iÃ§inde indirmeniz gerekir [virtual environment](https://docs.python.org/3/library/venv.html).Python sanal ortamlarÄ±na aÅŸina deÄŸilseniz, ÅŸuraya gÃ¶z atÄ±n: [user guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).

Ã–ncelikle kullanacaÄŸÄ±nÄ±z Python sÃ¼rÃ¼mÃ¼yle sanal bir ortam oluÅŸturun ve etkinleÅŸtirin.

Daha sonra Flax, PyTorch veya TensorFlow'dan en az birini yÃ¼klemeniz gerekecektir.
BakÄ±nÄ±z [TensorFlow installation page](https://www.tensorflow.org/install/), [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) and/or [Flax](https://github.com/google/flax#quick-install) and [Jax](https://github.com/google/jax#installation) platformunuza Ã¶zel kurulum komutuyla ilgili kurulum sayfalarÄ±.

Bu back-end'lerden biri kurulduÄŸunda, ğŸ¤— TransformatÃ¶rler pip kullanÄ±larak aÅŸaÄŸÄ±daki gibi kurulabilir:

```bash
pip install transformers
```

Ã–rneklerle oynamak istiyorsanÄ±z veya kodun son noktasÄ±na ihtiyacÄ±nÄ±z varsa ve yeni sÃ¼rÃ¼mÃ¼ sabÄ±rsÄ±zlÄ±kla bekliyorsanÄ±z, [kÃ¼tÃ¼phaneyi kaynaÄŸÄ±ndan indirin](https://huggingface.co/docs/transformers/installation#installing-from-source).

### conda Kullanarak

ğŸ¤— Conda kullanÄ±larak Transformers aÅŸaÄŸÄ±daki gibi kurulabilir:

```shell script
conda install conda-forge::transformers
```

> **_NOT:_**  `transformers`'Ä±   `huggingface` Ã¼zerinden indirme kanalÄ± kullanÄ±mdan kaldÄ±rÄ±ldÄ±.

Conda ile nasÄ±l kurulacaÄŸÄ±nÄ± gÃ¶rmek iÃ§in Flax, PyTorch veya TensorFlow'un kurulum sayfalarÄ±nÄ± takip edin.

> **_NOT:_** Windows'ta Ã¶nbelleÄŸe alma Ã¶zelliÄŸinden yararlanmak iÃ§in GeliÅŸtirici Modunu etkinleÅŸtirmeniz istenebilir. Bu sizin iÃ§in bir seÃ§enek deÄŸilse lÃ¼tfen bize bildirin. [bu problemi](https://github.com/huggingface/huggingface_hub/issues/1062).

## Model mimarileri

**[TÃ¼m model kontrol noktalarÄ±](https://huggingface.co/models)** ğŸ¤— Transformers, huggingface.co'dan sorunsuz bir ÅŸekilde entegre edilmiÅŸtir.[model hub](https://huggingface.co/models), wburada doÄŸrudan tarafÄ±ndan yÃ¼klenirler [kullanÄ±cÄ±](https://huggingface.co/users) ve [organizasyonlar](https://huggingface.co/organizations).

AnlÄ±k olarak kontrol noktalarÄ± sayÄ±sÄ±: ![](https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen)

ğŸ¤— Transformers ÅŸu anda aÅŸaÄŸÄ±daki mimarileri sunmaktadÄ±r: buradan [bakÄ±n](https://huggingface.co/docs/transformers/model_summary) her birinin Ã¼st dÃ¼zey bir Ã¶zeti iÃ§in.

Her modelin Flax, PyTorch veya TensorFlow'da bir uygulamasÄ± olup olmadÄ±ÄŸÄ±nÄ± veya ğŸ¤— Tokenizers kÃ¼tÃ¼phanesi tarafÄ±ndan desteklenen iliÅŸkili bir tokenizer'a sahip olup olmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in bakÄ±nÄ±z [bu tabloya](https://huggingface.co/docs/transformers/index#supported-frameworks).

Bu uygulamalar Ã§eÅŸitli veri kÃ¼melerinde test edilmiÅŸtir (Ã¶rnek komut dosyalarÄ±na bakÄ±n) ve orijinal uygulamalarÄ±n performansÄ±yla eÅŸleÅŸmelidir. Performansla ilgili daha fazla ayrÄ±ntÄ±yÄ± Ã–rnekler bÃ¶lÃ¼mÃ¼nde bulabilirsiniz. [dokÃ¼man](https://github.com/huggingface/transformers/tree/main/examples).


## Daha fazlasÄ±nÄ± Ã¶ÄŸrenin

| BÃ¶lÃ¼m | AÃ§Ä±klama |
|-|-|
| [DokÃ¼man](https://huggingface.co/docs/transformers/) | Tam API belgeleri ve eÄŸitimleri |
| [GÃ¶rev Ã–zeti](https://huggingface.co/docs/transformers/task_summary) | ğŸ¤— Transformers tarafÄ±ndan desteklenen gÃ¶revler |
| [Ã–n iÅŸleme eÄŸitimi](https://huggingface.co/docs/transformers/preprocessing) | Modellere veri hazÄ±rlamak iÃ§in `Tokenizer` sÄ±nÄ±fÄ±nÄ± kullanma |
| [EÄŸitim ve ince ayar](https://huggingface.co/docs/transformers/training) | ğŸ¤— Transformers tarafÄ±ndan saÄŸlanan modelleri PyTorch/TensorFlow eÄŸitim dÃ¶ngÃ¼sÃ¼nde ve `Tokenizer` API'sinde kullanma |
| [HÄ±zlÄ± tur: Ä°nce ayar/kullanÄ±m komut dosyalarÄ±](https://github.com/huggingface/transformers/tree/main/examples) | Ã‡ok Ã§eÅŸitli gÃ¶revlerde modellerde ince ayar yapmak iÃ§in Ã¶rnek komut dosyalarÄ± |
| [Model paylaÅŸÄ±mÄ± ve yÃ¼kleme](https://huggingface.co/docs/transformers/model_sharing) | Ä°nce ayarlÄ± modellerinizi yÃ¼kleyin ve toplulukla paylaÅŸÄ±n |

## AlÄ±ntÄ±

Biz artÄ±k bir [kaÄŸÄ±t](https://www.aclweb.org/anthology/2020.emnlp-demos.6/) sahibiyiz. ğŸ¤— Transformers kÃ¼tÃ¼phanesi iÃ§in alÄ±ntÄ± yapabilirsiniz:
```bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
```
