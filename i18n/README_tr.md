<!--- 
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers KÃ¼tÃ¼phanesi" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<p align="center">
    <a href="https://huggingface.co/models"><img alt="Hub'daki Kontrol NoktalarÄ±" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub sÃ¼rÃ¼mÃ¼" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="KatkÄ±da Bulunan SÃ¶zleÅŸmesi" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <b>Ä°ngilizce</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">ç®€ä½“ä¸­æ–‡</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">ç¹é«”ä¸­æ–‡</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">í•œêµ­ì–´</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">EspaÃ±ol</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">æ—¥æœ¬èª</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">PortuguÃªs</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">à°¤à±†à°²à±à°—à±</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">FranÃ§ais</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiáº¿ng Viá»‡t</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">Ø§Ø±Ø¯Ùˆ</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_tr.md">TÃ¼rkÃ§e</a>
    </p>
</h4>

<h3 align="center">
    <p>Ã‡Ä±karÄ±m ve eÄŸitim iÃ§in en son teknoloji Ã¶nceden eÄŸitilmiÅŸ modeller</p>
</h3>

<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>

Transformers, metin, bilgisayar gÃ¶rÃ¼sÃ¼, ses, video ve multimodal modeller iÃ§in Ã¶nceden eÄŸitilmiÅŸ bir kÃ¼tÃ¼phanedir ve Ã§Ä±karÄ±m ve eÄŸitim iÃ§in kullanÄ±labilir. Transformers'Ä± kullanarak modelleri kendi verilerinizle ince ayar yapabilir, Ã§Ä±karÄ±m uygulamalarÄ± oluÅŸturabilir ve Ã§oklu modalitelerde yapay zeka kullanÄ±m durumlarÄ±nÄ± gerÃ§ekleÅŸtirebilirsiniz.

[Hugging Face Hub](https://huggingface.com/models) Ã¼zerinde Transformers iÃ§in 500K'dan fazla [model kontrol noktasÄ±](https://huggingface.co/models?library=transformers&sort=trending) bulunmaktadÄ±r ve bunlarÄ± kullanabilirsiniz.

BugÃ¼n [Hub](https://huggingface.co/)'Ä± keÅŸfedin, bir model bulun ve Transformers'Ä± kullanarak hemen baÅŸlayÄ±n.

## Kurulum

Transformers, Python 3.9+ ile Ã§alÄ±ÅŸÄ±r ve [PyTorch](https://pytorch.org/get-started/locally/) 2.1+, [TensorFlow](https://www.tensorflow.org/install/pip) 2.6+ ve [Flax](https://flax.readthedocs.io/en/latest/) 0.4.1+ ile uyumludur.

[venv](https://docs.python.org/3/library/venv.html) veya [uv](https://docs.astral.sh/uv/) ile sanal bir ortam oluÅŸturun ve etkinleÅŸtirin, uv hÄ±zlÄ± bir Rust tabanlÄ± Python paket ve proje yÃ¶neticisidir.

```py
# venv
python -m venv .my-env
source .my-env/bin/activate
# uv
uv venv .my-env
source .my-env/bin/activate
```

Sanal ortamÄ±nÄ±za Transformers'Ä± kurun.

```py
# pip
pip install "transformers[torch]"

# uv
uv pip install "transformers[torch]"
```

KÃ¼tÃ¼phanedeki en son deÄŸiÅŸiklikleri almak istiyorsanÄ±z veya katkÄ±da bulunmakla ilgileniyorsanÄ±z, Transformers'Ä± kaynak kodundan kurun. Ancak, *en son* sÃ¼rÃ¼m stabil olmayabilir. Bir hata ile karÅŸÄ±laÅŸÄ±rsanÄ±z lÃ¼tfen bir [issue](https://github.com/huggingface/transformers/issues) aÃ§Ä±n.

```shell
git clone https://github.com/huggingface/transformers.git
cd transformers

# pip
pip install .[torch]

# uv
uv pip install .[torch]
```

## HÄ±zlÄ± BaÅŸlangÄ±Ã§

[Pipeline](https://huggingface.co/docs/transformers/pipeline_tutorial) API'si ile Transformers'Ä± hemen kullanmaya baÅŸlayÄ±n. `Pipeline`, metin, ses, gÃ¶rÃ¼ntÃ¼ ve multimodal gÃ¶revleri destekleyen yÃ¼ksek seviyeli bir Ã§Ä±karÄ±m sÄ±nÄ±fÄ±dÄ±r. GiriÅŸin Ã¶n iÅŸlemesini yapar ve uygun Ã§Ä±ktÄ±yÄ± dÃ¶ndÃ¼rÃ¼r.

Metin oluÅŸturma iÃ§in kullanmak istediÄŸiniz modeli belirterek bir pipeline oluÅŸturun. Model indirilir ve Ã¶nbelleÄŸe alÄ±nÄ±r, bÃ¶ylece tekrar kolayca kullanabilirsiniz. Son olarak, modeli tetiklemek iÃ§in bazÄ± metinler geÃ§irin.

```py
from transformers import pipeline

pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]
```

Bir model ile sohbet etmek iÃ§in kullanÄ±m modeli aynÄ±dÄ±r. Tek fark, sizin ve sistem arasÄ±ndaki bir sohbet geÃ§miÅŸi oluÅŸturmanÄ±z gerektiÄŸidir (bu `Pipeline` iÃ§in girdidir).

> [!Ä°PUCU]
> Bir model ile komut satÄ±rÄ±ndan da sohbet edebilirsiniz.
> ```shell
> transformers chat Qwen/Qwen2.5-0.5B-Instruct
> ```

```py
import torch
from transformers import pipeline

chat = [
    {"role": "system", "content": "You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986."},
    {"role": "user", "content": "Hey, can you tell me any fun things to do in New York?"}
]

pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
```

AÅŸaÄŸÄ±daki Ã¶rnekleri geniÅŸletin ve `Pipeline`'Ä±n farklÄ± modaliteler ve gÃ¶revler iÃ§in nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼n.

<details>
<summary>Otomatik konuÅŸma tanÄ±ma</summary>

```py
from transformers import pipeline

pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

</details>

<details>
<summary>GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma</summary>

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>

```py
from transformers import pipeline

pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
```

</details>

<details>
<summary>GÃ¶rsel soru cevaplama</summary>

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>

```py
from transformers import pipeline

pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
```

</details>

## Neden Transformers kullanmalÄ±yÄ±m?

1. KullanÄ±mÄ± kolay en son teknoloji modeller:
    - DoÄŸal dil anlama ve oluÅŸturma, bilgisayar gÃ¶rÃ¼sÃ¼, ses, video ve multimodal gÃ¶revlerde yÃ¼ksek performans.
    - AraÅŸtÄ±rmacÄ±lar, mÃ¼hendisler ve geliÅŸtiriciler iÃ§in dÃ¼ÅŸÃ¼k giriÅŸ engeli.
    - KullanÄ±cÄ±ya yÃ¶nelik sadece Ã¼Ã§ sÄ±nÄ±f Ã¶ÄŸrenmek iÃ§in birkaÃ§ soyutlama.
    - TÃ¼m Ã¶nceden eÄŸitilmiÅŸ modellerimiz iÃ§in birleÅŸtirilmiÅŸ bir API.

2. Daha dÃ¼ÅŸÃ¼k hesaplama maliyetleri, daha kÃ¼Ã§Ã¼k karbon ayak izi:
    - SÄ±fÄ±rdan eÄŸitmek yerine eÄŸitilmiÅŸ modelleri paylaÅŸÄ±n.
    - Hesaplama sÃ¼resini ve Ã¼retim maliyetlerini azaltÄ±n.
    - TÃ¼m modalitelerde 1M'dan fazla Ã¶nceden eÄŸitilmiÅŸ kontrol noktasÄ± ile dÃ¼zinece model mimarisi.

3. Bir modelin yaÅŸam dÃ¶ngÃ¼sÃ¼nÃ¼n her aÅŸamasÄ± iÃ§in doÄŸru Ã§erÃ§eveyi seÃ§in:
    - 3 satÄ±r kodla en son teknoloji modelleri eÄŸitin.
    - Bir modeli PyTorch/JAX/TF2.0 Ã§erÃ§eveleri arasÄ±nda istediÄŸiniz gibi taÅŸÄ±yÄ±n.
    - EÄŸitim, deÄŸerlendirme ve Ã¼retim iÃ§in doÄŸru Ã§erÃ§eveyi seÃ§in.

4. Bir modeli veya Ã¶rneÄŸi ihtiyaÃ§larÄ±nÄ±za kolayca Ã¶zelleÅŸtirin:
    - Her mimari iÃ§in Ã¶rnekler saÄŸlÄ±yoruz, bÃ¶ylece orijinal yazarlarÄ± tarafÄ±ndan yayÄ±nlanan sonuÃ§larÄ± yeniden Ã¼retebilirsiniz.
    - Model iÃ§leri mÃ¼mkÃ¼n olduÄŸunca tutarlÄ± bir ÅŸekilde aÃ§Ä±klanmÄ±ÅŸtÄ±r.
    - HÄ±zlÄ± deneyler iÃ§in model dosyalarÄ± kÃ¼tÃ¼phaneden baÄŸÄ±msÄ±z olarak kullanÄ±labilir.

<a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br>

## Neden Transformers kullanmamalÄ±yÄ±m?

- Bu kÃ¼tÃ¼phane, sinir aÄŸlarÄ± iÃ§in modÃ¼ler bir araÃ§ kutusu deÄŸildir. Model dosyalarÄ±ndaki kod, araÅŸtÄ±rmacÄ±larÄ±n ek soyutlamalar/dosyalarla uÄŸraÅŸmadan her bir model Ã¼zerinde hÄ±zlÄ± bir ÅŸekilde Ã§alÄ±ÅŸabilmesi iÃ§in kasÄ±tlÄ± olarak ek soyutlamalarla yeniden dÃ¼zenlenmemiÅŸtir.
- EÄŸitim API'si, Transformers tarafÄ±ndan saÄŸlanan PyTorch modelleriyle Ã§alÄ±ÅŸacak ÅŸekilde optimize edilmiÅŸtir. Genel makine Ã¶ÄŸrenimi dÃ¶ngÃ¼leri iÃ§in baÅŸka bir kÃ¼tÃ¼phane kullanmalÄ±sÄ±nÄ±z, Ã¶rneÄŸin [Accelerate](https://huggingface.co/docs/accelerate).
- [Ã–rnek betikler](https://github.com/huggingface/transformers/tree/main/examples) sadece *Ã¶rneklerdir*. Belirli kullanÄ±m durumunuzda doÄŸrudan Ã§alÄ±ÅŸmayabilirler ve Ã§alÄ±ÅŸmasÄ± iÃ§in kodu uyarlamanÄ±z gerekebilir.

## Transformers kullanan 100 proje

Transformers, Ã¶nceden eÄŸitilmiÅŸ modelleri kullanmak iÃ§in bir araÃ§ setinden daha fazlasÄ±dÄ±r, aynÄ± zamanda Hugging Face Hub etrafÄ±nda inÅŸa edilmiÅŸ projelerin bir topluluÄŸudur. Transformers'Ä± kullanarak geliÅŸtiricilerin, araÅŸtÄ±rmacÄ±larÄ±n, Ã¶ÄŸrencilerin, profesÃ¶rlerin, mÃ¼hendislerin ve diÄŸer herkesin hayal ettikleri projeleri oluÅŸturmalarÄ±nÄ± saÄŸlamak istiyoruz.

Transformers'Ä±n 100.000 yÄ±ldÄ±zÄ±nÄ± kutlamak iÃ§in, Transformers ile inÅŸa edilmiÅŸ 100 inanÄ±lmaz projeyi listeleyen [awesome-transformers](./awesome-transformers.md) sayfasÄ± ile topluluÄŸu Ã¶ne Ã§Ä±karmak istedik.

Listeye dahil edilmesi gerektiÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z bir projeniz varsa veya kullanÄ±yorsanÄ±z, lÃ¼tfen onu eklemek iÃ§in bir PR aÃ§Ä±n!

## Ã–rnek modeller

Ã‡oÄŸu modelimizi doÄŸrudan [Hub model sayfalarÄ±](https://huggingface.co/models) Ã¼zerinde test edebilirsiniz.

Her modalite iÃ§in Ã§eÅŸitli kullanÄ±m durumlarÄ± iÃ§in birkaÃ§ Ã¶rnek model gÃ¶rmek Ã¼zere aÅŸaÄŸÄ±daki modaliteleri geniÅŸletin.

<details>
<summary>Ses</summary>

- [Whisper](https://huggingface.co/openai/whisper-large-v3-turbo) ile ses sÄ±nÄ±flandÄ±rma
- [Moonshine](https://huggingface.co/UsefulSensors/moonshine) ile otomatik konuÅŸma tanÄ±ma
- [Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks) ile anahtar kelime tespiti
- [Moshi](https://huggingface.co/kyutai/moshiko-pytorch-bf16) ile konuÅŸmadan konuÅŸmaya oluÅŸturma
- [MusicGen](https://huggingface.co/facebook/musicgen-large) ile metinden sese
- [Bark](https://huggingface.co/suno/bark) ile metinden konuÅŸmaya

</details>

<details>
<summary>Bilgisayar GÃ¶rÃ¼ÅŸÃ¼</summary>

- [SAM](https://huggingface.co/facebook/sam-vit-base) ile otomatik maske oluÅŸturma
- [DepthPro](https://huggingface.co/apple/DepthPro-hf) ile derinlik tahmini
- [DINO v2](https://huggingface.co/facebook/dinov2-base) ile gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma
- [SuperGlue](https://huggingface.co/magic-leap-community/superglue_outdoor) ile anahtar nokta tespiti
- [SuperGlue](https://huggingface.co/magic-leap-community/superglue) ile anahtar nokta eÅŸleÅŸtirme
- [RT-DETRv2](https://huggingface.co/PekingU/rtdetr_v2_r50vd) ile nesne tespiti
- [VitPose](https://huggingface.co/usyd-community/vitpose-base-simple) ile poz tahmini
- [OneFormer](https://huggingface.co/shi-labs/oneformer_ade20k_swin_large) ile evrensel segmentasyon
- [VideoMAE](https://huggingface.co/MCG-NJU/videomae-large) ile video sÄ±nÄ±flandÄ±rma

</details>

<details>
<summary>Ã‡oklu Modalite</summary>

- [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B) ile ses veya metinden metne
- [LayoutLMv3](https://huggingface.co/microsoft/layoutlmv3-base) ile belge soru cevaplama
- [Qwen-VL](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct) ile gÃ¶rÃ¼ntÃ¼ veya metinden metne
- [BLIP-2](https://huggingface.co/Salesforce/blip2-opt-2.7b) ile gÃ¶rÃ¼ntÃ¼ aÃ§Ä±klama
- [GOT-OCR2](https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf) ile OCR tabanlÄ± belge anlama
- [TAPAS](https://huggingface.co/google/tapas-base) ile tablo soru cevaplama
- [Emu3](https://huggingface.co/BAAI/Emu3-Gen) ile birleÅŸik Ã§oklu modalite anlama ve oluÅŸturma
- [Llava-OneVision](https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf) ile gÃ¶rÃ¼ntÃ¼den metne
- [Llava](https://huggingface.co/llava-hf/llava-1.5-7b-hf) ile gÃ¶rsel soru cevaplama
- [Kosmos-2](https://huggingface.co/microsoft/kosmos-2-patch14-224) ile gÃ¶rsel referans ifadesi segmentasyonu

</details>

<details>
<summary>NLP</summary>

- [ModernBERT](https://huggingface.co/answerdotai/ModernBERT-base) ile maske kelime tamamlama
- [Gemma](https://huggingface.co/google/gemma-2-2b) ile isimli varlÄ±k tanÄ±ma
- [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1) ile soru cevaplama
- [BART](https://huggingface.co/facebook/bart-large-cnn) ile Ã¶zetleme
- [T5](https://huggingface.co/google-t5/t5-base) ile Ã§eviri
- [Llama](https://huggingface.co/meta-llama/Llama-3.2-1B) ile metin oluÅŸturma
- [Qwen](https://huggingface.co/Qwen/Qwen2.5-0.5B) ile metin sÄ±nÄ±flandÄ±rma

</details>

## AtÄ±f

Åimdi ğŸ¤— Transformers kÃ¼tÃ¼phanesi iÃ§in atÄ±f yapabileceÄŸiniz bir [makale](https://www.aclweb.org/anthology/2020.emnlp-demos.6/)miz var:
```bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
```
