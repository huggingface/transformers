<!---
Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<p align="center">
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <a href="https://github.com/huggingface/transformers/">English</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">ÁÆÄ‰Ωì‰∏≠Êñá</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">ÁπÅÈ´î‰∏≠Êñá</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">ÌïúÍµ≠Ïñ¥</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Espa√±ol</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">Êó•Êú¨Ë™û</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a> |
        <b>–†—É—Å—Å–∫–∏–π</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">–†ortugu√™s</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Fran√ßais</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Ti·∫øng Vi·ªát</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">ÿßÿ±ÿØŸà</a> |
    <p>
</h4>

<h3 align="center">
    <p>–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è JAX, PyTorch –∏ TensorFlow</p>
</h3>

<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>

ü§ó Transformers –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç—ã—Å—è—á–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á, —Ç–∞–∫–∏—Ö –∫–∞–∫ —Ç–µ–∫—Å—Ç, –∑—Ä–µ–Ω–∏–µ –∏ –∞—É–¥–∏–æ.

–≠—Ç–∏ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫:

* üìù –¢–µ–∫—Å—Ç—É –¥–ª—è —Ç–∞–∫–∏—Ö –∑–∞–¥–∞—á, –∫–∞–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –æ–±–æ–±—â–µ–Ω–∏–µ, –ø–µ—Ä–µ–≤–æ–¥, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –±–æ–ª–µ–µ —á–µ–º 100 —è–∑—ã–∫–∞—Ö.
* üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.
* üó£Ô∏è –ê—É–¥–∏–æ –¥–ª—è –∑–∞–¥–∞—á —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∞—É–¥–∏–æ.

–ú–æ–¥–µ–ª–∏ transformers —Ç–∞–∫–∂–µ –º–æ–≥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á, —Ç–∞–∫–∏–µ –∫–∞–∫ –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–ø—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∏–¥–µ–æ –∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.

ü§ó Transformers –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç API –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∏—Ö —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∏–º–∏ —Å —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º –Ω–∞ –Ω–∞—à–µ–º [—Å–∞–π—Ç–µ](https://huggingface.co/models). –í —Ç–æ –∂–µ –≤—Ä–µ–º—è –∫–∞–∂–¥—ã–π python –º–æ–¥—É–ª—å, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∏–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–µ–Ω –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –±—ã—Å—Ç—Ä—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

ü§ó Transformers –æ–ø–∏—Ä–∞–µ—Ç—Å—è –Ω–∞ —Ç—Ä–∏ —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è - [Jax](https://jax.readthedocs.io/en/latest/), [PyTorch](https://pytorch.org/) –∏ [TensorFlow](https://www.tensorflow.org/) - –∏ –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è –º–µ–∂–¥—É –Ω–∏–º–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª–µ–≥–∫–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é –æ–¥–Ω–æ–π –∏–∑ –Ω–∏—Ö, –∞ –∑–∞—Ç–µ–º –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏—Ö –¥–ª—è –≤—ã–≤–æ–¥–æ–≤ —Å –ø–æ–º–æ—â—å—é –¥—Ä—É–≥–æ–π.

## –û–Ω–ª–∞–π–Ω –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è

–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –Ω–∞—à–∏—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ –∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö —Å [—Å–∞–π—Ç–∞](https://huggingface.co/models). –ú—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º [–ø—Ä–∏–≤–∞—Ç–Ω—ã–π —Ö–æ—Å—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π, –∫–æ–Ω—Ç—Ä–æ–ª—å –≤–µ—Ä—Å–∏–π –∏ API –¥–ª—è –≤—ã–≤–æ–¥–æ–≤](https://huggingface.co/pricing) –¥–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –∏ —á–∞—Å—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤:

–í –æ–±–ª–∞—Å—Ç–∏ NLP ( –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ ):
- [–ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é BERT](https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)
- [–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å –ø–æ–º–æ—â—å—é Electra](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)
- [–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é GPT-2](https://huggingface.co/openai-community/gpt2?text=A+long+time+ago%2C+)
- [–í—ã–≤–æ–¥—ã –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ —Å –ø–æ–º–æ—â—å—é RoBERTa](https://huggingface.co/FacebookAI/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal)
- [–û–±–æ–±—â–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é BART](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)
- [–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–º–æ—â—å—é DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species)
- [–ü–µ—Ä–µ–≤–æ–¥ —Å –ø–æ–º–æ—â—å—é T5](https://huggingface.co/google-t5/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin)

–í –æ–±–ª–∞—Å—Ç–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è:
- [–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é ViT](https://huggingface.co/google/vit-base-patch16-224)
- [–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é DETR](https://huggingface.co/facebook/detr-resnet-50)
- [–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é SegFormer](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512)
- [–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–∞–Ω–æ–ø—Ç–∏–∫—É–º–∞ —Å –ø–æ–º–æ—â—å—é MaskFormer](https://huggingface.co/facebook/maskformer-swin-small-coco)
- [–û—Ü–µ–Ω–∫–∞ –≥–ª—É–±–∏–Ω—ã —Å –ø–æ–º–æ—â—å—é DPT](https://huggingface.co/docs/transformers/model_doc/dpt)
- [–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é VideoMAE](https://huggingface.co/docs/transformers/model_doc/videomae)
- [–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é OneFormer](https://huggingface.co/shi-labs/oneformer_ade20k_dinat_large)

–í –æ–±–ª–∞—Å—Ç–∏ –∑–≤—É–∫–∞:
- [–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base-960h)
- [–ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks)
- [–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é —Ç—Ä–∞—Å–Ω—Ñ–æ—Ä–º–µ—Ä–∞ –∞—É–¥–∏–æ—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º](https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593)

–í –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö:
- [–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–∞–±–ª–∏—Ü–µ —Å –ø–æ–º–æ—â—å—é TAPAS](https://huggingface.co/google/tapas-base-finetuned-wtq)
- [–í–∏–∑—É–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–º–æ—â—å—é ViLT](https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)
- [Zero-shot –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é CLIP](https://huggingface.co/openai/clip-vit-large-patch14)
- [–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º —Å –ø–æ–º–æ—â—å—é LayoutLM](https://huggingface.co/impira/layoutlm-document-qa)
- [Zero-shot –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é X-CLIP](https://huggingface.co/docs/transformers/model_doc/xclip)


## 100 –ø—Ä–æ–µ–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö Transformers

Transformers - —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: —ç—Ç–æ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ –ø—Ä–æ–µ–∫—Ç–æ–≤, —Å–æ–∑–¥–∞–Ω–Ω–æ–µ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ, –∏
Hugging Face Hub. –ú—ã —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã Transformers –ø–æ–∑–≤–æ–ª–∏–ª —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º, –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è–º, —Å—Ç—É–¥–µ–Ω—Ç–∞–º, –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞–º, –∏–Ω–∂–µ–Ω–µ—Ä–∞–º –∏ –≤—Å–µ–º –∂–µ–ª–∞—é—â–∏–º
—Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–æ–µ–∫—Ç—ã —Å–≤–æ–µ–π –º–µ—á—Ç—ã.

–ß—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–∑–¥–Ω–æ–≤–∞—Ç—å 100 —Ç—ã—Å—è—á –∑–≤–µ–∑–¥ Transformers, –º—ã —Ä–µ—à–∏–ª–∏ —Å–¥–µ–ª–∞—Ç—å –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–µ, –∏ —Å–æ–∑–¥–∞–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É [awesome-transformers](./awesome-transformers.md), –Ω–∞ –∫–æ—Ç–æ—Ä–æ–π –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã 100
–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤, —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é transformers.

–ï—Å–ª–∏ –≤—ã —è–≤–ª—è–µ—Ç–µ—Å—å –≤–ª–∞–¥–µ–ª—å—Ü–µ–º –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –ø—Ä–æ–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π, –ø–æ –≤–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∫–ª—é—á–µ–Ω –≤ —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–∫—Ä–æ–π—Ç–µ PR –¥–ª—è –µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è!

## –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É –æ—Ç –∫–æ–º–∞–Ω–¥—ã Hugging Face

<a target="_blank" href="https://huggingface.co/support">
    <img alt="HuggingFace Expert Acceleration Program" src="https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png" style="max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);">
</a><br>

## –ë—ã—Å—Ç—Ä—ã–π –≥–∞–π–¥

–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–º –≤—Ö–æ–¥–µ (—Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∑–≤—É–∫, ...) –º—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º API `pipeline`. –ö–æ–Ω–≤–µ–π–µ—Ä—ã –æ–±—ä–µ–¥–∏–Ω—è—é—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –ø—Ä–∏ –µ–µ –æ–±—É—á–µ–Ω–∏–∏. –í–æ—Ç –∫–∞–∫ –º–æ–∂–Ω–æ –±—ã—Å—Ç—Ä–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤:

```python
>>> from transformers import pipeline

# –í—ã–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
>>> classifier = pipeline('sentiment-analysis')
>>> classifier('–ú—ã –æ—á–µ–Ω—å —Ä–∞–¥—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–æ–Ω–≤–µ–π–µ—Ä –≤ transformers.')
[{'label': 'POSITIVE', 'score': 0.9996980428695679}]
```

–í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–æ–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –∫–æ–Ω–≤–µ–π–µ—Ä–æ–º, –∞ —Ç—Ä–µ—Ç—å—è –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –µ–µ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ. –ó–¥–µ—Å—å –æ—Ç–≤–µ—Ç "POSITIVE" —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é 99,97%.

–í–æ –º–Ω–æ–≥–∏—Ö –∑–∞–¥–∞—á–∞—Ö, –∫–∞–∫ –≤ –ù–õ–ü, —Ç–∞–∫ –∏ –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏ –∏ —Ä–µ—á–∏, —É–∂–µ –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–π `pipeline`. –ù–∞–ø—Ä–∏–º–µ—Ä, –º—ã –º–æ–∂–µ–º –ª–µ–≥–∫–æ –∏–∑–≤–ª–µ—á—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏:

``` python
>>> import requests
>>> from PIL import Image
>>> from transformers import pipeline

# –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –º–∏–ª—ã–º–∏ –∫–æ—Ç–∏–∫–∞–º–∏
>>> url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png"
>>> image_data = requests.get(url, stream=True).raw
>>> image = Image.open(image_data)

# –í—ã–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
>>> object_detector = pipeline('object-detection')
>>> object_detector(image)
[{'score': 0.9982201457023621,
  'label': 'remote',
  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},
 {'score': 0.9960021376609802,
  'label': 'remote',
  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},
 {'score': 0.9954745173454285,
  'label': 'couch',
  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},
 {'score': 0.9988006353378296,
  'label': 'cat',
  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},
 {'score': 0.9986783862113953,
  'label': 'cat',
  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]
```

–ó–¥–µ—Å—å –º—ã –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤, –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, —Å —Ä–∞–º–∫–æ–π –≤–æ–∫—Ä—É–≥ –æ–±—ä–µ–∫—Ç–∞ –∏ –æ—Ü–µ–Ω–∫–æ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏. –°–ª–µ–≤–∞ - –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —Å–ø—Ä–∞–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑—ã:

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png" width="400"></a>
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample_post_processed.png" width="400"></a>
</h3>

–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ –∑–∞–¥–∞—á–∞—Ö, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö API `pipeline`, –º–æ–∂–Ω–æ —É–∑–Ω–∞—Ç—å –≤ [—ç—Ç–æ–º —É—á–µ–±–Ω–æ–º –ø–æ—Å–æ–±–∏–∏](https://huggingface.co/docs/transformers/task_sum)

–í –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ `pipeline`, –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª—é–±–æ–π –∏–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç—Ä–µ—Ö —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞. –í–æ—Ç –≤–µ—Ä—Å–∏—è –¥–ª—è PyTorch:
```python
>>> from transformers import AutoTokenizer, AutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = AutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä!", return_tensors="pt")
>>> outputs = model(**inputs)
```

–ê –≤–æ—Ç —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–π –∫–æ–¥ –¥–ª—è TensorFlow:
```python
>>> from transformers import AutoTokenizer, TFAutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = TFAutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä!", return_tensors="tf")
>>> outputs = model(**inputs)
```

–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –≤—Å—é –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É, –∫–æ—Ç–æ—Ä—É—é –æ–∂–∏–¥–∞–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–∑–≤–∞–Ω –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ —Å –ø–æ–º–æ—â—å—é –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (–∫–∞–∫ –≤ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã—Ö –≤—ã—à–µ –ø—Ä–∏–º–µ—Ä–∞—Ö) –∏–ª–∏ –Ω–∞ —Å–ø–∏—Å–∫–µ. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –±—É–¥–µ—Ç –ø–æ–ª—É—á–µ–Ω —Å–ª–æ–≤–∞—Ä—å, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –∫–æ–¥–µ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø—Ä—è–º—É—é –ø–µ—Ä–µ–¥–∞—Ç—å –≤ –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ **.

–°–∞–º–∞ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –æ–±—ã—á–Ω—ã–π [Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) –∏–ª–∏ [TensorFlow `tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –±—ç–∫–µ–Ω–¥–∞), –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω–æ. [–í —ç—Ç–æ–º —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ](https://huggingface.co/docs/transformers/training) —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è, –∫–∞–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–∫—É—é –º–æ–¥–µ–ª—å –≤ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è PyTorch –∏–ª–∏ TensorFlow, –∏–ª–∏ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—à API `Trainer` –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞ –Ω–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.

## –ü–æ—á–µ–º—É –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å transformers?

1. –ü—Ä–æ—Å—Ç—ã–µ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:
    - –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –∑–∞–¥–∞—á–∞—Ö –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞, –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –∞—É–¥–∏–æ.
    - –ù–∏–∑–∫–∏–π –≤—Ö–æ–¥–Ω–æ–π –±–∞—Ä—å–µ—Ä –¥–ª—è –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–π –∏ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤.
    - –ù–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤—Å–µ–≥–æ —Ç—Ä–∏ –∫–ª–∞—Å—Å–∞ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è.
    - –ï–¥–∏–Ω—ã–π API –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –Ω–∞—à–∏—Ö –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

1. –ë–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã, –º–µ–Ω—å—à–∏–π "—É–≥–ª–µ—Ä–æ–¥–Ω—ã–π —Å–ª–µ–¥":
    - –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç –æ–±–º–µ–Ω–∏–≤–∞—Ç—å—Å—è –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Ö –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å.
    - –ü—Ä–∞–∫—Ç–∏–∫–∏ –º–æ–≥—É—Ç —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã.
    - –î–µ—Å—è—Ç–∫–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä —Å –±–æ–ª–µ–µ —á–µ–º 60 000 –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π.

1. –í—ã–±–æ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –∂–∏–∑–Ω–∏ –º–æ–¥–µ–ª–∏:
    - –û–±—É—á–µ–Ω–∏–µ —Å–∞–º—ã—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∑–∞ 3 —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞.
    - –ü–µ—Ä–µ–º–µ—â–∞–π—Ç–µ –æ–¥–Ω—É –º–æ–¥–µ–ª—å –º–µ–∂–¥—É —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ TF2.0/PyTorch/JAX –ø–æ —Å–≤–æ–µ–º—É —É—Å–º–æ—Ç—Ä–µ–Ω–∏—é.
    - –ë–µ—Å–ø—Ä–µ–ø—è—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –æ—Ü–µ–Ω–∫–∏ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞.

1. –õ–µ–≥–∫–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –∏–ª–∏ –ø—Ä–∏–º–µ—Ä –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã:
    - –ú—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, —á—Ç–æ–±—ã –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –∏—Ö –∞–≤—Ç–æ—Ä–∞–º–∏.
    - –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏ —Ä–∞—Å–∫—Ä—ã–≤–∞—é—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ.
    - –§–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –±—ã—Å—Ç—Ä—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

## –ü–æ—á–µ–º—É —è –Ω–µ –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å transformers?

- –î–∞–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–æ–¥—É–ª—å–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π. –ö–æ–¥ –≤ —Ñ–∞–π–ª–∞—Ö –º–æ–¥–µ–ª–µ–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –Ω–µ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è–º–∏, —á—Ç–æ–±—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥–ª–∏ –±—ã—Å—Ç—Ä–æ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∫–∞–∂–¥–æ–π –∏–∑ –º–æ–¥–µ–ª–µ–π, –Ω–µ –ø–æ–≥—Ä—É–∂–∞—è—Å—å –≤ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏/—Ñ–∞–π–ª—ã.
- API –æ–±—É—á–µ–Ω–∏—è –Ω–µ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª—é–±–æ–π –º–æ–¥–µ–ª—å—é, –∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π. –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–±—â–∏–º–∏ —Ü–∏–∫–ª–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É (–≤–æ–∑–º–æ–∂–Ω–æ, [Accelerate](https://huggingface.co/docs/accelerate)).
- –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –º—ã —Å—Ç—Ä–µ–º–∏–º—Å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, —Å–∫—Ä–∏–ø—Ç—ã –≤ –Ω–∞—à–µ–π –ø–∞–ø–∫–µ [–ø—Ä–∏–º–µ—Ä–æ–≤](https://github.com/huggingface/transformers/tree/main/examples) —è–≤–ª—è—é—Ç—Å—è –∏–º–µ–Ω–Ω–æ –ø—Ä–∏–º–µ—Ä–∞–º–∏. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ –Ω–µ –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å "–∏–∑ –∫–æ—Ä–æ–±–∫–∏" –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –≤–∞—à–µ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏, –∏ –≤–∞–º –ø—Ä–∏–¥–µ—Ç—Å—è –∏–∑–º–µ–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞, —á—Ç–æ–±—ã –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Ö –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã.

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –° –ø–æ–º–æ—â—å—é pip

–î–∞–Ω–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ –∏ TensorFlow 2.6+.

–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å ü§ó Transformers —Å–ª–µ–¥—É–µ—Ç –≤ [–≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–µ](https://docs.python.org/3/library/venv.html). –ï—Å–ª–∏ –≤—ã –Ω–µ –∑–Ω–∞–∫–æ–º—ã —Å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º–∏ —Å—Ä–µ–¥–∞–º–∏ Python, –æ–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å [—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).

–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—É—é —Å—Ä–µ–¥—É —Å —Ç–æ–π –≤–µ—Ä—Å–∏–µ–π Python, –∫–æ—Ç–æ—Ä—É—é –≤—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –µ–µ.

–ó–∞—Ç–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –±–µ–∫–µ–Ω–¥ –∏–∑ Flax, PyTorch –∏–ª–∏ TensorFlow.
–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º [TensorFlow —É—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞](https://www.tensorflow.org/install/), [PyTorch —É—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞](https://pytorch.org/get-started/locally/#start-locally) –∏/–∏–ª–∏ [Flax](https://github.com/google/flax#quick-install) –∏ [Jax](https://github.com/google/jax#installation), –≥–¥–µ –æ–ø–∏—Å–∞–Ω—ã –∫–æ–º–∞–Ω–¥—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥–ª—è –≤–∞—à–µ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã.

–ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–¥–Ω–æ–≥–æ –∏–∑ —ç—Ç–∏—Ö –±—ç–∫–µ–Ω–¥–æ–≤ ü§ó Transformers –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å –ø–æ–º–æ—â—å—é pip —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

```bash
pip install transformers
```

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–∏–≥—Ä–∞—Ç—å —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–ª–∏ –≤–∞–º –Ω—É–∂–µ–Ω —Å–∞–º—ã–π —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–¥ –∏ –≤—ã –Ω–µ –º–æ–∂–µ—Ç–µ –∂–¥–∞—Ç—å –Ω–æ–≤–æ–≥–æ —Ä–µ–ª–∏–∑–∞, –≤—ã –¥–æ–ª–∂–Ω—ã [—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞](https://huggingface.co/docs/transformers/installation#installing-from-source).

### –° –ø–æ–º–æ—â—å—é conda

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Transformers —Å –ø–æ–º–æ—â—å—é conda –º–æ–∂–Ω–æ —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

```bash
conda install conda-forge::transformers
```

> **_–ó–ê–ú–ï–¢–ö–ê:_** –£—Å—Ç–∞–Ω–æ–≤–∫–∞ `transformers` —á–µ—Ä–µ–∑ –∫–∞–Ω–∞–ª `huggingface` —É—Å—Ç–∞—Ä–µ–ª–∞.

–û —Ç–æ–º, –∫–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Flax, PyTorch –∏–ª–∏ TensorFlow —Å –ø–æ–º–æ—â—å—é conda, —á–∏—Ç–∞–π—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö, –ø–æ—Å–≤—è—â–µ–Ω–Ω—ã—Ö –∏—Ö —É—Å—Ç–∞–Ω–æ–≤–∫–µ.

> **_–ó–ê–ú–ï–¢–ö–ê:_** –í –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ Windows –≤–∞–º –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞, —á—Ç–æ–±—ã –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞–º–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è. –ï—Å–ª–∏ –¥–ª—è –≤–∞—Å —ç—Ç–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ, —Å–æ–æ–±—â–∏—Ç–µ –Ω–∞–º –æ–± —ç—Ç–æ–º [–∑–¥–µ—Å—å](https://github.com/huggingface/huggingface_hub/issues/1062).

## –ú–æ–¥–µ–ª—å–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

**[–í—Å–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –º–æ–¥–µ–ª–µ–π](https://huggingface.co/models)**, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã–µ ü§ó Transformers, –±–µ—Å–ø—Ä–µ–ø—è—Ç—Å—Ç–≤–µ–Ω–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—Ç—Å—è —Å huggingface.co [model hub](https://huggingface.co/models), –∫—É–¥–∞ –æ–Ω–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ [–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏](https://huggingface.co/users) –∏ [–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏](https://huggingface.co/organizations).

–¢–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫: ![](https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen)

ü§ó –í –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è Transformers –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –∏–∑ –Ω–∏—Ö —Å–º. [–∑–¥–µ—Å—å](https://huggingface.co/docs/transformers/model_summary).

–ß—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —É –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ Flax, PyTorch –∏–ª–∏ TensorFlow, –∏–ª–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –Ω–µ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π ü§ó Tokenizers, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ [—ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü–µ](https://huggingface.co/docs/transformers/index#supported-frameworks).

–≠—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –±—ã–ª–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö (—Å–º. –ø—Ä–∏–º–µ—Ä—ã —Å–∫—Ä–∏–ø—Ç–æ–≤) –∏ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π. –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ "–ü—Ä–∏–º–µ—Ä—ã" [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏](https://github.com/huggingface/transformers/tree/main/examples).


## –ò–∑—É—á–∏ –±–æ–ª—å—à–µ

| –°–µ–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ |
|-|-|
| [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://huggingface.co/docs/transformers/) | –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ API –∏ –≥–∞–π–¥—ã |
| [–ö—Ä–∞—Ç–∫–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –∑–∞–¥–∞—á](https://huggingface.co/docs/transformers/task_summary) | –ó–∞–¥–∞—á–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è ü§ó Transformers |
| [–ü–æ—Å–æ–±–∏–µ –ø–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ](https://huggingface.co/docs/transformers/preprocessing) | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ `Tokenizer` –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–µ–π |
| [–û–±—É—á–µ–Ω–∏–µ –∏ –¥–æ—Ä–∞–±–æ—Ç–∫–∞](https://huggingface.co/docs/transformers/training) | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã—Ö ü§ó Transformers, –≤ —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è PyTorch/TensorFlow –∏ API `Trainer`. |
| [–ë—ã—Å—Ç—Ä—ã–π —Ç—É—Ä: –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞/—Å–∫—Ä–∏–ø—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](https://github.com/huggingface/transformers/tree/main/examples) | –ü—Ä–∏–º–µ—Ä—ã —Å–∫—Ä–∏–ø—Ç–æ–≤ –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π –Ω–∞ —à–∏—Ä–æ–∫–æ–º —Å–ø–µ–∫—Ç—Ä–µ –∑–∞–¥–∞—á |
| [–°–æ–≤–º–µ—Å—Ç–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π](https://huggingface.co/docs/transformers/model_sharing) | –ó–∞–≥—Ä—É–∂–∞–π—Ç–µ –∏ –¥–µ–ª–∏—Ç–µ—Å—å —Å —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º —Å–≤–æ–∏–º–∏ –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ |

## –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–¢–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å [—Å—Ç–∞—Ç—å—è](https://www.aclweb.org/anthology/2020.emnlp-demos.6/), –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ü§ó Transformers:
```bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
```
