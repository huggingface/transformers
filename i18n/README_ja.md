<!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<!---
A useful guide for English-Traditional Japanese translation of Hugging Face documentation
- Use square quotes, e.g.,ã€Œå¼•ç”¨ã€

Dictionary

API: API(ç¿»è¨³ã—ãªã„)
add: è¿½åŠ 
checkpoint: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
code: ã‚³ãƒ¼ãƒ‰
community: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
confidence: ä¿¡é ¼åº¦
dataset: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
documentation: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
example: ä¾‹
finetune: å¾®èª¿æ•´
Hugging Face: Hugging Face(ç¿»è¨³ã—ãªã„)
implementation: å®Ÿè£…
inference: æ¨è«–
library: ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
module: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
NLP/Natural Language Processing: NLPã¨è¡¨ç¤ºã•ã‚Œã‚‹å ´åˆã¯ç¿»è¨³ã•ã‚Œãšã€Natural Language Processingã¨è¡¨ç¤ºã•ã‚Œã‚‹å ´åˆã¯ç¿»è¨³ã•ã‚Œã‚‹
online demos: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢
pipeline: pipeline(ç¿»è¨³ã—ãªã„)
pretrained/pretrain: å­¦ç¿’æ¸ˆã¿
Python data structures (e.g., list, set, dict): ãƒªã‚¹ãƒˆã€ã‚»ãƒƒãƒˆã€ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã¨è¨³ã•ã‚Œã€æ‹¬å¼§å†…ã¯åŸæ–‡è‹±èª
repository: repository(ç¿»è¨³ã—ãªã„)
summary: æ¦‚è¦
token-: token-(ç¿»è¨³ã—ãªã„)
Trainer: Trainer(ç¿»è¨³ã—ãªã„)
transformer: transformer(ç¿»è¨³ã—ãªã„)
tutorial: ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
user: ãƒ¦ãƒ¼ã‚¶
-->

<p align="center">
    <br>
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers_logo_name.png" width="400"/>
    <br>
</p>
<p align="center">
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <a href="https://github.com/huggingface/transformers/">English</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">ç®€ä½“ä¸­æ–‡</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">ç¹é«”ä¸­æ–‡</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">í•œêµ­ì–´</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">EspaÃ±ol</a> |
        <b>æ—¥æœ¬èª</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Ğ ortuguÃªs</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">à°¤à±†à°²à±à°—à±</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">FranÃ§ais</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiáº¿ng Viá»‡t</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> |
    </p>
</h4>

<h3 align="center">
    <p>JAXã€PyTorchã€TensorFlowã®ãŸã‚ã®æœ€å…ˆç«¯æ©Ÿæ¢°å­¦ç¿’</p>
</h3>

<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>

ğŸ¤—Transformersã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€è¦–è¦šã€éŸ³å£°ãªã©ã®ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«å¯¾ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã€äº‹å‰ã«å­¦ç¿’ã•ã›ãŸæ•°åƒã®ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚

ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯æ¬¡ã®ã‚ˆã†ãªå ´åˆã«é©ç”¨ã§ãã¾ã™:

* ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†é¡ã€æƒ…å ±æŠ½å‡ºã€è³ªå•å¿œç­”ã€è¦ç´„ã€ç¿»è¨³ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãªã©ã®ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã«ã€100ä»¥ä¸Šã®è¨€èªã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
* ğŸ–¼ï¸ ç”»åƒåˆ†é¡ã€ç‰©ä½“æ¤œå‡ºã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã®ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®ç”»åƒã€‚
* ğŸ—£ï¸ éŸ³å£°ã¯ã€éŸ³å£°èªè­˜ã‚„éŸ³å£°åˆ†é¡ãªã©ã®ã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã—ã¾ã™ã€‚

ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«è³ªå•å¿œç­”ã€å…‰å­¦æ–‡å­—èªè­˜ã€ã‚¹ã‚­ãƒ£ãƒ³æ–‡æ›¸ã‹ã‚‰ã®æƒ…å ±æŠ½å‡ºã€ãƒ“ãƒ‡ã‚ªåˆ†é¡ã€è¦–è¦šçš„è³ªå•å¿œç­”ãªã©ã€**è¤‡æ•°ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ„ã¿åˆã‚ã›ãŸ**ã‚¿ã‚¹ã‚¯ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚

ğŸ¤—Transformersã¯ã€ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ãã‚Œã‚‰ã®äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ç´ æ—©ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨ã—ã€ã‚ãªãŸè‡ªèº«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãã‚Œã‚‰ã‚’å¾®èª¿æ•´ã—ã€ç§ãŸã¡ã®[model hub](https://huggingface.co/models)ã§ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã™ã‚‹ãŸã‚ã®APIã‚’æä¾›ã—ã¾ã™ã€‚åŒæ™‚ã«ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®šç¾©ã™ã‚‹å„Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å®Œå…¨ã«ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã§ã‚ã‚Šã€è¿…é€Ÿãªç ”ç©¶å®Ÿé¨“ã‚’å¯èƒ½ã«ã™ã‚‹ãŸã‚ã«å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ğŸ¤—Transformersã¯[Jax](https://jax.readthedocs.io/en/latest/)ã€[PyTorch](https://pytorch.org/)ã€[TensorFlow](https://www.tensorflow.org/)ã¨ã„ã†3å¤§ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ã«æ”¯ãˆã‚‰ã‚Œã€ãã‚Œãã‚Œã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã—ã¦ã„ã¾ã™ã€‚ç‰‡æ–¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ã‹ã‚‰ã€ã‚‚ã†ç‰‡æ–¹ã§æ¨è«–ç”¨ã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã¯ç°¡å˜ãªã“ã¨ã§ã™ã€‚

## ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢

[model hub](https://huggingface.co/models)ã‹ã‚‰ã€ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒšãƒ¼ã‚¸ã§ç›´æ¥ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€[ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã€æ¨è«–API](https://huggingface.co/pricing)ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

ä»¥ä¸‹ã¯ãã®ä¸€ä¾‹ã§ã™:

 è‡ªç„¶è¨€èªå‡¦ç†ã«ã¦:
- [BERTã«ã‚ˆã‚‹ãƒã‚¹ã‚¯ãƒ‰ãƒ¯ãƒ¼ãƒ‰è£œå®Œ](https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)
- [Electraã«ã‚ˆã‚‹åå‰å®Ÿä½“èªè­˜](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)
- [GPT-2ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ](https://huggingface.co/openai-community/gpt2?text=A+long+time+ago%2C+)
- [RoBERTaã«ã‚ˆã‚‹è‡ªç„¶è¨€èªæ¨è«–](https://huggingface.co/FacebookAI/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal)
- [BARTã«ã‚ˆã‚‹è¦ç´„](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)
- [DistilBERTã«ã‚ˆã‚‹è³ªå•å¿œç­”](https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species)
- [T5ã«ã‚ˆã‚‹ç¿»è¨³](https://huggingface.co/google-t5/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin)

ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¦:
- [ViTã«ã‚ˆã‚‹ç”»åƒåˆ†é¡](https://huggingface.co/google/vit-base-patch16-224)
- [DETRã«ã‚ˆã‚‹ç‰©ä½“æ¤œå‡º](https://huggingface.co/facebook/detr-resnet-50)
- [SegFormerã«ã‚ˆã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512)
- [DETRã«ã‚ˆã‚‹ãƒ‘ãƒãƒ—ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³](https://huggingface.co/facebook/detr-resnet-50-panoptic)

ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã«ã¦:
- [Wav2Vec2ã«ã‚ˆã‚‹è‡ªå‹•éŸ³å£°èªè­˜](https://huggingface.co/facebook/wav2vec2-base-960h)
- [Wav2Vec2ã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢](https://huggingface.co/superb/wav2vec2-base-superb-ks)

ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã«ã¦:
- [ViLTã«ã‚ˆã‚‹è¦–è¦šçš„è³ªå•å¿œç­”](https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)

Hugging Faceãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦ä½œã‚‰ã‚ŒãŸ **[ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ä½¿ã£ãŸæ›¸ãè¾¼ã¿](https://transformer.huggingface.co)** ã¯ã€ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆæ©Ÿèƒ½ã®å…¬å¼ãƒ‡ãƒ¢ã§ã‚ã‚‹ã€‚

## Hugging Faceãƒãƒ¼ãƒ ã«ã‚ˆã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ»ã‚µãƒãƒ¼ãƒˆã‚’ã”å¸Œæœ›ã®å ´åˆ

<a target="_blank" href="https://huggingface.co/support">
    <img alt="HuggingFace Expert Acceleration Program" src="https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png" style="max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);">
</a><br>

## ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ã‚¢ãƒ¼

ä¸ãˆã‚‰ã‚ŒãŸå…¥åŠ›ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã€...ï¼‰ã«å¯¾ã—ã¦ã™ãã«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ãŸã‚ã«ã€æˆ‘ã€…ã¯`pipeline`ã¨ã„ã†APIã‚’æä¾›ã—ã¦ãŠã‚Šã¾ã™ã€‚pipelineã¯ã€å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã¨ã€ãã®ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸå‰å‡¦ç†ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸã‚‚ã®ã§ã™ã€‚ä»¥ä¸‹ã¯ã€è‚¯å®šçš„ãªãƒ†ã‚­ã‚¹ãƒˆã¨å¦å®šçš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã«pipelineã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã§ã™:

```python
>>> from transformers import pipeline

# Allocate a pipeline for sentiment-analysis
>>> classifier = pipeline('sentiment-analysis')
>>> classifier('We are very happy to introduce pipeline to the transformers repository.')
[{'label': 'POSITIVE', 'score': 0.9996980428695679}]
```

2è¡Œç›®ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ã€pipelineã§ä½¿ç”¨ã•ã‚Œã‚‹äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€3è¡Œç›®ã§ã¯ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ãã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€ç­”ãˆã¯99.97%ã®ä¿¡é ¼åº¦ã§ã€Œãƒã‚¸ãƒ†ã‚£ãƒ–ã€ã§ã™ã€‚

è‡ªç„¶è¨€èªå‡¦ç†ã ã‘ã§ãªãã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã‚„éŸ³å£°å‡¦ç†ã«ãŠã„ã¦ã‚‚ã€å¤šãã®ã‚¿ã‚¹ã‚¯ã«ã¯ã‚ã‚‰ã‹ã˜ã‚è¨“ç·´ã•ã‚ŒãŸ`pipeline`ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã€‚ä¾‹ãˆã°ã€ç”»åƒã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸç‰©ä½“ã‚’ç°¡å˜ã«æŠ½å‡ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹:

``` python
>>> import requests
>>> from PIL import Image
>>> from transformers import pipeline

# Download an image with cute cats
>>> url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png"
>>> image_data = requests.get(url, stream=True).raw
>>> image = Image.open(image_data)

# Allocate a pipeline for object detection
>>> object_detector = pipeline('object-detection')
>>> object_detector(image)
[{'score': 0.9982201457023621,
  'label': 'remote',
  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},
 {'score': 0.9960021376609802,
  'label': 'remote',
  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},
 {'score': 0.9954745173454285,
  'label': 'couch',
  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},
 {'score': 0.9988006353378296,
  'label': 'cat',
  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},
 {'score': 0.9986783862113953,
  'label': 'cat',
  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]
```

ã“ã“ã§ã¯ã€ç”»åƒã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆãŒå¾—ã‚‰ã‚Œã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å›²ã‚€ãƒœãƒƒã‚¯ã‚¹ã¨ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å·¦å´ãŒå…ƒç”»åƒã€å³å´ãŒäºˆæ¸¬çµæœã‚’è¡¨ç¤ºã—ãŸã‚‚ã®ã§ã™:

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png" width="400"></a>
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample_post_processed.png" width="400"></a>
</h3>

[ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/task_summary)ã§ã¯ã€`pipeline`APIã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ã„ã¾ã™ã€‚

`pipeline`ã«åŠ ãˆã¦ã€ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã«å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã®ã¯ã€3è¡Œã®ã‚³ãƒ¼ãƒ‰ã ã‘ã§ã™ã€‚ä»¥ä¸‹ã¯PyTorchã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã™:
```python
>>> from transformers import AutoTokenizer, AutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = AutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("Hello world!", return_tensors="pt")
>>> outputs = model(**inputs)
```

ãã—ã¦ã“ã¡ã‚‰ã¯TensorFlowã¨åŒç­‰ã®ã‚³ãƒ¼ãƒ‰ã¨ãªã‚Šã¾ã™:
```python
>>> from transformers import AutoTokenizer, TFAutoModel

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
>>> model = TFAutoModel.from_pretrained("google-bert/bert-base-uncased")

>>> inputs = tokenizer("Hello world!", return_tensors="tf")
>>> outputs = model(**inputs)
```

ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ã™ã¹ã¦ã®å‰å‡¦ç†ã‚’æ‹…å½“ã—ã€å˜ä¸€ã®æ–‡å­—åˆ— (ä¸Šè¨˜ã®ä¾‹ã®ã‚ˆã†ã«) ã¾ãŸã¯ãƒªã‚¹ãƒˆã«å¯¾ã—ã¦ç›´æ¥å‘¼ã³å‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯ä¸‹æµã®ã‚³ãƒ¼ãƒ‰ã§ä½¿ç”¨ã§ãã‚‹è¾æ›¸ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚ã¾ãŸã€å˜ç´”ã« ** å¼•æ•°å±•é–‹æ¼”ç®—å­ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã«ç›´æ¥æ¸¡ã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯é€šå¸¸ã®[Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) ã¾ãŸã¯ [TensorFlow `tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚ˆã£ã¦ç•°ãªã‚‹)ã§ã€é€šå¸¸é€šã‚Šä½¿ç”¨ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚[ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/training)ã§ã¯ã€ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã‚’å¾“æ¥ã®PyTorchã‚„TensorFlowã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã«çµ±åˆã™ã‚‹æ–¹æ³•ã‚„ã€ç§ãŸã¡ã®`Trainer`APIã‚’ä½¿ã£ã¦æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç´ æ—©ãå¾®èª¿æ•´ã‚’è¡Œã†æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

## ãªãœtransformersã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ

1. ä½¿ã„ã‚„ã™ã„æœ€æ–°ãƒ¢ãƒ‡ãƒ«:
    - è‡ªç„¶è¨€èªç†è§£ãƒ»ç”Ÿæˆã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®å„ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚
    - æ•™è‚²è€…ã€å®Ÿå‹™è€…ã«ã¨ã£ã¦ã®ä½ã„å‚å…¥éšœå£ã€‚
    - å­¦ç¿’ã™ã‚‹ã‚¯ãƒ©ã‚¹ã¯3ã¤ã ã‘ã§ã€ãƒ¦ãƒ¼ã‚¶ãŒç›´é¢ã™ã‚‹æŠ½è±¡åŒ–ã¯ã»ã¨ã‚“ã©ã‚ã‚Šã¾ã›ã‚“ã€‚
    - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸAPIã€‚

1. ä½ã„è¨ˆç®—ã‚³ã‚¹ãƒˆã€å°‘ãªã„ã‚«ãƒ¼ãƒœãƒ³ãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆ:
    - ç ”ç©¶è€…ã¯ã€å¸¸ã«å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã®ã§ã¯ãªãã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å…±æœ‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
    - å®Ÿå‹™å®¶ã¯ã€è¨ˆç®—æ™‚é–“ã‚„ç”Ÿç”£ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
    - ã™ã¹ã¦ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã„ã¦ã€60,000ä»¥ä¸Šã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æŒã¤æ•°å¤šãã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¾ã™ã€‚

1. ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚¿ã‚¤ãƒ ã®ã‚ã‚‰ã‚†ã‚‹éƒ¨åˆ†ã§é©åˆ‡ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é¸æŠå¯èƒ½:
    - 3è¡Œã®ã‚³ãƒ¼ãƒ‰ã§æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚
    - TF2.0/PyTorch/JAXãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã§1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªåœ¨ã«ç§»å‹•ã•ã›ã‚‹ã€‚
    - å­¦ç¿’ã€è©•ä¾¡ã€ç”Ÿç”£ã«é©ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«é¸æŠã§ãã¾ã™ã€‚

1. ãƒ¢ãƒ‡ãƒ«ã‚„ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã¦ç°¡å˜ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½:
    - åŸè‘—è€…ãŒç™ºè¡¨ã—ãŸçµæœã‚’å†ç¾ã™ã‚‹ãŸã‚ã«ã€å„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ä¾‹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚
    - ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã¯å¯èƒ½ãªé™ã‚Šä¸€è²«ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚
    - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã¯ç‹¬ç«‹ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã€è¿…é€Ÿãªå®Ÿé¨“ãŒå¯èƒ½ã§ã™ã€‚

## ãªãœtransformersã‚’ä½¿ã£ã¦ã¯ã„ã‘ãªã„ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ

- ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®ãŸã‚ã®ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¼ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ç ”ç©¶è€…ãŒè¿½åŠ ã®æŠ½è±¡åŒ–/ãƒ•ã‚¡ã‚¤ãƒ«ã«é£›ã³è¾¼ã‚€ã“ã¨ãªãã€å„ãƒ¢ãƒ‡ãƒ«ã‚’ç´ æ—©ãåå¾©ã§ãã‚‹ã‚ˆã†ã«ã€æ„å›³çš„ã«è¿½åŠ ã®æŠ½è±¡åŒ–ã§ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
- å­¦ç¿’APIã¯ã©ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚å‹•ä½œã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæä¾›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§å‹•ä½œã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸€èˆ¬çš„ãªæ©Ÿæ¢°å­¦ç¿’ã®ãƒ«ãƒ¼ãƒ—ã«ã¯ã€åˆ¥ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª(ãŠãã‚‰ã[Accelerate](https://huggingface.co/docs/accelerate))ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
- ç§ãŸã¡ã¯ã§ãã‚‹ã ã‘å¤šãã®ä½¿ç”¨ä¾‹ã‚’ç´¹ä»‹ã™ã‚‹ã‚ˆã†åŠªåŠ›ã—ã¦ã„ã¾ã™ãŒã€[examples ãƒ•ã‚©ãƒ«ãƒ€](https://github.com/huggingface/transformers/tree/main/examples) ã«ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã‚ãã¾ã§ä¾‹ã§ã™ã€‚ã‚ãªãŸã®ç‰¹å®šã®å•é¡Œã«å¯¾ã—ã¦ã™ãã«å‹•ä½œã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ã‚ãªãŸã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã‚‹ãŸã‚ã«æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ãŒäºˆæƒ³ã•ã‚Œã¾ã™ã€‚

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### pipã«ã¦

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€Python 3.8+, Flax 0.4.1+, PyTorch 1.11+, TensorFlow 2.6+ ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚

ğŸ¤—Transformersã¯[ä»®æƒ³ç’°å¢ƒ](https://docs.python.org/3/library/venv.html)ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Pythonã®ä»®æƒ³ç’°å¢ƒã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

ã¾ãšã€ä½¿ç”¨ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®Pythonã§ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆã—ã¾ã™ã€‚

ãã®å¾Œã€Flax, PyTorch, TensorFlowã®ã†ã¡å°‘ãªãã¨ã‚‚1ã¤ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
[TensorFlowã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸](https://www.tensorflow.org/install/)ã€[PyTorchã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸](https://pytorch.org/get-started/locally/#start-locally)ã€[Flax](https://github.com/google/flax#quick-install)ã€[Jax](https://github.com/google/jax#installation)ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã§ã€ãŠä½¿ã„ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

ã“ã‚Œã‚‰ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã„ãšã‚Œã‹ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ğŸ¤—Transformersã¯ä»¥ä¸‹ã®ã‚ˆã†ã«pipã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™:

```bash
pip install transformers
```

ã‚‚ã—ã‚µãƒ³ãƒ—ãƒ«ã‚’è©¦ã—ãŸã„ã€ã¾ãŸã¯ã‚³ãƒ¼ãƒ‰ã®æœ€å…ˆç«¯ãŒå¿…è¦ã§ã€æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹ã‚’å¾…ã¦ãªã„å ´åˆã¯ã€[ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](https://huggingface.co/docs/transformers/installation#installing-from-source)ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### condaã«ã¦

ğŸ¤—Transformersã¯ä»¥ä¸‹ã®ã‚ˆã†ã«condaã‚’ä½¿ã£ã¦è¨­ç½®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™:

```shell script
conda install conda-forge::transformers
```

> **_æ³¨æ„:_**  `huggingface` ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰ `transformers` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã¯éæ¨å¥¨ã§ã™ã€‚

Flaxã€PyTorchã€TensorFlowã‚’condaã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹æ–¹æ³•ã¯ã€ãã‚Œãã‚Œã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã«å¾“ã£ã¦ãã ã•ã„ã€‚

> **_æ³¨æ„:_**  Windowsã§ã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ©æµã‚’å—ã‘ã‚‹ãŸã‚ã«ã€ãƒ‡ãƒ™ãƒ­ãƒƒãƒ‘ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‚ˆã†ä¿ƒã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ã‚ˆã†ãªå ´åˆã¯ã€[ã“ã®issue](https://github.com/huggingface/huggingface_hub/issues/1062)ã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

## ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

ğŸ¤—TransformersãŒæä¾›ã™ã‚‹ **[å…¨ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ](https://huggingface.co/models)** ã¯ã€[ãƒ¦ãƒ¼ã‚¶ãƒ¼](https://huggingface.co/users)ã‚„[çµ„ç¹”](https://huggingface.co/organizations)ã«ã‚ˆã£ã¦ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹huggingface.co [model hub](https://huggingface.co)ã‹ã‚‰ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚

ç¾åœ¨ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ•°: ![](https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen)

ğŸ¤—Transformersã¯ç¾åœ¨ã€ä»¥ä¸‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¦ã„ã¾ã™: ãã‚Œãã‚Œã®ãƒã‚¤ãƒ¬ãƒ™ãƒ«ãªè¦ç´„ã¯[ã“ã¡ã‚‰](https://huggingface.co/docs/transformers/model_summary)ã‚’å‚ç…§ã—ã¦ãã ã•ã„.

å„ãƒ¢ãƒ‡ãƒ«ãŒFlaxã€PyTorchã€TensorFlowã§å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‹ã€ğŸ¤—Tokenizersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ”¯ãˆã‚‰ã‚ŒãŸé–¢é€£ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’æŒã£ã¦ã„ã‚‹ã‹ã¯ã€[ã“ã®è¡¨](https://huggingface.co/docs/transformers/index#supported-frameworks)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

ã“ã‚Œã‚‰ã®å®Ÿè£…ã¯ã„ãã¤ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ãŠã‚Š(ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‚ç…§)ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å®Ÿè£…ã®æ€§èƒ½ã¨ä¸€è‡´ã™ã‚‹ã¯ãšã§ã‚ã‚‹ã€‚æ€§èƒ½ã®è©³ç´°ã¯[documentation](https://github.com/huggingface/transformers/tree/main/examples)ã®Examplesã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚


## ã•ã‚‰ã«è©³ã—ã

| ã‚»ã‚¯ã‚·ãƒ§ãƒ³ | æ¦‚è¦ |
|-|-|
| [ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://huggingface.co/docs/transformers/) | å®Œå…¨ãªAPIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« |
| [ã‚¿ã‚¹ã‚¯æ¦‚è¦](https://huggingface.co/docs/transformers/task_summary) | ğŸ¤—TransformersãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¿ã‚¹ã‚¯ |
| [å‰å‡¦ç†ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/preprocessing) | ãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹ãŸã‚ã«`Tokenizer`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ |
| [ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¾®èª¿æ•´](https://huggingface.co/docs/transformers/training) | PyTorch/TensorFlowã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã¨`Trainer`APIã§ğŸ¤—TransformersãŒæä¾›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ |
| [ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ã‚¢ãƒ¼: å¾®èª¿æ•´/ä½¿ç”¨æ–¹æ³•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples) | æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§ãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã‚’è¡Œã†ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ |
| [ãƒ¢ãƒ‡ãƒ«ã®å…±æœ‰ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰](https://huggingface.co/docs/transformers/model_sharing) | å¾®èª¿æ•´ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§å…±æœ‰ã™ã‚‹ |
| [ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³](https://huggingface.co/docs/transformers/migration) | `pytorch-transformers`ã¾ãŸã¯`pytorch-pretrained-bert`ã‹ã‚‰ğŸ¤—Transformers ã«ç§»è¡Œã™ã‚‹ |

## å¼•ç”¨

ğŸ¤— ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«å¼•ç”¨ã§ãã‚‹[è«–æ–‡](https://www.aclweb.org/anthology/2020.emnlp-demos.6/)ãŒå‡ºæ¥ã¾ã—ãŸ:
```bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
```
