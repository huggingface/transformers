name: Self-hosted runner scale set (AMD mi325 scheduled CI caller)

# Note: For every job in this workflow, the name of the runner scale set is finalized in the runner yaml i.e. huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml
# For example, 1gpu scale set: amd-mi325-ci-1gpu
#              2gpu scale set: amd-mi325-ci-2gpu

on:
  workflow_run:
    workflows: ["Self-hosted runner (AMD scheduled CI caller)"]
    branches: ["main"]
    types: [completed]
  push:
    branches:
      - run_amd_scheduled_ci_caller*

jobs:
  # This job is to only cache the huggigface/transformers-pytorch-amd-gpu image,
  # as it is heavily used in the model-ci job
  cache-pytorch-image:
    name: Cache Pytorch Image
    runs-on: amd-mi325-1gpu
    steps:
      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}
      
      - name: Pull and save docker image to cache
        run: |
          image="huggingface/transformers-pytorch-amd-gpu"
          final_path="/mnt/image-cache/transformers-pytorch-amd-gpu.tar"
          tmp_path="${final_path}.tmp"

          echo "Pulling image: ${image}"
          docker pull "${image}"

          echo "Saving to temp file: ${tmp_path}"
          docker save "${image}" -o "${tmp_path}"

          echo "Moving to final path: ${final_path}"
          mv -f "${tmp_path}" "${final_path}"

          echo "Cache populated successfully at ${final_path}"

  model-ci:
    name: Model CI
    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main
    needs: cache-pytorch-image
    with:
      job: run_models_gpu
      slack_report_channel: "#amd-hf-ci"
      runner_group: amd-mi325
      docker: huggingface/transformers-pytorch-amd-gpu
      ci_event: Scheduled CI (AMD) - mi325
      report_repo_id: optimum-amd/transformers_daily_ci
      env_file: /etc/podinfo/gha-gpu-isolation-settings
    secrets: inherit

  torch-pipeline:
    name: Torch pipeline CI
    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main
    needs: cache-pytorch-image
    with:
      job: run_pipelines_torch_gpu
      slack_report_channel: "#amd-hf-ci"
      runner_group: amd-mi325
      docker: huggingface/transformers-pytorch-amd-gpu
      ci_event: Scheduled CI (AMD) - mi325
      report_repo_id: optimum-amd/transformers_daily_ci
      env_file: /etc/podinfo/gha-gpu-isolation-settings
    secrets: inherit

  example-ci:
    name: Example CI
    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main
    needs: cache-pytorch-image
    with:
      job: run_examples_gpu
      slack_report_channel: "#amd-hf-ci"
      runner_group: amd-mi325
      docker: huggingface/transformers-pytorch-amd-gpu
      ci_event: Scheduled CI (AMD) - mi325
      report_repo_id: optimum-amd/transformers_daily_ci
      env_file: /etc/podinfo/gha-gpu-isolation-settings
    secrets: inherit

  deepspeed-ci:
    name: DeepSpeed CI
    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main
    with:
      job: run_torch_cuda_extensions_gpu
      slack_report_channel: "#amd-hf-ci"
      runner_group: amd-mi325
      docker: huggingface/transformers-pytorch-deepspeed-amd-gpu
      ci_event: Scheduled CI (AMD) - mi325
      report_repo_id: optimum-amd/transformers_daily_ci
      env_file: /etc/podinfo/gha-gpu-isolation-settings
    secrets: inherit
