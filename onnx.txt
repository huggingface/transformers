============================= test session starts ==============================
platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /home/ilyas/transformers/.docker/bin/python3
cachedir: .pytest_cache
hypothesis profile 'default'
rootdir: /home/ilyas/transformers
configfile: pyproject.toml
plugins: anyio-4.11.0, xdist-3.8.0, asyncio-1.3.0, timeout-2.4.0, rich-0.2.0, rerunfailures-15.1, hypothesis-6.148.2, order-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=function, asyncio_default_test_loop_scope=function
created: 64/64 workers
64 workers [477 items]

scheduling tests via LoadScheduling

tests/models/aimv2/test_modeling_aimv2.py::Aimv2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/aria/test_modeling_aria.py::AriaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/align/test_modeling_align.py::AlignVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/align/test_modeling_align.py::AlignModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bigbird_pegasus/test_modeling_bigbird_pegasus.py::BigBirdPegasusStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/apertus/test_modeling_apertus.py::ApertusModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bit/test_modeling_bit.py::BitModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip/test_modeling_blip.py::BlipTextRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/big_bird/test_modeling_big_bird.py::BigBirdModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bark/test_modeling_bark.py::BarkSemanticModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip_2/test_modeling_blip_2.py::Blip2ForConditionalGenerationDecoderOnlyTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bark/test_modeling_bark.py::BarkFineModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blenderbot/test_modeling_blenderbot.py::BlenderbotModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bert/test_modeling_bert.py::BertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bart/test_modeling_bart.py::BartStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip/test_modeling_blip.py::BlipModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blenderbot_small/test_modeling_blenderbot_small.py::BlenderbotSmallModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip/test_modeling_blip.py::BlipVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip/test_modeling_blip_text.py::BlipTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip_2/test_modeling_blip_2.py::Blip2TextModelWithProjectionTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/altclip/test_modeling_altclip.py::AltCLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/aimv2/test_modeling_aimv2.py::Aimv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/audioflamingo3/test_modeling_audioflamingo3.py::AudioFlamingo3ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bros/test_modeling_bros.py::BrosModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/aya_vision/test_modeling_aya_vision.py::AyaVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blt/test_modeling_blt.py::BltModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip_2/test_modeling_blip_2.py::Blip2TextRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/chameleon/test_modeling_chameleon.py::ChameleonModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/chinese_clip/test_modeling_chinese_clip.py::ChineseCLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clap/test_modeling_clap.py::ClapTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clip/test_modeling_clip.py::CLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/chinese_clip/test_modeling_chinese_clip.py::ChineseCLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/codegen/test_modeling_codegen.py::CodeGenModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clipseg/test_modeling_clipseg.py::CLIPSegVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/cohere2_vision/test_modeling_cohere2_vision.py::Cohere2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clipseg/test_modeling_clipseg.py::CLIPSegModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clvp/test_modeling_clvp.py::ClvpDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/cohere2/test_modeling_cohere2.py::CohereModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/colqwen2/test_modeling_colqwen2.py::ColQwen2ForRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/convbert/test_modeling_convbert.py::ConvBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clip/test_modeling_clip.py::CLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/csm/test_modeling_csm.py::CsmForConditionalGenerationTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/convnextv2/test_modeling_convnextv2.py::ConvNextV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dac/test_modeling_dac.py::DacModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/cvt/test_modeling_cvt.py::CvtModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dbrx/test_modeling_dbrx.py::DbrxModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/data2vec/test_modeling_data2vec_text.py::Data2VecTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deberta_v2/test_modeling_deberta_v2.py::DebertaV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deepseek_v2/test_modeling_deepseek_v2.py::DeepseekV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/donut/test_modeling_donut_swin.py::DonutSwinModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/d_fine/test_modeling_d_fine.py::DFineModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/diffllama/test_modeling_diffllama.py::DiffLlamaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deformable_detr/test_modeling_deformable_detr.py::DeformableDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/depth_anything/test_modeling_depth_anything.py::DepthAnythingModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dinov2/test_modeling_dinov2.py::Dinov2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dinov3_convnext/test_modeling_dinov3_convnext.py::DINOv3ConvNextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/detr/test_modeling_detr.py::DetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/distilbert/test_modeling_distilbert.py::DistilBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dpr/test_modeling_dpr.py::DPRModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dpt/test_modeling_dpt_auto_backbone.py::DPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deepseek_vl/test_modeling_deepseek_vl.py::DeepseekVLModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/edgetam/test_modeling_edgetam.py::EdgeTamModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/efficientnet/test_modeling_efficientnet.py::EfficientNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/emu3/test_modeling_emu3.py::Emu3Text2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [  0%] PASSED tests/models/colqwen2/test_modeling_colqwen2.py::ColQwen2ForRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/conditional_detr/test_modeling_conditional_detr.py::ConditionalDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [  0%] PASSED tests/models/chameleon/test_modeling_chameleon.py::ChameleonModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/chameleon/test_modeling_chameleon.py::ChameleonVision2SeqModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw11] [  0%] PASSED tests/models/aria/test_modeling_aria.py::AriaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/audio_spectrogram_transformer/test_modeling_audio_spectrogram_transformer.py::ASTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [  0%] PASSED tests/models/bros/test_modeling_bros.py::BrosModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/canine/test_modeling_canine.py::CanineModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [  1%] PASSED tests/models/chameleon/test_modeling_chameleon.py::ChameleonVision2SeqModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/eomt/test_modeling_eomt.py::EomtForUniversalSegmentationTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [  1%] PASSED tests/models/eomt/test_modeling_eomt.py::EomtForUniversalSegmentationTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ernie4_5_moe/test_modeling_ernie4_5_moe.py::Ernie4_5_MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [  1%] PASSED tests/models/chinese_clip/test_modeling_chinese_clip.py::ChineseCLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/chinese_clip/test_modeling_chinese_clip.py::ChineseCLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [  1%] PASSED tests/models/altclip/test_modeling_altclip.py::AltCLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/altclip/test_modeling_altclip.py::AltCLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [  1%] PASSED tests/models/bark/test_modeling_bark.py::BarkSemanticModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [  2%] PASSED tests/models/blip/test_modeling_blip.py::BlipVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bark/test_modeling_bark.py::BarkCoarseModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip/test_modeling_blip.py::BlipTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [  2%] PASSED tests/models/blip_2/test_modeling_blip_2.py::Blip2TextModelWithProjectionTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip_2/test_modeling_blip_2.py::Blip2VisionModelWithProjectionTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [  2%] PASSED tests/models/blip/test_modeling_blip_text.py::BlipTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip_2/test_modeling_blip_2.py::Blip2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw8] [  2%] PASSED tests/models/bark/test_modeling_bark.py::BarkFineModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bart/test_modeling_bart.py::BartModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [  2%] PASSED tests/models/clipseg/test_modeling_clipseg.py::CLIPSegVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clipseg/test_modeling_clipseg.py::CLIPSegTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [  3%] PASSED tests/models/emu3/test_modeling_emu3.py::Emu3Text2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/emu3/test_modeling_emu3.py::Emu3Vision2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [  3%] PASSED tests/models/aimv2/test_modeling_aimv2.py::Aimv2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/aimv2/test_modeling_aimv2.py::Aimv2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [  3%] PASSED tests/models/depth_anything/test_modeling_depth_anything.py::DepthAnythingModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/depth_pro/test_modeling_depth_pro.py::DepthProModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw59] [  3%] PASSED tests/models/dpt/test_modeling_dpt_auto_backbone.py::DPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dpt/test_modeling_dpt_hybrid.py::DPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw31] [  3%] PASSED tests/models/chinese_clip/test_modeling_chinese_clip.py::ChineseCLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clap/test_modeling_clap.py::ClapAudioModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [  4%] PASSED tests/models/emu3/test_modeling_emu3.py::Emu3Vision2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [  4%] PASSED tests/models/blip/test_modeling_blip.py::BlipModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip/test_modeling_blip.py::BlipVQAModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flaubert/test_modeling_flaubert.py::FlaubertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [  4%] PASSED tests/models/blip/test_modeling_blip.py::BlipTextRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip/test_modeling_blip.py::BlipTextImageModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw16] [  4%] PASSED tests/models/clip/test_modeling_clip.py::CLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clip/test_modeling_clip.py::CLIPForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw3] [  5%] PASSED tests/models/aimv2/test_modeling_aimv2.py::Aimv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/albert/test_modeling_albert.py::AlbertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw30] [  5%] FAILED tests/models/bit/test_modeling_bit.py::BitModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bitnet/test_modeling_bitnet.py::BitNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [  5%] PASSED tests/models/clipseg/test_modeling_clipseg.py::CLIPSegTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/fastspeech2_conformer/test_modeling_fastspeech2_conformer.py::FastSpeech2ConformerWithHifiGanTest::test_onnx_export <- tests/test_modeling_common.py 
[gw34] [  5%] PASSED tests/models/clap/test_modeling_clap.py::ClapTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clap/test_modeling_clap.py::ClapModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw22] [  5%] PASSED tests/models/bart/test_modeling_bart.py::BartStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/beit/test_modeling_beit.py::BeitModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [  6%] PASSED tests/models/bark/test_modeling_bark.py::BarkCoarseModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/exaone4/test_modeling_exaone4.py::Exaone4ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [  6%] PASSED tests/models/csm/test_modeling_csm.py::CsmForConditionalGenerationTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ctrl/test_modeling_ctrl.py::CTRLModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [  6%] PASSED tests/models/blip/test_modeling_blip.py::BlipTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/falcon/test_modeling_falcon.py::FalconModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [  6%] PASSED tests/models/bigbird_pegasus/test_modeling_bigbird_pegasus.py::BigBirdPegasusStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/biogpt/test_modeling_biogpt.py::BioGptModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw11] [  6%] PASSED tests/models/audio_spectrogram_transformer/test_modeling_audio_spectrogram_transformer.py::ASTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ernie/test_modeling_ernie.py::ErnieModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw4] [  7%] FAILED tests/models/audioflamingo3/test_modeling_audioflamingo3.py::AudioFlamingo3ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/autoformer/test_modeling_autoformer.py::AutoformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [  7%] PASSED tests/models/clip/test_modeling_clip.py::CLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clip/test_modeling_clip.py::CLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [  7%] PASSED tests/models/chinese_clip/test_modeling_chinese_clip.py::ChineseCLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/esm/test_modeling_esmfold.py::EsmFoldModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw32] [  7%] PASSED tests/models/blip_2/test_modeling_blip_2.py::Blip2TextRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bloom/test_modeling_bloom.py::BloomModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw54] [  7%] PASSED tests/models/blip_2/test_modeling_blip_2.py::Blip2ForConditionalGenerationDecoderOnlyTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blip_2/test_modeling_blip_2.py::Blip2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw4] [  8%] PASSED tests/models/autoformer/test_modeling_autoformer.py::AutoformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gemma3n/test_modeling_gemma3n.py::Gemma3nAudioModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw4] [  8%] SKIPPED tests/models/gemma3n/test_modeling_gemma3n.py::Gemma3nAudioModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/glm/test_modeling_glm.py::GlmModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [  8%] PASSED tests/models/blip_2/test_modeling_blip_2.py::Blip2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/falcon_mamba/test_modeling_falcon_mamba.py::FalconMambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [  8%] PASSED tests/models/clvp/test_modeling_clvp.py::ClvpDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clvp/test_modeling_clvp.py::ClvpModelForConditionalGenerationTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [  9%] PASSED tests/models/aimv2/test_modeling_aimv2.py::Aimv2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flava/test_modeling_flava.py::FlavaImageModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw44] [  9%] FAILED tests/models/blt/test_modeling_blt.py::BltModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bridgetower/test_modeling_bridgetower.py::BridgeTowerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [  9%] PASSED tests/models/dinov3_convnext/test_modeling_dinov3_convnext.py::DINOv3ConvNextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dinov3_vit/test_modeling_dinov3_vit.py::Dinov3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw16] [  9%] PASSED tests/models/clip/test_modeling_clip.py::CLIPForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/florence2/test_modeling_florence2.py::Florence2ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw56] [  9%] PASSED tests/models/cohere2/test_modeling_cohere2.py::CohereModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/cohere2/test_modeling_cohere2.py::Cohere2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [ 10%] PASSED tests/models/altclip/test_modeling_altclip.py::AltCLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/evolla/test_modeling_evolla.py::EvollaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 10%] PASSED tests/models/esm/test_modeling_esmfold.py::EsmFoldModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gemma3n/test_modeling_gemma3n.py::Gemma3nVision2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 10%] SKIPPED tests/models/gemma3n/test_modeling_gemma3n.py::Gemma3nVision2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gpt_neo/test_modeling_gpt_neo.py::GPTNeoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [ 10%] PASSED tests/models/fastspeech2_conformer/test_modeling_fastspeech2_conformer.py::FastSpeech2ConformerWithHifiGanTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/fsmt/test_modeling_fsmt.py::FSMTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw21] [ 10%] PASSED tests/models/codegen/test_modeling_codegen.py::CodeGenModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/cohere/test_modeling_cohere.py::CohereModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw27] [ 11%] PASSED tests/models/dpr/test_modeling_dpr.py::DPRModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dpt/test_modeling_dpt.py::DPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 11%] PASSED tests/models/blip_2/test_modeling_blip_2.py::Blip2VisionModelWithProjectionTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/falcon_h1/test_modeling_falcon_h1.py::FalconH1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 11%] PASSED tests/models/dbrx/test_modeling_dbrx.py::DbrxModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deberta/test_modeling_deberta.py::DebertaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 11%] PASSED tests/models/falcon_h1/test_modeling_falcon_h1.py::FalconH1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/granite/test_modeling_granite.py::GraniteModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 11%] PASSED tests/models/deepseek_vl/test_modeling_deepseek_vl.py::DeepseekVLModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deepseek_vl_hybrid/test_modeling_deepseek_vl_hybrid.py::DeepseekVLHybridModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw51] [ 12%] PASSED tests/models/dinov2/test_modeling_dinov2.py::Dinov2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dinov2_with_registers/test_modeling_dinov2_with_registers.py::Dinov2WithRegistersModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw12] [ 12%] PASSED tests/models/blenderbot_small/test_modeling_blenderbot_small.py::BlenderbotSmallModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blenderbot_small/test_modeling_blenderbot_small.py::BlenderbotSmallStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 12%] PASSED tests/models/blenderbot/test_modeling_blenderbot.py::BlenderbotModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/blenderbot/test_modeling_blenderbot.py::BlenderbotStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 12%] PASSED tests/models/blip/test_modeling_blip.py::BlipTextImageModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flex_olmo/test_modeling_flex_olmo.py::FlexOlmoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 12%] PASSED tests/models/clipseg/test_modeling_clipseg.py::CLIPSegModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/clvp/test_modeling_clvp.py::ClvpEncoderTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 13%] PASSED tests/models/flava/test_modeling_flava.py::FlavaImageModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/glm4v_moe/test_modeling_glm4v_moe.py::Glm4vMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [ 13%] PASSED tests/models/clvp/test_modeling_clvp.py::ClvpModelForConditionalGenerationTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/glm4v/test_modeling_glm4v.py::Glm4vModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 13%] PASSED tests/models/align/test_modeling_align.py::AlignVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/align/test_modeling_align.py::AlignTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 13%] PASSED tests/models/cohere2_vision/test_modeling_cohere2_vision.py::Cohere2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/colpali/test_modeling_colpali.py::ColPaliForRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw9] [ 14%] PASSED tests/models/apertus/test_modeling_apertus.py::ApertusModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/arcee/test_modeling_arcee.py::ArceeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [ 14%] PASSED tests/models/glm4v/test_modeling_glm4v.py::Glm4vModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/helium/test_modeling_helium.py::HeliumModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw7] [ 14%] PASSED tests/models/aya_vision/test_modeling_aya_vision.py::AyaVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 14%] PASSED tests/models/glm4v_moe/test_modeling_glm4v_moe.py::Glm4vMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/groupvit/test_modeling_groupvit.py::GroupViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bamba/test_modeling_bamba.py::BambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw7] [ 14%] PASSED tests/models/bamba/test_modeling_bamba.py::BambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/hunyuan_v1_dense/test_modeling_hunyuan_v1_dense.py::HunYuanDenseV1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 15%] PASSED tests/models/blip/test_modeling_blip.py::BlipVQAModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flava/test_modeling_flava.py::FlavaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 15%] PASSED tests/models/flava/test_modeling_flava.py::FlavaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/idefics/test_modeling_idefics.py::IdeficsModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [ 15%] PASSED tests/models/clip/test_modeling_clip.py::CLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gemma3n/test_modeling_gemma3n.py::Gemma3nTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 15%] PASSED tests/models/align/test_modeling_align.py::AlignModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/altclip/test_modeling_altclip.py::AltCLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 15%] PASSED tests/models/align/test_modeling_align.py::AlignTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/hgnet_v2/test_modeling_hgnet_v2.py::HGNetV2ForImageClassificationTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 16%] PASSED tests/models/dac/test_modeling_dac.py::DacModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/data2vec/test_modeling_data2vec_audio.py::Data2VecAudioModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw30] [ 16%] PASSED tests/models/bitnet/test_modeling_bitnet.py::BitNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/focalnet/test_modeling_focalnet.py::FocalNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 16%] PASSED tests/models/clvp/test_modeling_clvp.py::ClvpEncoderTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/groupvit/test_modeling_groupvit.py::GroupViTTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 16%] PASSED tests/models/data2vec/test_modeling_data2vec_audio.py::Data2VecAudioModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/idefics3/test_modeling_idefics3.py::Idefics3ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 16%] PASSED tests/models/idefics3/test_modeling_idefics3.py::Idefics3ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/informer/test_modeling_informer.py::InformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 17%] FAILED tests/models/flaubert/test_modeling_flaubert.py::FlaubertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flava/test_modeling_flava.py::FlavaForPreTrainingTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 17%] PASSED tests/models/ernie4_5_moe/test_modeling_ernie4_5_moe.py::Ernie4_5_MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/esm/test_modeling_esm.py::EsmModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 17%] PASSED tests/models/informer/test_modeling_informer.py::InformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/instructblip/test_modeling_instructblip.py::InstructBlipVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 17%] PASSED tests/models/esm/test_modeling_esm.py::EsmModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/instructblipvideo/test_modeling_instructblipvideo.py::InstructBlipVideoVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 18%] PASSED tests/models/flava/test_modeling_flava.py::FlavaForPreTrainingTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/instructblip/test_modeling_instructblip.py::InstructBlipForConditionalGenerationDecoderOnlyTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [ 18%] PASSED tests/models/dinov3_vit/test_modeling_dinov3_vit.py::Dinov3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/got_ocr2/test_modeling_got_ocr2.py::GotOcr2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw49] [ 18%] PASSED tests/models/donut/test_modeling_donut_swin.py::DonutSwinModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dots1/test_modeling_dots1.py::Dots1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 18%] PASSED tests/models/altclip/test_modeling_altclip.py::AltCLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/idefics2/test_modeling_idefics2.py::Idefics2ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 18%] PASSED tests/models/idefics2/test_modeling_idefics2.py::Idefics2ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/jetmoe/test_modeling_jetmoe.py::JetMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 19%] PASSED tests/models/jetmoe/test_modeling_jetmoe.py::JetMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/kosmos2/test_modeling_kosmos2.py::Kosmos2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw12] [ 19%] PASSED tests/models/blenderbot_small/test_modeling_blenderbot_small.py::BlenderbotSmallStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/granitemoeshared/test_modeling_granitemoeshared.py::GraniteMoeSharedModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw56] [ 19%] PASSED tests/models/cohere2/test_modeling_cohere2.py::Cohere2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gpt_bigcode/test_modeling_gpt_bigcode.py::GPTBigCodeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 19%] PASSED tests/models/kosmos2/test_modeling_kosmos2.py::Kosmos2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/kosmos2_5/test_modeling_kosmos2_5.py::Kosmos2_5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw12] [ 19%] PASSED tests/models/granitemoeshared/test_modeling_granitemoeshared.py::GraniteMoeSharedModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/kyutai_speech_to_text/test_modeling_kyutai_speech_to_text.py::KyutaiSpeechToTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 20%] PASSED tests/models/kosmos2_5/test_modeling_kosmos2_5.py::Kosmos2_5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/layoutlmv2/test_modeling_layoutlmv2.py::LayoutLMv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 20%] SKIPPED tests/models/layoutlmv2/test_modeling_layoutlmv2.py::LayoutLMv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/led/test_modeling_led.py::LEDModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 20%] PASSED tests/models/instructblip/test_modeling_instructblip.py::InstructBlipVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/instructblipvideo/test_modeling_instructblipvideo.py::InstructBlipVideoForConditionalGenerationDecoderOnlyTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 20%] PASSED tests/models/led/test_modeling_led.py::LEDModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/levit/test_modeling_levit.py::LevitModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw13] [ 20%] PASSED tests/models/convnextv2/test_modeling_convnextv2.py::ConvNextV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/cpmant/test_modeling_cpmant.py::CpmAntModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 21%] PASSED tests/models/blenderbot/test_modeling_blenderbot.py::BlenderbotStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/grounding_dino/test_modeling_grounding_dino.py::GroundingDinoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw21] [ 21%] PASSED tests/models/cohere/test_modeling_cohere.py::CohereModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gpt_oss/test_modeling_gpt_oss.py::GptOssModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 21%] PASSED tests/models/granite/test_modeling_granite.py::GraniteModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/granitemoe/test_modeling_granitemoe.py::GraniteMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [ 21%] PASSED tests/models/ctrl/test_modeling_ctrl.py::CTRLModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gemma/test_modeling_gemma.py::GemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 22%] PASSED tests/models/instructblipvideo/test_modeling_instructblipvideo.py::InstructBlipVideoVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/internvl/test_modeling_internvl.py::InternVLModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 22%] PASSED tests/models/granitemoe/test_modeling_granitemoe.py::GraniteMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/llama/test_modeling_llama.py::LlamaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw34] [ 22%] PASSED tests/models/clap/test_modeling_clap.py::ClapModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/funnel/test_modeling_funnel.py::FunnelModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw42] [ 22%] PASSED tests/models/distilbert/test_modeling_distilbert.py::DistilBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/doge/test_modeling_doge.py::DogeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [ 22%] PASSED tests/models/falcon_mamba/test_modeling_falcon_mamba.py::FalconMambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/glm4_moe/test_modeling_glm4_moe.py::Glm4MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 23%] PASSED tests/models/grounding_dino/test_modeling_grounding_dino.py::GroundingDinoModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/lightglue/test_modeling_lightglue.py::LightGlueModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw40] [ 23%] PASSED tests/models/deberta_v2/test_modeling_deberta_v2.py::DebertaV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/decision_transformer/test_modeling_decision_transformer.py::DecisionTransformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 23%] PASSED tests/models/biogpt/test_modeling_biogpt.py::BioGptModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gemma3/test_modeling_gemma3.py::Gemma3TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 23%] PASSED tests/models/lightglue/test_modeling_lightglue.py::LightGlueModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/longt5/test_modeling_longt5.py::LongT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 23%] PASSED tests/models/longt5/test_modeling_longt5.py::LongT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/longt5/test_modeling_longt5.py::LongT5EncoderOnlyTGlobalModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 24%] PASSED tests/models/longt5/test_modeling_longt5.py::LongT5EncoderOnlyTGlobalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/luke/test_modeling_luke.py::LukeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 24%] PASSED tests/models/groupvit/test_modeling_groupvit.py::GroupViTTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/imagegpt/test_modeling_imagegpt.py::ImageGPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [ 24%] PASSED tests/models/fsmt/test_modeling_fsmt.py::FSMTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gpt_neox_japanese/test_modeling_gpt_neox_japanese.py::GPTNeoXModelJapaneseTest::test_onnx_export <- tests/test_modeling_common.py 
[gw36] [ 24%] PASSED tests/models/efficientnet/test_modeling_efficientnet.py::EfficientNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/electra/test_modeling_electra.py::ElectraModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 24%] PASSED tests/models/colpali/test_modeling_colpali.py::ColPaliForRetrievalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/hiera/test_modeling_hiera.py::HieraModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 25%] PASSED tests/models/depth_pro/test_modeling_depth_pro.py::DepthProModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flava/test_modeling_flava.py::FlavaTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw34] [ 25%] PASSED tests/models/funnel/test_modeling_funnel.py::FunnelModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/llava_onevision/test_modeling_llava_onevision.py::LlavaOnevisionForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw34] [ 25%] PASSED tests/models/llava_onevision/test_modeling_llava_onevision.py::LlavaOnevisionForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw51] [ 25%] PASSED tests/models/dinov2_with_registers/test_modeling_dinov2_with_registers.py::Dinov2WithRegistersModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/granitemoehybrid/test_modeling_granitemoehybrid.py::GraniteMoeHybridModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 25%] PASSED tests/models/hiera/test_modeling_hiera.py::HieraModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/marian/test_modeling_marian.py::MarianModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw51] [ 26%] PASSED tests/models/granitemoehybrid/test_modeling_granitemoehybrid.py::GraniteMoeHybridModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/maskformer/test_modeling_maskformer.py::MaskFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw16] [ 26%] PASSED tests/models/florence2/test_modeling_florence2.py::Florence2ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gpt2/test_modeling_gpt2.py::GPT2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw60] [ 26%] PASSED tests/models/data2vec/test_modeling_data2vec_text.py::Data2VecTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/data2vec/test_modeling_data2vec_vision.py::Data2VecVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [ 26%] PASSED tests/models/evolla/test_modeling_evolla.py::EvollaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gpt_bigcode/test_modeling_gpt_bigcode.py::GPTBigCodeMHAModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 27%] PASSED tests/models/diffllama/test_modeling_diffllama.py::DiffLlamaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dinat/test_modeling_dinat.py::DinatModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 27%] SKIPPED tests/models/dinat/test_modeling_dinat.py::DinatModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 27%] PASSED tests/models/flex_olmo/test_modeling_flex_olmo.py::FlexOlmoModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/groupvit/test_modeling_groupvit.py::GroupViTVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw32] [ 27%] PASSED tests/models/bloom/test_modeling_bloom.py::BloomModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/git/test_modeling_git.py::GitVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw45] [ 27%] PASSED tests/models/deepseek_v2/test_modeling_deepseek_v2.py::DeepseekV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deepseek_v3/test_modeling_deepseek_v3.py::DeepseekV3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw40] [ 28%] PASSED tests/models/decision_transformer/test_modeling_decision_transformer.py::DecisionTransformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/longt5/test_modeling_longt5.py::LongT5TGlobalModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw20] [ 28%] PASSED tests/models/convbert/test_modeling_convbert.py::ConvBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/convnext/test_modeling_convnext.py::ConvNextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw4] [ 28%] PASSED tests/models/glm/test_modeling_glm.py::GlmModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/glm4/test_modeling_glm4.py::Glm4ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw40] [ 28%] PASSED tests/models/longt5/test_modeling_longt5.py::LongT5TGlobalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/minimax/test_modeling_minimax.py::MiniMaxModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw12] [ 28%] PASSED tests/models/kyutai_speech_to_text/test_modeling_kyutai_speech_to_text.py::KyutaiSpeechToTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/layoutlmv3/test_modeling_layoutlmv3.py::LayoutLMv3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 29%] PASSED tests/models/canine/test_modeling_canine.py::CanineModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ernie4_5/test_modeling_ernie4_5.py::Ernie4_5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw27] [ 29%] PASSED tests/models/dpt/test_modeling_dpt.py::DPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gptj/test_modeling_gptj.py::GPTJModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 29%] PASSED tests/models/flava/test_modeling_flava.py::FlavaTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/marian/test_modeling_marian.py::MarianStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw31] [ 29%] PASSED tests/models/clap/test_modeling_clap.py::ClapAudioModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flava/test_modeling_flava.py::FlavaImageCodebookTest::test_onnx_export <- tests/test_modeling_common.py 
[gw31] [ 29%] PASSED tests/models/flava/test_modeling_flava.py::FlavaImageCodebookTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mm_grounding_dino/test_modeling_mm_grounding_dino.py::MMGroundingDinoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw3] [ 30%] PASSED tests/models/albert/test_modeling_albert.py::AlbertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/fnet/test_modeling_fnet.py::FNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw7] [ 30%] PASSED tests/models/hunyuan_v1_dense/test_modeling_hunyuan_v1_dense.py::HunYuanDenseV1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ibert/test_modeling_ibert.py::IBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw32] [ 30%] PASSED tests/models/git/test_modeling_git.py::GitVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mgp_str/test_modeling_mgp_str.py::MgpstrModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [ 30%] PASSED tests/models/helium/test_modeling_helium.py::HeliumModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/hubert/test_modeling_hubert.py::HubertRobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 31%] PASSED tests/models/gpt_neo/test_modeling_gpt_neo.py::GPTNeoModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gpt_neox/test_modeling_gpt_neox.py::GPTNeoXModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [ 31%] PASSED tests/models/gpt_neox_japanese/test_modeling_gpt_neox_japanese.py::GPTNeoXModelJapaneseTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mamba/test_modeling_mamba.py::MambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw13] [ 31%] PASSED tests/models/cpmant/test_modeling_cpmant.py::CpmAntModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/lfm2_vl/test_modeling_lfm2_vl.py::Lfm2VlModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw31] [ 31%] PASSED tests/models/mm_grounding_dino/test_modeling_mm_grounding_dino.py::MMGroundingDinoModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mobilebert/test_modeling_mobilebert.py::MobileBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [ 31%] PASSED tests/models/falcon/test_modeling_falcon.py::FalconModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gemma2/test_modeling_gemma2.py::Gemma2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw13] [ 32%] PASSED tests/models/lfm2_vl/test_modeling_lfm2_vl.py::Lfm2VlModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/moonshine/test_modeling_moonshine.py::MoonshineModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw7] [ 32%] PASSED tests/models/ibert/test_modeling_ibert.py::IBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mobilenet_v2/test_modeling_mobilenet_v2.py::MobileNetV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [ 32%] PASSED tests/models/hubert/test_modeling_hubert.py::HubertRobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mobilevitv2/test_modeling_mobilevitv2.py::MobileViTV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw54] [ 32%] PASSED tests/models/blip_2/test_modeling_blip_2.py::Blip2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/git/test_modeling_git.py::GitModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw8] [ 32%] PASSED tests/models/bart/test_modeling_bart.py::BartModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/fastspeech2_conformer/test_modeling_fastspeech2_conformer.py::FastSpeech2ConformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw55] [ 33%] PASSED tests/models/bert/test_modeling_bert.py::BertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bert_generation/test_modeling_bert_generation.py::BertGenerationEncoderTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 33%] PASSED tests/models/deepseek_vl_hybrid/test_modeling_deepseek_vl_hybrid.py::DeepseekVLHybridModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/granitemoehybrid/test_modeling_granitemoehybrid.py::BambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 33%] PASSED tests/models/hgnet_v2/test_modeling_hgnet_v2.py::HGNetV2ForImageClassificationTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/idefics3/test_modeling_idefics3.py::Idefics3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 33%] PASSED tests/models/granitemoehybrid/test_modeling_granitemoehybrid.py::BambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/musicgen/test_modeling_musicgen.py::MusicgenTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 33%] PASSED tests/models/idefics3/test_modeling_idefics3.py::Idefics3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/musicgen_melody/test_modeling_musicgen_melody.py::MusicgenMelodyDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
[gw56] [ 34%] PASSED tests/models/gpt_bigcode/test_modeling_gpt_bigcode.py::GPTBigCodeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/layoutlm/test_modeling_layoutlm.py::LayoutLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 34%] PASSED tests/models/groupvit/test_modeling_groupvit.py::GroupViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/hunyuan_v1_moe/test_modeling_hunyuan_v1_moe.py::HunYuanMoEV1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 34%] PASSED tests/models/edgetam/test_modeling_edgetam.py::EdgeTamModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/efficientloftr/test_modeling_efficientloftr.py::EfficientLoFTRModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 34%] PASSED tests/models/deberta/test_modeling_deberta.py::DebertaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/granite_speech/test_modeling_granite_speech.py::GraniteSpeechForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 35%] PASSED tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 35%] PASSED tests/models/efficientloftr/test_modeling_efficientloftr.py::EfficientLoFTRModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/nllb_moe/test_modeling_nllb_moe.py::NllbMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 35%] PASSED tests/models/nllb_moe/test_modeling_nllb_moe.py::NllbMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/olmo2/test_modeling_olmo2.py::Olmo2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 35%] PASSED tests/models/exaone4/test_modeling_exaone4.py::Exaone4ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/fuyu/test_modeling_fuyu.py::FuyuModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 35%] PASSED tests/models/idefics/test_modeling_idefics.py::IdeficsModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/idefics/test_modeling_idefics.py::IdeficsForVisionText2TextTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 36%] PASSED tests/models/granite_speech/test_modeling_granite_speech.py::GraniteSpeechForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/nystromformer/test_modeling_nystromformer.py::NystromformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw8] [ 36%] PASSED tests/models/fastspeech2_conformer/test_modeling_fastspeech2_conformer.py::FastSpeech2ConformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mt5/test_modeling_mt5.py::MT5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 36%] PASSED tests/models/imagegpt/test_modeling_imagegpt.py::ImageGPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/m2m_100/test_modeling_m2m_100.py::M2M100ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw49] [ 36%] PASSED tests/models/dots1/test_modeling_dots1.py::Dots1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/janus/test_modeling_janus.py::JanusVQModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 36%] PASSED tests/models/instructblip/test_modeling_instructblip.py::InstructBlipForConditionalGenerationDecoderOnlyTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/jamba/test_modeling_jamba.py::JambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw9] [ 37%] PASSED tests/models/arcee/test_modeling_arcee.py::ArceeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/hubert/test_modeling_hubert.py::HubertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [ 37%] PASSED tests/models/glm4_moe/test_modeling_glm4_moe.py::Glm4MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/longformer/test_modeling_longformer.py::LongformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 37%] PASSED tests/models/marian/test_modeling_marian.py::MarianStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mllama/test_modeling_mllama.py::MllamaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw32] [ 37%] PASSED tests/models/mgp_str/test_modeling_mgp_str.py::MgpstrModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mobilevit/test_modeling_mobilevit.py::MobileViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw9] [ 37%] PASSED tests/models/hubert/test_modeling_hubert.py::HubertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlv2/test_modeling_owlv2.py::Owlv2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 38%] PASSED tests/models/internvl/test_modeling_internvl.py::InternVLModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/llava_next/test_modeling_llava_next.py::LlavaNextForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [ 38%] PASSED tests/models/longformer/test_modeling_longformer.py::LongformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlv2/test_modeling_owlv2.py::Owlv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 38%] PASSED tests/models/llava_next/test_modeling_llava_next.py::LlavaNextForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlvit/test_modeling_owlvit.py::OwlViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 38%] FAILED tests/models/mllama/test_modeling_mllama.py::MllamaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlv2/test_modeling_owlv2.py::Owlv2ForObjectDetectionTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 38%] PASSED tests/models/marian/test_modeling_marian.py::MarianModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/maskformer/test_modeling_maskformer_swin.py::MaskFormerSwinModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 39%] PASSED tests/models/maskformer/test_modeling_maskformer_swin.py::MaskFormerSwinModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw11] [ 39%] PASSED tests/models/ernie/test_modeling_ernie.py::ErnieModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/gemma3/test_modeling_gemma3.py::Gemma3Vision2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/parakeet/test_modeling_parakeet.py::ParakeetEncoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [ 39%] PASSED tests/models/gemma/test_modeling_gemma.py::GemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/llava/test_modeling_llava.py::LlavaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw42] [ 39%] PASSED tests/models/doge/test_modeling_doge.py::DogeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/longcat_flash/test_modeling_longcat_flash.py::LongcatFlashModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [ 40%] PASSED tests/models/got_ocr2/test_modeling_got_ocr2.py::GotOcr2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/janus/test_modeling_janus.py::JanusVisionText2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 40%] PASSED tests/models/instructblipvideo/test_modeling_instructblipvideo.py::InstructBlipVideoForConditionalGenerationDecoderOnlyTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/lfm2/test_modeling_lfm2.py::Lfm2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw55] [ 40%] PASSED tests/models/bert_generation/test_modeling_bert_generation.py::BertGenerationEncoderTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/musicgen/test_modeling_musicgen.py::MusicgenDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 40%] PASSED tests/models/ernie4_5/test_modeling_ernie4_5.py::Ernie4_5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mlcd/test_modeling_mlcd.py::MLCDVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 40%] PASSED tests/models/mlcd/test_modeling_mlcd.py::MLCDVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/perceiver/test_modeling_perceiver.py::PerceiverModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [ 41%] PASSED tests/models/janus/test_modeling_janus.py::JanusVisionText2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pegasus/test_modeling_pegasus.py::PegasusStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw23] [ 41%] FAILED tests/models/d_fine/test_modeling_d_fine.py::DFineModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dab_detr/test_modeling_dab_detr.py::DabDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [ 41%] PASSED tests/models/gpt_bigcode/test_modeling_gpt_bigcode.py::GPTBigCodeMHAModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 41%] PASSED tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/olmo/test_modeling_olmo.py::OlmoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw34] [ 41%] PASSED tests/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mask2former/test_modeling_mask2former.py::Mask2FormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 42%] PASSED tests/models/musicgen_melody/test_modeling_musicgen_melody.py::MusicgenMelodyDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mvp/test_modeling_mvp.py::MvpModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 42%] PASSED tests/models/gemma3/test_modeling_gemma3.py::Gemma3TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/longt5/test_modeling_longt5.py::LongT5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 42%] PASSED tests/models/longt5/test_modeling_longt5.py::LongT5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pix2struct/test_modeling_pix2struct.py::Pix2StructTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 42%] PASSED tests/models/perceiver/test_modeling_perceiver.py::PerceiverModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/perception_lm/test_modeling_perception_lm.py::PerceptionLMForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw22] [ 42%] PASSED tests/models/beit/test_modeling_beit.py::BeitModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/funnel/test_modeling_funnel.py::FunnelBaseModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [ 43%] PASSED tests/models/mamba/test_modeling_mamba.py::MambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/modernbert_decoder/test_modeling_modernbert_decoder.py::ModernBertDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw22] [ 43%] PASSED tests/models/funnel/test_modeling_funnel.py::FunnelBaseModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/plbart/test_modeling_plbart.py::PLBartModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 43%] PASSED tests/models/olmo2/test_modeling_olmo2.py::Olmo2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/olmo3/test_modeling_olmo3.py::Olmo3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 43%] PASSED tests/models/fuyu/test_modeling_fuyu.py::FuyuModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/olmoe/test_modeling_olmoe.py::OlmoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 44%] PASSED tests/models/idefics/test_modeling_idefics.py::IdeficsForVisionText2TextTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/omdet_turbo/test_modeling_omdet_turbo.py::OmDetTurboModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw54] [ 44%] PASSED tests/models/git/test_modeling_git.py::GitModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mt5/test_modeling_mt5.py::MT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 44%] PASSED tests/models/llama/test_modeling_llama.py::LlamaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/llava_next_video/test_modeling_llava_next_video.py::LlavaNextVideoForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw8] [ 44%] PASSED tests/models/mt5/test_modeling_mt5.py::MT5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/openai/test_modeling_openai.py::OpenAIGPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 44%] PASSED tests/models/llava_next_video/test_modeling_llava_next_video.py::LlavaNextVideoForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/prophetnet/test_modeling_prophetnet.py::ProphetNetStandaloneEncoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 45%] PASSED tests/models/prophetnet/test_modeling_prophetnet.py::ProphetNetStandaloneEncoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pvt_v2/test_modeling_pvt_v2.py::PvtV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [ 45%] PASSED tests/models/conditional_detr/test_modeling_conditional_detr.py::ConditionalDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/encodec/test_modeling_encodec.py::EncodecModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 45%] PASSED tests/models/omdet_turbo/test_modeling_omdet_turbo.py::OmDetTurboModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/prophetnet/test_modeling_prophetnet.py::ProphetNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 45%] PASSED tests/models/groupvit/test_modeling_groupvit.py::GroupViTVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2ForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw30] [ 45%] PASSED tests/models/focalnet/test_modeling_focalnet.py::FocalNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ijepa/test_modeling_ijepa.py::IJepaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 46%] PASSED tests/models/prophetnet/test_modeling_prophetnet.py::ProphetNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py::Qwen2_5_VLModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 46%] PASSED tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py::Qwen2_5_VLModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen2_vl/test_modeling_qwen2_vl.py::Qwen2VLModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw60] [ 46%] PASSED tests/models/data2vec/test_modeling_data2vec_vision.py::Data2VecVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/megatron_bert/test_modeling_megatron_bert.py::MegatronBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 46%] PASSED tests/models/qwen2_vl/test_modeling_qwen2_vl.py::Qwen2VLModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen3/test_modeling_qwen3.py::Qwen3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 46%] PASSED tests/models/musicgen/test_modeling_musicgen.py::MusicgenTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/musicgen_melody/test_modeling_musicgen_melody.py::MusicgenMelodyTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [ 47%] PASSED tests/models/encodec/test_modeling_encodec.py::EncodecModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py::Qwen2_5OmniThinkerForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw21] [ 47%] PASSED tests/models/gpt_oss/test_modeling_gpt_oss.py::GptOssModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/lilt/test_modeling_lilt.py::LiltModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 47%] PASSED tests/models/pix2struct/test_modeling_pix2struct.py::Pix2StructTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pix2struct/test_modeling_pix2struct.py::Pix2StructModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [ 47%] PASSED tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py::Qwen2_5OmniThinkerForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen3_vl/test_modeling_qwen3_vl.py::Qwen3VLModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [ 48%] PASSED tests/models/qwen3_vl/test_modeling_qwen3_vl.py::Qwen3VLModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/reformer/test_modeling_reformer.py::ReformerLocalAttnModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw33] [ 48%] PASSED tests/models/detr/test_modeling_detr.py::DetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/dia/test_modeling_dia.py::DiaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [ 48%] PASSED tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/phi3/test_modeling_phi3.py::Phi3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 48%] PASSED tests/models/metaclip_2/test_modeling_metaclip_2.py::MetaClip2ForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen2_audio/test_modeling_qwen2_audio.py::Qwen2AudioForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 48%] FAILED tests/models/parakeet/test_modeling_parakeet.py::ParakeetEncoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/patchtsmixer/test_modeling_patchtsmixer.py::PatchTSMixerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 49%] PASSED tests/models/olmo/test_modeling_olmo.py::OlmoModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/phi4_multimodal/test_modeling_phi4_multimodal.py::Phi4MultimodalModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 49%] PASSED tests/models/lfm2/test_modeling_lfm2.py::Lfm2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pegasus_x/test_modeling_pegasus_x.py::PegasusXModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [ 49%] PASSED tests/models/pegasus/test_modeling_pegasus.py::PegasusStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/persimmon/test_modeling_persimmon.py::PersimmonModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw49] [ 49%] PASSED tests/models/janus/test_modeling_janus.py::JanusVQModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ovis2/test_modeling_ovis2.py::Ovis2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 49%] PASSED tests/models/patchtsmixer/test_modeling_patchtsmixer.py::PatchTSMixerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/roberta/test_modeling_roberta.py::RobertaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 50%] PASSED tests/models/phi4_multimodal/test_modeling_phi4_multimodal.py::Phi4MultimodalModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/roberta_prelayernorm/test_modeling_roberta_prelayernorm.py::RobertaPreLayerNormModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw20] [ 50%] PASSED tests/models/convnext/test_modeling_convnext.py::ConvNextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/ministral/test_modeling_ministral.py::MinistralModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [ 50%] PASSED tests/models/gemma3n/test_modeling_gemma3n.py::Gemma3nTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/idefics2/test_modeling_idefics2.py::Idefics2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw16] [ 50%] PASSED tests/models/gpt2/test_modeling_gpt2.py::GPT2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mbart/test_modeling_mbart.py::MBartStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw63] [ 50%] PASSED tests/models/cvt/test_modeling_cvt.py::CvtModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/cwm/test_modeling_cwm.py::CwmModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [ 51%] PASSED tests/models/idefics2/test_modeling_idefics2.py::Idefics2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sam/test_modeling_sam.py::SamModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw4] [ 51%] PASSED tests/models/glm4/test_modeling_glm4.py::Glm4ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 51%] PASSED tests/models/m2m_100/test_modeling_m2m_100.py::M2M100ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mistral/test_modeling_mistral.py::MistralModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/opt/test_modeling_opt.py::OPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw55] [ 51%] PASSED tests/models/musicgen/test_modeling_musicgen.py::MusicgenDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pegasus_x/test_modeling_pegasus_x.py::PegasusXStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw27] [ 51%] PASSED tests/models/gptj/test_modeling_gptj.py::GPTJModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw9] [ 52%] PASSED tests/models/owlv2/test_modeling_owlv2.py::Owlv2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlvit/test_modeling_owlvit.py::OwlViTTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mllama/test_modeling_mllama.py::MllamaForCausalLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw3] [ 52%] PASSED tests/models/fnet/test_modeling_fnet.py::FNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mobilenet_v1/test_modeling_mobilenet_v1.py::MobileNetV1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw56] [ 52%] PASSED tests/models/layoutlm/test_modeling_layoutlm.py::LayoutLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mvp/test_modeling_mvp.py::MvpStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw13] [ 52%] PASSED tests/models/moonshine/test_modeling_moonshine.py::MoonshineModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mpnet/test_modeling_mpnet.py::MPNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [ 53%] PASSED tests/models/llava/test_modeling_llava.py::LlavaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/patchtst/test_modeling_patchtst.py::PatchTSTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw30] [ 53%] PASSED tests/models/ijepa/test_modeling_ijepa.py::IJepaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen2_moe/test_modeling_qwen2_moe.py::Qwen2MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw12] [ 53%] PASSED tests/models/layoutlmv3/test_modeling_layoutlmv3.py::LayoutLMv3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mixtral/test_modeling_mixtral.py::MixtralModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 53%] PASSED tests/models/jamba/test_modeling_jamba.py::JambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlv2/test_modeling_owlv2.py::Owlv2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw44] [ 53%] PASSED tests/models/bridgetower/test_modeling_bridgetower.py::BridgeTowerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/glpn/test_modeling_glpn.py::GLPNModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [ 54%] PASSED tests/models/gemma2/test_modeling_gemma2.py::Gemma2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/moshi/test_modeling_moshi.py::MoshiTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 54%] PASSED tests/models/olmo3/test_modeling_olmo3.py::Olmo3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pop2piano/test_modeling_pop2piano.py::Pop2PianoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 54%] PASSED tests/models/pix2struct/test_modeling_pix2struct.py::Pix2StructModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/recurrent_gemma/test_modeling_recurrent_gemma.py::RecurrentGemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 54%] PASSED tests/models/gpt_neox/test_modeling_gpt_neox.py::GPTNeoXModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/modernbert/test_modeling_modernbert.py::ModernBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw55] [ 54%] PASSED tests/models/pegasus_x/test_modeling_pegasus_x.py::PegasusXStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/seamless_m4t/test_modeling_seamless_m4t.py::SeamlessM4TModelWithTextInputTest::test_onnx_export <- tests/test_modeling_common.py 
[gw36] [ 55%] PASSED tests/models/electra/test_modeling_electra.py::ElectraModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mamba2/test_modeling_mamba2.py::Mamba2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw42] [ 55%] PASSED tests/models/longcat_flash/test_modeling_longcat_flash.py::LongcatFlashModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pegasus/test_modeling_pegasus.py::PegasusModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw36] [ 55%] PASSED tests/models/mamba2/test_modeling_mamba2.py::Mamba2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 55%] PASSED tests/models/nystromformer/test_modeling_nystromformer.py::NystromformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw45] [ 55%] PASSED tests/models/deepseek_v3/test_modeling_deepseek_v3.py::DeepseekV3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/oneformer/test_modeling_oneformer.py::OneFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mimi/test_modeling_mimi.py::MimiModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/smollm3/test_modeling_smollm3.py::SmolLM3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [ 56%] PASSED tests/models/owlv2/test_modeling_owlv2.py::Owlv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlvit/test_modeling_owlvit.py::OwlViTForObjectDetectionTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 56%] PASSED tests/models/hunyuan_v1_moe/test_modeling_hunyuan_v1_moe.py::HunYuanMoEV1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/nemotron/test_modeling_nemotron.py::NemotronModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 56%] PASSED tests/models/nemotron/test_modeling_nemotron.py::NemotronModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ForTextToSpeechTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 56%] PASSED tests/models/olmoe/test_modeling_olmoe.py::OlmoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/prompt_depth_anything/test_modeling_prompt_depth_anything.py::PromptDepthAnythingModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw27] [ 57%] PASSED tests/models/mllama/test_modeling_mllama.py::MllamaForCausalLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelWithTextInputTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 57%] PASSED tests/models/oneformer/test_modeling_oneformer.py::OneFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/speech_to_text/test_modeling_speech_to_text.py::Speech2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 57%] PASSED tests/models/speech_to_text/test_modeling_speech_to_text.py::Speech2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/squeezebert/test_modeling_squeezebert.py::SqueezeBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 57%] PASSED tests/models/qwen2_audio/test_modeling_qwen2_audio.py::Qwen2AudioForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/resnet/test_modeling_resnet.py::ResNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 57%] PASSED tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ForTextToSpeechTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ForSpeechToSpeechTest::test_onnx_export <- tests/test_modeling_common.py 
[gw51] [ 58%] PASSED tests/models/maskformer/test_modeling_maskformer.py::MaskFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 58%] PASSED tests/models/owlvit/test_modeling_owlvit.py::OwlViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mbart/test_modeling_mbart.py::MBartModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/paligemma/test_modeling_paligemma.py::PaliGemmaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw16] [ 58%] PASSED tests/models/mbart/test_modeling_mbart.py::MBartStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sam2/test_modeling_sam2.py::Sam2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw45] [ 58%] PASSED tests/models/mimi/test_modeling_mimi.py::MimiModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw45] [ 58%] PASSED tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/swin2sr/test_modeling_swin2sr.py::Swin2SRModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 59%] PASSED tests/models/owlv2/test_modeling_owlv2.py::Owlv2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip/test_modeling_siglip.py::SiglipTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 59%] PASSED tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ForSpeechToSpeechTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/superglue/test_modeling_superglue.py::SuperGlueModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw45] [ 59%] PASSED tests/models/swin2sr/test_modeling_swin2sr.py::Swin2SRModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/swinv2/test_modeling_swinv2.py::Swinv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 59%] PASSED tests/models/owlv2/test_modeling_owlv2.py::Owlv2ForObjectDetectionTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/paligemma2/test_modeling_paligemma2.py::PaliGemma2ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [ 59%] PASSED tests/models/modernbert_decoder/test_modeling_modernbert_decoder.py::ModernBertDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/plbart/test_modeling_plbart.py::PLBartStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw8] [ 60%] PASSED tests/models/openai/test_modeling_openai.py::OpenAIGPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pvt/test_modeling_pvt.py::PvtModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw18] [ 60%] PASSED tests/models/deformable_detr/test_modeling_deformable_detr.py::DeformableDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/deit/test_modeling_deit.py::DeiTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw56] [ 60%] PASSED tests/models/mvp/test_modeling_mvp.py::MvpStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/segformer/test_modeling_segformer.py::SegformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 60%] PASSED tests/models/musicgen_melody/test_modeling_musicgen_melody.py::MusicgenMelodyTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen3_omni_moe/test_modeling_qwen3_omni_moe.py::Qwen2_5OmniThinkerForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw63] [ 61%] PASSED tests/models/cwm/test_modeling_cwm.py::CwmModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sam2/test_modeling_sam2.py::Sam2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 61%] PASSED tests/models/qwen3_omni_moe/test_modeling_qwen3_omni_moe.py::Qwen2_5OmniThinkerForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/textnet/test_modeling_textnet.py::TextNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [ 61%] PASSED tests/models/moshi/test_modeling_moshi.py::MoshiTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip/test_modeling_siglip.py::SiglipForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 61%] PASSED tests/models/modernbert/test_modeling_modernbert.py::ModernBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip2/test_modeling_siglip2.py::Siglip2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 61%] PASSED tests/models/siglip/test_modeling_siglip.py::SiglipTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/switch_transformers/test_modeling_switch_transformers.py::SwitchTransformersModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 62%] PASSED tests/models/pop2piano/test_modeling_pop2piano.py::Pop2PianoModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip2/test_modeling_siglip2.py::Siglip2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 62%] PASSED tests/models/siglip2/test_modeling_siglip2.py::Siglip2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/trocr/test_modeling_trocr.py::TrOCRStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [ 62%] PASSED tests/models/sam/test_modeling_sam.py::SamModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sam_hq/test_modeling_sam_hq.py::SamHQVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 62%] PASSED tests/models/siglip2/test_modeling_siglip2.py::Siglip2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/timm_backbone/test_modeling_timm_backbone.py::TimmBackboneModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw49] [ 62%] PASSED tests/models/ovis2/test_modeling_ovis2.py::Ovis2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/rt_detr/test_modeling_rt_detr.py::RTDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 63%] PASSED tests/models/levit/test_modeling_levit.py::LevitModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/lfm2_moe/test_modeling_lfm2_moe.py::Lfm2MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 63%] PASSED tests/models/opt/test_modeling_opt.py::OPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/seamless_m4t/test_modeling_seamless_m4t.py::SeamlessM4TModelWithSpeechInputTest::test_onnx_export <- tests/test_modeling_common.py 
[gw22] [ 63%] PASSED tests/models/plbart/test_modeling_plbart.py::PLBartModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/poolformer/test_modeling_poolformer.py::PoolFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 63%] PASSED tests/models/prompt_depth_anything/test_modeling_prompt_depth_anything.py::PromptDepthAnythingModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/speecht5/test_modeling_speecht5.py::SpeechT5HifiGanTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 63%] PASSED tests/models/speecht5/test_modeling_speecht5.py::SpeechT5HifiGanTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/unispeech_sat/test_modeling_unispeech_sat.py::UniSpeechSatRobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw9] [ 64%] PASSED tests/models/owlvit/test_modeling_owlvit.py::OwlViTTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelWithSpeechInputTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [ 64%] FAILED tests/models/patchtst/test_modeling_patchtst.py::PatchTSTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sew/test_modeling_sew.py::SEWModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 64%] PASSED tests/models/unispeech_sat/test_modeling_unispeech_sat.py::UniSpeechSatRobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/univnet/test_modeling_univnet.py::UnivNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 64%] PASSED tests/models/perception_lm/test_modeling_perception_lm.py::PerceptionLMForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pixtral/test_modeling_pixtral.py::PixtralVisionModelModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 64%] PASSED tests/models/pixtral/test_modeling_pixtral.py::PixtralVisionModelModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/video_llama_3/test_modeling_video_llama_3.py::VideoLlama3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [ 65%] PASSED tests/models/reformer/test_modeling_reformer.py::ReformerLocalAttnModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/reformer/test_modeling_reformer.py::ReformerLSHAttnModelTest::test_onnx_export 
[gw15] [ 65%] PASSED tests/models/plbart/test_modeling_plbart.py::PLBartStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/t5gemma/test_modeling_t5gemma.py::T5GemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 65%] PASSED tests/models/video_llama_3/test_modeling_video_llama_3.py::VideoLlama3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [ 65%] PASSED tests/models/sew/test_modeling_sew.py::SEWModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vaultgemma/test_modeling_vaultgemma.py::VaultGemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/video_llava/test_modeling_video_llava.py::VideoLlavaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw40] [ 66%] PASSED tests/models/minimax/test_modeling_minimax.py::MiniMaxModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mistral3/test_modeling_mistral3.py::Mistral3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw33] [ 66%] PASSED tests/models/dia/test_modeling_dia.py::DiaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/regnet/test_modeling_regnet.py::RegNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [ 66%] PASSED tests/models/persimmon/test_modeling_persimmon.py::PersimmonModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/roformer/test_modeling_roformer.py::RoFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 66%] PASSED tests/models/timm_backbone/test_modeling_timm_backbone.py::TimmBackboneModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/udop/test_modeling_udop.py::UdopEncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw21] [ 66%] PASSED tests/models/lilt/test_modeling_lilt.py::LiltModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen3_vl_moe/test_modeling_qwen3_vl_moe.py::Qwen3VLMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [ 67%] PASSED tests/models/siglip/test_modeling_siglip.py::SiglipForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/timesformer/test_modeling_timesformer.py::TimesformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 67%] PASSED tests/models/recurrent_gemma/test_modeling_recurrent_gemma.py::RecurrentGemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip2/test_modeling_siglip2.py::Siglip2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw40] [ 67%] PASSED tests/models/mistral3/test_modeling_mistral3.py::Mistral3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/visual_bert/test_modeling_visual_bert.py::VisualBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 67%] PASSED tests/models/pegasus_x/test_modeling_pegasus_x.py::PegasusXModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/roc_bert/test_modeling_roc_bert.py::RoCBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [ 67%] PASSED tests/models/mobilevitv2/test_modeling_mobilevitv2.py::MobileViTV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mra/test_modeling_mra.py::MraModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [ 68%] PASSED tests/models/phi3/test_modeling_phi3.py::Phi3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/rembert/test_modeling_rembert.py::RemBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [ 68%] PASSED tests/models/sam_hq/test_modeling_sam_hq.py::SamHQVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/udop/test_modeling_udop.py::UdopModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw21] [ 68%] PASSED tests/models/qwen3_vl_moe/test_modeling_qwen3_vl_moe.py::Qwen3VLMoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vitdet/test_modeling_vitdet.py::VitDetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw11] [ 68%] PASSED tests/models/gemma3/test_modeling_gemma3.py::Gemma3Vision2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/parakeet/test_modeling_parakeet.py::ParakeetForCTCModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw42] [ 68%] PASSED tests/models/pegasus/test_modeling_pegasus.py::PegasusModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/smolvlm/test_modeling_smolvlm.py::SmolVLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw7] [ 69%] PASSED tests/models/mobilenet_v2/test_modeling_mobilenet_v2.py::MobileNetV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/mpt/test_modeling_mpt.py::MptModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw42] [ 69%] PASSED tests/models/smolvlm/test_modeling_smolvlm.py::SmolVLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/wav2vec2_bert/test_modeling_wav2vec2_bert.py::Wav2Vec2BertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 69%] PASSED tests/models/paligemma2/test_modeling_paligemma2.py::PaliGemma2ForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/t5/test_modeling_t5.py::T5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 69%] PASSED tests/models/luke/test_modeling_luke.py::LukeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/lxmert/test_modeling_lxmert.py::LxmertModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 70%] PASSED tests/models/qwen3/test_modeling_qwen3.py::Qwen3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen3_next/test_modeling_qwen3_next.py::Qwen3NextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 70%] PASSED tests/models/qwen3_next/test_modeling_qwen3_next.py::Qwen3NextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/whisper/test_modeling_whisper.py::WhisperStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 70%] PASSED tests/models/mvp/test_modeling_mvp.py::MvpModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/pix2struct/test_modeling_pix2struct.py::Pix2StructVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 70%] PASSED tests/models/trocr/test_modeling_trocr.py::TrOCRStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/tvp/test_modeling_tvp.py::TVPModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw3] [ 70%] PASSED tests/models/mobilenet_v1/test_modeling_mobilenet_v1.py::MobileNetV1ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/seed_oss/test_modeling_seed_oss.py::SeedOssModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 71%] PASSED tests/models/siglip2/test_modeling_siglip2.py::Siglip2TextModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vitpose/test_modeling_vitpose.py::VitPoseModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 71%] PASSED tests/models/resnet/test_modeling_resnet.py::ResNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/starcoder2/test_modeling_starcoder2.py::Starcoder2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 71%] PASSED tests/models/lfm2_moe/test_modeling_lfm2_moe.py::Lfm2MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/umt5/test_modeling_umt5.py::UMT5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 71%] PASSED tests/models/udop/test_modeling_udop.py::UdopEncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vit_msn/test_modeling_vit_msn.py::ViTMSNModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 71%] PASSED tests/models/textnet/test_modeling_textnet.py::TextNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/timesfm/test_modeling_timesfm.py::TimesFmModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw31] [ 72%] PASSED tests/models/mobilebert/test_modeling_mobilebert.py::MobileBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/moshi/test_modeling_moshi.py::MoshiDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
[gw18] [ 72%] PASSED tests/models/deit/test_modeling_deit.py::DeiTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/table_transformer/test_modeling_table_transformer.py::TableTransformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 72%] PASSED tests/models/paligemma/test_modeling_paligemma.py::PaliGemmaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/swiftformer/test_modeling_swiftformer.py::SwiftFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 72%] PASSED tests/models/roberta/test_modeling_roberta.py::RobertaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/rt_detr_v2/test_modeling_rt_detr_v2.py::RTDetrV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw13] [ 72%] PASSED tests/models/mpnet/test_modeling_mpnet.py::MPNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/seggpt/test_modeling_seggpt.py::SegGptModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw20] [ 73%] PASSED tests/models/ministral/test_modeling_ministral.py::MinistralModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sam/test_modeling_sam.py::SamVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw22] [ 73%] PASSED tests/models/poolformer/test_modeling_poolformer.py::PoolFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/unispeech_sat/test_modeling_unispeech_sat.py::UniSpeechSatModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 73%] PASSED tests/models/pvt_v2/test_modeling_pvt_v2.py::PvtV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen2/test_modeling_qwen2.py::Qwen2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 73%] PASSED tests/models/pix2struct/test_modeling_pix2struct.py::Pix2StructVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/x_clip/test_modeling_x_clip.py::XCLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw42] [ 74%] PASSED tests/models/wav2vec2_bert/test_modeling_wav2vec2_bert.py::Wav2Vec2BertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/wavlm/test_modeling_wavlm.py::WavLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 74%] PASSED tests/models/univnet/test_modeling_univnet.py::UnivNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/video_llama_3/test_modeling_video_llama_3.py::VideoLlama3VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw6] [ 74%] PASSED tests/models/video_llama_3/test_modeling_video_llama_3.py::VideoLlama3VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw59] [ 74%] PASSED tests/models/dpt/test_modeling_dpt_hybrid.py::DPTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/flava/test_modeling_flava.py::FlavaMultimodalModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 74%] PASSED tests/models/timesfm/test_modeling_timesfm.py::TimesFmModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/xlstm/test_modeling_xlstm.py::xLSTMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [ 75%] PASSED tests/models/owlvit/test_modeling_owlvit.py::OwlViTForObjectDetectionTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ForSpeechToTextTest::test_onnx_export <- tests/test_modeling_common.py 
[gw22] [ 75%] PASSED tests/models/unispeech_sat/test_modeling_unispeech_sat.py::UniSpeechSatModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 75%] PASSED tests/models/t5/test_modeling_t5.py::T5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/whisper/test_modeling_whisper.py::WhisperModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw21] [ 75%] PASSED tests/models/vitdet/test_modeling_vitdet.py::VitDetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/wav2vec2/test_modeling_wav2vec2.py::Wav2Vec2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw42] [ 75%] PASSED tests/models/wavlm/test_modeling_wavlm.py::WavLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw36] [ 76%] PASSED tests/models/smollm3/test_modeling_smollm3.py::SmolLM3ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/smolvlm/test_modeling_smolvlm.py::SmolVLMForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw4] [ 76%] PASSED tests/models/mistral/test_modeling_mistral.py::MistralModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sam_hq/test_modeling_sam_hq.py::SamHQModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw48] [ 76%] PASSED tests/models/speecht5/test_modeling_speecht5.py::SpeechT5ForSpeechToTextTest::test_onnx_export <- tests/test_modeling_common.py 
[gw54] [ 76%] PASSED tests/models/mt5/test_modeling_mt5.py::MT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/prophetnet/test_modeling_prophetnet.py::ProphetNetStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw36] [ 76%] PASSED tests/models/smolvlm/test_modeling_smolvlm.py::SmolVLMForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw54] [ 77%] PASSED tests/models/prophetnet/test_modeling_prophetnet.py::ProphetNetStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 77%] PASSED tests/models/whisper/test_modeling_whisper.py::WhisperStandaloneDecoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/x_clip/test_modeling_x_clip.py::XCLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw23] [ 77%] PASSED tests/models/dab_detr/test_modeling_dab_detr.py::DabDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/phi/test_modeling_phi.py::PhiModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw21] [ 77%] PASSED tests/models/wav2vec2/test_modeling_wav2vec2.py::Wav2Vec2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 77%] PASSED tests/models/vitpose/test_modeling_vitpose.py::VitPoseModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/xglm/test_modeling_xglm.py::XGLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw33] [ 78%] PASSED tests/models/regnet/test_modeling_regnet.py::RegNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vit/test_modeling_vit.py::ViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [ 78%] PASSED tests/models/vaultgemma/test_modeling_vaultgemma.py::VaultGemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vilt/test_modeling_vilt.py::ViltForImagesAndTextClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 78%] PASSED tests/models/vit_msn/test_modeling_vit_msn.py::ViTMSNModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/xlnet/test_modeling_xlnet.py::XLNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw0] [ 78%] PASSED tests/models/x_clip/test_modeling_x_clip.py::XCLIPTextModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 79%] PASSED tests/models/umt5/test_modeling_umt5.py::UMT5EncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/xlm_roberta_xl/test_modeling_xlm_roberta_xl.py::XLMRobertaXLModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw24] [ 79%] PASSED tests/models/vilt/test_modeling_vilt.py::ViltForImagesAndTextClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw60] [ 79%] PASSED tests/models/megatron_bert/test_modeling_megatron_bert.py::MegatronBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/qwen3_moe/test_modeling_qwen3_moe.py::Qwen3MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 79%] PASSED tests/models/roberta_prelayernorm/test_modeling_roberta_prelayernorm.py::RobertaPreLayerNormModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/rwkv/test_modeling_rwkv.py::RwkvModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw59] [ 79%] PASSED tests/models/flava/test_modeling_flava.py::FlavaMultimodalModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw20] [ 80%] PASSED tests/models/sam/test_modeling_sam.py::SamVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/zoedepth/test_modeling_zoedepth.py::ZoeDepthModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 80%] PASSED tests/models/squeezebert/test_modeling_squeezebert.py::SqueezeBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/stablelm/test_modeling_stablelm.py::StableLmModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw11] [ 80%] FAILED tests/models/parakeet/test_modeling_parakeet.py::ParakeetForCTCModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/wav2vec2/test_modeling_wav2vec2.py::Wav2Vec2RobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 80%] PASSED tests/models/video_llava/test_modeling_video_llava.py::VideoLlavaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vipllava/test_modeling_vipllava.py::VipLlavaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [ 80%] PASSED tests/models/timesformer/test_modeling_timesformer.py::TimesformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vitmatte/test_modeling_vitmatte.py::VitMatteModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw51] [ 81%] PASSED tests/models/mbart/test_modeling_mbart.py::MBartModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/superpoint/test_modeling_superpoint.py::SuperPointModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw51] [ 81%] PASSED tests/models/superpoint/test_modeling_superpoint.py::SuperPointModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [ 81%] PASSED tests/models/reformer/test_modeling_reformer.py::ReformerLSHAttnModelTest::test_onnx_export 
tests/models/videomae/test_modeling_videomae.py::VideoMAEModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw26] [ 81%] PASSED tests/models/videomae/test_modeling_videomae.py::VideoMAEModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw11] [ 81%] PASSED tests/models/wav2vec2/test_modeling_wav2vec2.py::Wav2Vec2RobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw10] [ 82%] PASSED tests/models/x_clip/test_modeling_x_clip.py::XCLIPVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 82%] PASSED tests/models/switch_transformers/test_modeling_switch_transformers.py::SwitchTransformersModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/timm_wrapper/test_modeling_timm_wrapper.py::TimmWrapperModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 82%] PASSED tests/models/tvp/test_modeling_tvp.py::TVPModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/x_clip/test_modeling_x_clip.py::XCLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [ 82%] PASSED tests/models/udop/test_modeling_udop.py::UdopModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/voxtral/test_modeling_voxtral.py::VoxtralForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw32] [ 83%] PASSED tests/models/mobilevit/test_modeling_mobilevit.py::MobileViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/owlvit/test_modeling_owlvit.py::OwlViTVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw44] [ 83%] PASSED tests/models/glpn/test_modeling_glpn.py::GLPNModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip/test_modeling_siglip.py::SiglipModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw25] [ 83%] PASSED tests/models/xglm/test_modeling_xglm.py::XGLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw31] [ 83%] PASSED tests/models/moshi/test_modeling_moshi.py::MoshiDecoderTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/xmod/test_modeling_xmod.py::XmodModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw49] [ 83%] FAILED tests/models/rt_detr/test_modeling_rt_detr.py::RTDetrModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw14] [ 84%] PASSED tests/models/vitmatte/test_modeling_vitmatte.py::VitMatteModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/umt5/test_modeling_umt5.py::UMT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw56] [ 84%] PASSED tests/models/segformer/test_modeling_segformer.py::SegformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/tapas/test_modeling_tapas.py::TapasModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw31] [ 84%] PASSED tests/models/xmod/test_modeling_xmod.py::XmodModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw12] [ 84%] PASSED tests/models/mixtral/test_modeling_mixtral.py::MixtralModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw56] [ 84%] PASSED tests/models/tapas/test_modeling_tapas.py::TapasModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip/test_modeling_siglip.py::SiglipVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw55] [ 85%] PASSED tests/models/seamless_m4t/test_modeling_seamless_m4t.py::SeamlessM4TModelWithTextInputTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/siglip2/test_modeling_siglip2.py::Siglip2ForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw29] [ 85%] PASSED tests/models/whisper/test_modeling_whisper.py::WhisperModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw34] [ 85%] PASSED tests/models/mask2former/test_modeling_mask2former.py::Mask2FormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/phimoe/test_modeling_phimoe.py::PhimoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 85%] PASSED tests/models/lxmert/test_modeling_lxmert.py::LxmertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/whisper/test_modeling_whisper.py::WhisperEncoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw27] [ 85%] PASSED tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelWithTextInputTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/splinter/test_modeling_splinter.py::SplinterModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw33] [ 86%] PASSED tests/models/vit/test_modeling_vit.py::ViTModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw32] [ 86%] PASSED tests/models/owlvit/test_modeling_owlvit.py::OwlViTVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw27] [ 86%] PASSED tests/models/splinter/test_modeling_splinter.py::SplinterModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw55] [ 86%] PASSED tests/models/siglip2/test_modeling_siglip2.py::Siglip2ForImageClassificationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw30] [ 87%] PASSED tests/models/qwen2_moe/test_modeling_qwen2_moe.py::Qwen2MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/sew_d/test_modeling_sew_d.py::SEWDModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw40] [ 87%] PASSED tests/models/visual_bert/test_modeling_visual_bert.py::VisualBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vitpose_backbone/test_modeling_vitpose_backbone.py::VitPoseBackboneModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw7] [ 87%] PASSED tests/models/mpt/test_modeling_mpt.py::MptModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/wav2vec2_conformer/test_modeling_wav2vec2_conformer.py::Wav2Vec2ConformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 87%] FAILED tests/models/superglue/test_modeling_superglue.py::SuperGlueModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/switch_transformers/test_modeling_switch_transformers.py::SwitchTransformersEncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 87%] PASSED tests/models/swiftformer/test_modeling_swiftformer.py::SwiftFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/yoso/test_modeling_yoso.py::YosoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw30] [ 88%] PASSED tests/models/sew_d/test_modeling_sew_d.py::SEWDModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw35] [ 88%] FAILED tests/models/voxtral/test_modeling_voxtral.py::VoxtralForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw3] [ 88%] PASSED tests/models/seed_oss/test_modeling_seed_oss.py::SeedOssModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/xcodec/test_modeling_xcodec.py::XcodecModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [ 88%] PASSED tests/models/mra/test_modeling_mra.py::MraModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vivit/test_modeling_vivit.py::VivitModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw44] [ 88%] PASSED tests/models/siglip/test_modeling_siglip.py::SiglipModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw52] [ 89%] PASSED tests/models/whisper/test_modeling_whisper.py::WhisperEncoderModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw12] [ 89%] PASSED tests/models/siglip/test_modeling_siglip.py::SiglipVisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw62] [ 89%] PASSED tests/models/x_clip/test_modeling_x_clip.py::XCLIPModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 89%] PASSED tests/models/starcoder2/test_modeling_starcoder2.py::Starcoder2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/xlm/test_modeling_xlm.py::XLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw7] [ 89%] PASSED tests/models/wav2vec2_conformer/test_modeling_wav2vec2_conformer.py::Wav2Vec2ConformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [ 90%] PASSED tests/models/rembert/test_modeling_rembert.py::RemBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vjepa2/test_modeling_vjepa2.py::VJEPA2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw2] [ 90%] PASSED tests/models/switch_transformers/test_modeling_switch_transformers.py::SwitchTransformersEncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw40] [ 90%] PASSED tests/models/vitpose_backbone/test_modeling_vitpose_backbone.py::VitPoseBackboneModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw23] [ 90%] PASSED tests/models/phi/test_modeling_phi.py::PhiModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw20] [ 90%] PASSED tests/models/zoedepth/test_modeling_zoedepth.py::ZoeDepthModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw19] [ 91%] PASSED tests/models/vipllava/test_modeling_vipllava.py::VipLlavaForConditionalGenerationModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw43] [ 91%] PASSED tests/models/stablelm/test_modeling_stablelm.py::StableLmModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw41] [ 91%] PASSED tests/models/vivit/test_modeling_vivit.py::VivitModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw58] [ 91%] PASSED tests/models/rwkv/test_modeling_rwkv.py::RwkvModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw3] [ 92%] PASSED tests/models/xcodec/test_modeling_xcodec.py::XcodecModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw37] [ 92%] PASSED tests/models/timm_wrapper/test_modeling_timm_wrapper.py::TimmWrapperModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [ 92%] PASSED tests/models/roformer/test_modeling_roformer.py::RoFormerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vit_mae/test_modeling_vit_mae.py::ViTMAEModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 92%] PASSED tests/models/roc_bert/test_modeling_roc_bert.py::RoCBertModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vits/test_modeling_vits.py::VitsModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw50] [ 92%] PASSED tests/models/qwen2/test_modeling_qwen2.py::Qwen2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw18] [ 93%] PASSED tests/models/table_transformer/test_modeling_table_transformer.py::TableTransformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/yolos/test_modeling_yolos.py::YolosModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw46] [ 93%] PASSED tests/models/vits/test_modeling_vits.py::VitsModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw45] [ 93%] PASSED tests/models/swinv2/test_modeling_swinv2.py::Swinv2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/t5/test_modeling_t5.py::T5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw61] [ 93%] FAILED tests/models/vit_mae/test_modeling_vit_mae.py::ViTMAEModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 93%] FAILED tests/models/rt_detr_v2/test_modeling_rt_detr_v2.py::RTDetrV2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/zamba/test_modeling_zamba.py::ZambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw38] [ 94%] FAILED tests/models/xlm/test_modeling_xlm.py::XLMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw9] [ 94%] PASSED tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelWithSpeechInputTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/upernet/test_modeling_upernet.py::UperNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw1] [ 94%] PASSED tests/models/xlm_roberta_xl/test_modeling_xlm_roberta_xl.py::XLMRobertaXLModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 94%] PASSED tests/models/seamless_m4t/test_modeling_seamless_m4t.py::SeamlessM4TModelWithSpeechInputTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/unispeech/test_modeling_unispeech.py::UniSpeechRobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw47] [ 94%] PASSED tests/models/xlstm/test_modeling_xlstm.py::xLSTMModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw17] [ 95%] PASSED tests/models/unispeech/test_modeling_unispeech.py::UniSpeechRobustModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [ 95%] PASSED tests/models/t5gemma/test_modeling_t5gemma.py::T5GemmaModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/vilt/test_modeling_vilt.py::ViltModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw60] [ 95%] PASSED tests/models/qwen3_moe/test_modeling_qwen3_moe.py::Qwen3MoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw15] [ 95%] PASSED tests/models/vilt/test_modeling_vilt.py::ViltModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw39] [ 96%] PASSED tests/models/xlnet/test_modeling_xlnet.py::XLNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw34] [ 96%] PASSED tests/models/phimoe/test_modeling_phimoe.py::PhimoeModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw5] [ 96%] PASSED tests/models/vjepa2/test_modeling_vjepa2.py::VJEPA2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw9] [ 96%] PASSED tests/models/upernet/test_modeling_upernet.py::UperNetModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw53] [ 96%] PASSED tests/models/yoso/test_modeling_yoso.py::YosoModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw49] [ 97%] PASSED tests/models/umt5/test_modeling_umt5.py::UMT5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw28] [ 97%] PASSED tests/models/big_bird/test_modeling_big_bird.py::BigBirdModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/bigbird_pegasus/test_modeling_bigbird_pegasus.py::BigBirdPegasusModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw45] [ 97%] PASSED tests/models/t5/test_modeling_t5.py::T5ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw4] [ 97%] PASSED tests/models/sam_hq/test_modeling_sam_hq.py::SamHQModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw57] [ 97%] PASSED tests/models/zamba/test_modeling_zamba.py::ZambaModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw28] [ 98%] PASSED tests/models/bigbird_pegasus/test_modeling_bigbird_pegasus.py::BigBirdPegasusModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw16] [ 98%] PASSED tests/models/sam2/test_modeling_sam2.py::Sam2VisionModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/swin/test_modeling_swin.py::SwinModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw63] [ 98%] PASSED tests/models/sam2/test_modeling_sam2.py::Sam2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/time_series_transformer/test_modeling_time_series_transformer.py::TimeSeriesTransformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw63] [ 98%] PASSED tests/models/time_series_transformer/test_modeling_time_series_transformer.py::TimeSeriesTransformerModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw16] [ 98%] PASSED tests/models/swin/test_modeling_swin.py::SwinModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw8] [ 99%] PASSED tests/models/pvt/test_modeling_pvt.py::PvtModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/t5gemma/test_modeling_t5gemma.py::T5GemmaEncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw8] [ 99%] PASSED tests/models/t5gemma/test_modeling_t5gemma.py::T5GemmaEncoderOnlyModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw13] [ 99%] PASSED tests/models/seggpt/test_modeling_seggpt.py::SegGptModelTest::test_onnx_export <- tests/test_modeling_common.py 
tests/models/zamba2/test_modeling_zamba2.py::Zamba2ModelTest::test_onnx_export <- tests/test_modeling_common.py 
[gw13] [ 99%] PASSED tests/models/zamba2/test_modeling_zamba2.py::Zamba2ModelTest::test_onnx_export <- tests/test_modeling_common.py 

=================================== FAILURES ===================================
________________________ BitModelTest.test_onnx_export _________________________
[gw30] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.bit.test_modeling_bit.BitModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 73 / 192 (38.0%)
E                   Greatest absolute difference: 0.18257492780685425 at index (2, 21, 0, 0) (up to 0.01 allowed)
E                   Greatest relative difference: inf at index (1, 39, 0, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['last_hidden_state']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.bit.test_modeling_bit.BitModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type bit failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 73 / 192 (38.0%)
E                   Greatest absolute difference: 0.18257492780685425 at index (2, 21, 0, 0) (up to 0.01 allowed)
E                   Greatest relative difference: inf at index (1, 39, 0, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['last_hidden_state']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 20 of general pattern rewrite rules.
_______ AudioFlamingo3ForConditionalGenerationModelTest.test_onnx_export _______
[gw4] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.audioflamingo3.test_modeling_audioflamingo3.AudioFlamingo3ForConditionalGenerationModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 6644 / 7425 (89.5%)
E                   Greatest absolute difference: 0.7158714532852173 at index (0, 2, 64) (up to 0.01 allowed)
E                   Greatest relative difference: 2271.84912109375 at index (0, 7, 9) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['logits']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.audioflamingo3.test_modeling_audioflamingo3.AudioFlamingo3ForConditionalGenerationModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type audioflamingo3 failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 6644 / 7425 (89.5%)
E                   Greatest absolute difference: 0.7158714532852173 at index (0, 2, 64) (up to 0.01 allowed)
E                   Greatest relative difference: 2271.84912109375 at index (0, 7, 9) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['logits']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 12 of general pattern rewrite rules.
----------------------------- Captured stderr call -----------------------------
[0;93m2025-11-19 08:37:06.996120722 [W:onnxruntime:Default, scatter_nd.h:51 ScatterNDWithAtomicReduction] ScatterND with reduction=='none' only guarantees to be correct if indices are not duplicated.[m
________________________ BltModelTest.test_onnx_export _________________________
[gw44] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.blt.test_modeling_blt.BltModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 330 / 336 (98.2%)
E                   Greatest absolute difference: 3.642883777618408 at index (1, 0, 12) (up to 0.01 allowed)
E                   Greatest relative difference: 3727.64306640625 at index (1, 3, 12) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['last_hidden_state']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.blt.test_modeling_blt.BltModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type blt failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 330 / 336 (98.2%)
E                   Greatest absolute difference: 3.642883777618408 at index (1, 0, 12) (up to 0.01 allowed)
E                   Greatest relative difference: 3727.64306640625 at index (1, 3, 12) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['last_hidden_state']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 5 of general pattern rewrite rules.
______________________ FlaubertModelTest.test_onnx_export ______________________
[gw37] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.flaubert.test_modeling_flaubert.FlaubertModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 135 / 325 (41.5%)
E                   Greatest absolute difference: 5 at index (0, 10) (up to 0.01 allowed)
E                   Greatest relative difference: 5.0 at index (0, 15) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['end_top_index']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.flaubert.test_modeling_flaubert.FlaubertModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type flaubert failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 135 / 325 (41.5%)
E                   Greatest absolute difference: 5 at index (0, 10) (up to 0.01 allowed)
E                   Greatest relative difference: 5.0 at index (0, 15) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['end_top_index']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 3 of general pattern rewrite rules.
Applied 2 of general pattern rewrite rules.
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 3 of general pattern rewrite rules.
Applied 2 of general pattern rewrite rules.
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 6 of general pattern rewrite rules.
Applied 2 of general pattern rewrite rules.
___________ MllamaForConditionalGenerationModelTest.test_onnx_export ___________
[gw29] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.mllama.test_modeling_mllama.MllamaForConditionalGenerationModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
>                   eager_outputs = model(**copy.deepcopy(inputs_dict))
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_modeling_common.py:3579: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/utils/generic.py:928: in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/utils/generic.py:758: in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/models/mllama/modeling_mllama.py:1552: in forward
    outputs = self.language_model(
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/utils/generic.py:928: in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/utils/generic.py:758: in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/models/mllama/modeling_mllama.py:1298: in forward
    hidden_states = decoder_layer(
src/transformers/modeling_layers.py:94: in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/models/mllama/modeling_mllama.py:707: in forward
    hidden_states, attn_weights = self.cross_attn(
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1775: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.docker/lib/python3.12/site-packages/torch/nn/modules/module.py:1786: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/transformers/models/mllama/modeling_mllama.py:459: in forward
    attn_output, attn_weights = attention_interface(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = MllamaTextCrossAttention(
  (q_proj): Linear(in_features=32, out_features=32, bias=False)
  (k_proj): Linear(in_features=32, out_features=32, bias=False)
  (v_proj): Linear(in_features=32, out_features=32, bias=False)
  (o_proj): Linear(in_features=32, out_features=32, bias=False)
  (q_norm): MllamaTextRMSNorm((8,), eps=1e-05)
  (k_norm): MllamaTextRMSNorm((8,), eps=1e-05)
)
query = tensor([[[[ 1.7303e+00, -1.0155e+00,  5.8327e-01, -2.9463e-01, -1.8138e+00,
            4.7859e-01, -3.3086e-02, -1.2608e-01],
          [ 1.3449e+00,  5.9267e-01, -1.4266e+00, -5.2054e-01, -9.8354e-01,
           -8.7886e-01, -6.3070e-01, -1.1784e+00],
          [-1.2547e-01,  9.3301e-01, -9.1869e-01,  1.8578e+00, -1.2246e+00,
            7.1592e-02, -4.5390e-01, -1.0504e+00],
          [-2.2905e-01,  1.1634e+00,  1.5535e+00,  1.2232e+00,  1.2813e+00,
            1.2766e-01, -8.8351e-02, -1.0068e+00],
          [-1.0738e-01, -7.9024e-01, -8.9110e-01,  7.9431e-01,  1.5547e-01,
           -1.8392e+00, -8.5101e-01, -1.3424e+00],
          [ 6.0040e-01, -4.6079e-01,  2.2814e-01, -1.6734e+00,  5.2574e-01,
           -3.9994e-01, -2.9498e-01,  2.0115e+00],
          [ 1.3162e+00,  5.0196e-01, -1.7795e+00, -5.0948e-01, -1.1990e+00,
           -6.7117e-01,  8.1702e-01,  1.5604e-01]],

         [[ 2.4039e-01,  6.4186e-01,  1.3799e+00, -1.1400e+00, -7.8892e-01,
           -7.3677e-01, -7.8893e-01, -1.5905e+00],
          [-5.4689e-01,  1.0075e+00, -1.9118e-01,  6.8427e-01,  1.9352e+00,
           -1.1712e+00,  8.4128e-01,  5.9287e-01],
          [ 3.5449e-01,  1.8669e+00, -5.1980e-01,  1.6111e-03,  6.6636e-01,
            1.4152e-01, -1.2903e+00,  1.4087e+00],
          [ 3.5121e-01,  9.9644e-03, -4.2513e-01, -1.4944e-03, -1.5145e-01,
            7.2963e-01, -8.8128e-01,  2.5222e+00],
          [-2.1030e-01,  9.4616e-01, -2.4287e-01,  1.4073e+00,  1.4544e+00,
           -1.2415e+00,  6.2045e-01,  9.8694e-01],
          [-1.3255e+00, -9.5050e-01,  2.3051e-01, -5.1569e-01,  5.0131e-01,
            1.5049e+00,  9.9962e-01, -1.2249e+00],
          [ 2.5052e-01,  1.7610e+00,  3.9595e-01, -1.6561e-01, -7.7577e-01,
           -1.7979e+00,  3.4404e-01,  8.3386e-01]],

         [[ 9.0414e-02, -4.2376e-01,  1.7323e+00, -1.5787e-01, -3.8809e-01,
            1.2123e+00,  1.7155e+00,  4.6491e-01],
          [ 3.6801e-01, -8.9628e-01,  3.4496e-01,  6.8497e-01, -8.8803e-01,
            2.2574e-01, -1.7613e+00,  1.5896e+00],
          [ 9.0767e-01, -6.9837e-01,  3.7843e-01,  1.7053e+00, -1.2399e+00,
            2.8807e-01,  1.4102e+00,  1.5505e-01],
          [-1.4069e+00,  8.1452e-01, -5.5015e-01,  4.3315e-02,  1.6987e+00,
            1.1286e+00, -2.9088e-05, -9.4290e-01],
          [ 6.7353e-01, -5.4379e-01,  1.3786e+00,  1.8268e+00,  9.4835e-01,
           -5.4713e-01,  1.5736e-01,  8.8633e-01],
          [ 3.5611e-01, -3.9983e-01, -1.1365e+00, -1.8555e+00, -1.1268e+00,
            7.7054e-01, -8.8736e-01, -5.6302e-01],
          [ 1.8705e+00,  4.0899e-01,  2.2911e-01,  5.3886e-01, -6.4710e-01,
            5.9758e-01, -2.2228e-01,  1.7771e+00]],

         [[ 3.3961e-01, -3.5495e-01, -8.4385e-01,  4.1303e-01,  2.4792e+00,
            2.1272e-01, -2.3841e-01, -7.8832e-01],
          [-2.1003e+00,  3.5085e-01,  9.9551e-01,  4.9894e-01, -4.7093e-01,
            1.2571e+00, -8.7224e-02, -6.3837e-01],
          [ 1.6275e+00,  5.7840e-01,  5.5175e-01, -2.2657e-01,  3.7222e-01,
            1.9825e+00,  2.0450e-01,  7.3158e-01],
          [-1.0675e+00,  6.3284e-01, -3.2766e-01, -1.8712e+00,  4.7090e-01,
            1.4763e+00, -3.8974e-01,  5.3234e-01],
          [-1.6603e+00,  6.3612e-01, -9.5882e-02, -1.4502e+00,  6.0412e-01,
            1.4256e+00,  5.5865e-01,  1.1422e-01],
          [-4.8330e-01, -1.2616e+00, -1.2225e+00,  4.7900e-01,  5.3098e-01,
           -1.5700e+00, -9.3587e-01,  9.0278e-01],
          [ 1.1981e+00,  1.0254e+00,  1.2997e+00,  5.9143e-01, -1.0238e-01,
           -1.1895e+00,  1.4284e+00,  3.6058e-02]]],


        [[[ 1.6088e+00,  1.0408e+00, -9.4513e-01,  1.4427e+00, -1.0920e+00,
            2.1576e-01, -1.9442e-01, -2.5781e-01],
          [ 1.2173e+00,  1.0609e+00, -1.3244e+00, -3.8147e-01, -1.4052e+00,
           -5.8654e-01, -4.5472e-01, -9.8076e-01],
          [ 4.7314e-01,  1.0095e+00, -2.0642e+00,  9.3200e-01, -1.0577e+00,
            6.6855e-01,  4.6842e-02, -2.3440e-01],
          [ 9.0748e-01,  1.3491e-01,  9.5946e-01, -2.6455e-01, -2.2035e-01,
           -9.1428e-01, -7.5918e-01,  2.1628e+00],
          [-7.1369e-01, -4.0275e-01, -9.4681e-01,  1.9207e+00, -1.4132e+00,
            4.0882e-02, -7.3450e-01,  4.4974e-01],
          [ 1.8113e+00,  8.9091e-01, -1.7453e+00,  3.7159e-01, -1.2576e-01,
           -6.6699e-01, -4.7108e-01,  2.3640e-01],
          [ 1.5579e+00, -4.3147e-01,  4.0968e-01, -1.3771e-01, -2.1780e+00,
            6.6376e-01,  6.7011e-02, -3.0389e-02]],

         [[-8.7919e-01,  9.9234e-01, -5.1517e-01, -1.4334e-01, -1.2931e+00,
           -1.8447e+00, -8.6066e-01, -3.6394e-01],
          [-8.0227e-01,  9.6980e-01, -3.1069e-01,  5.6146e-01,  1.6664e+00,
           -1.5727e+00,  6.3621e-01,  5.8673e-01],
          [-8.5248e-01,  1.2484e+00,  1.1328e-01, -3.2417e-01, -5.9369e-01,
           -1.1078e+00, -1.8710e+00, -7.1289e-01],
          [ 1.3352e+00, -3.8681e-01, -4.2005e-01,  1.9771e+00, -1.0861e+00,
            7.2887e-01,  4.7654e-01, -2.0037e-01],
          [ 1.0471e+00,  1.6841e+00,  1.0560e+00,  2.8245e-01, -7.2210e-01,
           -1.1620e+00,  1.8511e-01, -9.7942e-01],
          [-1.9677e+00,  1.6694e+00,  4.8643e-01, -4.8131e-03,  7.0193e-01,
            4.7569e-01,  2.1750e-01,  5.7662e-01],
          [ 3.6403e-02,  5.4035e-01,  1.1792e+00, -1.1351e+00, -9.9272e-01,
           -1.0766e+00, -9.5163e-01, -1.4035e+00]],

         [[ 2.9624e-01,  1.1791e+00,  2.0282e-01, -2.1404e+00, -4.3763e-01,
           -1.0810e+00,  1.1771e-01, -7.2221e-01],
          [ 3.4651e-01, -1.1618e+00,  3.1885e-01, -1.1345e-01, -1.0138e+00,
           -5.1890e-02, -1.8518e+00,  1.3966e+00],
          [-4.4261e-01, -8.9927e-01,  6.0563e-02, -1.4125e+00, -5.3559e-01,
           -1.6356e+00,  1.4245e+00,  4.0741e-02],
          [ 8.0125e-01,  7.8025e-01, -1.0170e+00,  1.0388e+00, -1.5922e+00,
           -1.2920e+00, -6.2588e-01,  1.6120e-01],
          [ 7.5550e-01, -7.7656e-01,  5.6799e-01, -1.7691e-02, -2.3484e+00,
           -4.8874e-01,  8.5881e-01, -8.0349e-02],
          [-8.6420e-01, -1.1291e+00, -6.9560e-02, -1.9820e-01,  2.0774e-01,
           -1.3553e+00,  1.9066e+00, -6.4394e-01],
          [-7.1662e-02, -5.6981e-01,  1.5941e+00, -7.5563e-01, -4.6593e-01,
            8.6047e-01,  1.8868e+00,  1.8477e-01]],

         [[ 8.0215e-01, -6.2874e-01,  7.8454e-01, -1.9832e+00, -1.1742e+00,
           -2.6792e-01,  9.7437e-01,  2.1765e-04],
          [-1.6283e+00, -7.0275e-02,  1.0591e+00,  6.6976e-01, -9.1380e-01,
            1.5914e+00,  2.1934e-01, -5.9148e-01],
          [ 1.9402e+00,  4.5521e-01,  2.2426e-02,  1.1678e+00, -2.4229e-01,
            9.2127e-01,  7.2366e-01,  1.1068e+00],
          [ 9.5682e-01, -2.9643e-01,  9.2269e-02,  1.2607e+00, -3.5126e-01,
           -3.4897e-01, -1.9980e+00,  1.0679e+00],
          [ 1.3134e+00, -2.5721e-02,  1.1686e+00, -2.4603e-02, -7.3470e-02,
           -1.3562e+00,  4.6655e-01,  1.6849e+00],
          [-1.0128e+00, -9.4317e-01, -5.1528e-01, -1.3186e+00, -6.2115e-01,
            1.2766e+00,  1.3215e+00,  5.6002e-01],
          [ 7.5668e-01, -7.1488e-01, -7.7338e-01,  5.8331e-01,  2.2877e+00,
            6.0179e-01, -3.6984e-02, -6.1173e-01]]],


        [[[-1.8887e+00,  4.7978e-01,  1.3044e+00, -9.7098e-01, -3.8009e-02,
            1.2360e+00, -1.6069e-01,  9.7899e-03],
          [ 7.9199e-01,  3.7509e-01, -1.0656e+00, -7.9472e-01, -1.1259e+00,
           -3.0517e-01, -9.7245e-01, -1.7742e+00],
          [-1.5614e+00,  1.1369e+00,  5.0825e-01,  1.6118e-01,  2.4798e-01,
           -1.2733e+00, -9.8004e-01, -1.1556e+00],
          [-2.0984e+00, -5.7102e-01,  3.3892e-01,  6.9814e-01,  6.0302e-01,
           -7.8088e-01,  7.5634e-01, -1.0584e+00],
          [ 1.7217e+00, -1.1835e+00,  6.4552e-01, -7.0386e-01,  6.5225e-01,
           -2.9801e-01, -1.7904e-01,  1.4733e+00],
          [ 1.1717e+00, -2.0281e-01, -7.7038e-01,  2.9348e-01, -8.4247e-01,
            1.7160e+00, -7.8196e-01, -1.2779e+00],
          [-4.8394e-01,  2.0523e+00, -4.0268e-01, -6.0466e-01, -2.6135e-01,
            1.5041e+00,  1.9511e-01,  8.0609e-01]],

         [[ 1.3557e-01,  1.2615e-01, -8.2028e-01,  8.6074e-01, -2.1383e+00,
           -4.5980e-01,  2.5596e-01,  1.2993e+00],
          [-3.1410e-01,  7.5180e-01, -3.2087e-01,  8.1419e-01,  1.6631e+00,
           -1.6554e+00,  9.0109e-01,  4.9568e-01],
          [ 1.9982e+00, -2.0440e-01, -1.2447e+00, -1.2518e-02, -1.1178e+00,
            9.4076e-01,  4.9119e-01,  1.6288e-01],
          [-1.7564e-01, -7.5518e-01,  4.4793e-02,  1.6516e+00, -1.2295e-01,
           -8.1799e-01, -1.2063e-01,  1.9917e+00],
          [-2.2515e+00, -1.2168e+00,  7.5688e-03, -5.2178e-01,  8.6905e-01,
            1.7128e-01,  6.2160e-01, -4.4378e-02],
          [ 1.0920e+00,  8.2903e-01,  2.1127e-01, -3.6942e-01, -7.6256e-01,
           -1.2108e-01, -4.5330e-01, -2.2656e+00],
          [ 4.2022e-02,  5.5545e-01, -5.4597e-01, -2.0914e+00,  7.5668e-01,
           -6.9058e-01, -1.4054e-01,  1.3943e+00]],

         [[ 5.6234e-02,  1.1035e+00,  1.2122e+00, -1.1686e+00,  5.7346e-01,
            7.0072e-01,  4.2941e-01, -1.7132e+00],
          [ 4.8887e-01, -7.6599e-01,  6.3363e-01,  2.9005e-02, -6.8671e-01,
            3.4769e-01, -2.1200e+00,  1.2964e+00],
          [ 8.5821e-01,  7.5981e-01,  1.2549e+00, -1.1524e-01, -1.4448e-01,
            1.2804e+00, -1.7726e+00,  5.3961e-01],
          [ 3.6089e-01,  4.7677e-01, -1.0704e+00,  1.8750e+00,  2.7385e-01,
           -1.4826e+00,  8.3434e-01, -2.0033e-02],
          [-4.8121e-01, -8.0079e-01,  8.2671e-01, -8.1261e-01,  1.7923e+00,
            8.1850e-01,  1.3739e+00, -8.8850e-02],
          [ 4.0964e-01, -3.5063e-01,  1.1134e+00, -9.7336e-01,  8.3833e-01,
           -2.0823e+00, -6.8741e-01, -6.4084e-02],
          [-4.6427e-02,  6.6270e-01,  6.2869e-01, -9.3357e-01, -1.2313e+00,
            1.4798e+00, -5.0227e-01, -1.5246e+00]],

         [[ 2.6774e-01, -4.0682e-01,  1.3161e-01,  2.0544e+00, -3.3357e-02,
           -1.1697e+00,  8.2616e-01, -1.2020e+00],
          [-1.8549e+00,  6.1124e-01,  1.3251e+00,  1.0220e+00, -4.4190e-01,
            9.2096e-01, -1.6608e-01, -5.5490e-01],
          [ 1.3439e+00, -5.3364e-01,  1.2848e+00,  1.0597e+00, -4.6834e-01,
            1.3324e+00, -1.0456e+00,  1.9919e-01],
          [-1.3736e+00,  1.2674e+00,  2.5534e-01,  9.9285e-01,  1.2791e+00,
           -8.0264e-01, -4.3650e-01, -9.8810e-01],
          [-6.0142e-01, -1.0259e+00, -2.4324e-01,  8.3572e-01,  1.6189e+00,
           -1.1979e+00,  1.2167e+00,  5.2950e-01],
          [ 9.5672e-01,  1.5641e+00,  1.3750e+00,  1.0068e-03, -3.8642e-01,
            1.2128e+00, -9.7292e-01,  4.1454e-01],
          [ 3.2282e-01, -1.7304e+00,  9.6374e-01,  4.3638e-02, -1.4426e+00,
            4.1411e-01,  6.2785e-01, -1.1450e+00]]]], device='cuda:0')
key = tensor([[[[-1.4018,  0.1246, -0.6496,  ..., -0.6318, -1.2288, -0.3283],
          [ 0.3478, -1.1953, -0.7986,  ..., -1.0518,  0.1684,  1.3727],
          [-0.8759, -0.7751, -1.0599,  ...,  0.9305, -0.8982,  0.2018],
          ...,
          [-0.1778, -1.6403, -1.4939,  ...,  0.5903, -0.7803,  0.5889],
          [-0.9368,  0.8516,  0.4906,  ...,  0.2239, -0.6487,  0.4997],
          [ 1.1020, -1.5451, -0.3843,  ..., -0.3593,  0.2188,  0.1446]],

         [[-1.4953,  0.3188, -0.9267,  ...,  0.0076, -1.2218,  0.3736],
          [-1.1822, -0.0719, -2.4525,  ..., -0.0272, -0.0690, -0.1863],
          [-1.3392, -0.1599, -1.9832,  ..., -1.2517, -0.2746, -0.2653],
          ...,
          [-0.7768, -0.7368, -2.3181,  ..., -0.6088,  0.3816, -0.3393],
          [-1.2847,  0.3145, -1.7392,  ..., -0.4731,  1.0542,  0.3358],
          [-1.3245, -0.7040, -1.5068,  ..., -0.2951,  1.2691, -0.4768]],

         [[-0.7093, -0.9522,  1.2676,  ...,  1.5205,  0.0124,  0.9533],
          [ 0.9156, -1.0862,  0.3137,  ...,  0.5681, -0.0045, -1.4225],
          [ 0.0323, -1.3562,  1.2584,  ...,  0.3850, -0.4219,  0.8775],
          ...,
          [-0.4919, -1.5436,  0.5413,  ...,  0.7255, -0.2700, -0.0448],
          [ 0.5052, -0.8540, -0.4348,  ..., -0.4487,  0.3265,  1.2165],
          [ 0.5316, -1.5428,  0.2422,  ..., -0.0300, -0.9966, -0.6953]],

         [[-1.1788, -0.2893,  1.6268,  ..., -0.4044,  1.1318,  0.6469],
          [-0.2581, -0.1337, -0.2169,  ...,  1.3433,  1.2992, -1.7568],
          [-0.4145, -1.0968,  1.3561,  ...,  0.1546,  0.7802, -1.0645],
          ...,
          [ 0.0186, -0.6227,  0.4559,  ..., -0.3246,  0.4605, -1.4914],
          [-1.2779, -0.9313,  0.3448,  ...,  0.5762,  0.2231, -1.0090],
          [-1.0809, -0.2805,  0.8527,  ...,  0.0908,  1.0425, -1.9045]]],


        [[[-1.4018,  0.1243, -0.6498,  ..., -0.6317, -1.2291, -0.3280],
          [-0.3935, -1.1176, -0.3823,  ..., -0.9041, -1.1081,  0.7860],
          [-1.4297, -0.2196, -0.5315,  ...,  0.6763,  0.1998, -0.0510],
          ...,
          [ 0.6465, -1.2410, -1.0560,  ..., -0.5414,  0.5171,  0.9901],
          [-0.4121,  0.0746, -0.5936,  ...,  0.1636,  0.2749,  1.2177],
          [ 0.5436, -1.8259, -0.3867,  ...,  0.8151, -0.1399, -0.4387]],

         [[-1.4952,  0.3188, -0.9268,  ...,  0.0077, -1.2218,  0.3736],
          [-1.4225,  0.2246, -2.0918,  ..., -0.2513, -0.3044,  0.2781],
          [-1.3877,  0.1512, -1.7860,  ..., -1.2456, -0.7262, -0.0087],
          ...,
          [-0.5564, -0.8046, -2.0723,  ..., -0.0770,  1.0191, -0.4857],
          [-0.5946, -0.4169, -2.1743,  ..., -0.7291,  1.1879, -0.3118],
          [-0.7966, -0.7653, -1.8921,  ..., -1.0183,  0.8859, -0.1766]],

         [[-0.7097, -0.9521,  1.2672,  ...,  1.5209,  0.0125,  0.9528],
          [ 0.3199, -1.4894, -0.5933,  ...,  0.6966, -0.0260, -1.2485],
          [ 0.8226, -1.1738,  1.4058,  ...,  0.1024, -0.1568,  0.8148],
          ...,
          [ 0.7195, -1.3193,  0.8015,  ...,  0.0053, -0.6729,  0.0875],
          [ 0.6559, -0.9307,  0.3702,  ..., -0.3980,  0.5166,  1.4748],
          [ 0.4349, -1.9966, -0.0138,  ..., -0.2822, -0.9188, -0.6968]],

         [[-1.1788, -0.2892,  1.6267,  ..., -0.4043,  1.1319,  0.6468],
          [-1.1930, -0.1361,  0.8160,  ...,  0.9586,  1.3708, -1.3326],
          [-0.4221, -1.2415,  1.6140,  ...,  0.4265,  1.1972, -0.3813],
          ...,
          [ 0.0933, -0.7238, -0.6304,  ...,  0.3614, -0.1228, -1.9653],
          [ 0.1267, -1.1299, -0.4986,  ...,  0.0637, -0.1661, -1.1098],
          [-0.6969, -0.6441,  1.4589,  ..., -0.3597,  0.9021, -1.3644]]],


        [[[-1.4020,  0.1247, -0.6495,  ..., -0.6317, -1.2288, -0.3285],
          [-0.2067, -1.0784, -0.7438,  ..., -0.8180, -0.5045,  1.2643],
          [-1.0206, -0.7225, -1.3624,  ...,  0.6444, -0.5402,  0.3801],
          ...,
          [ 0.5736, -0.7599, -0.6168,  ..., -1.0778,  0.7745,  0.9911],
          [ 0.0054, -0.1563, -0.4214,  ..., -0.8352,  0.0888,  1.2047],
          [ 0.6044, -2.1749, -0.8601,  ...,  0.3871,  0.4164,  0.2276]],

         [[-1.4952,  0.3189, -0.9267,  ...,  0.0076, -1.2217,  0.3737],
          [-1.0577, -0.1223, -2.4479,  ..., -0.3974, -0.2000,  0.0150],
          [-1.2357, -0.4489, -2.0103,  ..., -1.2394, -0.2596, -0.3050],
          ...,
          [-0.6740, -0.8408, -1.8991,  ...,  0.2000,  1.3053, -0.2621],
          [-1.4590, -0.1506, -2.0033,  ...,  0.0727,  1.0574, -0.2130],
          [-0.0992, -1.0309, -1.7478,  ..., -0.5762,  0.7448, -0.1701]],

         [[-0.7093, -0.9522,  1.2675,  ...,  1.5205,  0.0124,  0.9534],
          [ 0.7354, -1.2506, -0.4004,  ...,  0.7316,  0.2869, -1.2741],
          [ 0.3370, -1.2431,  1.1745,  ...,  0.4023, -0.4113,  1.0868],
          ...,
          [ 1.1117, -1.2056,  0.4427,  ..., -0.2289, -0.5512,  0.4953],
          [ 0.7204, -1.0905,  0.2073,  ..., -0.1193, -0.1915,  0.8635],
          [ 0.6422, -1.9254,  0.1871,  ...,  0.0516, -0.3008, -0.7764]],

         [[-1.1788, -0.2893,  1.6268,  ..., -0.4043,  1.1318,  0.6470],
          [-0.3412, -0.3367,  0.0877,  ...,  1.3775,  1.0339, -1.7108],
          [-0.1029, -1.3245,  1.2361,  ...,  0.2248,  0.5432, -1.0471],
          ...,
          [-0.2848, -0.9064, -0.6661,  ...,  0.5443, -0.3785, -1.8888],
          [-0.8092, -0.7022, -0.2838,  ...,  0.9591,  0.2833, -1.7879],
          [ 0.0966, -0.6366,  0.8915,  ..., -0.8233,  0.6564, -1.0401]]]],
       device='cuda:0')
value = tensor([[[[ 1.1615e-02, -2.0871e-02,  7.7225e-03,  ...,  5.6548e-03,
           -1.1107e-02,  5.2484e-03],
          [-3.4901e-03, -7.5536e-03,  4.3364e-03,  ..., -6.8531e-03,
           -1.6604e-02, -3.0754e-04],
          [ 6.8791e-03, -8.8045e-04,  4.9515e-03,  ...,  2.1578e-03,
           -7.5277e-03,  2.4436e-03],
          ...,
          [ 7.2481e-03, -3.5936e-03,  8.5186e-03,  ..., -7.1817e-03,
            3.2509e-03, -2.2115e-03],
          [ 8.2420e-03, -1.2376e-03, -2.3221e-03,  ...,  3.3573e-04,
           -1.6093e-02,  5.8873e-03],
          [-1.1309e-02, -9.5986e-03, -1.5263e-03,  ..., -1.4532e-02,
           -9.6584e-04,  3.9969e-03]],

         [[ 1.0055e-02, -1.0489e-02,  2.8097e-02,  ...,  1.5282e-02,
            1.1923e-02,  2.7427e-03],
          [ 4.4010e-03, -3.0582e-04,  6.4364e-03,  ..., -9.4202e-03,
            3.0608e-03, -1.8400e-03],
          [ 5.1077e-03, -9.8531e-03,  2.2112e-02,  ..., -8.2874e-03,
            1.8413e-02, -2.4778e-04],
          ...,
          [ 5.8308e-03, -1.5928e-02,  1.1424e-02,  ..., -2.1165e-02,
            7.7141e-04, -1.2805e-02],
          [ 8.8470e-03, -1.1787e-02, -5.1876e-03,  ...,  9.1586e-03,
            1.8068e-02,  7.5734e-03],
          [ 5.2414e-03, -1.6713e-02, -5.2330e-03,  ..., -1.4593e-02,
           -8.9830e-03, -5.6254e-03]],

         [[ 2.5372e-03, -5.6527e-03,  7.0040e-03,  ..., -1.7296e-02,
            6.3833e-03, -1.0577e-02],
          [ 9.0891e-03,  3.7663e-03, -8.8705e-04,  ..., -3.4652e-03,
           -8.8938e-05,  7.3101e-03],
          [ 2.2444e-02, -1.0168e-02,  3.0418e-03,  ..., -2.3181e-02,
            8.4886e-03,  4.8236e-03],
          ...,
          [ 1.8823e-02, -1.3067e-02,  9.7816e-03,  ..., -1.4402e-02,
            3.2568e-03,  9.0503e-04],
          [-2.4148e-03,  7.4669e-03, -8.2791e-03,  ...,  5.3495e-03,
            1.0906e-03,  3.6482e-03],
          [ 1.9024e-02, -3.9979e-03,  6.4878e-03,  ..., -7.1458e-03,
            9.7394e-05,  4.6374e-04]],

         [[-8.0946e-03,  1.1951e-02,  3.0324e-02,  ...,  1.6430e-02,
           -2.6246e-02, -2.5267e-03],
          [-1.5195e-03,  6.4178e-03,  1.6434e-02,  ..., -2.0037e-03,
            6.4402e-03,  9.8197e-03],
          [ 3.1134e-03,  8.5058e-03,  1.1921e-02,  ..., -5.8828e-03,
           -4.8477e-03,  1.5841e-02],
          ...,
          [ 1.0148e-02,  3.7140e-03,  7.4645e-03,  ..., -3.7285e-03,
            1.3312e-02,  5.3749e-03],
          [ 3.0263e-03,  1.4205e-02,  1.4735e-02,  ..., -3.9955e-04,
           -3.1787e-03,  1.5468e-02],
          [ 1.3823e-02,  9.2702e-03,  1.4664e-02,  ...,  9.8490e-03,
            8.8846e-03,  1.1813e-02]]],


        [[[ 1.1615e-02, -2.0870e-02,  7.7234e-03,  ...,  5.6531e-03,
           -1.1111e-02,  5.2476e-03],
          [ 1.5124e-03, -1.2064e-02,  1.2378e-03,  ..., -1.9678e-03,
           -2.7876e-02,  8.8644e-03],
          [ 5.0247e-03, -3.1429e-04,  5.3208e-03,  ...,  7.0391e-03,
           -1.0934e-02,  3.6176e-03],
          ...,
          [-2.6964e-03, -6.7785e-03,  5.3508e-04,  ..., -1.3116e-02,
            1.2150e-02, -5.9552e-03],
          [ 8.6976e-03,  2.9079e-03,  3.6655e-03,  ..., -3.4711e-03,
            4.1701e-03, -4.4612e-03],
          [-1.9234e-03, -1.7290e-03,  9.1868e-04,  ..., -5.3815e-03,
           -1.8003e-03,  6.4936e-03]],

         [[ 1.0054e-02, -1.0491e-02,  2.8093e-02,  ...,  1.5276e-02,
            1.1922e-02,  2.7386e-03],
          [ 4.7943e-03, -9.0051e-03,  8.2280e-03,  ..., -4.8865e-03,
            1.6335e-02,  2.8475e-03],
          [ 4.0705e-03,  1.4204e-03,  2.6198e-02,  ...,  3.5407e-03,
            1.9894e-02,  8.1143e-03],
          ...,
          [ 8.1506e-03, -2.0392e-02,  7.6925e-03,  ..., -1.4754e-02,
           -1.3736e-02, -1.0886e-02],
          [ 8.3095e-03, -8.8960e-03,  5.2900e-03,  ...,  1.7786e-03,
            6.4419e-03,  1.4175e-03],
          [ 2.7024e-03, -1.4876e-02,  3.5159e-03,  ..., -2.0800e-02,
            2.0952e-03, -6.5804e-03]],

         [[ 2.5340e-03, -5.6517e-03,  7.0035e-03,  ..., -1.7293e-02,
            6.3816e-03, -1.0578e-02],
          [ 6.6127e-03,  5.4933e-03, -2.3887e-03,  ..., -5.9530e-03,
            1.4458e-03,  2.4957e-03],
          [ 1.9960e-02, -7.3543e-03, -2.0724e-03,  ..., -2.6573e-02,
            1.1149e-02,  4.9089e-03],
          ...,
          [ 1.6626e-02, -7.7725e-03,  7.9701e-03,  ..., -3.8896e-03,
           -5.3408e-03,  5.9680e-03],
          [ 6.9411e-03, -2.8532e-03, -2.8723e-03,  ..., -1.6283e-03,
            4.1354e-03,  7.3046e-03],
          [ 2.4237e-02, -1.2740e-02,  6.7849e-03,  ..., -2.0182e-02,
            7.3123e-03, -7.2358e-04]],

         [[-8.0965e-03,  1.1951e-02,  3.0324e-02,  ...,  1.6429e-02,
           -2.6241e-02, -2.5296e-03],
          [-7.7127e-03,  1.3189e-02,  2.3271e-02,  ...,  3.2097e-03,
           -6.3029e-03,  1.2061e-02],
          [ 8.3396e-04,  7.9216e-03,  1.6665e-02,  ..., -3.6830e-04,
           -1.3697e-02,  1.7511e-02],
          ...,
          [ 1.3338e-02,  2.5101e-03,  4.0943e-03,  ..., -9.2482e-03,
            1.9311e-02,  1.2979e-02],
          [ 1.2249e-02,  7.4744e-03,  1.7395e-03,  ..., -8.6268e-03,
            9.9026e-03,  1.5091e-02],
          [ 1.7100e-02,  4.8034e-03,  9.1406e-03,  ...,  7.3519e-03,
            5.2417e-03,  1.3430e-02]]],


        [[[ 1.1616e-02, -2.0871e-02,  7.7225e-03,  ...,  5.6555e-03,
           -1.1109e-02,  5.2491e-03],
          [ 2.4962e-03, -6.3829e-03,  3.4186e-03,  ..., -1.9933e-03,
           -1.9640e-02,  9.7450e-04],
          [ 8.3383e-03, -5.5037e-04,  6.4176e-03,  ...,  3.0030e-03,
           -1.0881e-03, -3.3867e-03],
          ...,
          [-2.6541e-03, -1.0347e-02, -4.2524e-03,  ..., -1.0668e-02,
            1.1056e-02, -5.6161e-03],
          [ 2.3811e-03, -7.8352e-03, -2.5858e-03,  ..., -7.6532e-03,
           -8.7579e-03, -2.2715e-05],
          [ 1.1079e-03, -6.4826e-04,  5.8816e-03,  ..., -5.8231e-03,
            1.0726e-02, -2.1946e-03]],

         [[ 1.0055e-02, -1.0489e-02,  2.8096e-02,  ...,  1.5282e-02,
            1.1924e-02,  2.7441e-03],
          [ 3.0987e-03, -5.2390e-03,  1.1081e-02,  ..., -9.8647e-03,
            1.0659e-02, -4.3719e-04],
          [ 5.3991e-03, -1.0595e-02,  2.5537e-02,  ..., -7.7691e-03,
            1.1733e-02, -2.0536e-03],
          ...,
          [ 9.9150e-03, -2.5301e-02,  6.7704e-03,  ..., -3.1827e-03,
           -1.5087e-02, -4.6259e-03],
          [ 1.2015e-02, -1.7492e-02, -1.9643e-03,  ...,  2.0308e-03,
            4.4924e-03,  4.2529e-04],
          [ 9.7103e-04, -9.5379e-03,  7.2422e-03,  ..., -1.9267e-02,
           -9.7254e-03, -8.3163e-03]],

         [[ 2.5371e-03, -5.6526e-03,  7.0028e-03,  ..., -1.7296e-02,
            6.3834e-03, -1.0577e-02],
          [ 6.9270e-03,  1.0364e-03, -2.5414e-03,  ..., -5.8847e-03,
            1.3607e-03,  7.1479e-03],
          [ 2.0080e-02, -1.4915e-02,  3.4604e-03,  ..., -2.3824e-02,
            8.5630e-03,  5.3349e-03],
          ...,
          [ 7.5965e-03, -5.7603e-03,  3.4396e-03,  ..., -3.3258e-05,
           -6.7272e-03,  5.7747e-03],
          [ 3.4967e-03,  5.4198e-03, -1.4239e-03,  ...,  7.2620e-03,
           -4.7724e-03,  5.5109e-03],
          [ 1.6876e-02, -1.7295e-02,  7.1511e-03,  ..., -1.9275e-02,
            6.8817e-03, -3.4193e-04]],

         [[-8.0956e-03,  1.1951e-02,  3.0324e-02,  ...,  1.6430e-02,
           -2.6247e-02, -2.5255e-03],
          [-4.7141e-03,  7.8405e-03,  1.3044e-02,  ..., -4.4563e-03,
            1.9268e-03,  1.2483e-02],
          [ 5.5412e-03,  5.7779e-03,  8.4386e-03,  ..., -5.0150e-03,
           -3.4612e-03,  1.5704e-02],
          ...,
          [ 1.4199e-02,  6.1007e-03,  6.5788e-03,  ..., -3.8926e-03,
            1.1798e-02,  1.8339e-02],
          [ 5.5266e-03,  1.3475e-02,  1.6693e-02,  ..., -4.0233e-03,
            5.3302e-03,  1.6214e-02],
          [ 2.0329e-02, -2.8265e-04,  1.2281e-03,  ...,  6.9922e-03,
            1.2337e-02,  7.6937e-03]]]], device='cuda:0')
attention_mask = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')
dropout = 0.0, scaling = 0.3535533905932738, is_causal = False, kwargs = {}
sdpa_kwargs = {}

    def sdpa_attention_forward(
        module: torch.nn.Module,
        query: torch.Tensor,
        key: torch.Tensor,
        value: torch.Tensor,
        attention_mask: Optional[torch.Tensor],
        dropout: float = 0.0,
        scaling: Optional[float] = None,
        is_causal: Optional[bool] = None,
        **kwargs,
    ) -> tuple[torch.Tensor, None]:
        if kwargs.get("output_attentions", False):
            logger.warning_once(
                "`sdpa` attention does not support `output_attentions=True`."
                " Please set your attention to `eager` if you want any of these features."
            )
        sdpa_kwargs = {}
        if hasattr(module, "num_key_value_groups"):
            if not use_gqa_in_sdpa(attention_mask, key):
                key = repeat_kv(key, module.num_key_value_groups)
                value = repeat_kv(value, module.num_key_value_groups)
            else:
                sdpa_kwargs = {"enable_gqa": True}
    
        if attention_mask is not None and attention_mask.ndim == 4:
            attention_mask = attention_mask[:, :, :, : key.shape[-2]]
    
        # Instead of relying on the value set in the module directly, we use the is_causal passed in kwargs if it is presented
        is_causal = is_causal if is_causal is not None else getattr(module, "is_causal", True)
    
        # SDPA's Flash Attention (and cuDNN) kernels rely on the `is_causal` flag. However, there are certain conditions:
        # - Not in decoding phase (otherwise we want full attention on the single query token)
        # - Attention mask is not to be provided (even if it is a causal pattern)
        # - Internally, we marked this as compatible with causal, i.e. it is a decoder attention type
        #
        # Quirks on the conditionals:
        # - We avoid inline passing this to the SDPA function directly to support both torch.compile's dynamic shapes and
        #   full graph options. Otherwise, dynamic shapes are prevented from compiling.
        # - It is important to check first for the shape, otherwise compile will fail with
        #   `argument 'is_causal' must be bool, not SymBool`.
        is_causal = query.shape[2] > 1 and attention_mask is None and is_causal
    
        # Shapes (e.g. query.shape[2]) are tensors during jit tracing, resulting in `is_causal` being a tensor.
        # We convert it to a bool for the SDPA kernel that only accepts bools.
        if torch.jit.is_tracing() and isinstance(is_causal, torch.Tensor):
            is_causal = is_causal.item()
    
        # When `is_causal = False` and the `attention_mask` is not of boolean type, the Ascend NPU's SDPA interface cannot utilize the FlashAttentionScore operator
        # and falls back to small-operator concatenation. To invoke the FlashAttentionScore, the attention_mask must be converted to boolean type.
        # This adaptation ensures the `attention_mask` meets the requirement for using FlashAttentionScore.
        if _is_torch_npu_available:
            if attention_mask is not None and attention_mask.dtype != torch.bool:
                # Convert to boolean type, making sdpa to force call FlashAttentionScore to improve performance.
                attention_mask = torch.logical_not(attention_mask.bool()).to(query.device)
    
>       attn_output = torch.nn.functional.scaled_dot_product_attention(
            query,
            key,
            value,
            attn_mask=attention_mask,
            dropout_p=dropout,
            scale=scaling,
            is_causal=is_causal,
            **sdpa_kwargs,
        )
E       RuntimeError: The expanded size of the tensor (1808) must match the existing size (904) at non-singleton dimension 3.  Target sizes: [3, 4, 7, 1808].  Tensor sizes: [3, 1, 7, 904]

src/transformers/integrations/sdpa_attention.py:97: RuntimeError
_______________________ DFineModelTest.test_onnx_export ________________________
[gw23] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.d_fine.test_modeling_d_fine.DFineModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 156 / 360 (43.3%)
E                   Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['enc_topk_bboxes']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.d_fine.test_modeling_d_fine.DFineModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type d_fine failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 156 / 360 (43.3%)
E                   Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['enc_topk_bboxes']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 219 of general pattern rewrite rules.
__________________ ParakeetEncoderModelTest.test_onnx_export ___________________
[gw57] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.parakeet.test_modeling_parakeet.ParakeetEncoderModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 106496 / 106496 (100.0%)
E                   Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['last_hidden_state']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.parakeet.test_modeling_parakeet.ParakeetEncoderModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type parakeet_encoder failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 106496 / 106496 (100.0%)
E                   Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['last_hidden_state']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 20 of general pattern rewrite rules.
______________________ PatchTSTModelTest.test_onnx_export ______________________
[gw24] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.patchtst.test_modeling_patchtst.PatchTSTModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Scalars are not close!
E                   
E                   Expected 0.0 but got nan.
E                   Absolute difference: nan (up to 0.01 allowed)
E                   Relative difference: inf (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['loss']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.patchtst.test_modeling_patchtst.PatchTSTModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type patchtst failed the output closeness test: Scalars are not close!
E                   
E                   Expected 0.0 but got nan.
E                   Absolute difference: nan (up to 0.01 allowed)
E                   Relative difference: inf (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['loss']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 6 of general pattern rewrite rules.
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 6 of general pattern rewrite rules.
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 7 of general pattern rewrite rules.
___________________ ParakeetForCTCModelTest.test_onnx_export ___________________
[gw11] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.parakeet.test_modeling_parakeet.ParakeetForCTCModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 212992 / 212992 (100.0%)
E                   Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['logits']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.parakeet.test_modeling_parakeet.ParakeetForCTCModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type parakeet_ctc failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 212992 / 212992 (100.0%)
E                   Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['logits']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 21 of general pattern rewrite rules.
_______________________ RTDetrModelTest.test_onnx_export _______________________
[gw49] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.rt_detr.test_modeling_rt_detr.RTDetrModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 156 / 360 (43.3%)
E                   Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['enc_topk_bboxes']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.rt_detr.test_modeling_rt_detr.RTDetrModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type rt_detr failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 156 / 360 (43.3%)
E                   Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['enc_topk_bboxes']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 152 of general pattern rewrite rules.
_____________________ SuperGlueModelTest.test_onnx_export ______________________
[gw2] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.superglue.test_modeling_superglue.SuperGlueModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 1576 / 2048 (77.0%)
E                   Greatest absolute difference: 3.625 at index (1, 1, 167, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 29.375 at index (0, 0, 85, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['keypoints']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.superglue.test_modeling_superglue.SuperGlueModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type superglue failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 1576 / 2048 (77.0%)
E                   Greatest absolute difference: 3.625 at index (1, 1, 167, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 29.375 at index (0, 0, 85, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['keypoints']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 62 of general pattern rewrite rules.
------------------------------ Captured log call -------------------------------
WARNING  onnx_ir.passes.common.initializer_deduplication:initializer_deduplication.py:24 Skipped deduplication of initializer 'mask' as it is a graph input or output
__________ VoxtralForConditionalGenerationModelTest.test_onnx_export ___________
[gw35] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.voxtral.test_modeling_voxtral.VoxtralForConditionalGenerationModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 9423 / 10395 (90.6%)
E                   Greatest absolute difference: 0.5360131859779358 at index (2, 23, 69) (up to 0.01 allowed)
E                   Greatest relative difference: 81534.640625 at index (2, 23, 11) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['logits']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.voxtral.test_modeling_voxtral.VoxtralForConditionalGenerationModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type voxtral failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 9423 / 10395 (90.6%)
E                   Greatest absolute difference: 0.5360131859779358 at index (2, 23, 69) (up to 0.01 allowed)
E                   Greatest relative difference: 81534.640625 at index (2, 23, 11) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['logits']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 10 of general pattern rewrite rules.
----------------------------- Captured stderr call -----------------------------
[0;93m2025-11-19 08:38:22.290202822 [W:onnxruntime:Default, scatter_nd.h:51 ScatterNDWithAtomicReduction] ScatterND with reduction=='none' only guarantees to be correct if indices are not duplicated.[m
_______________________ ViTMAEModelTest.test_onnx_export _______________________
[gw61] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.vit_mae.test_modeling_vit_mae.ViTMAEModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 2886 / 2925 (98.7%)
E                   Greatest absolute difference: 223 at index (2, 100) (up to 0.01 allowed)
E                   Greatest relative difference: inf at index (0, 46) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['ids_restore']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.vit_mae.test_modeling_vit_mae.ViTMAEModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type vit_mae failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 2886 / 2925 (98.7%)
E                   Greatest absolute difference: 223 at index (2, 100) (up to 0.01 allowed)
E                   Greatest relative difference: inf at index (0, 46) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['ids_restore']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 3 of general pattern rewrite rules.
______________________ RTDetrV2ModelTest.test_onnx_export ______________________
[gw57] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.rt_detr_v2.test_modeling_rt_detr_v2.RTDetrV2ModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 156 / 360 (43.3%)
E                   Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['enc_topk_bboxes']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.rt_detr_v2.test_modeling_rt_detr_v2.RTDetrV2ModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type rt_detr_v2 failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 156 / 360 (43.3%)
E                   Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
E                   Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['enc_topk_bboxes']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 148 of general pattern rewrite rules.
________________________ XLMModelTest.test_onnx_export _________________________
[gw38] linux -- Python 3.12.12 /home/ilyas/transformers/.docker/bin/python3

self = <tests.models.xlm.test_modeling_xlm.XLMModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
>                   torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
E                   AssertionError: Tensor-likes are not close!
E                   
E                   Mismatched elements: 23 / 325 (7.1%)
E                   Greatest absolute difference: 3 at index (5, 20) (up to 0.01 allowed)
E                   Greatest relative difference: 3.0 at index (5, 20) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['end_top_index']

tests/test_modeling_common.py:3607: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.models.xlm.test_modeling_xlm.XLMModelTest testMethod=test_onnx_export>
atol = 0.01, rtol = 0.01

    @slow
    @require_onnxscript
    @require_onnxruntime
    @require_torch_greater_or_equal("2.5")
    @pytest.mark.onnx_export_test
    def test_onnx_export(self, atol=1e-2, rtol=1e-2):
        """
        Test if model can be exported with torch.onnx.export()
    
        Args:
            atol (`float`, *optional*, defaults to 1e-2): absolute tolerance for output comparison
            rtol (`float`, *optional*, defaults to 1e-2): relative tolerance for output comparison
        """
    
        exporter = OnnxExporter(export_config=OnnxConfig())
    
        for model_class in self.all_model_classes:
            with self.subTest(model_class.__name__):
                if hasattr(self.model_tester, "prepare_config_and_inputs_for_model_class"):
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)
                else:
                    config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()
                inputs_dict = self._prepare_for_class(inputs_dict, model_class)
                model = model_class(config).eval().to(torch_device)
    
                # prepare cache inputs for auto-regressive models and include it for computing eager outputs
                # process output flags (e.g. use_cache, output_attentions, etc) to avoid passing them as inputs
                model, inputs_dict = prepare_for_export(model, inputs_dict)
    
                with torch.no_grad():
                    # Running the eager inference before the export to catch model/inputs comatibility issues, also sometimes after
                    # the export, the model used for export will return FakeTensors instead of real ones (torch cuda/inductor issue)
                    # This happens on cuda with (codegen, clvp, esm, gptj, levit, wav2vec2_bert and wav2vec2_conformer)
                    set_seed(1234)
                    eager_outputs = model(**copy.deepcopy(inputs_dict))
                    eager_outputs = get_leaf_tensors(eager_outputs)
                    self.assertTrue(eager_outputs, "Eager outputs is empty.")
    
                try:
                    onnx_program = exporter.export(model, inputs_dict)
                except NotImplementedError:
                    continue
    
                # Remove non-tensor inputs as they were probably converted to constants during the onnx export
                inputs_dict = {
                    k: v
                    for k, v in inputs_dict.items()
                    if not isinstance(v, (int, float, bool, str)) and v is not None
                }
    
                set_seed(1234)
                onnx_outputs = onnx_program(**copy.deepcopy(inputs_dict))
                onnx_names = (re.sub(r"^output.", "", node.name) for node in onnx_program.model_proto.graph.output)
                onnx_outputs = dict(zip(onnx_names, onnx_outputs))
                self.assertTrue(onnx_outputs, "ONNX outputs is empty.")
    
                # Sometimes the model will return the same tensor multiple times under different names
                # while onnx will just return it once, dropping one of the duplicates (arbitrarily).
                eager_outputs = {k: v for k, v in eager_outputs.items() if k in onnx_outputs}
    
                try:
                    # Check if outputs are close:
                    torch.testing.assert_close(onnx_outputs, eager_outputs, atol=atol, rtol=rtol, check_device=False)
                except AssertionError as e:
                    mismatch_percentage = re.search(r"(\d+\.?\d*%)", str(e))
                    if mismatch_percentage is not None:
                        percentage = float(mismatch_percentage.group(1).strip("%"))
                        if percentage < 5.0:
                            continue
>                   self.fail(f"ONNX exported model of type {config.model_type} failed the output closeness test: {e}")
E                   AssertionError: ONNX exported model of type xlm failed the output closeness test: Tensor-likes are not close!
E                   
E                   Mismatched elements: 23 / 325 (7.1%)
E                   Greatest absolute difference: 3 at index (5, 20) (up to 0.01 allowed)
E                   Greatest relative difference: 3.0 at index (5, 20) (up to 0.01 allowed)
E                   
E                   The failure occurred for item ['end_top_index']

tests/test_modeling_common.py:3614: AssertionError
----------------------------- Captured stdout call -----------------------------
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 3 of general pattern rewrite rules.
Applied 2 of general pattern rewrite rules.
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 3 of general pattern rewrite rules.
Applied 2 of general pattern rewrite rules.
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... 
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... 
Applied 6 of general pattern rewrite rules.
Applied 2 of general pattern rewrite rules.
=============================== warnings summary ===============================
tests/test_modeling_common.py:3549: 64 warnings
  /home/ilyas/transformers/tests/test_modeling_common.py:3549: PytestUnknownMarkWarning: Unknown pytest.mark.onnx_export_test - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.onnx_export_test

<frozen importlib._bootstrap>:488: 128 warnings
  <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute

<frozen importlib._bootstrap>:488: 128 warnings
  <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute

<frozen importlib._bootstrap>:488: 64 warnings
  <frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute

tests/models/bros/test_modeling_bros.py::BrosModelTest::test_onnx_export
tests/models/flava/test_modeling_flava.py::FlavaModelTest::test_onnx_export
tests/models/flava/test_modeling_flava.py::FlavaForPreTrainingTest::test_onnx_export
tests/models/flava/test_modeling_flava.py::FlavaTextModelTest::test_onnx_export
tests/models/layoutlmv3/test_modeling_layoutlmv3.py::LayoutLMv3ModelTest::test_onnx_export
tests/models/layoutlmv3/test_modeling_layoutlmv3.py::LayoutLMv3ModelTest::test_onnx_export
tests/models/layoutlmv3/test_modeling_layoutlmv3.py::LayoutLMv3ModelTest::test_onnx_export
tests/models/layoutlmv3/test_modeling_layoutlmv3.py::LayoutLMv3ModelTest::test_onnx_export
tests/models/flava/test_modeling_flava.py::FlavaMultimodalModelTest::test_onnx_export
  /home/ilyas/transformers/src/transformers/modeling_utils.py:1421: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
    warnings.warn(

tests/models/blt/test_modeling_blt.py: 2 warnings
tests/models/patchtst/test_modeling_patchtst.py: 3 warnings
tests/models/univnet/test_modeling_univnet.py: 36 warnings
  /home/ilyas/transformers/.docker/lib/python3.12/site-packages/onnx/reference/ops/op_range.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
    return (np.arange(starts, ends, steps).astype(starts.dtype),)

tests/models/led/test_modeling_led.py::LEDModelTest::test_onnx_export
  /home/ilyas/transformers/src/transformers/models/led/modeling_led.py:2114: FutureWarning: The `transformers.LEDForSequenceClassification` class is deprecated and will be removed in version 5 of Transformers. No actual method were provided in the original paper on how to perform sequence classification.
    warnings.warn(

tests/models/funnel/test_modeling_funnel.py::FunnelModelTest::test_onnx_export
tests/models/funnel/test_modeling_funnel.py::FunnelBaseModelTest::test_onnx_export
  /home/ilyas/transformers/src/transformers/models/funnel/modeling_funnel.py:245: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)
    tensor = torch.cat([tensor[cls_slice], tensor], axis=axis)

tests/models/funnel/test_modeling_funnel.py::FunnelModelTest::test_onnx_export
tests/models/funnel/test_modeling_funnel.py::FunnelBaseModelTest::test_onnx_export
  /home/ilyas/transformers/src/transformers/models/funnel/modeling_funnel.py:246: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)
    return tensor[enc_slice]

tests/models/bloom/test_modeling_bloom.py::BloomModelTest::test_onnx_export
  /home/ilyas/transformers/src/transformers/models/bloom/modeling_bloom.py:504: FutureWarning: `position_ids` have no functionality in BLOOM and will be removed in v5.0.0. You can safely ignore passing `position_ids`.
    warnings.warn(

tests/models/cpmant/test_modeling_cpmant.py: 2 warnings
tests/models/blip_2/test_modeling_blip_2.py: 2 warnings
tests/models/mt5/test_modeling_mt5.py: 6 warnings
tests/models/musicgen/test_modeling_musicgen.py: 1 warning
tests/models/pix2struct/test_modeling_pix2struct.py: 2 warnings
tests/models/layoutlmv3/test_modeling_layoutlmv3.py: 4 warnings
tests/models/musicgen_melody/test_modeling_musicgen_melody.py: 1 warning
tests/models/pop2piano/test_modeling_pop2piano.py: 1 warning
tests/models/udop/test_modeling_udop.py: 3 warnings
tests/models/mpnet/test_modeling_mpnet.py: 6 warnings
tests/models/t5/test_modeling_t5.py: 6 warnings
tests/models/umt5/test_modeling_umt5.py: 6 warnings
tests/models/switch_transformers/test_modeling_switch_transformers.py: 3 warnings
  /home/ilyas/transformers/.docker/lib/python3.12/site-packages/onnx/reference/ops/op_log.py:13: RuntimeWarning: divide by zero encountered in log
    return (np.log(x).astype(x.dtype),)

tests/models/cpmant/test_modeling_cpmant.py: 2 warnings
tests/models/blip_2/test_modeling_blip_2.py: 2 warnings
tests/models/mt5/test_modeling_mt5.py: 6 warnings
tests/models/musicgen/test_modeling_musicgen.py: 1 warning
tests/models/pix2struct/test_modeling_pix2struct.py: 2 warnings
tests/models/layoutlmv3/test_modeling_layoutlmv3.py: 4 warnings
tests/models/musicgen_melody/test_modeling_musicgen_melody.py: 1 warning
tests/models/pop2piano/test_modeling_pop2piano.py: 1 warning
tests/models/udop/test_modeling_udop.py: 3 warnings
tests/models/mpnet/test_modeling_mpnet.py: 6 warnings
tests/models/t5/test_modeling_t5.py: 6 warnings
tests/models/umt5/test_modeling_umt5.py: 6 warnings
tests/models/switch_transformers/test_modeling_switch_transformers.py: 3 warnings
  /home/ilyas/transformers/.docker/lib/python3.12/site-packages/onnx/reference/ops/op_cast.py:34: RuntimeWarning: invalid value encountered in cast
    return x.astype(dtype)

tests/models/oneformer/test_modeling_oneformer.py::OneFormerModelTest::test_onnx_export
  /home/ilyas/transformers/.docker/lib/python3.12/site-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)
    return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

tests/models/timesfm/test_modeling_timesfm.py::TimesFmModelTest::test_onnx_export
  /home/ilyas/transformers/src/transformers/models/timesfm/modeling_timesfm.py:641: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
    torch.tensor(freq[: len(inputs)], dtype=torch.int32).reshape(-1, 1),

tests/models/timesfm/test_modeling_timesfm.py::TimesFmModelTest::test_onnx_export
  /home/ilyas/transformers/.docker/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:1066: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
    return func(*args, **kwargs)

tests/models/wavlm/test_modeling_wavlm.py::WavLMModelTest::test_onnx_export
  /home/ilyas/transformers/.docker/lib/python3.12/site-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
    warnings.warn(

tests/models/wav2vec2/test_modeling_wav2vec2.py::Wav2Vec2ModelTest::test_onnx_export
tests/models/wav2vec2/test_modeling_wav2vec2.py::Wav2Vec2RobustModelTest::test_onnx_export
  /home/ilyas/transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py:1647: FutureWarning: The class `Wav2Vec2ForMaskedLM` is deprecated. Please use `Wav2Vec2ForCTC` instead.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/models/bit/test_modeling_bit.py::BitModelTest::test_onnx_export - AssertionError: ONNX exported model of type bit failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 73 / 192 (38.0%)
Greatest absolute difference: 0.18257492780685425 at index (2, 21, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 39, 0, 0) (up to 0.01 allowed)

The failure occurred for item ['last_hidden_state']
FAILED tests/models/audioflamingo3/test_modeling_audioflamingo3.py::AudioFlamingo3ForConditionalGenerationModelTest::test_onnx_export - AssertionError: ONNX exported model of type audioflamingo3 failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 6644 / 7425 (89.5%)
Greatest absolute difference: 0.7158714532852173 at index (0, 2, 64) (up to 0.01 allowed)
Greatest relative difference: 2271.84912109375 at index (0, 7, 9) (up to 0.01 allowed)

The failure occurred for item ['logits']
FAILED tests/models/blt/test_modeling_blt.py::BltModelTest::test_onnx_export - AssertionError: ONNX exported model of type blt failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 330 / 336 (98.2%)
Greatest absolute difference: 3.642883777618408 at index (1, 0, 12) (up to 0.01 allowed)
Greatest relative difference: 3727.64306640625 at index (1, 3, 12) (up to 0.01 allowed)

The failure occurred for item ['last_hidden_state']
FAILED tests/models/flaubert/test_modeling_flaubert.py::FlaubertModelTest::test_onnx_export - AssertionError: ONNX exported model of type flaubert failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 135 / 325 (41.5%)
Greatest absolute difference: 5 at index (0, 10) (up to 0.01 allowed)
Greatest relative difference: 5.0 at index (0, 15) (up to 0.01 allowed)

The failure occurred for item ['end_top_index']
FAILED tests/models/mllama/test_modeling_mllama.py::MllamaForConditionalGenerationModelTest::test_onnx_export - RuntimeError: The expanded size of the tensor (1808) must match the existing size (904) at non-singleton dimension 3.  Target sizes: [3, 4, 7, 1808].  Tensor sizes: [3, 1, 7, 904]
FAILED tests/models/d_fine/test_modeling_d_fine.py::DFineModelTest::test_onnx_export - AssertionError: ONNX exported model of type d_fine failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 156 / 360 (43.3%)
Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)

The failure occurred for item ['enc_topk_bboxes']
FAILED tests/models/parakeet/test_modeling_parakeet.py::ParakeetEncoderModelTest::test_onnx_export - AssertionError: ONNX exported model of type parakeet_encoder failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 106496 / 106496 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)

The failure occurred for item ['last_hidden_state']
FAILED tests/models/patchtst/test_modeling_patchtst.py::PatchTSTModelTest::test_onnx_export - AssertionError: ONNX exported model of type patchtst failed the output closeness test: Scalars are not close!

Expected 0.0 but got nan.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: inf (up to 0.01 allowed)

The failure occurred for item ['loss']
FAILED tests/models/parakeet/test_modeling_parakeet.py::ParakeetForCTCModelTest::test_onnx_export - AssertionError: ONNX exported model of type parakeet_ctc failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 212992 / 212992 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)

The failure occurred for item ['logits']
FAILED tests/models/rt_detr/test_modeling_rt_detr.py::RTDetrModelTest::test_onnx_export - AssertionError: ONNX exported model of type rt_detr failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 156 / 360 (43.3%)
Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)

The failure occurred for item ['enc_topk_bboxes']
FAILED tests/models/superglue/test_modeling_superglue.py::SuperGlueModelTest::test_onnx_export - AssertionError: ONNX exported model of type superglue failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 1576 / 2048 (77.0%)
Greatest absolute difference: 3.625 at index (1, 1, 167, 0) (up to 0.01 allowed)
Greatest relative difference: 29.375 at index (0, 0, 85, 0) (up to 0.01 allowed)

The failure occurred for item ['keypoints']
FAILED tests/models/voxtral/test_modeling_voxtral.py::VoxtralForConditionalGenerationModelTest::test_onnx_export - AssertionError: ONNX exported model of type voxtral failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 9423 / 10395 (90.6%)
Greatest absolute difference: 0.5360131859779358 at index (2, 23, 69) (up to 0.01 allowed)
Greatest relative difference: 81534.640625 at index (2, 23, 11) (up to 0.01 allowed)

The failure occurred for item ['logits']
FAILED tests/models/vit_mae/test_modeling_vit_mae.py::ViTMAEModelTest::test_onnx_export - AssertionError: ONNX exported model of type vit_mae failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 2886 / 2925 (98.7%)
Greatest absolute difference: 223 at index (2, 100) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 46) (up to 0.01 allowed)

The failure occurred for item ['ids_restore']
FAILED tests/models/rt_detr_v2/test_modeling_rt_detr_v2.py::RTDetrV2ModelTest::test_onnx_export - AssertionError: ONNX exported model of type rt_detr_v2 failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 156 / 360 (43.3%)
Greatest absolute difference: 0.8750001192092896 at index (0, 16, 0) (up to 0.01 allowed)
Greatest relative difference: 10.0 at index (0, 5, 0) (up to 0.01 allowed)

The failure occurred for item ['enc_topk_bboxes']
FAILED tests/models/xlm/test_modeling_xlm.py::XLMModelTest::test_onnx_export - AssertionError: ONNX exported model of type xlm failed the output closeness test: Tensor-likes are not close!

Mismatched elements: 23 / 325 (7.1%)
Greatest absolute difference: 3 at index (5, 20) (up to 0.01 allowed)
Greatest relative difference: 3.0 at index (5, 20) (up to 0.01 allowed)

The failure occurred for item ['end_top_index']
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! KeyboardInterrupt !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
/root/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/threading.py:359: KeyboardInterrupt
(to show a full traceback on KeyboardInterrupt use --full-trace)
===== 15 failed, 457 passed, 4 skipped, 532 warnings in 696.26s (0:11:36) ======
