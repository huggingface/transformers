<!--ç‰ˆæƒæ‰€æœ‰ 2022 å¹´ HuggingFace å›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚
æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰æˆæƒï¼›åœ¨ä¸è¿åè®¸å¯è¯çš„æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½ä¸ä¼šä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨ä¸‹é¢è·å–è®¸å¯è¯çš„å‰¯æœ¬
http://www.apache.org/licenses/LICENSE-2.0
é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼ŒæŒ‰åŸæ ·åˆ†å‘çš„è½¯ä»¶åœ¨è®¸å¯è¯ä¸‹åˆ†å‘åŸºç¡€ä¸Šï¼Œâ€œæŒ‰åŸæ ·â€ BASISï¼Œæ— è®ºæ˜¯æ˜ç¤ºè¿˜æ˜¯æš—ç¤ºï¼Œä¸å¸¦ä»»ä½•å½¢å¼çš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚è¯·å‚é˜…è®¸å¯è¯ç‰¹å®šè¯­è¨€çš„æƒé™å’Œé™åˆ¶ã€‚
âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶é‡‡ç”¨ Markdown æ ¼å¼ï¼Œä½†åŒ…å«ç‰¹å®šäºæˆ‘ä»¬çš„ doc-builderï¼ˆç±»ä¼¼äº MDXï¼‰çš„è¯­æ³•ï¼Œå¯èƒ½æ— æ³•åœ¨æ‚¨çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®å‘ˆç°ã€‚
-->

# ç”¨äºæ¨ç†çš„å¤šè¯­è¨€æ¨¡å‹

[[åœ¨ Colab ä¸­æ‰“å¼€]]

åœ¨ğŸ¤— Transformers ä¸­æœ‰å‡ ä¸ªå¤šè¯­è¨€æ¨¡å‹ï¼Œå®ƒä»¬çš„æ¨ç†ç”¨æ³•ä¸å•è¯­æ¨¡å‹ä¸åŒã€‚ä½†å¹¶é *æ‰€æœ‰* å¤šè¯­è¨€æ¨¡å‹çš„ç”¨æ³•éƒ½ä¸åŒã€‚æŸäº›æ¨¡å‹ï¼Œå¦‚ [bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased)ï¼Œå¯ä»¥åƒå•è¯­æ¨¡å‹ä¸€æ ·ä½¿ç”¨ã€‚æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç”¨äºæ¨ç†çš„ç”¨æ³•ä¸å…¶ä»–å¤šè¯­è¨€æ¨¡å‹ä¸åŒçš„å¤šè¯­è¨€æ¨¡å‹ã€‚
## XLM

XLM æœ‰åä¸ªä¸åŒçš„æ£€æŸ¥ç‚¹ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªæ˜¯å•è¯­çš„ã€‚å…¶ä½™ä¹ä¸ªæ¨¡å‹æ£€æŸ¥ç‚¹å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šä½¿ç”¨è¯­è¨€åµŒå…¥çš„æ£€æŸ¥ç‚¹å’Œä¸ä½¿ç”¨è¯­è¨€åµŒå…¥çš„æ£€æŸ¥ç‚¹ã€‚

### ä½¿ç”¨è¯­è¨€åµŒå…¥çš„ XLM

ä»¥ä¸‹ XLM æ¨¡å‹åœ¨æ¨ç†æ—¶ä½¿ç”¨è¯­è¨€åµŒå…¥æ¥æŒ‡å®šä½¿ç”¨çš„è¯­è¨€ï¼š
- `xlm-mlm-ende-1024`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼Œè‹±å¾·ï¼‰
- `xlm-mlm-enfr-1024`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼Œè‹±æ³•ï¼‰
- `xlm-mlm-enro-1024`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼Œè‹±ç½—ï¼‰
- `xlm-mlm-xnli15-1024`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼ŒXNLI ç³»åˆ—è¯­è¨€ï¼‰
- `xlm-mlm-tlm-xnli15-1024`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡+ç¿»è¯‘ï¼ŒXNLI ç³»åˆ—è¯­è¨€ï¼‰
- `xlm-clm-enfr-1024`ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±æ³•ï¼‰
- `xlm-clm-ende-1024`ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±å¾·ï¼‰

è¯­è¨€åµŒå…¥è¡¨ç¤ºä¸ºä¸ä¼ é€’ç»™æ¨¡å‹çš„ `input_ids` å½¢çŠ¶ç›¸åŒçš„å¼ é‡ã€‚è¿™äº›å¼ é‡ä¸­çš„å€¼å–å†³äºä½¿ç”¨çš„è¯­è¨€ï¼Œå¹¶ç”±æ ‡è®°å™¨çš„ `lang2id` å’Œ `id2lang` å±æ€§æ ‡è¯†ã€‚

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½ `xlm-clm-enfr-1024` æ£€æŸ¥ç‚¹ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±æ³•ï¼‰ï¼š
```py
>>> import torch
>>> from transformers import XLMTokenizer, XLMWithLMHeadModel

>>> tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
>>> model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")
```

æ ‡è®°å™¨çš„ `lang2id` å±æ€§æ˜¾ç¤ºäº†è¯¥æ¨¡å‹çš„è¯­è¨€åŠå…¶ IDï¼š
```py
>>> print(tokenizer.lang2id)
{'en': 0, 'fr': 1}
```

æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªç¤ºä¾‹è¾“å…¥ï¼š
```py
>>> input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # batch size of 1
```

å°†è¯­è¨€ ID è®¾ç½®ä¸º `"en"` å¹¶ä½¿ç”¨å®ƒæ¥å®šä¹‰è¯­è¨€åµŒå…¥ã€‚è¯­è¨€åµŒå…¥æ˜¯ä¸€ä¸ªå¡«å……ä¸º `0` çš„å¼ é‡ï¼Œå› ä¸ºè¿™æ˜¯è‹±è¯­çš„è¯­è¨€ IDã€‚è¯¥å¼ é‡åº”ä¸ `input_ids` çš„å¤§å°ç›¸åŒã€‚
```py
>>> language_id = tokenizer.lang2id["en"]  # 0
>>> langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])

>>> # We reshape it to be of size (batch_size, sequence_length)
>>> langs = langs.view(1, -1)  # is now of shape [1, sequence_length] (we have a batch size of 1)
```

ç°åœ¨ï¼Œæ‚¨å¯ä»¥å°† `input_ids` å’Œè¯­è¨€åµŒå…¥ä¼ é€’ç»™æ¨¡å‹ï¼š
```py
>>> outputs = model(input_ids, langs=langs)
```

[run_generation.py](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py) è„šæœ¬å¯ä»¥ä½¿ç”¨ `xlm-clm` æ£€æŸ¥ç‚¹ç”Ÿæˆå…·æœ‰è¯­è¨€åµŒå…¥çš„æ–‡æœ¬ã€‚

### ä¸ä½¿ç”¨è¯­è¨€åµŒå…¥çš„ XLM

ä»¥ä¸‹ XLM æ¨¡å‹åœ¨æ¨ç†æ—¶ä¸éœ€è¦è¯­è¨€åµŒå…¥ï¼š
- `xlm-mlm-17-1280`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼Œ17 ç§è¯­è¨€ï¼‰
- `xlm-mlm-100-1280`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼Œ100 ç§è¯­è¨€ï¼‰
è¿™äº›æ¨¡å‹ç”¨äºé€šç”¨å¥å­è¡¨ç¤ºï¼Œä¸ä¹‹å‰çš„ XLM æ£€æŸ¥ç‚¹ä¸åŒã€‚
## BERT
ä»¥ä¸‹ BERT æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ä»»åŠ¡ï¼š
- `bert-base-multilingual-uncased`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡+ä¸‹ä¸€å¥é¢„æµ‹ï¼Œ102 ç§è¯­è¨€ï¼‰
- `bert-base-multilingual-cased`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡+ä¸‹ä¸€å¥é¢„æµ‹ï¼Œ104 ç§è¯­è¨€ï¼‰
åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè¿™äº›æ¨¡å‹ä¸éœ€è¦è¯­è¨€åµŒå…¥ã€‚å®ƒä»¬åº”è¯¥ä»ä¸Šä¸‹æ–‡ä¸­è¯†åˆ«è¯­è¨€å¹¶ç›¸åº”åœ°è¿›è¡Œæ¨ç†ã€‚
## XLM-RoBERTa

ä»¥ä¸‹ XLM-RoBERTa æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ä»»åŠ¡ï¼š
- `xlm-roberta-base`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼Œ100 ç§è¯­è¨€ï¼‰
- `xlm-roberta-large`ï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼Œ100 ç§è¯­è¨€ï¼‰

XLM-RoBERTa åœ¨ 100 ç§è¯­è¨€çš„æ–°åˆ›å»ºå’Œæ¸…ç†çš„ CommonCrawl æ•°æ®ä¸Šè¿›è¡Œäº† 2.5TB çš„è®­ç»ƒã€‚å®ƒåœ¨åˆ†ç±»ã€åºåˆ—æ ‡æ³¨å’Œé—®ç­”ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸Šç›¸æ¯”å…ˆå‰å‘å¸ƒçš„å¤šè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ mBERT æˆ– XLMï¼‰å–å¾—äº†å¾ˆå¤§çš„æå‡ã€‚

## M2M100

ä»¥ä¸‹ M2M100 æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ç¿»è¯‘ï¼š
- `facebook/m2m100_418M`ï¼ˆç¿»è¯‘ï¼‰
- `facebook/m2m100_1.2B`ï¼ˆç¿»è¯‘ï¼‰

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½ `facebook/m2m100_418M` æ£€æŸ¥ç‚¹ä»¥å°†ä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡ã€‚æ‚¨å¯ä»¥åœ¨æ ‡è®°å™¨ä¸­è®¾ç½®æºè¯­è¨€ï¼š

```py
>>> from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

>>> en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
>>> chinese_text = "ä¸è¦æ’æ‰‹å·«å¸«çš„äº‹å‹™, å› ç‚ºä»–å€‘æ˜¯å¾®å¦™çš„, å¾ˆå¿«å°±æœƒç™¼æ€’."

>>> tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M", src_lang="zh")
>>> model = M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")
```

å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼š
```py
>>> encoded_zh = tokenizer(chinese_text, return_tensors="pt")
```

M2M100 å°†ç›®æ ‡è¯­è¨€ ID å¼ºåˆ¶ä¸ºè¦ç¿»è¯‘åˆ°çš„ç›®æ ‡è¯­è¨€çš„ç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°ã€‚åœ¨ `generate` æ–¹æ³•ä¸­å°† `forced_bos_token_id` è®¾ç½®ä¸º `en` ä»¥è¿›è¡Œè‹±è¯­ç¿»è¯‘ï¼š
```py
>>> generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id("en"))
>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
'Do not interfere with the matters of the witches, because they are delicate and will soon be angry.'
```

## MBart

ä»¥ä¸‹ MBart æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ç¿»è¯‘ï¼š
- `facebook/mbart-large-50-one-to-many-mmt`ï¼ˆä¸€å¯¹å¤šå¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50 ç§è¯­è¨€ï¼‰
- `facebook/mbart-large-50-many-to-many-mmt`ï¼ˆå¤šå¯¹å¤šå¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50 ç§è¯­è¨€ï¼‰
- `facebook/mbart-large-50-many-to-one-mmt`ï¼ˆå¤šå¯¹ä¸€å¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50 ç§è¯­è¨€ï¼‰- `facebook/mbart-large-50`ï¼ˆå¤šè¯­è¨€ç¿»è¯‘ï¼Œ50 ç§è¯­è¨€ï¼‰
- `facebook/mbart-large-cc25`
åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½ `facebook/mbart-large-50-many-to-many-mmt` æ£€æŸ¥ç‚¹ä»¥å°†èŠ¬å…°è¯­ç¿»è¯‘ä¸ºè‹±è¯­ã€‚æ‚¨å¯ä»¥åœ¨æ ‡è®°å™¨ä¸­è®¾ç½®æºè¯­è¨€ï¼š
```py
>>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

>>> en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
>>> fi_text = "Ã„lÃ¤ sekaannu velhojen asioihin, sillÃ¤ ne ovat hienovaraisia ja nopeasti vihaisia."

>>> tokenizer = AutoTokenizer.from_pretrained("facebook/mbart-large-50-many-to-many-mmt", src_lang="fi_FI")
>>> model = AutoModelForSeq2SeqLM.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")
```

å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼š
```py
>>> encoded_en = tokenizer(en_text, return_tensors="pt")
```

MBart å°†ç›®æ ‡è¯­è¨€ ID å¼ºåˆ¶ä¸ºè¦ç¿»è¯‘åˆ°çš„ç›®æ ‡è¯­è¨€çš„ç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°ã€‚åœ¨ `generate` æ–¹æ³•ä¸­å°† `forced_bos_token_id` è®¾ç½®ä¸º `en` ä»¥è¿›è¡Œè‹±è¯­ç¿»è¯‘ï¼š
```py
>>> generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id("en_XX"))
>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
"Don't interfere with the wizard's affairs, because they are subtle, will soon get angry."
```

å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ `facebook/mbart-large-50-many-to-one-mmt` æ£€æŸ¥ç‚¹ï¼Œåˆ™ä¸éœ€è¦å°†ç›®æ ‡è¯­è¨€ ID å¼ºåˆ¶ä¸ºç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°ï¼Œå¦åˆ™ä½¿ç”¨æ–¹æ³•ç›¸åŒã€‚