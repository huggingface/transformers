<!---
Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# æ•…éšœæ’é™¤

é”™è¯¯æ˜¯éš¾å…çš„ï¼Œä½†æˆ‘ä»¬éšæ—¶ä¸ºä½ æä¾›å¸®åŠ©ï¼æœ¬æŒ‡å—æ¶µç›–äº†ä¸€äº›æˆ‘ä»¬æœ€å¸¸è§åˆ°çš„é—®é¢˜ä»¥åŠå®ƒä»¬çš„è§£å†³æ–¹æ³•ã€‚ä½†æœ¬æŒ‡å—å¹¶ä¸ä¼šæ¶µç›–æ‰€æœ‰çš„ ğŸ¤— Transformers é—®é¢˜ã€‚å¦‚æœä½ éœ€è¦æ›´å¤šæ•…éšœæ’é™¤æ–¹é¢çš„å¸®åŠ©ï¼Œè¯·å°è¯•ï¼š

<Youtube id="S2EEG3JIt2A"/>

1. åœ¨[è®ºå›](https://discuss.huggingface.co/)ä¸Šå¯»æ±‚å¸®åŠ©ã€‚ä½ å¯ä»¥å°†é—®é¢˜å‘å¸ƒåˆ°ç‰¹å®šç±»åˆ«ä¸‹ï¼Œä¾‹å¦‚ [åˆå­¦è€…](https://discuss.huggingface.co/c/beginners/5) æˆ– [ğŸ¤— Transformers](https://discuss.huggingface.co/c/transformers/9)ã€‚è¯·åœ¨è®ºå›å¸–å­å†…è¯¦ç»†æè¿°é—®é¢˜ï¼Œå¹¶é™„ä¸Šå¯é‡ç°çš„ä»£ç ï¼Œä»¥å¢åŠ è§£å†³é—®é¢˜çš„å¯èƒ½æ€§ï¼

<Youtube id="_PAli-V4wj0"/>

2. å¦‚æœæ˜¯ä¸åº“ç›¸å…³çš„ bugï¼Œè¯·åœ¨ ğŸ¤— Transformers ä»£ç ä»“åº“ä¸­æäº¤ä¸€ä¸ª [Issue](https://github.com/huggingface/transformers/issues/new/choose)ã€‚å¹¶ä¸”å°½å¯èƒ½è¯¦ç»†å¾—æè¿°ä¸ bug æœ‰å…³çš„ä¿¡æ¯ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°å®šä½ä»¥åŠä¿®å¤é—®é¢˜ã€‚

3. å¦‚æœä½ ä½¿ç”¨çš„æ˜¯è¾ƒæ—§ç‰ˆæœ¬çš„ ğŸ¤— Transformersï¼Œè¯·æŸ¥é˜…[è¿ç§»](migration)æŒ‡å—ï¼Œå› ä¸ºæ–°æ—§ç‰ˆæœ¬ä¹‹é—´å¼•å…¥äº†ä¸€äº›é‡è¦çš„æ›´æ”¹ã€‚

æœ‰å…³æ•…éšœæ’é™¤å’Œè·å–å¸®åŠ©çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜… Hugging Face è¯¾ç¨‹çš„[ç¬¬ 8 ç« ](https://huggingface.co/course/chapter8/1?fw=pt)ã€‚


## é˜²ç«å¢™ç¯å¢ƒ

ä¸€äº›äº‘å’Œå†…è”ç½‘ä¸Šçš„ GPU å®ä¾‹å¯¹å¤–éƒ¨è¿æ¥è®¾ç½®äº†é˜²ç«å¢™ï¼Œå¯¼è‡´è¿æ¥é”™è¯¯ã€‚å½“ä½ çš„è„šæœ¬å°è¯•ä¸‹è½½æ¨¡å‹æƒé‡æˆ–æ•°æ®é›†æ—¶ï¼Œä¸‹è½½å°†æŒ‚èµ·ï¼Œéšåè¶…æ—¶å¹¶æ˜¾ç¤ºä»¥ä¸‹æŠ¥é”™ä¿¡æ¯ï¼š

```
ValueError: Connection error, and we cannot find the requested files in the cached path.
Please try again or make sure your Internet connection is on.
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ åº”è¯¥å°è¯•ä»¥ [ç¦»çº¿æ¨¡å¼](installation#offline-mode) è¿è¡Œ ğŸ¤— Transformers ä»¥é¿å…è¿æ¥é”™è¯¯ã€‚

## CUDA å†…å­˜ä¸è¶³

åœ¨æ²¡æœ‰é€‚å½“ç¡¬ä»¶çš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒæ•°ç™¾ä¸‡å‚æ•°çš„å¤§å‹æ¨¡å‹å¯èƒ½ä¼šå¾ˆæœ‰æŒ‘æˆ˜æ€§ã€‚å½“ GPU å†…å­˜ä¸è¶³æ—¶ï¼Œä½ å¯èƒ½ä¼šé‡åˆ°ä»¥ä¸‹å¸¸è§é”™è¯¯ï¼š

```
CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)
```

ä»¥ä¸‹çš„ä¸€äº›è§£å†³æ–¹æ¡ˆæˆ–è®¸èƒ½å¤Ÿå‡å°‘ä½ çš„å†…å­˜ä½¿ç”¨ï¼š

- åœ¨ [`TrainingArguments`] ä¸­å‡å°‘ [`per_device_train_batch_size`](main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size) å€¼çš„å¤§å°ã€‚
- å°è¯•åœ¨ [`TrainingArguments`] ä½¿ç”¨ [`gradient_accumulation_steps`](main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps) ä»¥æœ‰æ•ˆåœ°å¢åŠ æ€»çš„ batch sizeã€‚

<Tip>

è¯·å‚è€ƒæ€§èƒ½[æŒ‡å—](performance)ä»¥è·å–æ›´å¤šèŠ‚çœ GPU å†…å­˜çš„æŠ€å·§ã€‚

</Tip>

## æ— æ³•åŠ è½½å·²ä¿å­˜çš„ TensorFlow æ¨¡å‹

TensorFlow çš„ [model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) æ–¹æ³•ä¼šå°†æ•´ä¸ªæ¨¡å‹ - æ¶æ„ã€æƒé‡ã€è®­ç»ƒé…ç½® - ä¿å­˜åœ¨å•ä¸ªæ–‡ä»¶ä¸­ã€‚ä½†æ˜¯ï¼Œä½ å†æ¬¡åŠ è½½æ¨¡å‹æ–‡ä»¶æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°é”™è¯¯ï¼Œå› ä¸º ğŸ¤— Transformers å¯èƒ½ä¸ä¼šåŠ è½½æ¨¡å‹æ–‡ä»¶ä¸­çš„æ‰€æœ‰ä¸ TensorFlow ç›¸å…³çš„å¯¹è±¡ã€‚ä¸ºäº†é¿å…ä¿å­˜å’ŒåŠ è½½ TensorFlow æ¨¡å‹æ—¶å‡ºç°é—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®ä½ ï¼š

- ä½¿ç”¨ [`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) å°†æ¨¡å‹æƒé‡ä¿å­˜ä¸º `h5` æ‰©å±•çš„æ–‡ä»¶æ ¼å¼ï¼Œç„¶åä½¿ç”¨ [`~TFPreTrainedModel.from_pretrained`] é‡æ–°åŠ è½½æ¨¡å‹ï¼š

```py
>>> from transformers import TFPreTrainedModel
>>> from tensorflow import keras

>>> model.save_weights("some_folder/tf_model.h5")
>>> model = TFPreTrainedModel.from_pretrained("some_folder")
```

- ä½¿ç”¨ [`~TFPretrainedModel.save_pretrained`] ä¿å­˜æ¨¡å‹ï¼Œç„¶åä½¿ç”¨ [`~TFPreTrainedModel.from_pretrained`] å†æ¬¡åŠ è½½æ¨¡å‹æƒé‡ï¼š

```py
>>> from transformers import TFPreTrainedModel

>>> model.save_pretrained("path_to/model")
>>> model = TFPreTrainedModel.from_pretrained("path_to/model")
```

## ImportError

ä½ å¯èƒ½ä¼šé‡åˆ°çš„å¦ä¸€ä¸ªå¸¸è§é”™è¯¯æ˜¯ `ImportError`ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨æ–°å‘å¸ƒçš„æ¨¡å‹æ—¶ï¼š

```
ImportError: cannot import name 'ImageGPTImageProcessor' from 'transformers' (unknown location)
```

å¯¹äºè¿™äº›é”™è¯¯ç±»å‹ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬çš„ ğŸ¤— Transformers ä»¥è®¿é—®æœ€æ–°çš„æ¨¡å‹ï¼š

```bash
pip install transformers --upgrade
```

## CUDA errorï¼šè§¦å‘è®¾å¤‡ç«¯æ–­è¨€

æœ‰æ—¶ä½ å¯èƒ½ä¼šé‡åˆ°ä¸€èˆ¬ CUDA é”™è¯¯ï¼Œæœ‰å…³è®¾å¤‡ä»£ç é”™è¯¯ã€‚

```
RuntimeError: CUDA error: device-side assert triggered
```

è¯·å…ˆå°è¯•åœ¨CPUä¸Šè¿è¡Œä»£ç ï¼Œä»¥è·å–æ›´è¯¦ç»†çš„é”™è¯¯æ¶ˆæ¯ã€‚å°†ä»¥ä¸‹ç¯å¢ƒå˜é‡æ·»åŠ åˆ°ä»£ç å¼€å¤´ï¼Œä»¥å°†è®¾å¤‡åˆ‡æ¢è‡³ CPUï¼š

```py
>>> import os

>>> os.environ["CUDA_VISIBLE_DEVICES"] = ""
```

å¦ä¸€ç§é€‰æ‹©æ˜¯ä» GPU è·å¾—æ›´å¥½çš„å›æº¯ã€‚å°†ä»¥ä¸‹ç¯å¢ƒå˜é‡æ·»åŠ åˆ°ä»£ç çš„å¼€å¤´ï¼Œä»¥ä½¿å›æº¯æŒ‡å‘é”™è¯¯æºï¼š

```py
>>> import os

>>> os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
```

## padding token æœªè¿›è¡Œ mask æ—¶çš„è¾“å‡ºé”™è¯¯

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æœ `input_ids` åŒ…æ‹¬ padding tokenï¼Œè¾“å‡ºçš„ `hidden_state` å¯èƒ½æ˜¯ä¸æ­£ç¡®çš„ã€‚ä¸ºäº†è¿›è¡Œæ¼”ç¤ºï¼Œè¯·åŠ è½½ä¸€ä¸ªæ¨¡å‹å’Œåˆ†è¯å™¨ã€‚ä½ å¯ä»¥è®¿é—®æ¨¡å‹çš„ `pad_token_id` æŸ¥çœ‹å®ƒçš„å€¼ã€‚ä¸€äº›æ¨¡å‹çš„ `pad_token_id` ä¹Ÿè®¸ä¸º  `None`ï¼Œä½†ä½ å§‹ç»ˆèƒ½å¤Ÿæ‰‹åŠ¨è®¾ç½®å®ƒã€‚

```py
>>> from transformers import AutoModelForSequenceClassification
>>> import torch

>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
>>> model.config.pad_token_id
0
```

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†æ¨¡å‹åœ¨æ²¡æœ‰å±è”½ padding token æƒ…å†µä¸‹çš„è¾“å‡ºï¼š

```py
>>> input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [ 0.1317, -0.1683]], grad_fn=<AddmmBackward0>)
```

è¿™æ˜¯ç¬¬äºŒä¸ªåºåˆ—çš„å®é™…è¾“å‡ºï¼š

```py
>>> input_ids = torch.tensor([[7592]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

å¤§å¤šæ•°æ—¶å€™ï¼Œä½ åº”è¯¥ä¸ºæ¨¡å‹æä¾›ä¸€ä¸ª `attention_mask` æ¥å¿½ç•¥ padding tokenï¼Œä»¥é¿å…è¿™ç§æ½œåœ¨é”™è¯¯ã€‚ç°åœ¨ç¬¬äºŒä¸ªåºåˆ—çš„è¾“å‡ºä¸å…¶å®é™…è¾“å‡ºä¸€è‡´äº†ï¼š

<Tip>

é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ†è¯å™¨ä¼šæ ¹æ®è¯¥åˆ†è¯å™¨çš„é»˜è®¤è®¾ç½®ä¸ºä½ åˆ›å»ºä¸€ä¸ª `attention_mask`ã€‚

</Tip>

```py
>>> attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])
>>> output = model(input_ids, attention_mask=attention_mask)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

å½“æä¾› padding token æ—¶ï¼ŒğŸ¤— Transformers ä¸ä¼šè‡ªåŠ¨åˆ›å»º `attention_mask` å¯¹å…¶è¿›è¡Œæ©ç›–ï¼ˆmaskï¼‰ï¼ŒåŸå› å¦‚ä¸‹ï¼š

- ä¸€äº›æ¨¡å‹æ²¡æœ‰ padding tokenã€‚
- æŸäº›ç”¨ä¾‹ä¸­ï¼Œç”¨æˆ·å¸Œæœ›æ¨¡å‹å¤„ç† padding tokenã€‚

## ValueError: æ— æ³•è¯†åˆ«æ­¤ç±» AutoModel çš„é…ç½®ç±» XYZ

é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ [`AutoModel`] ç±»æ¥åŠ è½½æ¨¡å‹çš„é¢„è®­ç»ƒå®ä¾‹ã€‚è¯¥ç±»å¯ä»¥æ ¹æ®é…ç½®è‡ªåŠ¨ä»ç»™å®šçš„æ£€æŸ¥ç‚¹ï¼ˆcheckpointï¼‰æ¨æ–­å¹¶åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹æ—¶çœ‹åˆ°æ­¤ `ValueError`ï¼Œæ„å‘³ç€ Auto ç±»æ— æ³•ä»ç»™å®šæ£€æŸ¥ç‚¹ä¸­ï¼Œæ‰¾åˆ°é…ç½®ä¸ä½ å°è¯•åŠ è½½çš„æ¨¡å‹ç±»å‹ä¹‹é—´çš„æ˜ å°„ã€‚è¿™ä¸ªé”™è¯¯æœ€å¸¸å‘ç”Ÿåœ¨åŠ è½½çš„æ£€æŸ¥ç‚¹ä¸æ”¯æŒç»™å®šä»»åŠ¡çš„æ—¶å€™ã€‚ä½ å°†åœ¨ä»¥ä¸‹ç¤ºä¾‹ä¸­çœ‹åˆ°æ­¤é”™è¯¯ï¼Œå› ä¸º GPT2 æ¨¡å‹ä¸æ”¯æŒé—®ç­”ï¼ˆquestion answeringï¼‰ä»»åŠ¡ï¼š

```py
>>> from transformers import AutoProcessor, AutoModelForQuestionAnswering

>>> processor = AutoProcessor.from_pretrained("gpt2-medium")
>>> model = AutoModelForQuestionAnswering.from_pretrained("gpt2-medium")
ValueError: Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForQuestionAnswering.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BloomConfig, ...
```
