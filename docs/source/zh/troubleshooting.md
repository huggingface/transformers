<!---ç‰ˆæƒæ‰€æœ‰ 2022 å¹´ HuggingFace å›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚
æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰æˆæƒï¼›é™¤ééµå®ˆè®¸å¯è¯ï¼Œå¦åˆ™æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯å‰¯æœ¬
    http://www.apache.org/licenses/LICENSE-2.0
é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™è½¯ä»¶åœ¨è®¸å¯è¯çš„åŸºç¡€ä¸Šåˆ†å‘ï¼Œè¯¥è®¸å¯è¯æ˜¯â€œæŒ‰åŸæ ·â€åˆ†å‘çš„ï¼Œæ— è®ºæ˜¯æ˜ç¤ºè¿˜æ˜¯æš—ç¤ºï¼Œå‡ä¸æä¾›ä»»ä½•å½¢å¼çš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚æœ‰å…³ç‰¹å®šè¯­è¨€çš„æƒé™å’Œé™åˆ¶ï¼Œè¯·å‚é˜…è®¸å¯è¯ã€‚
âš ï¸ è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯ Markdown æ ¼å¼ï¼Œä½†åŒ…å«æˆ‘ä»¬ doc-builder çš„ç‰¹å®šè¯­æ³•ï¼ˆç±»ä¼¼äº MDXï¼‰ï¼Œåœ¨ Markdown æŸ¥çœ‹å™¨ä¸­å¯èƒ½æ— æ³•æ­£ç¡®å‘ˆç°ã€‚
-->

# æ•…éšœæ’é™¤

æœ‰æ—¶ä¼šå‘ç”Ÿé”™è¯¯ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é‡Œå¸®åŠ©æ‚¨ï¼æœ¬æŒ‡å—æ¶µç›–äº†æˆ‘ä»¬é‡åˆ°çš„ä¸€äº›å¸¸è§é—®é¢˜åŠå…¶è§£å†³æ–¹æ³•ã€‚ä½†æ˜¯ï¼Œæœ¬æŒ‡å—å¹¶ä¸æ„å‘³ç€æ˜¯æ¯ä¸ªğŸ¤— Transformers é—®é¢˜çš„å…¨é¢é›†åˆã€‚å¦‚æœéœ€è¦æ›´å¤šæ•…éšœæ’é™¤å¸®åŠ©ï¼Œè¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
<Youtube id="S2EEG3JIt2A"/>

1. åœ¨ [è®ºå›](https://discuss.huggingface.co/) ä¸Šå¯»æ±‚å¸®åŠ©ã€‚æ‚¨å¯ä»¥æ ¹æ®å…·ä½“çš„ç±»åˆ«å‘å¸ƒé—®é¢˜ï¼Œæ¯”å¦‚ [åˆå­¦è€…](https://discuss.huggingface.co/c/beginners/5) æˆ– [ğŸ¤— Transformers](https://discuss.huggingface.co/c/transformers/9)ã€‚

è¯·ç¡®ä¿ç¼–å†™ä¸€ä¸ªå…·æœ‰ä¸€äº›å¯é‡ç°ä»£ç çš„æ¸…æ™°æè¿°çš„è®ºå›å¸–å­ï¼Œä»¥æœ€å¤§ç¨‹åº¦åœ°æé«˜é—®é¢˜è§£å†³çš„å¯èƒ½æ€§ï¼

<Youtube id="_PAli-V4wj0"/>

2. åœ¨ğŸ¤— Transformers å­˜å‚¨åº“ä¸Šåˆ›å»º [é—®é¢˜](https://github.com/huggingface/transformers/issues/new/choose)ï¼Œå¦‚æœæ˜¯ä¸åº“ç›¸å…³çš„é”™è¯¯ã€‚è¯·å°½é‡æä¾›å°½å¯èƒ½å¤šçš„æè¿°é”™è¯¯çš„ä¿¡æ¯ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ä»¥åŠå¦‚ä½•ä¿®å¤ã€‚

3. å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯æ—§ç‰ˆæœ¬çš„ğŸ¤— Transformersï¼Œè¯·æŸ¥çœ‹ [è¿ç§»](migration) æŒ‡å—ï¼Œå› ä¸ºä¸åŒç‰ˆæœ¬ä¹‹é—´å¯èƒ½å¼•å…¥äº†ä¸€äº›é‡è¦çš„æ›´æ”¹ã€‚

æœ‰å…³æ•…éšœæ’é™¤å’Œè·å–å¸®åŠ©çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… Hugging Face è¯¾ç¨‹çš„ [ç¬¬ 8 ç« ](https://huggingface.co/course/chapter8/1?fw=pt)ã€‚

## é˜²ç«å¢™ç¯å¢ƒ

æŸäº›äº‘ç«¯å’Œå†…éƒ¨ç½‘ç»œè®¾ç½®çš„ GPU å®ä¾‹è¢«é˜²ç«å¢™é˜»æ­¢å¯¹å¤–éƒ¨è¿æ¥ï¼Œå¯¼è‡´è¿æ¥é”™è¯¯ã€‚å½“æ‚¨çš„è„šæœ¬å°è¯•ä¸‹è½½æ¨¡å‹æƒé‡æˆ–æ•°æ®é›†æ—¶ï¼Œä¸‹è½½å°†æŒ‚èµ·ï¼Œç„¶åè¶…æ—¶ï¼Œå¹¶æ˜¾ç¤ºä»¥ä¸‹æ¶ˆæ¯ï¼š
```
ValueError: Connection error, and we cannot find the requested files in the cached path.
Please try again or make sure your Internet connection is on.
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥å°è¯•åœ¨ [ç¦»çº¿æ¨¡å¼](installation#offline-mode) ä¸‹è¿è¡ŒğŸ¤— Transformersï¼Œä»¥é¿å…è¿æ¥é”™è¯¯ã€‚

## CUDA å†…å­˜ä¸è¶³

åœ¨è®­ç»ƒå‚æ•°æœ‰æ•°ç™¾ä¸‡ä¸ªçš„å¤§å‹æ¨¡å‹æ—¶ï¼Œå¦‚æœæ²¡æœ‰é€‚å½“çš„ç¡¬ä»¶ï¼Œå¯èƒ½ä¼šé¢ä¸´å†…å­˜ä¸è¶³çš„æŒ‘æˆ˜ã€‚å½“ GPU å†…å­˜ä¸è¶³æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°ä»¥ä¸‹å¸¸è§é”™è¯¯ï¼š
```
CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)
```

ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å°è¯•å‡å°‘å†…å­˜ä½¿ç”¨çš„ä¸€äº›è§£å†³æ–¹æ¡ˆï¼š
- åœ¨ [`TrainingArguments`] ä¸­å‡å°‘ [`per_device_train_batch_size`](main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size) çš„å€¼ã€‚- å°è¯•ä½¿ç”¨ [`TrainingArguments`] ä¸­çš„ [`gradient_accumulation_steps`](main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps)ï¼Œä»¥æœ‰æ•ˆå¢åŠ æ€»æ‰¹é‡å¤§å°ã€‚
<Tip>
æœ‰å…³èŠ‚çœå†…å­˜çš„æŠ€å·§çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ€§èƒ½ [æŒ‡å—](performance)ã€‚
</Tip>
## æ— æ³•åŠ è½½ä¿å­˜çš„ TensorFlow æ¨¡å‹
TensorFlow çš„ [model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) æ–¹æ³•ä¼šå°†æ•´ä¸ªæ¨¡å‹ï¼ˆæ¶æ„ã€æƒé‡ã€è®­ç»ƒé…ç½®ï¼‰ä¿å­˜åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ã€‚

ä½†æ˜¯ï¼Œå½“æ‚¨å†æ¬¡åŠ è½½æ¨¡å‹æ–‡ä»¶æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°é”™è¯¯ï¼Œå› ä¸ºğŸ¤— Transformers å¯èƒ½æ— æ³•åŠ è½½æ¨¡å‹æ–‡ä»¶ä¸­çš„æ‰€æœ‰ä¸ TensorFlow ç›¸å…³çš„å¯¹è±¡ã€‚ä¸ºäº†é¿å…ä¿å­˜å’ŒåŠ è½½ TensorFlow æ¨¡å‹æ—¶å‡ºç°é—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ï¼š
- ä½¿ç”¨ [`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) å°†æ¨¡å‹æƒé‡ä¿å­˜ä¸º `h5` æ–‡ä»¶æ‰©å±•åï¼Œç„¶åä½¿ç”¨ [`~TFPreTrainedModel.from_pretrained`] é‡æ–°åŠ è½½æ¨¡å‹ï¼š
```py
>>> from transformers import TFPreTrainedModel
>>> from tensorflow import keras

>>> model.save_weights("some_folder/tf_model.h5")
>>> model = TFPreTrainedModel.from_pretrained("some_folder")
```

- ä½¿ç”¨ [`~TFPretrainedModel.save_pretrained`] ä¿å­˜æ¨¡å‹ï¼Œç„¶åä½¿ç”¨ [`~TFPreTrainedModel.from_pretrained`] å†æ¬¡åŠ è½½å®ƒï¼š
```py
>>> from transformers import TFPreTrainedModel

>>> model.save_pretrained("path_to/model")
>>> model = TFPreTrainedModel.from_pretrained("path_to/model")
```

## ImportError
å¦ä¸€ä¸ªå¸¸è§é”™è¯¯æ˜¯ `ImportError`ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ–°å‘å¸ƒçš„æ¨¡å‹ï¼š
```
ImportError: cannot import name 'ImageGPTImageProcessor' from 'transformers' (unknown location)
```

å¯¹äºè¿™äº›é”™è¯¯ç±»å‹ï¼Œè¯·ç¡®ä¿æ‚¨å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬çš„ğŸ¤— Transformersï¼Œä»¥è®¿é—®æœ€æ–°çš„æ¨¡å‹ï¼š
```bash
pip install transformers --upgrade
```

## CUDA é”™è¯¯ï¼šè®¾å¤‡ç«¯è§¦å‘äº†æ–­è¨€
æœ‰æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°æœ‰å…³è®¾å¤‡ä»£ç é”™è¯¯çš„é€šç”¨ CUDA é”™è¯¯ã€‚
```
RuntimeError: CUDA error: device-side assert triggered
```

æ‚¨åº”è¯¥é¦–å…ˆåœ¨ CPU ä¸Šè¿è¡Œä»£ç ï¼Œä»¥è·å–æ›´è¯¦ç»†çš„é”™è¯¯æ¶ˆæ¯ã€‚åœ¨ä»£ç å¼€å¤´æ·»åŠ ä»¥ä¸‹ç¯å¢ƒå˜é‡ä»¥åˆ‡æ¢åˆ° CPUï¼š
```py
>>> import os

>>> os.environ["CUDA_VISIBLE_DEVICES"] = ""
```

å¦ä¸€ç§é€‰æ‹©æ˜¯ä» GPU è·å–æ›´å¥½çš„å›æº¯ä¿¡æ¯ã€‚åœ¨ä»£ç å¼€å¤´æ·»åŠ ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼Œä»¥ä½¿å›æº¯æŒ‡å‘é”™è¯¯çš„æºä»£ç ï¼š
```py
>>> import os

>>> os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
```

## å½“å¡«å……æ ‡è®°æœªè¢«æ©ç æ—¶è¾“å‡ºä¸æ­£ç¡®
åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æœ `input_ids` åŒ…å«å¡«å……æ ‡è®°ï¼Œåˆ™è¾“å‡ºçš„ `hidden_state` å¯èƒ½æ˜¯ä¸æ­£ç¡®çš„ã€‚ä¸ºäº†æ¼”ç¤ºï¼ŒåŠ è½½ä¸€ä¸ªæ¨¡å‹å’Œåˆ†è¯å™¨ (Tokenizer)ã€‚æ‚¨å¯ä»¥è®¿é—®æ¨¡å‹çš„ `pad_token_id` ä»¥æŸ¥çœ‹å…¶å€¼ã€‚

å¯¹äºæŸäº›æ¨¡å‹ï¼Œ`pad_token_id` å¯èƒ½ä¸º `None`ï¼Œä½†æ‚¨å§‹ç»ˆå¯ä»¥æ‰‹åŠ¨è®¾ç½®å®ƒã€‚
```py
>>> from transformers import AutoModelForSequenceClassification
>>> import torch

>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
>>> model.config.pad_token_id
0
```

ä»¥ä¸‹ç¤ºä¾‹æ˜¾ç¤ºäº†æœªå¯¹å¡«å……æ ‡è®°è¿›è¡Œæ©ç çš„è¾“å‡ºï¼š
```py
>>> input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [ 0.1317, -0.1683]], grad_fn=<AddmmBackward0>)
```

è¿™æ˜¯ç¬¬äºŒä¸ªåºåˆ—çš„å®é™…è¾“å‡ºï¼š
```py
>>> input_ids = torch.tensor([[7592]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥ä¸ºæ¨¡å‹æä¾›ä¸€ä¸ª `attention_mask`ï¼Œä»¥å¿½ç•¥å¡«å……æ ‡è®°ï¼Œä»¥é¿å…æ­¤é™é»˜é”™è¯¯ã€‚ç°åœ¨ï¼Œç¬¬äºŒä¸ªåºåˆ—çš„è¾“å‡ºä¸å®é™…è¾“å‡ºç›¸åŒ¹é…ï¼š
<Tip>
é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ†è¯å™¨ (Tokenizer)æ ¹æ®ç‰¹å®šåˆ†è¯å™¨ (Tokenizer)çš„é»˜è®¤å€¼ä¸ºæ‚¨åˆ›å»º `attention_mask`ã€‚
</Tip>
```py
>>> attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])
>>> output = model(input_ids, attention_mask=attention_mask)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

ğŸ¤— Transformers ä¸ä¼šè‡ªåŠ¨åˆ›å»ºç”¨äºå±è”½å¡«å……æ ‡è®°çš„ `attention_mask`ï¼Œå› ä¸ºï¼š
- æŸäº›æ¨¡å‹æ²¡æœ‰å¡«å……æ ‡è®°ã€‚
- å¯¹äºæŸäº›ç”¨ä¾‹ï¼Œç”¨æˆ·å¸Œæœ›æ¨¡å‹å…³æ³¨å¡«å……æ ‡è®°ã€‚

## ValueErrorï¼šæ— æ³•è¯†åˆ«æ­¤ç±» AutoModel çš„é…ç½®ç±» XYZ

ä¸€èˆ¬è€Œè¨€ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ [`AutoModel`] ç±»åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„å®ä¾‹ã€‚è¯¥ç±»å¯ä»¥æ ¹æ®ç»™å®šçš„æ£€æŸ¥ç‚¹çš„é…ç½®è‡ªåŠ¨æ¨æ–­å’ŒåŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚å¦‚æœåœ¨ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹æ—¶çœ‹åˆ°æ­¤ `ValueError`ï¼Œè¿™æ„å‘³ç€ Auto ç±»æ‰¾ä¸åˆ°ä»ç»™å®šæ£€æŸ¥ç‚¹çš„é…ç½®åˆ°æ‚¨å°è¯•åŠ è½½çš„æ¨¡å‹ç±»å‹ä¹‹é—´çš„æ˜ å°„ã€‚

æœ€å¸¸è§çš„æƒ…å†µæ˜¯ç»™å®šä»»åŠ¡ä¸æ”¯æŒç»™å®šçš„æ£€æŸ¥ç‚¹ã€‚

ä¾‹å¦‚ï¼Œæ‚¨å°†åœ¨ä»¥ä¸‹ç¤ºä¾‹ä¸­çœ‹åˆ°æ­¤é”™è¯¯ï¼Œå› ä¸ºæ²¡æœ‰é€‚ç”¨äºé—®ç­”çš„ GPT2 æ¨¡å‹ï¼š

```py
>>> from transformers import AutoProcessor, AutoModelForQuestionAnswering

>>> processor = AutoProcessor.from_pretrained("gpt2-medium")
>>> model = AutoModelForQuestionAnswering.from_pretrained("gpt2-medium")
ValueError: Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForQuestionAnswering.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BloomConfig, ...
```
