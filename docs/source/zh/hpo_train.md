<!--ç‰ˆæƒæ‰€æœ‰ 2022 å¹´çš„ HuggingFace å›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚
æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰è·å¾—è®¸å¯ï¼›é™¤éç¬¦åˆè®¸å¯è¯çš„è§„å®šï¼Œå¦åˆ™æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è·å–è®¸å¯è¯çš„å‰¯æœ¬
http://www.apache.org/licenses/LICENSE-2.0
é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶ä»¥â€œæŒ‰åŸæ ·â€åˆ†å‘ï¼Œä¸é™„å¸¦ä»»ä½•å½¢å¼çš„ä¿è¯æˆ–æ¡ä»¶ã€‚æœ‰å…³è®¸å¯è¯çš„è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…è®¸å¯è¯ã€‚
âš ï¸ è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶ä½¿ç”¨ Markdown ç¼–å†™ï¼Œä½†åŒ…å«æˆ‘ä»¬æ–‡æ¡£ç”Ÿæˆå™¨ï¼ˆç±»ä¼¼äº MDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½æ— æ³•åœ¨ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ¸²æŸ“ã€‚rendered properly in your Markdown viewer.
-->

# ä½¿ç”¨ Trainer API è¿›è¡Œè¶…å‚æ•°æœç´¢

ğŸ¤— Transformers æä¾›äº†ä¸€ä¸ªç»è¿‡ä¼˜åŒ–çš„ [`Trainer`] ç±»ï¼Œç”¨äºè®­ç»ƒğŸ¤— Transformers æ¨¡å‹ï¼Œä½¿å¾—å¼€å§‹è®­ç»ƒè€Œæ— éœ€æ‰‹åŠ¨ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªç¯æ›´åŠ å®¹æ˜“ã€‚[`Trainer`] æä¾›äº†è¶…å‚æ•°æœç´¢çš„ APIã€‚æœ¬æ–‡æ¡£å±•ç¤ºäº†å¦‚ä½•åœ¨ç¤ºä¾‹ä¸­å¯ç”¨è¶…å‚æ•°æœç´¢ã€‚

## è¶…å‚æ•°æœç´¢åç«¯

[`Trainer`] å½“å‰æ”¯æŒå››ä¸ªè¶…å‚æ•°æœç´¢åç«¯ï¼š
[optuna](https://optuna.org/)ï¼Œ[sigopt](https://sigopt.com/)ï¼Œ[raytune](https://docs.ray.io/en/latest/tune/index.html) å’Œ [wandb](https://wandb.ai/site/sweeps)ã€‚

åœ¨ä½¿ç”¨è¶…å‚æ•°æœç´¢åç«¯ä¹‹å‰ï¼Œæ‚¨åº”è¯¥å…ˆå®‰è£…å®ƒä»¬ã€‚
```bash
pip install optuna/sigopt/wandb/ray[tune] 
```

## å¦‚ä½•åœ¨ç¤ºä¾‹ä¸­å¯ç”¨è¶…å‚æ•°æœç´¢

å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´ï¼Œä¸åŒçš„åç«¯éœ€è¦ä¸åŒçš„æ ¼å¼ã€‚
å¯¹äº sigoptï¼Œè¯·å‚é˜… sigopt [object_parameter](https://docs.sigopt.com/ai-module-api-references/api_reference/objects/object_parameter)ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```py
>>> def sigopt_hp_space(trial):
...     return [
...         {"bounds": {"min": 1e-6, "max": 1e-4}, "name": "learning_rate", "type": "double"},
...         {
...             "categorical_values": ["16", "32", "64", "128"],
...             "name": "per_device_train_batch_size",
...             "type": "categorical",
...         },
...     ]
```

å¯¹äº optunaï¼Œè¯·å‚é˜… optuna [object_parameter](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/002_configurations.html#sphx-glr-tutorial-10-key-features-002-configurations-py)ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```py
>>> def optuna_hp_space(trial):
...     return {
...         "learning_rate": trial.suggest_float("learning_rate", 1e-6, 1e-4, log=True),
...         "per_device_train_batch_size": trial.suggest_categorical("per_device_train_batch_size", [16, 32, 64, 128]),
...     }
```

å¯¹äº raytuneï¼Œè¯·å‚é˜… raytune [object_parameter](https://docs.ray.io/en/latest/tune/api/search_space.html)ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```py
>>> def ray_hp_space(trial):
...     return {
...         "learning_rate": tune.loguniform(1e-6, 1e-4),
...         "per_device_train_batch_size": tune.choice([16, 32, 64, 128]),
...     }
```

å¯¹äº wandbï¼Œè¯·å‚é˜… wandb [object_parameter](https://docs.wandb.ai/guides/sweeps/configuration)ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```py
>>> def wandb_hp_space(trial):
...     return {
...         "method": "random",
...         "metric": {"name": "objective", "goal": "minimize"},
...         "parameters": {
...             "learning_rate": {"distribution": "uniform", "min": 1e-6, "max": 1e-4},
...             "per_device_train_batch_size": {"values": [16, 32, 64, 128]},
...         },
...     }
```

å®šä¹‰ä¸€ä¸ª `model_init` å‡½æ•°ï¼Œå¹¶å°†å…¶ä½œä¸ºç¤ºä¾‹ä¼ é€’ç»™ [`Trainer`]ï¼š```py
>>> def model_init(trial):
...     return AutoModelForSequenceClassification.from_pretrained(
...         model_args.model_name_or_path,
...         from_tf=bool(".ckpt" in model_args.model_name_or_path),
...         config=config,
...         cache_dir=model_args.cache_dir,
...         revision=model_args.model_revision,
...         use_auth_token=True if model_args.use_auth_token else None,
...     )
```

ä½¿ç”¨æ‚¨çš„ `model_init` å‡½æ•°ã€è®­ç»ƒå‚æ•°ã€è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä»¥åŠè¯„ä¼°å‡½æ•°åˆ›å»ºä¸€ä¸ª [`Trainer`]ï¼š
```py
>>> trainer = Trainer(
...     model=None,
...     args=training_args,
...     train_dataset=small_train_dataset,
...     eval_dataset=small_eval_dataset,
...     compute_metrics=compute_metrics,
...     tokenizer=tokenizer,
...     model_init=model_init,
...     data_collator=data_collator,
... )
```

è°ƒç”¨è¶…å‚æ•°æœç´¢ï¼Œè·å–æœ€ä½³çš„è¯•éªŒå‚æ•°ï¼Œåç«¯å¯ä»¥æ˜¯ `"optuna"`/`"sigopt"`/`"wandb"`/`"ray"`ã€‚direction å¯ä»¥æ˜¯ `"minimize"` æˆ– `"maximize"`ï¼Œè¡¨ç¤ºä¼˜åŒ–æ›´å¤§æˆ–æ›´å°çš„ç›®æ ‡ã€‚
å¦‚æœæœªå®šä¹‰ï¼Œæ‚¨å¯ä»¥å®šä¹‰è‡ªå·±çš„ compute_objective å‡½æ•°ï¼Œå°†è°ƒç”¨é»˜è®¤çš„ compute_objective å‡½æ•°ï¼Œå¹¶å°†è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚ f1ï¼‰çš„æ€»å’Œä½œä¸ºç›®æ ‡å€¼è¿”å›ã€‚
```py
>>> best_trial = trainer.hyperparameter_search(
...     direction="maximize",
...     backend="optuna",
...     hp_space=optuna_hp_space,
...     n_trials=20,
...     compute_objective=compute_objective,
... )
```

## DDP å¾®è°ƒçš„è¶…å‚æ•°æœç´¢

ç›®å‰ï¼ŒDDP çš„è¶…å‚æ•°æœç´¢ä»…æ”¯æŒ optuna å’Œ sigoptã€‚ä»… rank-zero è¿›ç¨‹å°†ç”Ÿæˆæœç´¢è¯•éªŒå¹¶å°†å‚æ•°ä¼ é€’ç»™å…¶ä»– rankã€‚