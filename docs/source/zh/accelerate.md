<!--ç‰ˆæƒ2022å¹´HuggingFaceå›¢é˜Ÿä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚
æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯ LICENSE â€ï¼‰è·å¾—è®¸å¯ï¼›é™¤éç¬¦åˆè®¸å¯è¯çš„è¦æ±‚ï¼Œå¦åˆ™ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯çš„å‰¯æœ¬ï¼š
http://www.apache.org/licenses/LICENSE-2.0
é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶ä»¥â€œåŸæ · AS ISâ€åˆ†å‘ï¼Œä¸é™„å¸¦ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚æœ‰å…³è®¸å¯è¯ä¸‹çš„ç‰¹å®šè¯­è¨€çš„æƒé™å’Œé™åˆ¶ï¼Œè¯·å‚é˜…è®¸å¯è¯ã€‚
âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶è™½ç„¶æ˜¯ Markdown æ ¼å¼ï¼Œä½†åŒ…å«æˆ‘ä»¬çš„æ–‡æ¡£æ„å»ºå™¨ï¼ˆç±»ä¼¼äº MDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½æ— æ³•åœ¨æ‚¨çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ¸²æŸ“ã€‚
-->
# ä½¿ç”¨ğŸ¤— Accelerate è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
éšç€æ¨¡å‹è¶Šæ¥è¶Šå¤§ï¼Œå¹¶è¡Œæ€§å·²æˆä¸ºåœ¨æœ‰é™ç¡¬ä»¶ä¸Šè®­ç»ƒæ›´å¤§æ¨¡å‹çš„ç­–ç•¥ï¼Œé€šè¿‡æ•°ä¸ªæ•°é‡çº§åŠ é€Ÿè®­ç»ƒé€Ÿåº¦ã€‚åœ¨ Hugging Faceï¼Œæˆ‘ä»¬åˆ›å»ºäº† [ğŸ¤— Accelerate](https://huggingface.co/docs/accelerate) åº“ï¼Œä»¥å¸®åŠ©ç”¨æˆ·åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼ç¯å¢ƒä¸­è½»æ¾è®­ç»ƒğŸ¤— Transformers æ¨¡å‹ï¼Œæ— è®ºæ˜¯ä¸€å°æœºå™¨ä¸Šçš„å¤šä¸ª GPU è¿˜æ˜¯å¤šå°æœºå™¨ä¸Šçš„å¤šä¸ª GPUã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œäº†è§£å¦‚ä½•è‡ªå®šä¹‰åŸç”Ÿ PyTorch è®­ç»ƒå¾ªç¯ä»¥å¯ç”¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„è®­ç»ƒã€‚
## è®¾ç½® Setup

é¦–å…ˆå®‰è£…ğŸ¤— Accelerateï¼š
```bash
pip install accelerate
```

ç„¶åå¯¼å…¥å¹¶åˆ›å»º [`~accelerate.Accelerator`] å¯¹è±¡ã€‚[`~accelerate.Accelerator`] å°†è‡ªåŠ¨æ£€æµ‹æ‚¨çš„åˆ†å¸ƒå¼è®¾ç½®ç±»å‹ï¼Œå¹¶åˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„è®­ç»ƒç»„ä»¶ã€‚æ‚¨ä¸éœ€è¦æ˜¾å¼åœ°å°†æ¨¡å‹æ”¾ç½®åœ¨è®¾å¤‡ä¸Šã€‚
```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
```

## å‡†å¤‡åŠ é€Ÿ Prepare to accelerate
ä¸‹ä¸€æ­¥æ˜¯å°†æ‰€æœ‰ç›¸å…³çš„è®­ç»ƒå¯¹è±¡ä¼ é€’ç»™ [`~accelerate.Accelerator.prepare`] æ–¹æ³•ã€‚è¿™åŒ…æ‹¬æ‚¨çš„è®­ç»ƒå’Œè¯„ä¼° DataLoaderï¼Œæ¨¡å‹å’Œä¼˜åŒ–å™¨ï¼š
```py
>>> train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
...     train_dataloader, eval_dataloader, model, optimizer
... )
```

## å›é€€ï¼ˆBackwardï¼‰
æœ€åä¸€æ­¥æ˜¯å°†è®­ç»ƒå¾ªç¯ä¸­å…¸å‹çš„ `loss.backward()` æ›¿æ¢ä¸ºğŸ¤— Accelerate çš„ [`~accelerate.Accelerator.backward`] æ–¹æ³•ï¼š
```py
>>> for epoch in range(num_epochs):
...     for batch in train_dataloader:
...         outputs = model(**batch)
...         loss = outputs.loss
...         accelerator.backward(loss)

...         optimizer.step()
...         lr_scheduler.step()
...         optimizer.zero_grad()
...         progress_bar.update(1)
```

å¦‚ä¸‹é¢çš„ä»£ç æ‰€ç¤ºï¼Œæ‚¨åªéœ€è¦åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ å››è¡Œé¢å¤–çš„ä»£ç å³å¯å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒï¼
```diff
+ from accelerate import Accelerator
  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

+ accelerator = Accelerator()

  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
  optimizer = AdamW(model.parameters(), lr=3e-5)

- device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
- model.to(device)

+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
+     train_dataloader, eval_dataloader, model, optimizer
+ )

  num_epochs = 3
  num_training_steps = num_epochs * len(train_dataloader)
  lr_scheduler = get_scheduler(
      "linear",
      optimizer=optimizer,
      num_warmup_steps=0,
      num_training_steps=num_training_steps
  )

  progress_bar = tqdm(range(num_training_steps))

  model.train()
  for epoch in range(num_epochs):
      for batch in train_dataloader:
-         batch = {k: v.to(device) for k, v in batch.items()}
          outputs = model(**batch)
          loss = outputs.loss
-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
          lr_scheduler.step()
          optimizer.zero_grad()
          progress_bar.update(1)
```

## è®­ç»ƒ
åœ¨æ·»åŠ ç›¸å…³ä»£ç è¡Œåï¼Œå¯ä»¥åœ¨è„šæœ¬æˆ–ç¬”è®°æœ¬ï¼ˆå¦‚ Colaboratoryï¼‰ä¸­å¯åŠ¨è®­ç»ƒã€‚

### ä½¿ç”¨è„šæœ¬è¿›è¡Œè®­ç»ƒ

å¦‚æœè¦ä»è„šæœ¬ä¸­è¿è¡Œè®­ç»ƒï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åˆ›å»ºå¹¶ä¿å­˜é…ç½®æ–‡ä»¶ï¼š

```bash
accelerate config
```

ç„¶åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š
```bash
accelerate launch train.py
```

### ä½¿ç”¨ç¬”è®°æœ¬è¿›è¡Œè®­ç»ƒ
å¦‚æœæ‚¨è®¡åˆ’ä½¿ç”¨ Colaboratory çš„ TPUï¼ŒğŸ¤— Accelerate ä¹Ÿå¯ä»¥åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œã€‚å°†è´Ÿè´£è®­ç»ƒçš„æ‰€æœ‰ä»£ç å°è£…åœ¨ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™ [`~accelerate.notebook_launcher`]ï¼š
```py
>>> from accelerate import notebook_launcher

>>> notebook_launcher(training_function)
```

æœ‰å…³ğŸ¤— Accelerate åŠå…¶ä¸°å¯ŒåŠŸèƒ½çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [æ–‡æ¡£](https://huggingface.co/docs/accelerate)ã€‚