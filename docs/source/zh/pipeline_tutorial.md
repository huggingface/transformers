<!--ç‰ˆæƒæ‰€æœ‰ 2022 å¹´ HuggingFace å›¢é˜Ÿä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚
æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰è·å¾—è®¸å¯ã€‚é™¤éç¬¦åˆè®¸å¯è¯ï¼Œå¦åˆ™æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨
http://www.apache.org/licenses/LICENSE-2.0
é€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„çš„æƒ…å†µä¸‹ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯åŸºäºâ€œæŒ‰åŸæ ·â€ BASISï¼Œæ— è®ºæ˜¯æ˜ç¤ºè¿˜æ˜¯æš—ç¤ºï¼Œéƒ½æ²¡æœ‰ä»»ä½•ä¿è¯æˆ–æ¡ä»¶ã€‚è¯·å‚é˜…è®¸å¯è¯ä»¥äº†è§£ç‰¹å®šè¯­è¨€ä¸‹çš„æƒé™å’Œé™åˆ¶ã€‚
âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯ Markdown æ ¼å¼çš„ï¼Œä½†åŒ…å«äº†æˆ‘ä»¬çš„ doc-builderï¼ˆç±»ä¼¼äº MDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½æ— æ³•åœ¨æ‚¨çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®å‘ˆç°ã€‚
-->
# æ¨ç†æµç¨‹
[`pipeline`] ä½¿å¾—åœ¨ä»»ä½•è¯­è¨€ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸Šä½¿ç”¨ [Hub](https://huggingface.co/models) ä¸­çš„ä»»ä½•æ¨¡å‹éƒ½å˜å¾—ç®€å•ã€‚å³ä½¿æ‚¨æ²¡æœ‰ä½¿ç”¨ç‰¹å®šæ¨¡æ€çš„ç»éªŒæˆ–ä¸ç†Ÿæ‚‰æ¨¡å‹èƒŒåçš„ä»£ç ï¼Œæ‚¨ä»ç„¶å¯ä»¥ä½¿ç”¨ [`pipeline`] è¿›è¡Œæ¨ç†ï¼æœ¬æ•™ç¨‹å°†æ•™æ‚¨ï¼š
* ä½¿ç”¨ [`pipeline`] è¿›è¡Œæ¨ç†ã€‚* ä½¿ç”¨ç‰¹å®šçš„åˆ†è¯å™¨ (Tokenizer)æˆ–æ¨¡å‹ã€‚* ä½¿ç”¨ [`pipeline`] è¿›è¡ŒéŸ³é¢‘ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡ã€‚
<Tip>
æŸ¥çœ‹ [`pipeline`] æ–‡æ¡£ï¼Œäº†è§£å®Œæ•´çš„å—æ”¯æŒä»»åŠ¡å’Œå¯ç”¨å‚æ•°åˆ—è¡¨ã€‚
</Tip>
## ä½¿ç”¨æµç¨‹
å°½ç®¡æ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªç›¸å…³çš„ [`pipeline`]ï¼Œä½†ä½¿ç”¨é€šç”¨çš„ [`pipeline`] æŠ½è±¡æ›´ç®€å•ï¼Œå®ƒåŒ…å«äº†æ‰€æœ‰ç‰¹å®šä»»åŠ¡çš„æµç¨‹ã€‚[`pipeline`] ä¼šè‡ªåŠ¨åŠ è½½é»˜è®¤æ¨¡å‹å’Œä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œæ¨ç†çš„é¢„å¤„ç†ç±»ã€‚
1. é¦–å…ˆåˆ›å»ºä¸€ä¸ª [`pipeline`] å¹¶æŒ‡å®šä¸€ä¸ªæ¨ç†ä»»åŠ¡ï¼š
```py
>>> from transformers import pipeline

>>> generator = pipeline(task="automatic-speech-recognition")
```

2. å°†è¾“å…¥æ–‡æœ¬ä¼ é€’ç»™ [`pipeline`]ï¼š
```py
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}
```

ç»“æœä¸æ‚¨é¢„æœŸçš„ä¸ä¸€æ ·å—ï¼Ÿåœ¨ Hub ä¸ŠæŸ¥çœ‹ä¸€äº› [ä¸‹è½½é‡æœ€å¤šçš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads)ï¼Œçœ‹çœ‹æ˜¯å¦å¯ä»¥è·å¾—æ›´å¥½çš„è½¬å½•ã€‚è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹ [openai/whisper-large](https://huggingface.co/openai/whisper-large)ï¼š
```py
>>> generator = pipeline(model="openai/whisper-large")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

ç°åœ¨è¿™ä¸ªç»“æœçœ‹èµ·æ¥æ›´å‡†ç¡®äº†ï¼æˆ‘ä»¬çœŸçš„é¼“åŠ±æ‚¨åœ¨ Hub ä¸ŠæŸ¥çœ‹ä¸åŒè¯­è¨€çš„æ¨¡å‹ã€ä¸“ä¸šé¢†åŸŸçš„æ¨¡å‹ç­‰ç­‰ã€‚æ‚¨å¯ä»¥ç›´æ¥ä»æµè§ˆå™¨åœ¨ Hub ä¸ŠæŸ¥çœ‹å’Œæ¯”è¾ƒæ¨¡å‹ç»“æœï¼Œçœ‹çœ‹å®ƒæ˜¯å¦æ¯”å…¶ä»–æ¨¡å‹æ›´é€‚åˆæˆ–èƒ½å¤Ÿå¤„ç†ç‰¹æ®Šæƒ…å†µã€‚å¦‚æœæ‚¨æ‰¾ä¸åˆ°é€‚ç”¨äºæ‚¨çš„ç”¨ä¾‹çš„æ¨¡å‹ï¼Œæ‚¨å§‹ç»ˆå¯ä»¥ [å¼€å§‹è®­ç»ƒ](training) æ‚¨è‡ªå·±çš„æ¨¡å‹ï¼And if you don't find a model for your use case, you can always start [training](training) your own!

å¦‚æœæ‚¨æœ‰å¤šä¸ªè¾“å…¥ï¼Œå¯ä»¥å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™ [`pipeline`]ï¼š
```py
generator(
    [
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac",
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac",
    ]
)
```

å¦‚æœæ‚¨æƒ³éå†æ•´ä¸ªæ•°æ®é›†ï¼Œæˆ–è€…æƒ³åœ¨ Web æœåŠ¡å™¨ä¸Šè¿›è¡Œæ¨ç†ï¼Œè¯·æŸ¥çœ‹ä¸“é—¨çš„éƒ¨åˆ†
[åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨æµç¨‹](#using-pipelines-on-a-dataset)
[åœ¨ Web æœåŠ¡å™¨ä¸Šä½¿ç”¨æµç¨‹](./pipeline_webserver)
## å‚æ•°
[`pipeline`] æ”¯æŒè®¸å¤šå‚æ•°ï¼›ä¸€äº›å‚æ•°æ˜¯ç‰¹å®šäºä»»åŠ¡çš„ï¼Œä¸€äº›å‚æ•°é€‚ç”¨äºæ‰€æœ‰æµç¨‹ã€‚é€šå¸¸æ‚¨å¯ä»¥åœ¨ä»»ä½•åœ°æ–¹æŒ‡å®šå‚æ•°ï¼š
```py
generator = pipeline(model="openai/whisper-large", my_parameter=1)
out = generator(...)  # This will use `my_parameter=1`.
out = generator(..., my_parameter=2)  # This will override and use `my_parameter=2`.
out = generator(...)  # This will go back to using `my_parameter=1`.
```

è®©æˆ‘ä»¬çœ‹çœ‹å…¶ä¸­çš„ 3 ä¸ªé‡è¦å‚æ•°ï¼š
### è®¾å¤‡
å¦‚æœä½¿ç”¨ `device=n`ï¼Œ[`pipeline`] ä¼šè‡ªåŠ¨å°†æ¨¡å‹æ”¾åœ¨æŒ‡å®šçš„è®¾å¤‡ä¸Šã€‚æ— è®ºæ‚¨æ˜¯ä½¿ç”¨ PyTorch è¿˜æ˜¯ Tensorflowï¼Œéƒ½å¯ä»¥è¿™æ ·åšã€‚
```py
generator = pipeline(model="openai/whisper-large", device=0)
```

å¦‚æœæ¨¡å‹å¯¹äºå•ä¸ª GPU æ¥è¯´å¤ªå¤§ï¼Œæ‚¨å¯ä»¥è®¾ç½® `device_map="auto"`ï¼Œä»¥å…è®¸ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate) è‡ªåŠ¨ç¡®å®šå¦‚ä½•åŠ è½½å’Œå­˜å‚¨æ¨¡å‹æƒé‡ã€‚
```py
#!pip install accelerate
generator = pipeline(model="openai/whisper-large", device_map="auto")
```

è¯·æ³¨æ„ï¼Œå¦‚æœä¼ é€’äº† `device_map="auto"`ï¼Œåœ¨å®ä¾‹åŒ–æ‚¨çš„ `pipeline` æ—¶æ— éœ€æ·»åŠ  `device=device` å‚æ•°ï¼Œå› ä¸ºå¯èƒ½ä¼šé‡åˆ°ä¸€äº›æ„å¤–è¡Œä¸ºï¼
### æ‰¹å¤„ç†å¤§å°
é»˜è®¤æƒ…å†µä¸‹ï¼Œæµç¨‹ä¸ä¼šå¯¹æ¨ç†è¿›è¡Œæ‰¹å¤„ç†ï¼ŒåŸå› å¯ä»¥åœ¨æ­¤å¤„è¯¦ç»†è§£é‡Š [here](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)ã€‚åŸå› æ˜¯æ‰¹å¤„ç†ä¸ä¸€å®šæ›´å¿«ï¼Œå®é™…ä¸Šåœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æ›´æ…¢ã€‚
ä½†æ˜¯å¦‚æœæ‚¨çš„ç”¨ä¾‹å¯ä»¥ä½¿ç”¨æ‰¹å¤„ç†ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š
```py
generator = pipeline(model="openai/whisper-large", device=0, batch_size=2)
audio_filenames = [f"audio_{i}.flac" for i in range(10)]
texts = generator(audio_filenames)
```

è¿™å°†åœ¨æä¾›çš„ 10 ä¸ªéŸ³é¢‘æ–‡ä»¶ä¸Šè¿è¡Œæµç¨‹ï¼Œä½†ä¼šå°†å®ƒä»¬åˆ†æ‰¹å¤„ç†ä¸º 2 ä¸ªä¼ é€’ç»™æ¨¡å‹ï¼ˆæ¨¡å‹åœ¨ GPU ä¸Šï¼Œæ‰¹å¤„ç†æ›´æœ‰å¯èƒ½æœ‰æ‰€å¸®åŠ©ï¼‰ï¼Œè€Œæ— éœ€æ‚¨ç¼–å†™æ›´å¤šçš„ä»£ç ã€‚è¾“å‡ºåº”å§‹ç»ˆä¸æ‚¨åœ¨ä¸è¿›è¡Œæ‰¹å¤„ç†æ—¶æ”¶åˆ°çš„ç»“æœç›¸åŒ¹é…ã€‚å®ƒåªæ˜¯ä¸€ç§å¸®åŠ©æ‚¨ä»æµç¨‹ä¸­è·å¾—æ›´é«˜é€Ÿåº¦çš„æ–¹æ³•ã€‚
æµç¨‹è¿˜å¯ä»¥å‡è½»ä¸€äº›æ‰¹å¤„ç†çš„å¤æ‚æ€§ï¼Œå› ä¸ºå¯¹äºæŸäº›æµç¨‹ï¼Œéœ€è¦å°†å•ä¸ªé¡¹ç›®ï¼ˆå¦‚é•¿éŸ³é¢‘æ–‡ä»¶ï¼‰åˆ†æˆå¤šä¸ªéƒ¨åˆ†ä»¥ä¾¿ç”±æ¨¡å‹å¤„ç†ã€‚æµç¨‹ä¼šä¸ºæ‚¨æ‰§è¡Œæ­¤ [*chunk batching*](./main_classes/pipelines#pipeline-chunk-batching)ã€‚
### ä»»åŠ¡ç‰¹å®šå‚æ•°
æ‰€æœ‰ä»»åŠ¡éƒ½æä¾›ä»»åŠ¡ç‰¹å®šå‚æ•°ï¼Œè¿™äº›å‚æ•°å…è®¸é¢å¤–çš„çµæ´»æ€§å’Œé€‰é¡¹ï¼Œä»¥å¸®åŠ©æ‚¨å®Œæˆå·¥ä½œã€‚ä¾‹å¦‚ï¼Œ[`transformers.AutomaticSpeechRecognitionPipeline.__call__`] æ–¹æ³•å…·æœ‰ä¸€ä¸ª `return_timestamps` å‚æ•°ï¼Œå¯¹äºåˆ¶ä½œå­—å¹•è§†é¢‘å¯èƒ½å¾ˆæœ‰ç”¨ï¼š

```py
>>> # Not using whisper, as it cannot provide timestamps.
>>> generator = pipeline(model="facebook/wav2vec2-large-960h-lv60-self", return_timestamps="word")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP AND LIVE OUT THE TRUE MEANING OF ITS CREED', 'chunks': [{'text': 'I', 'timestamp': (1.22, 1.24)}, {'text': 'HAVE', 'timestamp': (1.42, 1.58)}, {'text': 'A', 'timestamp': (1.66, 1.68)}, {'text': 'DREAM', 'timestamp': (1.76, 2.14)}, {'text': 'BUT', 'timestamp': (3.68, 3.8)}, {'text': 'ONE', 'timestamp': (3.94, 4.06)}, {'text': 'DAY', 'timestamp': (4.16, 4.3)}, {'text': 'THIS', 'timestamp': (6.36, 6.54)}, {'text': 'NATION', 'timestamp': (6.68, 7.1)}, {'text': 'WILL', 'timestamp': (7.32, 7.56)}, {'text': 'RISE', 'timestamp': (7.8, 8.26)}, {'text': 'UP', 'timestamp': (8.38, 8.48)}, {'text': 'AND', 'timestamp': (10.08, 10.18)}, {'text': 'LIVE', 'timestamp': (10.26, 10.48)}, {'text': 'OUT', 'timestamp': (10.58, 10.7)}, {'text': 'THE', 'timestamp': (10.82, 10.9)}, {'text': 'TRUE', 'timestamp': (10.98, 11.18)}, {'text': 'MEANING', 'timestamp': (11.26, 11.58)}, {'text': 'OF', 'timestamp': (11.66, 11.7)}, {'text': 'ITS', 'timestamp': (11.76, 11.88)}, {'text': 'CREED', 'timestamp': (12.0, 12.38)}]}
```

æ­£å¦‚æ‚¨æ‰€è§ï¼Œæ¨¡å‹æ¨æ–­å‡ºæ–‡æœ¬å¹¶è¾“å‡ºäº†å„ä¸ªå•è¯çš„ **å‘éŸ³æ—¶é—´**ã€‚
æ¯ä¸ªä»»åŠ¡éƒ½æœ‰è®¸å¤šå¯ç”¨å‚æ•°ï¼Œå› æ­¤è¯·æŸ¥çœ‹æ¯ä¸ªä»»åŠ¡çš„ API å‚è€ƒï¼Œäº†è§£æ‚¨å¯ä»¥è¿›è¡Œå“ªäº›è°ƒæ•´ï¼ä¾‹å¦‚ï¼Œ[`~transformers.AutomaticSpeechRecognitionPipeline`] æœ‰ä¸€ä¸ª `chunk_length_s` å‚æ•°ï¼Œå¯¹äºå¤„ç†éå¸¸é•¿çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œä¸ºæ•´éƒ¨ç”µå½±æˆ–ä¸€å°æ—¶é•¿çš„è§†é¢‘åˆ¶ä½œå­—å¹•ï¼‰éå¸¸æœ‰å¸®åŠ©ã€‚è¿™äº›æ˜¯æ¨¡å‹é€šå¸¸æ— æ³•å•ç‹¬å¤„ç†çš„æ–‡ä»¶ã€‚

å¦‚æœæ‰¾ä¸åˆ°çœŸæ­£æœ‰å¸®åŠ©çš„å‚æ•°ï¼Œè¯·éšæ—¶ [æå‡ºè¯·æ±‚](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)ï¼

## åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨æµç¨‹
æµç¨‹è¿˜å¯ä»¥å¯¹å¤§å‹æ•°æ®é›†è¿›è¡Œæ¨ç†ã€‚æˆ‘ä»¬æ¨èçš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨è¿­ä»£å™¨ï¼š
```py
def data():
    for i in range(1000):
        yield f"My example {i}"


pipe = pipeline(model="gpt2", device=0)
generated_characters = 0
for out in pipe(data()):
    generated_characters += len(out[0]["generated_text"])
```

è¿­ä»£å™¨ `data()` äº§ç”Ÿæ¯ä¸ªç»“æœï¼Œè€Œæµç¨‹ä¼šè‡ªåŠ¨è¯†åˆ«åˆ°è¾“å…¥æ˜¯å¯è¿­ä»£çš„ï¼Œå¹¶åœ¨ç»§ç»­å¤„ç†çš„åŒæ—¶åœ¨ GPU ä¸Šå¤„ç†æ•°æ®ï¼ˆè¿™åœ¨åº•å±‚ä½¿ç”¨ [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ï¼‰ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºæ‚¨ä¸éœ€è¦ä¸ºæ•´ä¸ªæ•°æ®é›†åˆ†é…å†…å­˜å¹¶ä¸”å¯ä»¥å°½å¯èƒ½å¿«åœ°å°†æ•°æ®ä¼ é€’ç»™ GPUã€‚
ç”±äºæ‰¹å¤„ç†å¯èƒ½åŠ å¿«é€Ÿåº¦ï¼Œå› æ­¤åœ¨è¿™é‡Œå°è¯•è°ƒæ•´ `batch_size` å‚æ•°å¯èƒ½å¾ˆæœ‰ç”¨ã€‚
éå†æ•°æ®é›†çš„æœ€ç®€å•æ–¹æ³•æ˜¯åªéœ€ä»ğŸ¤— [Datasets](https://github.com/huggingface/datasets/) åŠ è½½ä¸€ä¸ªæ•°æ®é›†ï¼š
```py
# KeyDataset is a util that will just output the item we're interested in.
from transformers.pipelines.pt_utils import KeyDataset
from datasets import load_dataset

pipe = pipeline(model="hf-internal-testing/tiny-random-wav2vec2", device=0)
dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation[:10]")

for out in pipe(KeyDataset(dataset, "audio")):
    print(out)
```


## åœ¨ Web æœåŠ¡å™¨ä¸Šä½¿ç”¨æµç¨‹
<Tip> åˆ›å»ºæ¨ç†å¼•æ“æ˜¯ä¸€ä¸ªå¤æ‚çš„ä¸»é¢˜ï¼Œå€¼å¾—æ‹¥æœ‰è‡ªå·±çš„é¡µé¢ã€‚</Tip>
[é“¾æ¥](./pipeline_webserver)
## è§†è§‰æµç¨‹
å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œä½¿ç”¨ [`pipeline`] å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚
æŒ‡å®šæ‚¨çš„ä»»åŠ¡å¹¶å°†å›¾åƒä¼ é€’ç»™åˆ†ç±»å™¨ã€‚å›¾åƒå¯ä»¥æ˜¯é“¾æ¥æˆ–å›¾åƒçš„æœ¬åœ°è·¯å¾„ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢æ˜¾ç¤ºäº†å“ªç§çŒ«çš„ç‰©ç§ï¼Ÿ
![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)
```py
>>> from transformers import pipeline

>>> vision_classifier = pipeline(model="google/vit-base-patch16-224")
>>> preds = vision_classifier(
...     images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]
```

## æ–‡æœ¬æµç¨‹
ä½¿ç”¨ NLP ä»»åŠ¡çš„ [`pipeline`] å®é™…ä¸Šæ˜¯å®Œå…¨ç›¸åŒçš„ã€‚
```py
>>> from transformers import pipeline

>>> # This model is a `zero-shot-classification` model.
>>> # It will classify text, except you are free to choose any label you might imagine
>>> classifier = pipeline(model="facebook/bart-large-mnli")
>>> classifier(
...     "I have a problem with my iphone that needs to be resolved asap!!",
...     candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
... )
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

## å¤šæ¨¡æ€ç®¡é“
[`pipeline`] æ”¯æŒå¤šä¸ªæ¨¡æ€ã€‚ä¾‹å¦‚ï¼Œè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒã€‚è¯·éšæ„ä½¿ç”¨æ‚¨å–œæ¬¢çš„ä»»ä½•å›¾åƒé“¾æ¥å’Œæƒ³è¦è¯¢é—®å›¾åƒçš„é—®é¢˜ã€‚å›¾åƒå¯ä»¥æ˜¯ URL æˆ–å›¾åƒçš„æœ¬åœ°è·¯å¾„ã€‚
ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨è¿™ä¸ª [å‘ç¥¨å›¾åƒ](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)ï¼š
```py
>>> from transformers import pipeline

>>> vqa = pipeline(model="impira/layoutlm-document-qa")
>>> vqa(
...     image="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png",
...     question="What is the invoice number?",
... )
[{'score': 0.42515, 'answer': 'us-001', 'start': 16, 'end': 16}]
```

<Tip>
è¦è¿è¡Œä¸Šé¢çš„ç¤ºä¾‹ï¼Œæ‚¨éœ€è¦é¢å¤–å®‰è£… [`pytesseract`](https://pypi.org/project/pytesseract/) å¹¶ä¸”å®‰è£… ğŸ¤— Transformers:
```bash
sudo apt install -y tesseract-ocr
pip install pytesseract
```

</Tip>
## ä½¿ç”¨ ğŸ¤— `accelerate` è¿è¡Œ `pipeline` çš„å¤§æ¨¡å‹:
æ‚¨å¯ä»¥ä½¿ç”¨ ğŸ¤— `accelerate` è½»æ¾è¿è¡Œå¤§å‹æ¨¡å‹ä¸Šçš„ `pipeline`ï¼é¦–å…ˆç¡®ä¿æ‚¨å·²ç»å®‰è£…äº† `accelerate`ï¼Œå¯ä»¥é€šè¿‡ `pip install accelerate` è¿›è¡Œå®‰è£…ã€‚
ä½¿ç”¨ `device_map="auto"` é¦–å…ˆåŠ è½½æ‚¨çš„æ¨¡å‹ï¼æˆ‘ä»¬å°†åœ¨ç¤ºä¾‹ä¸­ä½¿ç”¨ `facebook/opt-1.3b`ã€‚
```py
# pip install accelerate
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", torch_dtype=torch.bfloat16, device_map="auto")
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

å¦‚æœæ‚¨å®‰è£…äº† `bitsandbytes` å¹¶æ·»åŠ äº†å‚æ•° `load_in_8bit=True`ï¼Œæ‚¨è¿˜å¯ä»¥ä¼ é€’ 8 ä½åŠ è½½çš„æ¨¡å‹
```py
# pip install accelerate bitsandbytes
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", device_map="auto", model_kwargs={"load_in_8bit": True})
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥å°†æ£€æŸ¥ç‚¹æ›¿æ¢ä¸ºä»»ä½•æ”¯æŒå¤§å‹æ¨¡å‹åŠ è½½çš„ Hugging Face æ¨¡å‹ï¼Œä¾‹å¦‚ BLOOMï¼