<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# æ¨ç†pipeline

[`pipeline`] è®©ä½¿ç”¨[Hub](https://huggingface.co/models)ä¸Šçš„ä»»ä½•æ¨¡å‹è¿›è¡Œä»»ä½•è¯­è¨€ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³ä»¥åŠå¤šæ¨¡æ€ä»»åŠ¡çš„æ¨ç†å˜å¾—éå¸¸ç®€å•ã€‚å³ä½¿æ‚¨å¯¹ç‰¹å®šçš„æ¨¡æ€æ²¡æœ‰ç»éªŒï¼Œæˆ–è€…ä¸ç†Ÿæ‚‰æ¨¡å‹çš„æºç ï¼Œæ‚¨ä»ç„¶å¯ä»¥ä½¿ç”¨[`pipeline`]è¿›è¡Œæ¨ç†ï¼æœ¬æ•™ç¨‹å°†æ•™æ‚¨ï¼š

- å¦‚ä½•ä½¿ç”¨[`pipeline`] è¿›è¡Œæ¨ç†ã€‚
- å¦‚ä½•ä½¿ç”¨ç‰¹å®šçš„`tokenizer`(åˆ†è¯å™¨)æˆ–æ¨¡å‹ã€‚
- å¦‚ä½•ä½¿ç”¨[`pipeline`] è¿›è¡ŒéŸ³é¢‘ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡çš„æ¨ç†ã€‚

<Tip>

è¯·æŸ¥çœ‹[`pipeline`]æ–‡æ¡£ä»¥è·å–å·²æ”¯æŒçš„ä»»åŠ¡å’Œå¯ç”¨å‚æ•°çš„å®Œæ•´åˆ—è¡¨ã€‚

</Tip>

## Pipelineä½¿ç”¨

è™½ç„¶æ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªå…³è”çš„[`pipeline`]ï¼Œä½†ä½¿ç”¨é€šç”¨çš„æŠ½è±¡çš„[`pipeline`]æ›´åŠ ç®€å•ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰ç‰¹å®šä»»åŠ¡çš„`pipelines`ã€‚[`pipeline`]ä¼šè‡ªåŠ¨åŠ è½½ä¸€ä¸ªé»˜è®¤æ¨¡å‹å’Œä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œä»»åŠ¡æ¨ç†çš„é¢„å¤„ç†ç±»ã€‚è®©æˆ‘ä»¬ä»¥ä½¿ç”¨[`pipeline`]è¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æˆ–è¯­éŸ³è½¬æ–‡æœ¬ä¸ºä¾‹ã€‚

1. é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ª[`pipeline`]å¹¶æŒ‡å®šæ¨ç†ä»»åŠ¡ï¼š

```py
>>> from transformers import pipeline

>>> transcriber = pipeline(task="automatic-speech-recognition")
```

2. å°†æ‚¨çš„è¾“å…¥ä¼ é€’ç»™[`pipeline`]ã€‚å¯¹äºè¯­éŸ³è¯†åˆ«ï¼Œè¿™é€šå¸¸æ˜¯ä¸€ä¸ªéŸ³é¢‘è¾“å…¥æ–‡ä»¶ï¼š


```py
>>> transcriber("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}
```

æ‚¨æ²¡æœ‰å¾—åˆ°æ‚¨æœŸæœ›çš„ç»“æœï¼Ÿå¯ä»¥åœ¨Hubä¸ŠæŸ¥çœ‹ä¸€äº›[æœ€å—æ¬¢è¿çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=trending) 
ï¼Œçœ‹çœ‹æ˜¯å¦å¯ä»¥è·å¾—æ›´å¥½çš„è½¬å½•ã€‚

è®©æˆ‘ä»¬å°è¯•æ¥è‡ª OpenAI çš„[Whisper large-v2](https://huggingface.co/openai/whisper-large) æ¨¡å‹ã€‚Whisperbæ¯”Wav2Vec2æ™š2å¹´å‘å¸ƒï¼Œä½¿ç”¨æ¥è¿‘10å€çš„æ•°æ®è¿›è¡Œäº†è®­ç»ƒã€‚å› æ­¤ï¼Œå®ƒåœ¨å¤§å¤šæ•°ä¸‹æ¸¸åŸºå‡†æµ‹è¯•ä¸Šå‡»è´¥äº†Wav2Vec2ã€‚
å®ƒè¿˜å…·æœ‰é¢„æµ‹æ ‡ç‚¹å’Œå¤§å°å†™çš„é™„åŠ ä¼˜åŠ¿ï¼Œè€ŒWav2Vec2åˆ™æ— æ³•å®ç°è¿™äº›åŠŸèƒ½ã€‚

è®©æˆ‘ä»¬åœ¨è¿™é‡Œå°è¯•ä¸€ä¸‹ï¼Œçœ‹çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ï¼š


```py
>>> transcriber = pipeline(model="openai/whisper-large-v2")
>>> transcriber("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

ç°åœ¨è¿™ä¸ªç»“æœçœ‹èµ·æ¥æ›´å‡†ç¡®äº†ï¼è¦è¿›è¡Œæ·±å…¥çš„Wav2Vec2ä¸Whisperæ¯”è¾ƒï¼Œè¯·å‚é˜…[éŸ³é¢‘å˜æ¢å™¨è¯¾ç¨‹](https://huggingface.co/learn/audio-course/chapter5/asr_models)ã€‚
æˆ‘ä»¬é¼“åŠ±æ‚¨åœ¨ Hub ä¸ŠæŸ¥çœ‹ä¸åŒè¯­è¨€çš„æ¨¡å‹ï¼Œä»¥åŠä¸“ä¸šé¢†åŸŸçš„æ¨¡å‹ç­‰ã€‚æ‚¨å¯ä»¥åœ¨Hubä¸Šç›´æ¥æŸ¥çœ‹å¹¶æ¯”è¾ƒæ¨¡å‹çš„ç»“æœï¼Œä»¥ç¡®å®šæ˜¯å¦é€‚åˆæˆ–å¤„ç†è¾¹ç¼˜æƒ…å†µæ˜¯å¦æ¯”å…¶ä»–æ¨¡å‹æ›´å¥½ã€‚å¦‚æœæ‚¨æ²¡æœ‰æ‰¾åˆ°é€‚ç”¨äºæ‚¨çš„ç”¨ä¾‹çš„æ¨¡å‹ï¼Œæ‚¨å§‹ç»ˆå¯ä»¥[è®­ç»ƒ](training)è‡ªå·±çš„æ¨¡å‹ï¼

å¦‚æœæ‚¨æœ‰å¤šä¸ªè¾“å…¥ï¼Œæ‚¨å¯ä»¥å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ é€’ï¼š


```py
transcriber(
    [
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac",
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac",
    ]
)
```

`Pipelines`éå¸¸é€‚åˆç”¨äºæµ‹è¯•ï¼Œå› ä¸ºä»ä¸€ä¸ªæ¨¡å‹åˆ‡æ¢åˆ°å¦ä¸€ä¸ªæ¨¡å‹éå¸¸çç¢ï¼›ä½†æ˜¯ï¼Œè¿˜æœ‰ä¸€äº›æ–¹æ³•å¯ä»¥å°†å®ƒä»¬ä¼˜åŒ–åç”¨äºå¤§å‹å·¥ä½œè´Ÿè½½è€Œä¸ä»…ä»…æ˜¯æµ‹è¯•ã€‚è¯·æŸ¥çœ‹ä»¥ä¸‹æŒ‡å—ï¼Œæ·±å…¥æ¢è®¨å¦‚ä½•è¿­ä»£æ•´ä¸ªæ•°æ®é›†æˆ–åœ¨WebæœåŠ¡å™¨ä¸­ä½¿ç”¨`Pipelines`ï¼š
* [åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨æµæ°´çº¿](#using-pipelines-on-a-dataset)
* [åœ¨WebæœåŠ¡å™¨ä¸­ä½¿ç”¨æµæ°´çº¿](./pipeline_webserver)


## å‚æ•°

[`pipeline`] æ”¯æŒè®¸å¤šå‚æ•°ï¼›æœ‰äº›æ˜¯é€‚ç”¨äºç‰¹å®šä»»åŠ¡çš„ï¼Œè€Œæœ‰äº›é€‚ç”¨äºæ‰€æœ‰`pipeline`ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥åœ¨ä»»ä½•åœ°æ–¹æŒ‡å®šå¯¹åº”å‚æ•°ï¼š


```py
transcriber = pipeline(model="openai/whisper-large-v2", my_parameter=1)

out = transcriber(...)  # This will use `my_parameter=1`.
out = transcriber(..., my_parameter=2)  # This will override and use `my_parameter=2`.
out = transcriber(...)  # This will go back to using `my_parameter=1`.
```

è®©æˆ‘ä»¬æŸ¥çœ‹å…¶ä¸­çš„ä¸‰ä¸ªé‡è¦å‚æ•°ï¼š


### è®¾å¤‡

å¦‚æœæ‚¨ä½¿ç”¨ `device=n`ï¼Œ`pipeline`ä¼šè‡ªåŠ¨å°†æ¨¡å‹æ”¾åœ¨æŒ‡å®šçš„è®¾å¤‡ä¸Šã€‚æ— è®ºæ‚¨ä½¿ç”¨PyTorchè¿˜æ˜¯Tensorflowï¼Œè¿™éƒ½å¯ä»¥å·¥ä½œã€‚


```py
transcriber = pipeline(model="openai/whisper-large-v2", device=0)
```

å¦‚æœæ¨¡å‹å¯¹äºå•ä¸ªGPUæ¥è¯´è¿‡äºåºå¤§ï¼Œå¹¶ä¸”æ‚¨æ­£åœ¨ä½¿ç”¨PyTorchï¼Œæ‚¨å¯ä»¥è®¾ç½® `device_map="auto"` ä»¥è‡ªåŠ¨ç¡®å®šå¦‚ä½•åŠ è½½å’Œå­˜å‚¨æ¨¡å‹æƒé‡ã€‚ä½¿ç”¨ `device_map` å‚æ•°éœ€è¦å®‰è£…ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate) è½¯ä»¶åŒ…ï¼š


```bash
pip install --upgrade accelerate
```

ä»¥ä¸‹ä»£ç ä¼šè‡ªåŠ¨åœ¨å„ä¸ªè®¾å¤‡ä¸ŠåŠ è½½å’Œå­˜å‚¨æ¨¡å‹æƒé‡ï¼š


```py
transcriber = pipeline(model="openai/whisper-large-v2", device_map="auto")
```

è¯·æ³¨æ„ï¼Œå¦‚æœä¼ é€’äº† `device_map="auto"`ï¼Œåœ¨å®ä¾‹åŒ–æ‚¨çš„ `pipeline` æ—¶ä¸éœ€è¦æ·»åŠ  `device=device` å‚æ•°ï¼Œå¦åˆ™å¯èƒ½ä¼šé‡åˆ°ä¸€äº›æ„å¤–çš„çŠ¶å†µï¼

### æ‰¹é‡å¤§å°

é»˜è®¤æƒ…å†µä¸‹ï¼Œ`pipelines`ä¸ä¼šè¿›è¡Œæ‰¹é‡æ¨ç†ï¼ŒåŸå› åœ¨[è¿™é‡Œ](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)è¯¦ç»†è§£é‡Šã€‚å› ä¸ºæ‰¹å¤„ç†ä¸ä¸€å®šæ›´å¿«ï¼Œå®é™…ä¸Šåœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½ä¼šæ›´æ…¢ã€‚

ä½†å¦‚æœåœ¨æ‚¨çš„ç”¨ä¾‹ä¸­èµ·ä½œç”¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š


```py
transcriber = pipeline(model="openai/whisper-large-v2", device=0, batch_size=2)
audio_filenames = [f"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/{i}.flac" for i in range(1, 5)]
texts = transcriber(audio_filenames)
```

ä»¥ä¸Šä»£ç ä¼šåœ¨æä¾›çš„4ä¸ªéŸ³é¢‘æ–‡ä»¶ä¸Šè¿è¡Œ`pipeline`ï¼Œå®ƒä¼šå°†å®ƒä»¬ä»¥2ä¸ªä¸€ç»„çš„æ‰¹æ¬¡ä¼ é€’ç»™æ¨¡å‹ï¼ˆæ¨¡å‹åœ¨GPUä¸Šï¼Œæ­¤æ—¶æ‰¹å¤„ç†æ›´æœ‰å¯èƒ½æœ‰æ‰€å¸®åŠ©ï¼‰ï¼Œè€Œæ‚¨æ— éœ€ç¼–å†™é¢å¤–çš„ä»£ç ã€‚è¾“å‡ºåº”å§‹ç»ˆä¸æ²¡æœ‰æ‰¹å¤„ç†æ—¶æ”¶åˆ°çš„ç»“æœç›¸ä¸€è‡´ã€‚å®ƒåªæ˜¯ä¸€ç§å¸®åŠ©æ‚¨æ›´å¿«åœ°ä½¿ç”¨`pipeline`çš„æ–¹å¼ã€‚

`pipeline`ä¹Ÿå¯ä»¥å‡è½»ä¸€äº›æ‰¹å¤„ç†çš„å¤æ‚æ€§ï¼Œå› ä¸ºå¯¹äºæŸäº›`pipeline`ï¼Œéœ€è¦å°†å•ä¸ªé¡¹ç›®ï¼ˆå¦‚é•¿éŸ³é¢‘æ–‡ä»¶ï¼‰åˆ†æˆå¤šä¸ªéƒ¨åˆ†ä»¥ä¾›æ¨¡å‹å¤„ç†ã€‚`pipeline`ä¸ºæ‚¨æ‰§è¡Œè¿™ç§[*chunk batching*](./main_classes/pipelines#pipeline-chunk-batching)ã€‚

### ä»»åŠ¡ç‰¹å®šå‚æ•°

æ‰€æœ‰ä»»åŠ¡éƒ½æä¾›äº†ç‰¹å®šäºä»»åŠ¡çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°æä¾›é¢å¤–çš„çµæ´»æ€§å’Œé€‰æ‹©ï¼Œä»¥å¸®åŠ©æ‚¨å®Œæˆå·¥ä½œã€‚
ä¾‹å¦‚ï¼Œ[`transformers.AutomaticSpeechRecognitionPipeline.__call__`] æ–¹æ³•å…·æœ‰ä¸€ä¸ª `return_timestamps` å‚æ•°ï¼Œå¯¹äºå­—å¹•è§†é¢‘ä¼¼ä¹å¾ˆæœ‰å¸®åŠ©ï¼š

```py
>>> transcriber = pipeline(model="openai/whisper-large-v2", return_timestamps=True)
>>> transcriber("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.', 'chunks': [{'timestamp': (0.0, 11.88), 'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its'}, {'timestamp': (11.88, 12.38), 'text': ' creed.'}]}
```

æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œæ¨¡å‹æ¨æ–­å‡ºäº†æ–‡æœ¬ï¼Œè¿˜è¾“å‡ºäº†å„ä¸ªå¥å­å‘éŸ³çš„**æ—¶é—´**ã€‚

æ¯ä¸ªä»»åŠ¡éƒ½æœ‰è®¸å¤šå¯ç”¨çš„å‚æ•°ï¼Œå› æ­¤è¯·æŸ¥çœ‹æ¯ä¸ªä»»åŠ¡çš„APIå‚è€ƒï¼Œä»¥äº†è§£æ‚¨å¯ä»¥è¿›è¡Œå“ªäº›è°ƒæ•´ï¼ä¾‹å¦‚ï¼Œ[`~transformers.AutomaticSpeechRecognitionPipeline`] å…·æœ‰ `chunk_length_s` å‚æ•°ï¼Œå¯¹äºå¤„ç†éå¸¸é•¿çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œä¸ºæ•´éƒ¨ç”µå½±æˆ–é•¿è¾¾ä¸€å°æ—¶çš„è§†é¢‘é…å­—å¹•ï¼‰éå¸¸æœ‰å¸®åŠ©ï¼Œè¿™é€šå¸¸æ˜¯æ¨¡å‹æ— æ³•å•ç‹¬å¤„ç†çš„ï¼š

```python
>>> transcriber = pipeline(model="openai/whisper-large-v2", chunk_length_s=30, return_timestamps=True)
>>> transcriber("https://huggingface.co/datasets/sanchit-gandhi/librispeech_long/resolve/main/audio.wav")
{'text': " Chapter 16. I might have told you of the beginning of this liaison in a few lines, but I wanted you to see every step by which we came.  I, too, agree to whatever Marguerite wished, Marguerite to be unable to live apart from me. It was the day after the evening...
```

å¦‚æœæ‚¨æ‰¾ä¸åˆ°ä¸€ä¸ªçœŸæ­£æœ‰å¸®åŠ©çš„å‚æ•°ï¼Œæ¬¢è¿[æå‡ºè¯·æ±‚](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)ï¼

## åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨pipelines

`pipelines`ä¹Ÿå¯ä»¥å¯¹å¤§å‹æ•°æ®é›†è¿›è¡Œæ¨ç†ã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨è¿­ä»£å™¨æ¥å®Œæˆè¿™ä¸€ä»»åŠ¡ï¼Œè¿™æ˜¯æœ€ç®€å•çš„æ–¹æ³•ï¼š


```py
def data():
    for i in range(1000):
        yield f"My example {i}"


pipe = pipeline(model="gpt2", device=0)
generated_characters = 0
for out in pipe(data()):
    generated_characters += len(out[0]["generated_text"])
```

è¿­ä»£å™¨ `data()` ä¼šäº§ç”Ÿæ¯ä¸ªç»“æœï¼Œ`pipelines`ä¼šè‡ªåŠ¨è¯†åˆ«è¾“å…¥ä¸ºå¯è¿­ä»£å¯¹è±¡ï¼Œå¹¶åœ¨GPUä¸Šå¤„ç†æ•°æ®çš„åŒæ—¶å¼€å§‹è·å–æ•°æ®ï¼ˆåœ¨åº•å±‚ä½¿ç”¨[DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ï¼‰ã€‚è¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºæ‚¨ä¸å¿…ä¸ºæ•´ä¸ªæ•°æ®é›†åˆ†é…å†…å­˜ï¼Œå¯ä»¥å°½å¯èƒ½å¿«åœ°å°†æ•°æ®ä¼ é€åˆ°GPUã€‚

ç”±äºæ‰¹å¤„ç†å¯ä»¥åŠ é€Ÿå¤„ç†ï¼Œå› æ­¤åœ¨è¿™é‡Œå°è¯•è°ƒæ•´ `batch_size` å‚æ•°å¯èƒ½ä¼šå¾ˆæœ‰ç”¨ã€‚

è¿­ä»£æ•°æ®é›†çš„æœ€ç®€å•æ–¹æ³•å°±æ˜¯ä»ğŸ¤— [Datasets](https://github.com/huggingface/datasets/) ä¸­åŠ è½½æ•°æ®é›†ï¼š


```py
# KeyDataset is a util that will just output the item we're interested in.
from transformers.pipelines.pt_utils import KeyDataset
from datasets import load_dataset

pipe = pipeline(model="hf-internal-testing/tiny-random-wav2vec2", device=0)
dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation[:10]")

for out in pipe(KeyDataset(dataset, "audio")):
    print(out)
```


## åœ¨WebæœåŠ¡å™¨ä¸Šä½¿ç”¨pipelines

<Tip>
åˆ›å»ºæ¨ç†å¼•æ“æ˜¯ä¸€ä¸ªå¤æ‚çš„ä¸»é¢˜ï¼Œå€¼å¾—æœ‰è‡ªå·±çš„é¡µé¢ã€‚
</Tip>

[é“¾æ¥](./pipeline_webserver)

## è§†è§‰æµæ°´çº¿

å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œä½¿ç”¨[`pipeline`] å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚

æŒ‡å®šæ‚¨çš„ä»»åŠ¡å¹¶å°†å›¾åƒä¼ é€’ç»™åˆ†ç±»å™¨ã€‚å›¾åƒå¯ä»¥æ˜¯é“¾æ¥ã€æœ¬åœ°è·¯å¾„æˆ–base64ç¼–ç çš„å›¾åƒã€‚ä¾‹å¦‚ï¼Œä¸‹é¢æ˜¾ç¤ºçš„æ˜¯å“ªç§å“ç§çš„çŒ«ï¼Ÿ

![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)
```py
>>> from transformers import pipeline

>>> vision_classifier = pipeline(model="google/vit-base-patch16-224")
>>> preds = vision_classifier(
...     images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]
```

## æ–‡æœ¬æµæ°´çº¿

å¯¹äºNLPä»»åŠ¡ï¼Œä½¿ç”¨[`pipeline`] å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚


```py
>>> from transformers import pipeline

>>> # This model is a `zero-shot-classification` model.
>>> # It will classify text, except you are free to choose any label you might imagine
>>> classifier = pipeline(model="facebook/bart-large-mnli")
>>> classifier(
...     "I have a problem with my iphone that needs to be resolved asap!!",
...     candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
... )
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

## å¤šæ¨¡æ€æµæ°´çº¿

[`pipeline`] æ”¯æŒå¤šä¸ªæ¨¡æ€ã€‚ä¾‹å¦‚ï¼Œè§†è§‰é—®é¢˜å›ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒã€‚è¯·éšæ„ä½¿ç”¨æ‚¨å–œæ¬¢çš„ä»»ä½•å›¾åƒé“¾æ¥å’Œæ‚¨æƒ³è¦é—®å…³äºè¯¥å›¾åƒçš„é—®é¢˜ã€‚å›¾åƒå¯ä»¥æ˜¯URLæˆ–å›¾åƒçš„æœ¬åœ°è·¯å¾„ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨è¿™ä¸ª[invoice image](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)ï¼š


```py
>>> from transformers import pipeline

>>> vqa = pipeline(model="impira/layoutlm-document-qa")
>>> vqa(
...     image="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png",
...     question="What is the invoice number?",
... )
[{'score': 0.42515, 'answer': 'us-001', 'start': 16, 'end': 16}]
```

<Tip>

è¦è¿è¡Œä¸Šé¢çš„ç¤ºä¾‹ï¼Œé™¤äº†ğŸ¤— Transformersä¹‹å¤–ï¼Œæ‚¨éœ€è¦å®‰è£…[`pytesseract`](https://pypi.org/project/pytesseract/)ã€‚


```bash
sudo apt install -y tesseract-ocr
pip install pytesseract
```

</Tip>

## åœ¨å¤§æ¨¡å‹ä¸Šä½¿ç”¨ğŸ¤— `accelerate`å’Œ`pipeline`ï¼š

æ‚¨å¯ä»¥è½»æ¾åœ°ä½¿ç”¨ğŸ¤— `accelerate`åœ¨å¤§æ¨¡å‹ä¸Šè¿è¡Œ `pipeline`ï¼é¦–å…ˆç¡®ä¿æ‚¨å·²ç»ä½¿ç”¨ `pip install accelerate` å®‰è£…äº† `accelerate`ã€‚

é¦–å…ˆä½¿ç”¨ `device_map="auto"` åŠ è½½æ‚¨çš„æ¨¡å‹ï¼æˆ‘ä»¬å°†åœ¨ç¤ºä¾‹ä¸­ä½¿ç”¨ `facebook/opt-1.3b`ã€‚


```py
# pip install accelerate
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", torch_dtype=torch.bfloat16, device_map="auto")
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

å¦‚æœå®‰è£… `bitsandbytes` å¹¶æ·»åŠ å‚æ•° `load_in_8bit=True`ï¼Œæ‚¨è¿˜å¯ä»¥ä¼ é€’8ä½åŠ è½½çš„æ¨¡å‹ã€‚


```py
# pip install accelerate bitsandbytes
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", device_map="auto", model_kwargs={"load_in_8bit": True})
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥å°†`checkpoint `æ›¿æ¢ä¸ºä»»ä½•æ”¯æŒå¤§æ¨¡å‹åŠ è½½çš„Hugging Faceæ¨¡å‹ï¼Œæ¯”å¦‚BLOOMï¼

