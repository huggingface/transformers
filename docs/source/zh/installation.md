<!---ç‰ˆæƒæ‰€æœ‰ 2022 å¹´ HuggingFace å›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚
æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰æˆæƒï¼›é™¤éç¬¦åˆè®¸å¯è¯ï¼Œå¦åˆ™æ‚¨æ— æ³•ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è·å–è®¸å¯è¯çš„å‰¯æœ¬
    http://www.apache.org/licenses/LICENSE-2.0
é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶åˆ†å‘åœ¨â€œæŒ‰åŸæ ·â€åŸºç¡€ä¸Šï¼Œæ²¡æœ‰ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯æˆ–æ¡ä»¶ã€‚æœ‰å…³ç‰¹å®šè¯­è¨€çš„æƒé™å’Œé™åˆ¶è¯¦è§è®¸å¯è¯ã€‚
âš ï¸ è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯ Markdown æ ¼å¼ï¼Œä½†åŒ…å«æˆ‘ä»¬çš„æ–‡æ¡£ç”Ÿæˆå™¨çš„ç‰¹å®šè¯­æ³•ï¼ˆç±»ä¼¼äº MDXï¼‰ï¼Œå¯èƒ½æ— æ³•åœ¨æ‚¨çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®å‘ˆç°ã€‚
-->

# å®‰è£…

æ ¹æ®æ‚¨ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ åº“å®‰è£… ğŸ¤— Transformersï¼Œè®¾ç½®ç¼“å­˜ï¼Œå¹¶å¯é€‰æ‹©é…ç½® ğŸ¤— Transformers ä»¥ç¦»çº¿è¿è¡Œã€‚

ğŸ¤— Transformers åœ¨ Python 3.6+ã€PyTorch 1.1.0+ã€TensorFlow 2.0+ å’Œ Flax ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚æŒ‰ç…§ä¸‹é¢çš„å®‰è£…è¯´æ˜å®‰è£…æ‚¨æ­£åœ¨ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ åº“ï¼š

* [PyTorch](https://pytorch.org/get-started/locally/) å®‰è£…è¯´æ˜ã€‚
* [TensorFlow 2.0](https://www.tensorflow.org/install/pip) å®‰è£…è¯´æ˜ã€‚
* [Flax](https://flax.readthedocs.io/en/latest/) å®‰è£…è¯´æ˜ã€‚

## ä½¿ç”¨ pip å®‰è£…

æ‚¨åº”è¯¥åœ¨ [è™šæ‹Ÿç¯å¢ƒ](https://docs.python.org/3/library/venv.html) ä¸­å®‰è£… ğŸ¤— Transformersã€‚å¦‚æœæ‚¨å¯¹ Python è™šæ‹Ÿç¯å¢ƒä¸ç†Ÿæ‚‰ï¼Œè¯·å‚é˜…æ­¤ [æŒ‡å—](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã€‚è™šæ‹Ÿç¯å¢ƒå¯ä»¥æ›´è½»æ¾åœ°ç®¡ç†ä¸åŒçš„é¡¹ç›®ï¼Œå¹¶é¿å…ä¾èµ–é¡¹ä¹‹é—´çš„å…¼å®¹æ€§é—®é¢˜ã€‚

é¦–å…ˆï¼Œåœ¨æ‚¨çš„é¡¹ç›®ç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼š
```bash
python -m venv .env
```

æ¿€æ´»è™šæ‹Ÿç¯å¢ƒã€‚åœ¨ Linux å’Œ MacOS ä¸Šï¼š
```bash
source .env/bin/activate
```
åœ¨ Windows ä¸Šæ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
```bash
.env/Scripts/activate
```

ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… ğŸ¤— Transformersï¼š
```bash
pip install transformers
```

ä»…æ”¯æŒ CPU çš„æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä¸€è¡Œå‘½ä»¤æ–¹ä¾¿åœ°å®‰è£… ğŸ¤— Transformers å’Œæ·±åº¦å­¦ä¹ åº“ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… ğŸ¤— Transformers å’Œ PyTorchï¼š
```bash
pip install 'transformers[torch]'
```

ğŸ¤— Transformers å’Œ TensorFlow 2.0ï¼š
```bash
pip install 'transformers[tf-cpu]'
```

<Tip warning={true}>

M1 / ARM ç”¨æˆ·    
åœ¨å®‰è£… TensorFlow 2.0 ä¹‹å‰ï¼Œæ‚¨éœ€è¦å®‰è£…ä»¥ä¸‹å†…å®¹ 
```
brew install cmake
brew install pkg-config
```

</Tip>

ğŸ¤— Transformers å’Œ Flaxï¼š
```bash
pip install 'transformers[flax]'
```

æœ€åï¼Œé€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ ğŸ¤— Transformers æ˜¯å¦å·²æ­£ç¡®å®‰è£…ã€‚å®ƒå°†ä¸‹è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼š
```bash
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
```

ç„¶åæ‰“å°æ ‡ç­¾å’Œåˆ†æ•°ï¼š
```bash
[{'label': 'POSITIVE', 'score': 0.9998704791069031}]
```

## ä»æºä»£ç å®‰è£…
ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä»æºä»£ç å®‰è£… ğŸ¤— Transformersï¼š
```bash
pip install git+https://github.com/huggingface/transformers
```

æ­¤å‘½ä»¤å®‰è£…æœ€æ–°çš„â€œmainâ€ç‰ˆæœ¬ï¼Œè€Œä¸æ˜¯æœ€æ–°çš„â€œstableâ€ç‰ˆæœ¬ã€‚â€œmainâ€ç‰ˆæœ¬å¯¹äºä¿æŒä¸æœ€æ–°çš„å¼€å‘ä¸€è‡´éå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœè‡ªä¸Šæ¬¡æ­£å¼å‘å¸ƒä»¥æ¥ä¿®å¤äº†é”™è¯¯ä½†å°šæœªå‘å¸ƒæ–°ç‰ˆæœ¬ã€‚ä½†æ˜¯ï¼Œè¿™æ„å‘³ç€â€œmainâ€ç‰ˆæœ¬å¯èƒ½å¹¶ä¸æ€»æ˜¯ç¨³å®šçš„ã€‚æˆ‘ä»¬åŠªåŠ›ä½¿â€œmainâ€ç‰ˆæœ¬æ­£å¸¸è¿è¡Œï¼Œå¤§å¤šæ•°é—®é¢˜é€šå¸¸åœ¨å‡ ä¸ªå°æ—¶æˆ–ä¸€å¤©å†…è§£å†³ã€‚å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ‰“å¼€ä¸€ä¸ª [Issue](https://github.com/huggingface/transformers/issues)ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æ›´å¿«åœ°ä¿®å¤ã€‚

é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ ğŸ¤— Transformers æ˜¯å¦å·²æ­£ç¡®å®‰è£…ï¼š

```bash
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))"
```

## å¯ç¼–è¾‘å®‰è£…

å¦‚æœæ‚¨æƒ³è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼Œæ‚¨å°†éœ€è¦ä¸€ä¸ªå¯ç¼–è¾‘å®‰è£…ï¼š

* ä½¿ç”¨æºä»£ç çš„â€œmainâ€ç‰ˆæœ¬ã€‚

* å¯¹ ğŸ¤— Transformers è¿›è¡Œè´¡çŒ®å¹¶éœ€è¦åœ¨ä»£ç ä¸­è¿›è¡Œæµ‹è¯•æ›´æ”¹ã€‚

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å…‹éš†å­˜å‚¨åº“å¹¶å®‰è£… ğŸ¤— Transformersï¼š

```bash
git clone https://github.com/huggingface/transformers.git
cd transformers
pip install -e .
```

è¿™äº›å‘½ä»¤å°†è¿æ¥æ‚¨å…‹éš†çš„å­˜å‚¨åº“çš„æ–‡ä»¶å¤¹å’Œ Python åº“è·¯å¾„ã€‚Python ç°åœ¨å°†åœ¨æ­£å¸¸åº“è·¯å¾„ä¹‹å¤–çš„æ–‡ä»¶å¤¹ä¸­æœç´¢ï¼š`~/transformers/`ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çš„ Python åŒ…é€šå¸¸å®‰è£…åœ¨ `~/anaconda3/envs/main/lib/python3.7/site-packages/` ä¸­ï¼ŒPython ä¹Ÿå°†æœç´¢æ‚¨å…‹éš†åˆ°çš„æ–‡ä»¶å¤¹ã€‚
<Tip warning={true}>

å¦‚æœè¦ç»§ç»­ä½¿ç”¨è¯¥åº“ï¼Œæ‚¨å¿…é¡»ä¿ç•™ `transformers` æ–‡ä»¶å¤¹ã€‚
</Tip>

ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è½»æ¾æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬çš„ ğŸ¤— Transformersï¼š
```bash
cd ~/transformers/
git pull
```

æ‚¨çš„ Python ç¯å¢ƒå°†åœ¨ä¸‹ä¸€æ¬¡è¿è¡Œæ—¶æ‰¾åˆ° `main` ç‰ˆæœ¬çš„ ğŸ¤— Transformersã€‚

## ä½¿ç”¨ conda å®‰è£…

ä» conda æ¸ é“ `huggingface` å®‰è£…ï¼š
```bash
conda install -c huggingface transformers
```

## ç¼“å­˜è®¾ç½®

é¢„è®­ç»ƒæ¨¡å‹åœ¨ `~/.cache/huggingface/hub` ä¸‹è½½å¹¶æœ¬åœ°ç¼“å­˜ã€‚è¿™æ˜¯ shell ç¯å¢ƒå˜é‡ `TRANSFORMERS_CACHE` ç»™å‡ºçš„é»˜è®¤ç›®å½•ã€‚åœ¨ Windows ä¸Šï¼Œé»˜è®¤ç›®å½•ç”± `C:\Users\username\.cache\huggingface\hub` ç»™å‡ºã€‚æ‚¨å¯ä»¥æŒ‰ç…§ä¸‹é¢ä¼˜å…ˆçº§çš„ shell ç¯å¢ƒå˜é‡æ›´æ”¹è¿™äº›å˜é‡æ¥æŒ‡å®šä¸åŒçš„ç¼“å­˜ç›®å½•ï¼š

1. Shell ç¯å¢ƒå˜é‡ï¼ˆé»˜è®¤ï¼‰ï¼š`HUGGINGFACE_HUB_CACHE` æˆ– `TRANSFORMERS_CACHE`ã€‚2. Shell ç¯å¢ƒå˜é‡ï¼š`HF_HOME`ã€‚3. Shell ç¯å¢ƒå˜é‡ï¼š`XDG_CACHE_HOME` + `/huggingface`ã€‚

<Tip>

å¦‚æœæ‚¨æ˜¯ä»æ­¤åº“çš„æ—©æœŸç‰ˆæœ¬è½¬æ¢è€Œæ¥å¹¶ä¸”å·²è®¾ç½®äº† shell ç¯å¢ƒå˜é‡ `PYTORCH_TRANSFORMERS_CACHE` æˆ– `PYTORCH_PRETRAINED_BERT_CACHE`ï¼Œåˆ™ğŸ¤— Transformers å°†ä½¿ç”¨è¿™äº›ç¯å¢ƒå˜é‡ï¼Œé™¤éæ‚¨æŒ‡å®š shell ç¯å¢ƒå˜é‡ `TRANSFORMERS_CACHE`ã€‚
</Tip>

## ç¦»çº¿æ¨¡å¼

ğŸ¤— Transformers å¯ä»¥åœ¨é˜²ç«å¢™æˆ–ç¦»çº¿ç¯å¢ƒä¸­è¿è¡Œï¼Œåªéœ€ä½¿ç”¨æœ¬åœ°æ–‡ä»¶å³å¯ã€‚è®¾ç½®ç¯å¢ƒå˜é‡ `TRANSFORMERS_OFFLINE=1` ä»¥å¯ç”¨æ­¤è¡Œä¸ºã€‚

<Tip>

é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ `HF_DATASETS_OFFLINE=1`ï¼Œå°† [ğŸ¤— Datasets](https://huggingface.co/docs/datasets/) æ·»åŠ åˆ°ç¦»çº¿è®­ç»ƒå·¥ä½œæµç¨‹ä¸­ã€‚
</Tip>

ä¾‹å¦‚ï¼Œæ‚¨é€šå¸¸ä¼šåœ¨æ™®é€šç½‘ç»œä¸Šçš„é˜²ç«å¢™ä¸Šè¿è¡Œç¨‹åºï¼Œä»¥ä¸‹æ˜¯å‘½ä»¤ï¼š
```bash
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...
```

åœ¨ç¦»çº¿å®ä¾‹ä¸­è¿è¡Œç›¸åŒçš„ç¨‹åºï¼š
```bash
HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...
```

ç°åœ¨ï¼Œè„šæœ¬åº”è¯¥å¯ä»¥è¿è¡Œè€Œæ— éœ€æŒ‚èµ·æˆ–ç­‰å¾…è¶…æ—¶ï¼Œå› ä¸ºå®ƒçŸ¥é“å®ƒåªåº”æŸ¥æ‰¾æœ¬åœ°æ–‡ä»¶ã€‚

### è·å–ç”¨äºç¦»çº¿ä½¿ç”¨çš„æ¨¡å‹å’Œåˆ†è¯å™¨ (Tokenizer)
ğŸ¤— Transformers çš„å¦ä¸€ç§ç¦»çº¿ä½¿ç”¨é€‰é¡¹æ˜¯æå‰ä¸‹è½½æ–‡ä»¶ï¼Œç„¶ååœ¨éœ€è¦ç¦»çº¿ä½¿ç”¨æ—¶æŒ‡å‘å…¶æœ¬åœ°è·¯å¾„ã€‚æœ‰ä¸‰ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼š

* é€šè¿‡ [æ¨¡å‹ä¸­å¿ƒ](https://huggingface.co/models) ä¸Šçš„ç”¨æˆ·ç•Œé¢ä¸‹è½½æ–‡ä»¶ï¼Œå•å‡» â†“ å›¾æ ‡ã€‚
    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)
* ä½¿ç”¨ [`PreTrainedModel.from_pretrained`] å’Œ [`PreTrainedModel.save_pretrained`] å·¥ä½œæµç¨‹ï¼š

    1. ä½¿ç”¨ [`PreTrainedModel.from_pretrained`] æå‰ä¸‹è½½æ‚¨çš„æ–‡ä»¶ï¼š

    ```py
    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

    >>> tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
    >>> model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")
    ```
    2. Save your files to a specified directory with [`PreTrainedModel.save_pretrained`]:

    ```py    
    >>> tokenizer.save_pretrained("./your/path/bigscience_t0")
    >>> model.save_pretrained("./your/path/bigscience_t0")
    ```
    3. Now when you're offline, reload your files with [`PreTrainedModel.from_pretrained`] from the specified directory:

    ```py    
    >>> tokenizer = AutoTokenizer.from_pretrained("./your/path/bigscience_t0")
    >>> model = AutoModel.from_pretrained("./your/path/bigscience_t0")
    ```
* ä½¿ç”¨ [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) åº“ä»¥ç¼–ç¨‹æ–¹å¼ä¸‹è½½æ–‡ä»¶ï¼š

   1. åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£… `huggingface_hub` åº“ï¼š

```bash    
python -m pip install huggingface_hub
```
    2. ä½¿ç”¨ [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) å‡½æ•°å°†æ–‡ä»¶ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„å‘½ä»¤å°†ä» [T0](https://huggingface.co/bigscience/T0_3B) æ¨¡å‹ä¸­ä¸‹è½½ `config.json` æ–‡ä»¶åˆ°ä½ æŒ‡å®šçš„è·¯å¾„ï¼š


    ```py
    >>> from huggingface_hub import hf_hub_download

    >>> hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./your/path/bigscience_t0")
    ```
ä¸€æ—¦æ–‡ä»¶ä¸‹è½½å¹¶ä¸”åœ¨æœ¬åœ°ç¼“å­˜ï¼Œä½ å¯ä»¥æŒ‡å®šå®ƒçš„æœ¬åœ°è·¯å¾„æ¥åŠ è½½å’Œä½¿ç”¨å®ƒï¼š

```py
>>> from transformers import AutoConfig

>>> config = AutoConfig.from_pretrained("./your/path/bigscience_t0/config.json")
```

<Tip>

æŸ¥çœ‹ [å¦‚ä½•ä» Hub ä¸‹è½½æ–‡ä»¶](https://huggingface.co/docs/hub/how-to-downstream) éƒ¨åˆ†ï¼Œäº†è§£æœ‰å…³ä» Hub ä¸‹è½½æ–‡ä»¶çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

</Tip>
