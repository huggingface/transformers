<!---
Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# å®‰è£…

ä¸ºä½ æ­£åœ¨ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶å®‰è£… ğŸ¤— Transformersã€è®¾ç½®ç¼“å­˜ï¼Œå¹¶é€‰æ‹©æ€§é…ç½® ğŸ¤— Transformers ä»¥ç¦»çº¿è¿è¡Œã€‚

ğŸ¤— Transformers å·²åœ¨ Python 3.6+ã€PyTorch 1.1.0+ã€TensorFlow 2.0+ ä»¥åŠ Flax ä¸Šè¿›è¡Œæµ‹è¯•ã€‚é’ˆå¯¹ä½ ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè¯·å‚ç…§ä»¥ä¸‹å®‰è£…è¯´æ˜è¿›è¡Œå®‰è£…ï¼š

* [PyTorch](https://pytorch.org/get-started/locally/) å®‰è£…è¯´æ˜ã€‚
* [TensorFlow 2.0](https://www.tensorflow.org/install/pip) å®‰è£…è¯´æ˜ã€‚
* [Flax](https://flax.readthedocs.io/en/latest/) å®‰è£…è¯´æ˜ã€‚

## ä½¿ç”¨ pip å®‰è£…

ä½ åº”è¯¥ä½¿ç”¨ [è™šæ‹Ÿç¯å¢ƒ](https://docs.python.org/3/library/venv.html) å®‰è£… ğŸ¤— Transformersã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰ Python è™šæ‹Ÿç¯å¢ƒï¼Œè¯·æŸ¥çœ‹æ­¤ [æ•™ç¨‹](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã€‚ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œä½ å¯ä»¥è½»æ¾ç®¡ç†ä¸åŒé¡¹ç›®ï¼Œé¿å…ä¸åŒä¾èµ–é¡¹ä¹‹é—´çš„å…¼å®¹æ€§é—®é¢˜ã€‚

é¦–å…ˆï¼Œåœ¨é¡¹ç›®ç›®å½•ä¸­åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š

```bash
python -m venv .env
```

åœ¨ Linux å’Œ MacOs ç³»ç»Ÿä¸­æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š

```bash
source .env/bin/activate
```
åœ¨ Windows ç³»ç»Ÿä¸­æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š

```bash
.env/Scripts/activate
```

ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… ğŸ¤— Transformersï¼š

```bash
pip install transformers
```

è‹¥ä»…éœ€ CPU æ”¯æŒï¼Œå¯ä»¥ä½¿ç”¨å•è¡Œå‘½ä»¤æ–¹ä¾¿åœ°å®‰è£… ğŸ¤— Transformers å’Œæ·±åº¦å­¦ä¹ åº“ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… ğŸ¤— Transformers å’Œ PyTorchï¼š

```bash
pip install 'transformers[torch]'
```

ğŸ¤— Transformers å’Œ TensorFlow 2.0ï¼š

```bash
pip install 'transformers[tf-cpu]'
```

<Tip warning={true}>

M1 / ARMç”¨æˆ·
    
åœ¨å®‰è£… TensorFlow 2.0 å‰ï¼Œä½ éœ€è¦å®‰è£…ä»¥ä¸‹åº“ï¼š
```
brew install cmake
brew install pkg-config
```

</Tip>

ğŸ¤— Transformers å’Œ Flax:

```bash
pip install 'transformers[flax]'
```

æœ€åï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥æ£€æŸ¥ ğŸ¤— Transformers æ˜¯å¦å·²è¢«æ­£ç¡®å®‰è£…ã€‚è¯¥å‘½ä»¤å°†ä¸‹è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼š

```bash
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
```

ç„¶åæ‰“å°æ ‡ç­¾ä»¥åŠåˆ†æ•°ï¼š

```bash
[{'label': 'POSITIVE', 'score': 0.9998704791069031}]
```

## æºç å®‰è£…

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä»æºç å®‰è£… ğŸ¤— Transformersï¼š

```bash
pip install git+https://github.com/huggingface/transformers
```

æ­¤å‘½ä»¤ä¸‹è½½çš„æ˜¯æœ€æ–°çš„å‰æ²¿ `main` ç‰ˆæœ¬è€Œä¸æ˜¯æœ€æ–°çš„ `stable` ç‰ˆæœ¬ã€‚`main` ç‰ˆæœ¬é€‚ç”¨äºè·Ÿæœ€æ–°å¼€å‘ä¿æŒä¸€è‡´ã€‚ä¾‹å¦‚ï¼Œä¸Šæ¬¡æ­£å¼ç‰ˆå‘å¸ƒå¸¦æ¥çš„ bug è¢«ä¿®å¤äº†ï¼Œä½†æ–°ç‰ˆæœ¬å°šæœªè¢«æ¨å‡ºã€‚ä½†æ˜¯ï¼Œè¿™ä¹Ÿè¯´æ˜ `main` ç‰ˆæœ¬å¹¶ä¸ä¸€å®šæ€»æ˜¯ç¨³å®šçš„ã€‚æˆ‘ä»¬åŠªåŠ›ä¿æŒ `main` ç‰ˆæœ¬çš„å¯æ“ä½œæ€§ï¼Œå¤§å¤šæ•°é—®é¢˜é€šå¸¸åœ¨å‡ ä¸ªå°æ—¶æˆ–ä¸€å¤©ä»¥å†…å°±èƒ½è¢«è§£å†³ã€‚å¦‚æœä½ é‡åˆ°é—®é¢˜ï¼Œè¯·æä¸ª [Issue](https://github.com/huggingface/transformers/issues) ä»¥ä¾¿æˆ‘ä»¬èƒ½æ›´å¿«ä¿®å¤ã€‚

è¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥æ£€æŸ¥ ğŸ¤— Transformers æ˜¯å¦å·²è¢«æ­£ç¡®å®‰è£…ï¼š

```bash
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))"
```

## å¯ç¼–è¾‘å®‰è£…

å¦‚æœä½ æœ‰ä¸‹åˆ—éœ€æ±‚ï¼Œéœ€è¦è¿›è¡Œå¯ç¼–è¾‘å®‰è£…ï¼š

* ä½¿ç”¨æºç çš„ `main` ç‰ˆæœ¬ã€‚
* ä¸º ğŸ¤— Transformers è´¡çŒ®ä»£ç ï¼Œéœ€è¦æµ‹è¯•ä»£ç ä¸­çš„æ›´æ”¹ã€‚

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å…‹éš†ä»“åº“å¹¶å®‰è£… ğŸ¤— Transformersï¼š

```bash
git clone https://github.com/huggingface/transformers.git
cd transformers
pip install -e .
```

è¿™äº›å‘½ä»¤å°†ä¼šé“¾æ¥ä½ å…‹éš†çš„ä»“åº“ä»¥åŠä½ çš„ Python åº“è·¯å¾„ã€‚ç°åœ¨ï¼ŒPython ä¸ä»…ä¼šåœ¨æ­£å¸¸çš„åº“è·¯å¾„ä¸­æœç´¢åº“ï¼Œä¹Ÿä¼šåœ¨ä½ å…‹éš†åˆ°çš„æ–‡ä»¶å¤¹ä¸­è¿›è¡ŒæŸ¥æ‰¾ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ çš„ Python åŒ…é€šå¸¸æœ¬åº”å®‰è£…åœ¨ `~/anaconda3/envs/main/lib/python3.7/site-packages/` ç›®å½•ä¸­ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ Python ä¹Ÿä¼šæœç´¢ä½ å…‹éš†åˆ°çš„æ–‡ä»¶å¤¹ï¼š`~/transformers/`ã€‚

<Tip warning={true}>

å¦‚æœä½ æƒ³ç»§ç»­ä½¿ç”¨è¿™ä¸ªåº“ï¼Œå¿…é¡»ä¿ç•™ `transformers` æ–‡ä»¶å¤¹ã€‚

</Tip>

ç°åœ¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼Œå°†ä½ å…‹éš†çš„ ğŸ¤— Transformers åº“è½»æ¾æ›´æ–°è‡³æœ€æ–°ç‰ˆæœ¬ï¼š

```bash
cd ~/transformers/
git pull
```

ä½ çš„ Python ç¯å¢ƒå°†åœ¨ä¸‹æ¬¡è¿è¡Œæ—¶æ‰¾åˆ° `main` ç‰ˆæœ¬çš„ ğŸ¤— Transformersã€‚

## ä½¿ç”¨ conda å®‰è£…

ä» conda çš„ `huggingface` é¢‘é“å®‰è£…ï¼š

```bash
conda install -c huggingface transformers
```

## ç¼“å­˜è®¾ç½®

é¢„è®­ç»ƒæ¨¡å‹ä¼šè¢«ä¸‹è½½å¹¶æœ¬åœ°ç¼“å­˜åˆ° `~/.cache/huggingface/hub`ã€‚è¿™æ˜¯ç”±ç¯å¢ƒå˜é‡ `TRANSFORMERS_CACHE` æŒ‡å®šçš„é»˜è®¤ç›®å½•ã€‚åœ¨ Windows ä¸Šï¼Œé»˜è®¤ç›®å½•ä¸º `C:\Users\username\.cache\huggingface\hub`ã€‚ä½ å¯ä»¥æŒ‰ç…§ä¸åŒä¼˜å…ˆçº§æ”¹å˜ä¸‹è¿°ç¯å¢ƒå˜é‡ï¼Œä»¥æŒ‡å®šä¸åŒçš„ç¼“å­˜ç›®å½•ã€‚

1. ç¯å¢ƒå˜é‡ï¼ˆé»˜è®¤ï¼‰: `HUGGINGFACE_HUB_CACHE` æˆ– `TRANSFORMERS_CACHE`ã€‚
2. ç¯å¢ƒå˜é‡ `HF_HOME`ã€‚
3. ç¯å¢ƒå˜é‡ `XDG_CACHE_HOME` + `/huggingface`ã€‚

<Tip>

é™¤éä½ æ˜ç¡®æŒ‡å®šäº†ç¯å¢ƒå˜é‡ `TRANSFORMERS_CACHE`ï¼ŒğŸ¤— Transformers å°†å¯èƒ½ä¼šä½¿ç”¨è¾ƒæ—©ç‰ˆæœ¬è®¾ç½®çš„ç¯å¢ƒå˜é‡ `PYTORCH_TRANSFORMERS_CACHE` æˆ– `PYTORCH_PRETRAINED_BERT_CACHE`ã€‚

</Tip>

## ç¦»çº¿æ¨¡å¼

ğŸ¤— Transformers å¯ä»¥ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶åœ¨é˜²ç«å¢™æˆ–ç¦»çº¿ç¯å¢ƒä¸­è¿è¡Œã€‚è®¾ç½®ç¯å¢ƒå˜é‡ `TRANSFORMERS_OFFLINE=1` ä»¥å¯ç”¨è¯¥è¡Œä¸ºã€‚

<Tip>

é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ `HF_DATASETS_OFFLINE=1` å°† [ğŸ¤— Datasets](https://huggingface.co/docs/datasets/) æ·»åŠ è‡³ä½ çš„ç¦»çº¿è®­ç»ƒå·¥ä½œæµç¨‹ä¸­ã€‚

</Tip>

ä¾‹å¦‚ï¼Œä½ é€šå¸¸ä¼šä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯¹å¤–éƒ¨å®ä¾‹è¿›è¡Œé˜²ç«å¢™ä¿æŠ¤çš„çš„æ™®é€šç½‘ç»œä¸Šè¿è¡Œç¨‹åºï¼š

```bash
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...
```

åœ¨ç¦»çº¿ç¯å¢ƒä¸­è¿è¡Œç›¸åŒçš„ç¨‹åºï¼š

```bash
HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...
```

ç°åœ¨è„šæœ¬å¯ä»¥åº”è¯¥æ­£å¸¸è¿è¡Œï¼Œè€Œæ— éœ€æŒ‚èµ·æˆ–ç­‰å¾…è¶…æ—¶ï¼Œå› ä¸ºå®ƒçŸ¥é“åªåº”æŸ¥æ‰¾æœ¬åœ°æ–‡ä»¶ã€‚

### è·å–ç¦»çº¿æ—¶ä½¿ç”¨çš„æ¨¡å‹å’Œåˆ†è¯å™¨

å¦ä¸€ç§ç¦»çº¿æ—¶ä½¿ç”¨ ğŸ¤— Transformers çš„æ–¹æ³•æ˜¯é¢„å…ˆä¸‹è½½å¥½æ–‡ä»¶ï¼Œç„¶ååœ¨éœ€è¦ç¦»çº¿ä½¿ç”¨æ—¶æŒ‡å‘å®ƒä»¬çš„ç¦»çº¿è·¯å¾„ã€‚æœ‰ä¸‰ç§å®ç°çš„æ–¹æ³•ï¼š

* å•å‡» [Model Hub](https://huggingface.co/models) ç”¨æˆ·ç•Œé¢ä¸Šçš„ â†“ å›¾æ ‡ä¸‹è½½æ–‡ä»¶ã€‚

    ![ä¸‹è½½å›¾æ ‡](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)

* ä½¿ç”¨ [`PreTrainedModel.from_pretrained`] å’Œ [`PreTrainedModel.save_pretrained`] å·¥ä½œæµç¨‹ï¼š

    1. é¢„å…ˆä½¿ç”¨ [`PreTrainedModel.from_pretrained`] ä¸‹è½½æ–‡ä»¶ï¼š

    ```py
    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

    >>> tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
    >>> model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")
    ```

    2. ä½¿ç”¨ [`PreTrainedModel.save_pretrained`] å°†æ–‡ä»¶ä¿å­˜è‡³æŒ‡å®šç›®å½•ï¼š

    ```py
    >>> tokenizer.save_pretrained("./your/path/bigscience_t0")
    >>> model.save_pretrained("./your/path/bigscience_t0")
    ```

    3. ç°åœ¨ï¼Œä½ å¯ä»¥åœ¨ç¦»çº¿æ—¶ä»æŒ‡å®šç›®å½•ä½¿ç”¨ [`PreTrainedModel.from_pretrained`] é‡æ–°åŠ è½½ä½ çš„æ–‡ä»¶ï¼š

    ```py
    >>> tokenizer = AutoTokenizer.from_pretrained("./your/path/bigscience_t0")
    >>> model = AutoModel.from_pretrained("./your/path/bigscience_t0")
    ```

* ä½¿ç”¨ä»£ç ç”¨ [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) åº“ä¸‹è½½æ–‡ä»¶ï¼š

    1. åœ¨ä½ çš„è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£… `huggingface_hub` åº“ï¼š

    ```bash
    python -m pip install huggingface_hub
    ```

    2. ä½¿ç”¨ [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) å‡½æ•°å°†æ–‡ä»¶ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹å‘½ä»¤å°† `config.json` æ–‡ä»¶ä» [T0](https://huggingface.co/bigscience/T0_3B) æ¨¡å‹ä¸‹è½½è‡³ä½ æƒ³è¦çš„è·¯å¾„ï¼š

    ```py
    >>> from huggingface_hub import hf_hub_download

    >>> hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./your/path/bigscience_t0")
    ```

ä¸‹è½½å®Œæ–‡ä»¶å¹¶åœ¨æœ¬åœ°ç¼“å­˜åï¼ŒæŒ‡å®šå…¶æœ¬åœ°è·¯å¾„ä»¥åŠ è½½å’Œä½¿ç”¨è¯¥æ¨¡å‹ï¼š

```py
>>> from transformers import AutoConfig

>>> config = AutoConfig.from_pretrained("./your/path/bigscience_t0/config.json")
```

<Tip>

è¯·å‚é˜… [å¦‚ä½•ä» Hub ä¸‹è½½æ–‡ä»¶](https://huggingface.co/docs/hub/how-to-downstream) éƒ¨åˆ†ï¼Œè·å–æœ‰å…³ä¸‹è½½å­˜å‚¨åœ¨ Hub ä¸Šæ–‡ä»¶çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

</Tip>
