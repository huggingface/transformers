<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Trainer

[`Trainer`] ç±»æä¾›äº†ä¸€ä¸ª PyTorch çš„ APIï¼Œç”¨äºå¤„ç†å¤§å¤šæ•°æ ‡å‡†ç”¨ä¾‹çš„å…¨åŠŸèƒ½è®­ç»ƒã€‚å®ƒåœ¨å¤§å¤šæ•°[ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples)ä¸­è¢«ä½¿ç”¨ã€‚

<Tip>

å¦‚æœä½ æƒ³è¦ä½¿ç”¨è‡ªå›å½’æŠ€æœ¯åœ¨æ–‡æœ¬æ•°æ®é›†ä¸Šå¾®è°ƒåƒ Llama-2 æˆ– Mistral è¿™æ ·çš„è¯­è¨€æ¨¡å‹ï¼Œè€ƒè™‘ä½¿ç”¨ [`trl`](https://github.com/huggingface/trl) çš„ [`~trl.SFTTrainer`]ã€‚[`~trl.SFTTrainer`] å°è£…äº† [`Trainer`]ï¼Œä¸“é—¨é’ˆå¯¹è¿™ä¸ªç‰¹å®šä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶æ”¯æŒåºåˆ—æ‰“åŒ…ã€LoRAã€é‡åŒ–å’Œ DeepSpeedï¼Œä»¥æœ‰æ•ˆæ‰©å±•åˆ°ä»»ä½•æ¨¡å‹å¤§å°ã€‚å¦ä¸€æ–¹é¢ï¼Œ[`Trainer`] æ˜¯ä¸€ä¸ªæ›´é€šç”¨çš„é€‰é¡¹ï¼Œé€‚ç”¨äºæ›´å¹¿æ³›çš„ä»»åŠ¡ã€‚

</Tip>

åœ¨å®ä¾‹åŒ–ä½ çš„ [`Trainer`] ä¹‹å‰ï¼Œåˆ›å»ºä¸€ä¸ª [`TrainingArguments`]ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒæœŸé—´è®¿é—®æ‰€æœ‰å®šåˆ¶ç‚¹ã€‚

è¿™ä¸ª API æ”¯æŒåœ¨å¤šä¸ª GPU/TPU ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ”¯æŒ [NVIDIA Apex](https://github.com/NVIDIA/apex) çš„æ··åˆç²¾åº¦å’Œ PyTorch çš„åŸç”Ÿ AMPã€‚

[`Trainer`] åŒ…å«åŸºæœ¬çš„è®­ç»ƒå¾ªç¯ï¼Œæ”¯æŒä¸Šè¿°åŠŸèƒ½ã€‚å¦‚æœéœ€è¦è‡ªå®šä¹‰è®­ç»ƒï¼Œä½ å¯ä»¥ç»§æ‰¿ `Trainer` å¹¶è¦†ç›–ä»¥ä¸‹æ–¹æ³•ï¼š

- **get_train_dataloader** -- åˆ›å»ºè®­ç»ƒ DataLoaderã€‚
- **get_eval_dataloader** -- åˆ›å»ºè¯„ä¼° DataLoaderã€‚
- **get_test_dataloader** -- åˆ›å»ºæµ‹è¯• DataLoaderã€‚
- **log** -- è®°å½•è§‚å¯Ÿè®­ç»ƒçš„å„ç§å¯¹è±¡çš„ä¿¡æ¯ã€‚
- **create_optimizer_and_scheduler** -- å¦‚æœå®ƒä»¬æ²¡æœ‰åœ¨åˆå§‹åŒ–æ—¶ä¼ é€’ï¼Œè¯·è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚è¯·æ³¨æ„ï¼Œä½ è¿˜å¯ä»¥å•ç‹¬ç»§æ‰¿æˆ–è¦†ç›– `create_optimizer` å’Œ `create_scheduler` æ–¹æ³•ã€‚
- **create_optimizer** -- å¦‚æœåœ¨åˆå§‹åŒ–æ—¶æ²¡æœ‰ä¼ é€’ï¼Œåˆ™è®¾ç½®ä¼˜åŒ–å™¨ã€‚
- **create_scheduler** -- å¦‚æœåœ¨åˆå§‹åŒ–æ—¶æ²¡æœ‰ä¼ é€’ï¼Œåˆ™è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
- **compute_loss** - è®¡ç®—å•æ‰¹è®­ç»ƒè¾“å…¥çš„æŸå¤±ã€‚
- **training_step** -- æ‰§è¡Œä¸€æ­¥è®­ç»ƒã€‚
- **prediction_step** -- æ‰§è¡Œä¸€æ­¥è¯„ä¼°/æµ‹è¯•ã€‚
- **evaluate** -- è¿è¡Œè¯„ä¼°å¾ªç¯å¹¶è¿”å›æŒ‡æ ‡ã€‚
- **predict** -- è¿”å›åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹ï¼ˆå¦‚æœæœ‰æ ‡ç­¾ï¼Œåˆ™åŒ…æ‹¬æŒ‡æ ‡ï¼‰ã€‚

<Tip warning={true}>

[`Trainer`] ç±»è¢«ä¼˜åŒ–ç”¨äº ğŸ¤— Transformers æ¨¡å‹ï¼Œå¹¶åœ¨ä½ åœ¨å…¶ä»–æ¨¡å‹ä¸Šä½¿ç”¨æ—¶å¯èƒ½ä¼šæœ‰ä¸€äº›ä»¤äººæƒŠè®¶çš„ç»“æœã€‚å½“åœ¨ä½ è‡ªå·±çš„æ¨¡å‹ä¸Šä½¿ç”¨æ—¶ï¼Œè¯·ç¡®ä¿ï¼š

- ä½ çš„æ¨¡å‹å§‹ç»ˆè¿”å›å…ƒç»„æˆ– [`~utils.ModelOutput`] çš„å­ç±»ã€‚
- å¦‚æœæä¾›äº† `labels` å‚æ•°ï¼Œä½ çš„æ¨¡å‹å¯ä»¥è®¡ç®—æŸå¤±ï¼Œå¹¶ä¸”æŸå¤±ä½œä¸ºå…ƒç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ è¿”å›ï¼ˆå¦‚æœä½ çš„æ¨¡å‹è¿”å›å…ƒç»„ï¼‰ã€‚
- ä½ çš„æ¨¡å‹å¯ä»¥æ¥å—å¤šä¸ªæ ‡ç­¾å‚æ•°ï¼ˆåœ¨ [`TrainingArguments`] ä¸­ä½¿ç”¨ `label_names` å°†å®ƒä»¬çš„åç§°æŒ‡ç¤ºç»™ [`Trainer`]ï¼‰ï¼Œä½†å®ƒä»¬ä¸­æ²¡æœ‰ä¸€ä¸ªåº”è¯¥è¢«å‘½åä¸º `"label"`ã€‚

</Tip>

ä»¥ä¸‹æ˜¯å¦‚ä½•è‡ªå®šä¹‰ [`Trainer`] ä»¥ä½¿ç”¨åŠ æƒæŸå¤±çš„ç¤ºä¾‹ï¼ˆåœ¨è®­ç»ƒé›†ä¸å¹³è¡¡æ—¶å¾ˆæœ‰ç”¨ï¼‰ï¼š

```python
from torch import nn
from transformers import Trainer


class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.pop("labels")
        # forward pass
        outputs = model(**inputs)
        logits = outputs.get("logits")
        # compute custom loss (suppose one has 3 labels with different weights)
        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0], device=model.device))
        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))
        return (loss, outputs) if return_outputs else loss
```

åœ¨ PyTorch [`Trainer`] ä¸­è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¡Œä¸ºçš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ [callbacks](callback)ï¼Œè¿™äº›å›è°ƒå¯ä»¥æ£€æŸ¥è®­ç»ƒå¾ªç¯çŠ¶æ€ï¼ˆç”¨äºè¿›åº¦æŠ¥å‘Šã€åœ¨ TensorBoard æˆ–å…¶ä»– ML å¹³å°ä¸Šè®°å½•æ—¥å¿—ç­‰ï¼‰å¹¶åšå‡ºå†³ç­–ï¼ˆæ¯”å¦‚æå‰åœæ­¢ï¼‰ã€‚


## Trainer

[[autodoc]] Trainer - all

## Seq2SeqTrainer

[[autodoc]] Seq2SeqTrainer - evaluate - predict

## TrainingArguments

[[autodoc]] TrainingArguments - all

## Seq2SeqTrainingArguments

[[autodoc]] Seq2SeqTrainingArguments - all

## Checkpoints

é»˜è®¤æƒ…å†µä¸‹ï¼Œ[`Trainer`] ä¼šå°†æ‰€æœ‰checkpointsä¿å­˜åœ¨ä½ ä½¿ç”¨çš„ [`TrainingArguments`] ä¸­è®¾ç½®çš„ `output_dir` ä¸­ã€‚è¿™äº›checkpointså°†ä½äºåä¸º `checkpoint-xxx` çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œxxx æ˜¯è®­ç»ƒçš„æ­¥éª¤ã€‚

ä»checkpointsæ¢å¤è®­ç»ƒå¯ä»¥é€šè¿‡è°ƒç”¨ [`Trainer.train`] æ—¶ä½¿ç”¨ä»¥ä¸‹ä»»ä¸€æ–¹å¼è¿›è¡Œï¼š

- `resume_from_checkpoint=True`ï¼Œè¿™å°†ä»æœ€æ–°çš„checkpointæ¢å¤è®­ç»ƒã€‚
- `resume_from_checkpoint=checkpoint_dir`ï¼Œè¿™å°†ä»æŒ‡å®šç›®å½•ä¸­çš„ç‰¹å®šcheckpointæ¢å¤è®­ç»ƒã€‚

æ­¤å¤–ï¼Œå½“ä½¿ç”¨ `push_to_hub=True` æ—¶ï¼Œä½ å¯ä»¥è½»æ¾å°†checkpointsä¿å­˜åœ¨ Model Hub ä¸­ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä¿å­˜åœ¨è®­ç»ƒä¸­é—´è¿‡ç¨‹çš„checkpointsä¸­çš„æ‰€æœ‰æ¨¡å‹éƒ½ä¿å­˜åœ¨ä¸åŒçš„æäº¤ä¸­ï¼Œä½†ä¸åŒ…æ‹¬ä¼˜åŒ–å™¨çŠ¶æ€ã€‚ä½ å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ [`TrainingArguments`] çš„ `hub-strategy` å€¼ï¼š

- `"checkpoint"`: æœ€æ–°çš„checkpointä¹Ÿè¢«æ¨é€åˆ°ä¸€ä¸ªåä¸º last-checkpoint çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œè®©ä½ å¯ä»¥é€šè¿‡ `trainer.train(resume_from_checkpoint="output_dir/last-checkpoint")` è½»æ¾æ¢å¤è®­ç»ƒã€‚
- `"all_checkpoints"`: æ‰€æœ‰checkpointséƒ½åƒå®ƒä»¬å‡ºç°åœ¨è¾“å‡ºæ–‡ä»¶å¤¹ä¸­ä¸€æ ·è¢«æ¨é€ï¼ˆå› æ­¤ä½ å°†åœ¨æœ€ç»ˆå­˜å‚¨åº“ä¸­çš„æ¯ä¸ªæ–‡ä»¶å¤¹ä¸­è·å¾—ä¸€ä¸ªcheckpointæ–‡ä»¶å¤¹ï¼‰ã€‚

## Logging

é»˜è®¤æƒ…å†µä¸‹ï¼Œ[`Trainer`] å°†å¯¹ä¸»è¿›ç¨‹ä½¿ç”¨ `logging.INFO`ï¼Œå¯¹å‰¯æœ¬ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ä½¿ç”¨ `logging.WARNING`ã€‚

å¯ä»¥é€šè¿‡ [`TrainingArguments`] çš„å‚æ•°è¦†ç›–è¿™äº›é»˜è®¤è®¾ç½®ï¼Œä½¿ç”¨å…¶ä¸­çš„ 5 ä¸ª `logging` çº§åˆ«ï¼š

- `log_level` - ç”¨äºä¸»è¿›ç¨‹
- `log_level_replica` - ç”¨äºå‰¯æœ¬

æ­¤å¤–ï¼Œå¦‚æœ [`TrainingArguments`] çš„ `log_on_each_node` è®¾ç½®ä¸º `False`ï¼Œåˆ™åªæœ‰ä¸»èŠ‚ç‚¹å°†ä½¿ç”¨å…¶ä¸»è¿›ç¨‹çš„æ—¥å¿—çº§åˆ«è®¾ç½®ï¼Œæ‰€æœ‰å…¶ä»–èŠ‚ç‚¹å°†ä½¿ç”¨å‰¯æœ¬çš„æ—¥å¿—çº§åˆ«è®¾ç½®ã€‚

è¯·æ³¨æ„ï¼Œ[`Trainer`] å°†åœ¨å…¶ [`Trainer.__init__`] ä¸­åˆ†åˆ«ä¸ºæ¯ä¸ªèŠ‚ç‚¹è®¾ç½® `transformers` çš„æ—¥å¿—çº§åˆ«ã€‚å› æ­¤ï¼Œå¦‚æœåœ¨åˆ›å»º [`Trainer`] å¯¹è±¡ä¹‹å‰è¦è°ƒç”¨å…¶ä»– `transformers` åŠŸèƒ½ï¼Œå¯èƒ½éœ€è¦æ›´æ—©åœ°è®¾ç½®è¿™ä¸€ç‚¹ï¼ˆè¯·å‚è§ä¸‹é¢çš„ç¤ºä¾‹ï¼‰ã€‚

ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„ç¤ºä¾‹ï¼š

```python
[...]
logger = logging.getLogger(__name__)

# Setup logging
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    datefmt="%m/%d/%Y %H:%M:%S",
    handlers=[logging.StreamHandler(sys.stdout)],
)

# set the main code and the modules it uses to the same log-level according to the node
log_level = training_args.get_process_log_level()
logger.setLevel(log_level)
datasets.utils.logging.set_verbosity(log_level)
transformers.utils.logging.set_verbosity(log_level)

trainer = Trainer(...)
```

ç„¶åï¼Œå¦‚æœä½ åªæƒ³åœ¨ä¸»èŠ‚ç‚¹ä¸Šçœ‹åˆ°è­¦å‘Šï¼Œå¹¶ä¸”æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ä¸æ‰“å°ä»»ä½•å¯èƒ½é‡å¤çš„è­¦å‘Šï¼Œå¯ä»¥è¿™æ ·è¿è¡Œï¼š

```bash
my_app.py ... --log_level warning --log_level_replica error
```

åœ¨å¤šèŠ‚ç‚¹ç¯å¢ƒä¸­ï¼Œå¦‚æœä½ ä¹Ÿä¸å¸Œæœ›æ¯ä¸ªèŠ‚ç‚¹çš„ä¸»è¿›ç¨‹çš„æ—¥å¿—é‡å¤è¾“å‡ºï¼Œä½ éœ€è¦å°†ä¸Šé¢çš„ä»£ç æ›´æ”¹ä¸ºï¼š

```bash
my_app.py ... --log_level warning --log_level_replica error --log_on_each_node 0
```

ç„¶åï¼Œåªæœ‰ç¬¬ä¸€ä¸ªèŠ‚ç‚¹çš„ä¸»è¿›ç¨‹å°†ä»¥ "warning" çº§åˆ«è®°å½•æ—¥å¿—ï¼Œä¸»èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰å…¶ä»–è¿›ç¨‹å’Œå…¶ä»–èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰è¿›ç¨‹å°†ä»¥ "error" çº§åˆ«è®°å½•æ—¥å¿—ã€‚

å¦‚æœä½ å¸Œæœ›åº”ç”¨ç¨‹åºå°½å¯èƒ½â€å®‰é™â€œï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š


```bash
my_app.py ... --log_level error --log_level_replica error --log_on_each_node 0
```

(å¦‚æœåœ¨å¤šèŠ‚ç‚¹ç¯å¢ƒï¼Œæ·»åŠ  `--log_on_each_node 0`)


## éšæœºæ€§

å½“ä» [`Trainer`] ç”Ÿæˆçš„checkpointæ¢å¤è®­ç»ƒæ—¶ï¼Œç¨‹åºä¼šå°½ä¸€åˆ‡åŠªåŠ›å°† _python_ã€_numpy_ å’Œ _pytorch_ çš„ RNGï¼ˆéšæœºæ•°ç”Ÿæˆå™¨ï¼‰çŠ¶æ€æ¢å¤ä¸ºä¿å­˜æ£€æŸ¥ç‚¹æ—¶çš„çŠ¶æ€ï¼Œè¿™æ ·å¯ä»¥ä½¿â€œåœæ­¢å’Œæ¢å¤â€å¼è®­ç»ƒå°½å¯èƒ½æ¥è¿‘â€œéåœæ­¢å¼â€è®­ç»ƒã€‚

ç„¶è€Œï¼Œç”±äºå„ç§é»˜è®¤çš„éç¡®å®šæ€§ PyTorch è®¾ç½®ï¼Œè¿™å¯èƒ½æ— æ³•å®Œå…¨å®ç°ã€‚å¦‚æœä½ æƒ³è¦å®Œå…¨ç¡®å®šæ€§ï¼Œè¯·å‚é˜…[æ§åˆ¶éšæœºæº](https://pytorch.org/docs/stable/notes/randomness)ã€‚æ­£å¦‚æ–‡æ¡£ä¸­æ‰€è§£é‡Šçš„é‚£æ ·ï¼Œä½¿äº‹ç‰©å˜å¾—ç¡®å®šçš„ä¸€äº›è®¾ç½®ï¼ˆä¾‹å¦‚ `torch.backends.cudnn.deterministic`ï¼‰å¯èƒ½ä¼šå‡æ…¢é€Ÿåº¦ï¼Œå› æ­¤ä¸èƒ½é»˜è®¤æ‰§è¡Œï¼Œä½†å¦‚æœéœ€è¦ï¼Œä½ å¯ä»¥è‡ªè¡Œå¯ç”¨è¿™äº›è®¾ç½®ã€‚


## ç‰¹å®šGPUé€‰æ‹©

è®©æˆ‘ä»¬è®¨è®ºä¸€ä¸‹å¦‚ä½•å‘Šè¯‰ä½ çš„ç¨‹åºåº”è¯¥ä½¿ç”¨å“ªäº› GPU ä»¥åŠä½¿ç”¨çš„é¡ºåºã€‚

å½“ä½¿ç”¨ [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html) ä¸”ä»…ä½¿ç”¨éƒ¨åˆ† GPU æ—¶ï¼Œä½ åªéœ€æŒ‡å®šè¦ä½¿ç”¨çš„ GPU æ•°é‡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ 4 ä¸ª GPUï¼Œä½†åªæƒ³ä½¿ç”¨å‰ 2 ä¸ªï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š


```bash
python -m torch.distributed.launch --nproc_per_node=2  trainer-program.py ...
```

å¦‚æœä½ å®‰è£…äº† [`accelerate`](https://github.com/huggingface/accelerate) æˆ– [`deepspeed`](https://github.com/microsoft/DeepSpeed)ï¼Œä½ è¿˜å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹æ³•å®ç°ç›¸åŒçš„æ•ˆæœï¼š


```bash
accelerate launch --num_processes 2 trainer-program.py ...
```

```bash
deepspeed --num_gpus 2 trainer-program.py ...
```

ä½ ä¸éœ€è¦ä½¿ç”¨ Accelerate æˆ– [Deepspeed é›†æˆ](Deepspeed) åŠŸèƒ½æ¥ä½¿ç”¨è¿™äº›å¯åŠ¨å™¨ã€‚

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»èƒ½å¤Ÿå‘Šè¯‰ç¨‹åºè¦ä½¿ç”¨å¤šå°‘ä¸ª GPUã€‚ç°åœ¨è®©æˆ‘ä»¬è®¨è®ºå¦‚ä½•é€‰æ‹©ç‰¹å®šçš„ GPU å¹¶æ§åˆ¶å®ƒä»¬çš„é¡ºåºã€‚

ä»¥ä¸‹ç¯å¢ƒå˜é‡å¯å¸®åŠ©ä½ æ§åˆ¶ä½¿ç”¨å“ªäº› GPU ä»¥åŠå®ƒä»¬çš„é¡ºåºã€‚


**`CUDA_VISIBLE_DEVICES`**

å¦‚æœä½ æœ‰å¤šä¸ª GPUï¼Œæƒ³è¦ä»…ä½¿ç”¨å…¶ä¸­çš„ä¸€ä¸ªæˆ–å‡ ä¸ª GPUï¼Œè¯·å°†ç¯å¢ƒå˜é‡ `CUDA_VISIBLE_DEVICES` è®¾ç½®ä¸ºè¦ä½¿ç”¨çš„ GPU åˆ—è¡¨ã€‚

ä¾‹å¦‚ï¼Œå‡è®¾ä½ æœ‰ 4 ä¸ª GPUï¼š0ã€1ã€2 å’Œ 3ã€‚è¦ä»…åœ¨ç‰©ç† GPU 0 å’Œ 2 ä¸Šè¿è¡Œï¼Œä½ å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š


```bash
CUDA_VISIBLE_DEVICES=0,2 python -m torch.distributed.launch trainer-program.py ...
```

ç°åœ¨ï¼ŒPyTorch å°†åªçœ‹åˆ° 2 ä¸ª GPUï¼Œå…¶ä¸­ä½ çš„ç‰©ç† GPU 0 å’Œ 2 åˆ†åˆ«æ˜ å°„åˆ° `cuda:0` å’Œ `cuda:1`ã€‚

ä½ ç”šè‡³å¯ä»¥æ”¹å˜å®ƒä»¬çš„é¡ºåºï¼š


```bash
CUDA_VISIBLE_DEVICES=2,0 python -m torch.distributed.launch trainer-program.py ...
```

è¿™é‡Œï¼Œä½ çš„ç‰©ç† GPU 0 å’Œ 2 åˆ†åˆ«æ˜ å°„åˆ° `cuda:1` å’Œ `cuda:0`ã€‚

ä¸Šé¢çš„ä¾‹å­éƒ½æ˜¯é’ˆå¯¹ `DistributedDataParallel` ä½¿ç”¨æ¨¡å¼çš„ï¼Œä½†åŒæ ·çš„æ–¹æ³•ä¹Ÿé€‚ç”¨äº [`DataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html)ï¼š


```bash
CUDA_VISIBLE_DEVICES=2,0 python trainer-program.py ...
```

ä¸ºäº†æ¨¡æ‹Ÿæ²¡æœ‰ GPU çš„ç¯å¢ƒï¼Œåªéœ€å°†æ­¤ç¯å¢ƒå˜é‡è®¾ç½®ä¸ºç©ºå€¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
CUDA_VISIBLE_DEVICES= python trainer-program.py ...
```

ä¸ä»»ä½•ç¯å¢ƒå˜é‡ä¸€æ ·ï¼Œä½ å½“ç„¶å¯ä»¥å°†å…¶exportåˆ°ç¯å¢ƒå˜é‡è€Œä¸æ˜¯å°†å…¶æ·»åŠ åˆ°å‘½ä»¤è¡Œï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š


```bash
export CUDA_VISIBLE_DEVICES=0,2
python -m torch.distributed.launch trainer-program.py ...
```

è¿™ç§æ–¹æ³•å¯èƒ½ä¼šä»¤äººå›°æƒ‘ï¼Œå› ä¸ºä½ å¯èƒ½ä¼šå¿˜è®°ä¹‹å‰è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œè¿›è€Œä¸æ˜ç™½ä¸ºä»€ä¹ˆä¼šä½¿ç”¨é”™è¯¯çš„ GPUã€‚å› æ­¤ï¼Œåœ¨åŒä¸€å‘½ä»¤è¡Œä¸­ä»…ä¸ºç‰¹å®šè¿è¡Œè®¾ç½®ç¯å¢ƒå˜é‡æ˜¯ä¸€ç§å¸¸è§åšæ³•ï¼Œæ­£å¦‚æœ¬èŠ‚å¤§å¤šæ•°ç¤ºä¾‹æ‰€ç¤ºã€‚


**`CUDA_DEVICE_ORDER`**

è¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„ç¯å¢ƒå˜é‡ `CUDA_DEVICE_ORDER`ï¼Œç”¨äºæ§åˆ¶ç‰©ç†è®¾å¤‡çš„æ’åºæ–¹å¼ã€‚æœ‰ä¸¤ä¸ªé€‰æ‹©ï¼š

1. æŒ‰ PCIe æ€»çº¿ ID æ’åºï¼ˆä¸ nvidia-smi çš„é¡ºåºç›¸åŒ¹é…ï¼‰- è¿™æ˜¯é»˜è®¤é€‰é¡¹ã€‚


```bash
export CUDA_DEVICE_ORDER=PCI_BUS_ID
```

2. æŒ‰ GPU è®¡ç®—èƒ½åŠ›æ’åºã€‚

```bash
export CUDA_DEVICE_ORDER=FASTEST_FIRST
```

å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ ä¸éœ€è¦å…³å¿ƒè¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œä½†å¦‚æœä½ çš„è®¾ç½®ä¸å‡åŒ€ï¼Œé‚£ä¹ˆè¿™å°†éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚ï¼Œæ‚¨çš„æ—§ GPU å’Œæ–° GPU ç‰©ç†ä¸Šå®‰è£…åœ¨ä¸€èµ·ï¼Œä½†è®©é€Ÿåº¦è¾ƒæ…¢çš„æ—§å¡æ’åœ¨è¿è¡Œçš„ç¬¬ä¸€ä½ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯äº¤æ¢å¡çš„ä½ç½®ã€‚ä½†å¦‚æœä¸èƒ½äº¤æ¢å¡ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœè®¾å¤‡çš„æ•£çƒ­å—åˆ°å½±å“ï¼‰ï¼Œé‚£ä¹ˆè®¾ç½® `CUDA_DEVICE_ORDER=FASTEST_FIRST` å°†å§‹ç»ˆå°†è¾ƒæ–°ã€æ›´å¿«çš„å¡æ”¾åœ¨ç¬¬ä¸€ä½ã€‚ä½†è¿™å¯èƒ½ä¼šæœ‰ç‚¹æ··ä¹±ï¼Œå› ä¸º `nvidia-smi` ä»ç„¶ä¼šæŒ‰ç…§ PCIe é¡ºåºæŠ¥å‘Šå®ƒä»¬ã€‚

äº¤æ¢å¡çš„é¡ºåºçš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ï¼š


```bash
export CUDA_VISIBLE_DEVICES=1,0
```

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬åªä½¿ç”¨äº† 2 ä¸ª GPUï¼Œä½†æ˜¯å½“ç„¶ï¼Œå¯¹äºè®¡ç®—æœºä¸Šæœ‰çš„ä»»ä½•æ•°é‡çš„ GPUï¼Œéƒ½é€‚ç”¨ç›¸åŒçš„æ–¹æ³•ã€‚

æ­¤å¤–ï¼Œå¦‚æœä½ è®¾ç½®äº†è¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œæœ€å¥½å°†å…¶è®¾ç½®åœ¨ `~/.bashrc` æ–‡ä»¶æˆ–å…¶ä»–å¯åŠ¨é…ç½®æ–‡ä»¶ä¸­ï¼Œç„¶åå°±å¯ä»¥å¿˜è®°å®ƒäº†ã€‚


## Traineré›†æˆ

[`Trainer`] å·²ç»è¢«æ‰©å±•ï¼Œä»¥æ”¯æŒå¯èƒ½æ˜¾è‘—æé«˜è®­ç»ƒæ—¶é—´å¹¶é€‚åº”æ›´å¤§æ¨¡å‹çš„åº“ã€‚

ç›®å‰ï¼Œå®ƒæ”¯æŒç¬¬ä¸‰æ–¹è§£å†³æ–¹æ¡ˆ [DeepSpeed](https://github.com/microsoft/DeepSpeed) å’Œ [PyTorch FSDP](https://pytorch.org/docs/stable/fsdp.html)ï¼Œå®ƒä»¬å®ç°äº†è®ºæ–‡ [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, by Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He](https://arxiv.org/abs/1910.02054) çš„éƒ¨åˆ†å†…å®¹ã€‚

æˆªè‡³æ’°å†™æœ¬æ–‡ï¼Œæ­¤æä¾›çš„æ”¯æŒæ˜¯æ–°çš„ä¸”å®éªŒæ€§çš„ã€‚å°½ç®¡æˆ‘ä»¬æ¬¢è¿å›´ç»• DeepSpeed å’Œ PyTorch FSDP çš„issuesï¼Œä½†æˆ‘ä»¬ä¸å†æ”¯æŒ FairScale é›†æˆï¼Œå› ä¸ºå®ƒå·²ç»é›†æˆåˆ°äº† PyTorch ä¸»çº¿ï¼ˆå‚è§ [PyTorch FSDP é›†æˆ](#pytorch-fully-sharded-data-parallel)ï¼‰ã€‚


<a id='zero-install-notes'></a>

### CUDAæ‹“å±•å®‰è£…æ³¨æ„äº‹é¡¹


æ’°å†™æ—¶ï¼ŒDeepspeed éœ€è¦åœ¨ä½¿ç”¨ä¹‹å‰ç¼–è¯‘ CUDA C++ ä»£ç ã€‚

è™½ç„¶æ‰€æœ‰å®‰è£…é—®é¢˜éƒ½åº”é€šè¿‡ [Deepspeed](https://github.com/microsoft/DeepSpeed/issues) çš„ GitHub Issueså¤„ç†ï¼Œä½†åœ¨æ„å»ºä¾èµ–CUDA æ‰©å±•çš„ä»»ä½• PyTorch æ‰©å±•æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°ä¸€äº›å¸¸è§é—®é¢˜ã€‚

å› æ­¤ï¼Œå¦‚æœåœ¨æ‰§è¡Œä»¥ä¸‹æ“ä½œæ—¶é‡åˆ°ä¸ CUDA ç›¸å…³çš„æ„å»ºé—®é¢˜ï¼š


```bash
pip install deepspeed
```

è¯·é¦–å…ˆé˜…è¯»ä»¥ä¸‹è¯´æ˜ã€‚

åœ¨è¿™äº›è¯´æ˜ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†åœ¨ `pytorch` ä½¿ç”¨ CUDA `10.2` æ„å»ºæ—¶åº”é‡‡å–çš„æ“ä½œç¤ºä¾‹ã€‚å¦‚æœä½ çš„æƒ…å†µæœ‰æ‰€ä¸åŒï¼Œè¯·è®°å¾—å°†ç‰ˆæœ¬å·è°ƒæ•´ä¸ºæ‚¨æ‰€éœ€çš„ç‰ˆæœ¬ã€‚


#### å¯èƒ½çš„é—®é¢˜ #1

å°½ç®¡ PyTorch è‡ªå¸¦äº†å…¶è‡ªå·±çš„ CUDA å·¥å…·åŒ…ï¼Œä½†è¦æ„å»ºè¿™ä¸¤ä¸ªé¡¹ç›®ï¼Œä½ å¿…é¡»åœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£…ç›¸åŒç‰ˆæœ¬çš„ CUDAã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨ Python ç¯å¢ƒä¸­ä½¿ç”¨ `cudatoolkit==10.2` å®‰è£…äº† `pytorch`ï¼Œä½ è¿˜éœ€è¦åœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£… CUDA `10.2`ã€‚

ç¡®åˆ‡çš„ä½ç½®å¯èƒ½å› ç³»ç»Ÿè€Œå¼‚ï¼Œä½†åœ¨è®¸å¤š Unix ç³»ç»Ÿä¸Šï¼Œ`/usr/local/cuda-10.2` æ˜¯æœ€å¸¸è§çš„ä½ç½®ã€‚å½“ CUDA æ­£ç¡®è®¾ç½®å¹¶æ·»åŠ åˆ° `PATH` ç¯å¢ƒå˜é‡æ—¶ï¼Œå¯ä»¥é€šè¿‡æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ‰¾åˆ°å®‰è£…ä½ç½®ï¼š


```bash
which nvcc
```

å¦‚æœä½ å°šæœªåœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£… CUDAï¼Œè¯·é¦–å…ˆå®‰è£…ã€‚ä½ å¯ä»¥ä½¿ç”¨ä½ å–œæ¬¢çš„æœç´¢å¼•æ“æŸ¥æ‰¾è¯´æ˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Ubuntuï¼Œä½ å¯èƒ½æƒ³æœç´¢ï¼š[ubuntu cuda 10.2 install](https://www.google.com/search?q=ubuntu+cuda+10.2+install)ã€‚


#### å¯èƒ½çš„é—®é¢˜ #2

å¦ä¸€ä¸ªå¯èƒ½çš„å¸¸è§é—®é¢˜æ˜¯ä½ å¯èƒ½åœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£…äº†å¤šä¸ª CUDA å·¥å…·åŒ…ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½æœ‰ï¼š


```bash
/usr/local/cuda-10.2
/usr/local/cuda-11.0
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ éœ€è¦ç¡®ä¿ `PATH` å’Œ `LD_LIBRARY_PATH` ç¯å¢ƒå˜é‡åŒ…å«æ‰€éœ€ CUDA ç‰ˆæœ¬çš„æ­£ç¡®è·¯å¾„ã€‚é€šå¸¸ï¼Œè½¯ä»¶åŒ…å®‰è£…ç¨‹åºå°†è®¾ç½®è¿™äº›å˜é‡ä»¥åŒ…å«æœ€æ–°å®‰è£…çš„ç‰ˆæœ¬ã€‚å¦‚æœé‡åˆ°æ„å»ºå¤±è´¥çš„é—®é¢˜ï¼Œä¸”æ˜¯å› ä¸ºåœ¨æ•´ä¸ªç³»ç»Ÿå®‰è£…ä½†è½¯ä»¶ä»æ‰¾ä¸åˆ°æ­£ç¡®çš„ CUDA ç‰ˆæœ¬ï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦è°ƒæ•´è¿™ä¸¤ä¸ªç¯å¢ƒå˜é‡ã€‚

é¦–å…ˆï¼Œä½ ä»¥æŸ¥çœ‹å®ƒä»¬çš„å†…å®¹ï¼š


```bash
echo $PATH
echo $LD_LIBRARY_PATH
```

å› æ­¤ï¼Œæ‚¨å¯ä»¥äº†è§£å…¶ä¸­çš„å†…å®¹ã€‚

`LD_LIBRARY_PATH` å¯èƒ½æ˜¯ç©ºçš„ã€‚

`PATH` åˆ—å‡ºäº†å¯ä»¥æ‰¾åˆ°å¯æ‰§è¡Œæ–‡ä»¶çš„ä½ç½®ï¼Œè€Œ `LD_LIBRARY_PATH` ç”¨äºæŸ¥æ‰¾å…±äº«åº“ã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œè¾ƒæ—©çš„æ¡ç›®ä¼˜å…ˆäºè¾ƒåçš„æ¡ç›®ã€‚ `:` ç”¨äºåˆ†éš”å¤šä¸ªæ¡ç›®ã€‚

ç°åœ¨ï¼Œä¸ºäº†å‘Šè¯‰æ„å»ºç¨‹åºåœ¨å“ªé‡Œæ‰¾åˆ°ç‰¹å®šçš„ CUDA å·¥å…·åŒ…ï¼Œè¯·æ’å…¥æ‰€éœ€çš„è·¯å¾„ï¼Œè®©å…¶é¦–å…ˆåˆ—å‡ºï¼š


```bash
export PATH=/usr/local/cuda-10.2/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH
```

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ²¡æœ‰è¦†ç›–ç°æœ‰å€¼ï¼Œè€Œæ˜¯åœ¨å‰é¢æ·»åŠ æ–°çš„å€¼ã€‚

å½“ç„¶ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´ç‰ˆæœ¬å·å’Œå®Œæ•´è·¯å¾„ã€‚æ£€æŸ¥ä½ åˆ†é…çš„ç›®å½•æ˜¯å¦å®é™…å­˜åœ¨ã€‚`lib64` å­ç›®å½•æ˜¯å„ç§ CUDA `.so` å¯¹è±¡ï¼ˆå¦‚ `libcudart.so`ï¼‰çš„ä½ç½®ï¼Œè¿™ä¸ªåå­—å¯èƒ½åœ¨ä½ çš„ç³»ç»Ÿä¸­æ˜¯ä¸åŒçš„ï¼Œå¦‚æœæ˜¯ï¼Œè¯·è°ƒæ•´ä»¥åæ˜ å®é™…æƒ…å†µã€‚


#### å¯èƒ½çš„é—®é¢˜ #3

ä¸€äº›è¾ƒæ—§çš„ CUDA ç‰ˆæœ¬å¯èƒ½ä¼šæ‹’ç»ä½¿ç”¨æ›´æ–°çš„ç¼–è¯‘å™¨ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½æœ‰ `gcc-9`ï¼Œä½† CUDA å¯èƒ½éœ€è¦ `gcc-7`ã€‚

æœ‰å„ç§æ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

å¦‚æœä½ å¯ä»¥å®‰è£…æœ€æ–°çš„ CUDA å·¥å…·åŒ…ï¼Œé€šå¸¸å®ƒåº”è¯¥æ”¯æŒæ›´æ–°çš„ç¼–è¯‘å™¨ã€‚

æˆ–è€…ï¼Œä½ å¯ä»¥åœ¨å·²ç»æ‹¥æœ‰çš„ç¼–è¯‘å™¨ç‰ˆæœ¬ä¹‹å¤–å®‰è£…è¾ƒä½ç‰ˆæœ¬ï¼Œæˆ–è€…ä½ å¯èƒ½å·²ç»å®‰è£…äº†å®ƒä½†å®ƒä¸æ˜¯é»˜è®¤çš„ç¼–è¯‘å™¨ï¼Œå› æ­¤æ„å»ºç³»ç»Ÿæ— æ³•æ‰¾åˆ°å®ƒã€‚å¦‚æœä½ å·²ç»å®‰è£…äº† `gcc-7` ä½†æ„å»ºç³»ç»Ÿæ‰¾ä¸åˆ°å®ƒï¼Œä»¥ä¸‹æ“ä½œå¯èƒ½ä¼šè§£å†³é—®é¢˜ï¼š


```bash
sudo ln -s /usr/bin/gcc-7  /usr/local/cuda-10.2/bin/gcc
sudo ln -s /usr/bin/g++-7  /usr/local/cuda-10.2/bin/g++
```

è¿™é‡Œï¼Œæˆ‘ä»¬æ­£åœ¨ä» `/usr/local/cuda-10.2/bin/gcc` åˆ›å»ºåˆ° `gcc-7` çš„è½¯é“¾æ¥ï¼Œç”±äº `/usr/local/cuda-10.2/bin/` åº”è¯¥åœ¨ `PATH` ç¯å¢ƒå˜é‡ä¸­ï¼ˆå‚è§å‰ä¸€ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼‰ï¼Œå®ƒåº”è¯¥èƒ½å¤Ÿæ‰¾åˆ° `gcc-7`ï¼ˆå’Œ `g++7`ï¼‰ï¼Œç„¶åæ„å»ºå°†æˆåŠŸã€‚

ä¸å¾€å¸¸ä¸€æ ·ï¼Œè¯·ç¡®ä¿ç¼–è¾‘ç¤ºä¾‹ä¸­çš„è·¯å¾„ä»¥åŒ¹é…ä½ çš„æƒ…å†µã€‚



### PyTorchå®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼ˆFSDP)

ä¸ºäº†åŠ é€Ÿåœ¨æ›´å¤§æ‰¹æ¬¡å¤§å°ä¸Šè®­ç»ƒåºå¤§æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®Œå…¨åˆ†ç‰‡çš„æ•°æ®å¹¶è¡Œæ¨¡å‹ã€‚è¿™ç§æ•°æ®å¹¶è¡ŒèŒƒä¾‹é€šè¿‡å¯¹ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œå‚æ•°è¿›è¡Œåˆ†ç‰‡ï¼Œå®ç°äº†åœ¨æ›´å¤šæ•°æ®å’Œæ›´å¤§æ¨¡å‹ä¸Šçš„è®­ç»ƒã€‚è¦äº†è§£æ›´å¤šä¿¡æ¯ä»¥åŠå…¶ä¼˜åŠ¿ï¼Œè¯·æŸ¥çœ‹[å®Œå…¨åˆ†ç‰‡çš„æ•°æ®å¹¶è¡Œåšå®¢](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/)ã€‚æˆ‘ä»¬å·²ç»é›†æˆäº†æœ€æ–°çš„PyTorchå®Œå…¨åˆ†ç‰‡çš„æ•°æ®å¹¶è¡Œï¼ˆFSDPï¼‰è®­ç»ƒåŠŸèƒ½ã€‚æ‚¨åªéœ€é€šè¿‡é…ç½®å¯ç”¨å®ƒã€‚

**FSDPæ”¯æŒæ‰€éœ€çš„PyTorchç‰ˆæœ¬**: PyTorch Nightlyï¼ˆæˆ–è€…å¦‚æœä½ åœ¨å‘å¸ƒåé˜…è¯»è¿™ä¸ªï¼Œä½¿ç”¨1.12.0ç‰ˆæœ¬ï¼Œå› ä¸ºå¸¦æœ‰æ¿€æ´»çš„FSDPçš„æ¨¡å‹ä¿å­˜ä»…åœ¨æœ€è¿‘çš„ä¿®å¤ä¸­å¯ç”¨ã€‚


**ç”¨æ³•**:

- å¦‚æœä½ å°šæœªä½¿ç”¨è¿‡åˆ†å¸ƒå¼å¯åŠ¨å™¨ï¼Œç¡®ä¿ä½ å·²ç»æ·»åŠ äº†å®ƒ `-m torch.distributed.launch --nproc_per_node=NUMBER_OF_GPUS_YOU_HAVE`ã€‚

- **åˆ†ç‰‡ç­–ç•¥**ï¼š
  - FULL_SHARDï¼šåœ¨æ•°æ®å¹¶è¡Œçº¿ç¨‹/GPUä¹‹é—´ï¼Œå¯¹ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œæ¨¡å‹å‚æ•°è¿›è¡Œåˆ†ç‰‡ã€‚
    ä¸ºæ­¤ï¼Œè¯·åœ¨å‘½ä»¤è¡Œå‚æ•°ä¸­æ·»åŠ  `--fsdp full_shard`ã€‚
  - SHARD_GRAD_OPï¼šåœ¨æ•°æ®å¹¶è¡Œçº¿ç¨‹/GPUä¹‹é—´å¯¹ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦è¿›è¡Œåˆ†ç‰‡ã€‚
    ä¸ºæ­¤ï¼Œè¯·åœ¨å‘½ä»¤è¡Œå‚æ•°ä¸­æ·»åŠ  `--fsdp shard_grad_op`ã€‚
  - NO_SHARDï¼šä¸è¿›è¡Œåˆ†ç‰‡ã€‚ä¸ºæ­¤ï¼Œè¯·åœ¨å‘½ä»¤è¡Œå‚æ•°ä¸­æ·»åŠ  `--fsdp no_shard`ã€‚
- è¦å°†å‚æ•°å’Œæ¢¯åº¦å¸è½½åˆ°CPUï¼Œæ·»åŠ  `--fsdp "full_shard offload"` æˆ– `--fsdp "shard_grad_op offload"` åˆ°å‘½ä»¤è¡Œå‚æ•°ä¸­ã€‚
- è¦ä½¿ç”¨ `default_auto_wrap_policy` è‡ªåŠ¨é€’å½’åœ°ç”¨FSDPåŒ…è£…å±‚ï¼Œè¯·æ·»åŠ  `--fsdp "full_shard auto_wrap"` æˆ– `--fsdp "shard_grad_op auto_wrap"` åˆ°å‘½ä»¤è¡Œå‚æ•°ä¸­ã€‚
- è¦åŒæ—¶å¯ç”¨CPUå¸è½½å’Œè‡ªåŠ¨åŒ…è£…å±‚å·¥å…·ï¼Œè¯·æ·»åŠ  `--fsdp "full_shard offload auto_wrap"` æˆ– `--fsdp "shard_grad_op offload auto_wrap"` åˆ°å‘½ä»¤è¡Œå‚æ•°ä¸­ã€‚
- å…¶ä½™çš„FSDPé…ç½®é€šè¿‡ `--fsdp_config <path_to_fsdp_config.json>` ä¼ é€’ã€‚å®ƒå¯ä»¥æ˜¯FSDP jsoné…ç½®æ–‡ä»¶çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œ`fsdp_config.json`ï¼‰æˆ–å·²åŠ è½½çš„jsonæ–‡ä»¶ä½œä¸º `dict`ã€‚
  - å¦‚æœå¯ç”¨äº†è‡ªåŠ¨åŒ…è£…ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨åŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥æˆ–åŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ã€‚
    - å¯¹äºåŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œå»ºè®®åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š `fsdp_transformer_layer_cls_to_wrap`ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™é»˜è®¤å€¼ä¸º `model._no_split_modules`ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚è¿™å°†æŒ‡å®šè¦åŒ…è£…çš„transformerå±‚ç±»åï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ [`BertLayer`]ã€[`GPTJBlock`]ã€[`T5Block`] ç­‰ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºå…±äº«æƒé‡çš„å­æ¨¡å—ï¼ˆä¾‹å¦‚ï¼Œembeddingå±‚ï¼‰ä¸åº”æœ€ç»ˆå‡ºç°åœ¨ä¸åŒçš„FSDPåŒ…è£…å•å…ƒä¸­ã€‚ä½¿ç”¨æ­¤ç­–ç•¥ï¼Œæ¯ä¸ªåŒ…è£…çš„å—å°†åŒ…å«å¤šå¤´æ³¨æ„åŠ›å’Œåé¢çš„å‡ ä¸ªMLPå±‚ã€‚å‰©ä½™çš„å±‚ï¼ŒåŒ…æ‹¬å…±äº«çš„embeddingå±‚ï¼Œéƒ½å°†è¢«æ–¹ä¾¿åœ°åŒ…è£…åœ¨åŒä¸€ä¸ªæœ€å¤–å±‚çš„FSDPå•å…ƒä¸­ã€‚å› æ­¤ï¼Œå¯¹äºåŸºäºtransformerçš„æ¨¡å‹ï¼Œè¯·ä½¿ç”¨è¿™ä¸ªæ–¹æ³•ã€‚
    - å¯¹äºåŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  `fsdp_min_num_params`ã€‚å®ƒæŒ‡å®šäº†FSDPè¿›è¡Œè‡ªåŠ¨åŒ…è£…çš„æœ€å°å‚æ•°æ•°é‡ã€‚
  - å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š `fsdp_backward_prefetch`ã€‚å®ƒæ§åˆ¶ä½•æ—¶é¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚`backward_pre` å’Œ `backward_pos` æ˜¯å¯ç”¨çš„é€‰é¡¹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… `torch.distributed.fsdp.fully_sharded_data_parallel.BackwardPrefetch`
  - å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š `fsdp_forward_prefetch`ã€‚å®ƒæ§åˆ¶ä½•æ—¶é¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚å¦‚æœæ˜¯`"True"`ï¼Œåœ¨æ‰§è¡Œå‰å‘ä¼ é€’æ—¶ï¼ŒFSDPæ˜ç¡®åœ°é¢„å–ä¸‹ä¸€æ¬¡å³å°†å‘ç”Ÿçš„å…¨å±€èšé›†ã€‚
  - å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š `limit_all_gathers`ã€‚å¦‚æœæ˜¯`"True"`ï¼ŒFSDPæ˜ç¡®åœ°åŒæ­¥CPUçº¿ç¨‹ï¼Œä»¥é˜²æ­¢å¤ªå¤šçš„è¿›è¡Œä¸­çš„å…¨å±€èšé›†ã€‚
  - å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š `activation_checkpointing`ã€‚å¦‚æœæ˜¯`"True"`ï¼ŒFSDP activation checkpointæ˜¯ä¸€ç§é€šè¿‡æ¸…é™¤æŸäº›å±‚çš„æ¿€æ´»å€¼å¹¶åœ¨åå‘ä¼ é€’æœŸé—´é‡æ–°è®¡ç®—å®ƒä»¬æ¥å‡å°‘å†…å­˜ä½¿ç”¨çš„æŠ€æœ¯ã€‚å®é™…ä¸Šï¼Œè¿™ä»¥æ›´å¤šçš„è®¡ç®—æ—¶é—´ä¸ºä»£ä»·å‡å°‘äº†å†…å­˜ä½¿ç”¨ã€‚


**éœ€è¦æ³¨æ„å‡ ä¸ªæ³¨æ„äº‹é¡¹**
- å®ƒä¸ `generate` ä¸å…¼å®¹ï¼Œå› æ­¤ä¸æ‰€æœ‰seq2seq/clmè„šæœ¬ï¼ˆç¿»è¯‘/æ‘˜è¦/clmç­‰ï¼‰ä¸­çš„ `--predict_with_generate` ä¸å…¼å®¹ã€‚è¯·å‚é˜…issue[#21667](https://github.com/huggingface/transformers/issues/21667)ã€‚


### PyTorch/XLA å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ

å¯¹äºæ‰€æœ‰TPUç”¨æˆ·ï¼Œæœ‰ä¸ªå¥½æ¶ˆæ¯ï¼PyTorch/XLAç°åœ¨æ”¯æŒFSDPã€‚æ‰€æœ‰æœ€æ–°çš„å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼ˆFSDPï¼‰è®­ç»ƒéƒ½å—æ”¯æŒã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[åœ¨äº‘ç«¯TPUä¸Šä½¿ç”¨FSDPæ‰©å±•PyTorchæ¨¡å‹](https://pytorch.org/blog/scaling-pytorch-models-on-cloud-tpus-with-fsdp/)å’Œ[PyTorch/XLA FSDPçš„å®ç°](https://github.com/pytorch/xla/tree/master/torch_xla/distributed/fsdp)ã€‚ä½¿ç”¨å®ƒåªéœ€é€šè¿‡é…ç½®å¯ç”¨ã€‚

**éœ€è¦çš„ PyTorch/XLA ç‰ˆæœ¬ä»¥æ”¯æŒ FSDP**ï¼š>=2.0

**ç”¨æ³•**ï¼š

ä¼ é€’ `--fsdp "full shard"`ï¼ŒåŒæ—¶å¯¹ `--fsdp_config <path_to_fsdp_config.json>` è¿›è¡Œä»¥ä¸‹æ›´æ”¹ï¼š
- `xla` åº”è®¾ç½®ä¸º `True` ä»¥å¯ç”¨ PyTorch/XLA FSDPã€‚
- `xla_fsdp_settings` çš„å€¼æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå­˜å‚¨ XLA FSDP å°è£…å‚æ•°ã€‚å®Œæ•´çš„é€‰é¡¹åˆ—è¡¨ï¼Œè¯·å‚è§[æ­¤å¤„](https://github.com/pytorch/xla/blob/master/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py)ã€‚
- `xla_fsdp_grad_ckpt`ã€‚å½“ `True` æ—¶ï¼Œåœ¨æ¯ä¸ªåµŒå¥—çš„ XLA FSDP å°è£…å±‚ä¸Šä½¿ç”¨æ¢¯åº¦checkpointã€‚è¯¥è®¾ç½®åªèƒ½åœ¨å°† xla æ ‡å¿—è®¾ç½®ä¸º trueï¼Œå¹¶é€šè¿‡ `fsdp_min_num_params` æˆ– `fsdp_transformer_layer_cls_to_wrap` æŒ‡å®šè‡ªåŠ¨åŒ…è£…ç­–ç•¥æ—¶ä½¿ç”¨ã€‚
- æ‚¨å¯ä»¥ä½¿ç”¨åŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥æˆ–åŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ã€‚
  - å¯¹äºåŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œå»ºè®®åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š `fsdp_transformer_layer_cls_to_wrap`ã€‚å¦‚æœæœªæŒ‡å®šï¼Œé»˜è®¤å€¼ä¸º `model._no_split_modules`ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚è¿™æŒ‡å®šäº†è¦åŒ…è£…çš„transformerå±‚ç±»ååˆ—è¡¨ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ [`BertLayer`]ã€[`GPTJBlock`]ã€[`T5Block`] ç­‰ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºå…±äº«æƒé‡çš„å­æ¨¡å—ï¼ˆä¾‹å¦‚ï¼Œembeddingå±‚ï¼‰ä¸åº”æœ€ç»ˆå‡ºç°åœ¨ä¸åŒçš„FSDPåŒ…è£…å•å…ƒä¸­ã€‚ä½¿ç”¨æ­¤ç­–ç•¥ï¼Œæ¯ä¸ªåŒ…è£…çš„å—å°†åŒ…å«å¤šå¤´æ³¨æ„åŠ›å’Œåé¢çš„å‡ ä¸ªMLPå±‚ã€‚å‰©ä½™çš„å±‚ï¼ŒåŒ…æ‹¬å…±äº«çš„embeddingå±‚ï¼Œéƒ½å°†è¢«æ–¹ä¾¿åœ°åŒ…è£…åœ¨åŒä¸€ä¸ªæœ€å¤–å±‚çš„FSDPå•å…ƒä¸­ã€‚å› æ­¤ï¼Œå¯¹äºåŸºäºtransformerçš„æ¨¡å‹ï¼Œè¯·ä½¿ç”¨è¿™ä¸ªæ–¹æ³•ã€‚
  - å¯¹äºåŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  `fsdp_min_num_params`ã€‚å®ƒæŒ‡å®šäº†è‡ªåŠ¨åŒ…è£…çš„ FSDP çš„æœ€å°å‚æ•°æ•°é‡ã€‚


### åœ¨ Mac ä¸Šä½¿ç”¨ Trainer è¿›è¡ŒåŠ é€Ÿçš„ PyTorch è®­ç»ƒ

éšç€ PyTorch v1.12 ç‰ˆæœ¬çš„å‘å¸ƒï¼Œå¼€å‘äººå‘˜å’Œç ”ç©¶äººå‘˜å¯ä»¥åˆ©ç”¨ Apple Silicon GPU è¿›è¡Œæ˜¾è‘—æ›´å¿«çš„æ¨¡å‹è®­ç»ƒã€‚è¿™ä½¿å¾—å¯ä»¥åœ¨ Mac ä¸Šæœ¬åœ°æ‰§è¡ŒåŸå‹è®¾è®¡å’Œå¾®è°ƒç­‰æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ã€‚Apple çš„ Metal Performance Shadersï¼ˆMPSï¼‰ä½œä¸º PyTorch çš„åç«¯å®ç°äº†è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æ–°çš„ `"mps"` è®¾å¤‡æ¥ä½¿ç”¨ã€‚
è¿™å°†åœ¨ MPS å›¾å½¢æ¡†æ¶ä¸Šæ˜ å°„è®¡ç®—å›¾å’Œç¥ç»å›¾å…ƒï¼Œå¹¶ä½¿ç”¨ MPS æä¾›çš„ä¼˜åŒ–å†…æ ¸ã€‚æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…å®˜æ–¹æ–‡æ¡£ [Introducing Accelerated PyTorch Training on Mac](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/) å’Œ [MPS BACKEND](https://pytorch.org/docs/stable/notes/mps.html)ã€‚


<Tip warning={false}>

æˆ‘ä»¬å¼ºçƒˆå»ºè®®åœ¨ä½ çš„ MacOS æœºå™¨ä¸Šå®‰è£… PyTorch >= 1.13ï¼ˆåœ¨æ’°å†™æœ¬æ–‡æ—¶ä¸ºæœ€æ–°ç‰ˆæœ¬ï¼‰ã€‚å¯¹äºåŸºäº transformer çš„æ¨¡å‹ï¼Œ å®ƒæä¾›ä¸æ¨¡å‹æ­£ç¡®æ€§å’Œæ€§èƒ½æ”¹è¿›ç›¸å…³çš„é‡å¤§ä¿®å¤ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[pytorch/pytorch#82707](https://github.com/pytorch/pytorch/issues/82707)ã€‚

</Tip>

**ä½¿ç”¨ Apple Silicon èŠ¯ç‰‡è¿›è¡Œè®­ç»ƒå’Œæ¨ç†çš„å¥½å¤„**

1. ä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨æœ¬åœ°è®­ç»ƒæ›´å¤§çš„ç½‘ç»œæˆ–æ‰¹é‡æ•°æ®ã€‚
2. ç”±äºç»Ÿä¸€å†…å­˜æ¶æ„ï¼Œå‡å°‘æ•°æ®æ£€ç´¢å»¶è¿Ÿï¼Œå¹¶ä¸º GPU æä¾›å¯¹å®Œæ•´å†…å­˜å­˜å‚¨çš„ç›´æ¥è®¿é—®ã€‚ä»è€Œæé«˜ç«¯åˆ°ç«¯æ€§èƒ½ã€‚
3. é™ä½ä¸åŸºäºäº‘çš„å¼€å‘æˆ–éœ€è¦é¢å¤–æœ¬åœ° GPU çš„æˆæœ¬ã€‚

**å…ˆå†³æ¡ä»¶**ï¼šè¦å®‰è£…å¸¦æœ‰ mps æ”¯æŒçš„ torchï¼Œè¯·æŒ‰ç…§è¿™ç¯‡ç²¾å½©çš„ Medium æ–‡ç« æ“ä½œ [GPU-Acceleration Comes to PyTorch on M1 Macs](https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1)ã€‚

**ç”¨æ³•**ï¼š
å¦‚æœå¯ç”¨ï¼Œ`mps` è®¾å¤‡å°†é»˜è®¤ä½¿ç”¨ï¼Œç±»ä¼¼äºä½¿ç”¨ `cuda` è®¾å¤‡çš„æ–¹å¼ã€‚å› æ­¤ï¼Œç”¨æˆ·æ— éœ€é‡‡å–ä»»ä½•æ“ä½œã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åœ¨ Apple Silicon GPU ä¸Šè¿è¡Œå®˜æ–¹çš„ Glue æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼ˆä»æ ¹æ–‡ä»¶å¤¹è¿è¡Œï¼‰ï¼š

```bash
export TASK_NAME=mrpc

python examples/pytorch/text-classification/run_glue.py \
  --model_name_or_path google-bert/bert-base-cased \
  --task_name $TASK_NAME \
  --do_train \
  --do_eval \
  --max_seq_length 128 \
  --per_device_train_batch_size 32 \
  --learning_rate 2e-5 \
  --num_train_epochs 3 \
  --output_dir /tmp/$TASK_NAME/ \
  --overwrite_output_dir
```

**éœ€è¦æ³¨æ„çš„ä¸€äº›æ³¨æ„äº‹é¡¹**

1. ä¸€äº› PyTorch æ“ä½œå°šæœªåœ¨ mps ä¸­å®ç°ï¼Œå°†å¼•å‘é”™è¯¯ã€‚è§£å†³æ­¤é—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡ `PYTORCH_ENABLE_MPS_FALLBACK=1`ï¼Œå®ƒå°†æŠŠè¿™äº›æ“ä½œå›é€€åˆ° CPU è¿›è¡Œã€‚ç„¶è€Œï¼Œå®ƒä»ç„¶ä¼šæŠ›å‡º UserWarning ä¿¡æ¯ã€‚
2. åˆ†å¸ƒå¼è®¾ç½® `gloo` å’Œ `nccl` åœ¨ `mps` è®¾å¤‡ä¸Šä¸èµ·ä½œç”¨ã€‚è¿™æ„å‘³ç€å½“å‰åªèƒ½ä½¿ç”¨ `mps` è®¾å¤‡ç±»å‹çš„å•ä¸ª GPUã€‚

æœ€åï¼Œè¯·è®°ä½ï¼ŒğŸ¤— `Trainer` ä»…é›†æˆäº† MPS åç«¯ï¼Œå› æ­¤å¦‚æœä½ åœ¨ä½¿ç”¨ MPS åç«¯æ—¶é‡åˆ°ä»»ä½•é—®é¢˜æˆ–æœ‰ç–‘é—®ï¼Œè¯·åœ¨ [PyTorch GitHub](https://github.com/pytorch/pytorch/issues) ä¸Šæäº¤é—®é¢˜ã€‚


## é€šè¿‡ Accelerate Launcher ä½¿ç”¨ Trainer

Accelerate ç°åœ¨æ”¯æŒ Trainerã€‚ç”¨æˆ·å¯ä»¥æœŸå¾…ä»¥ä¸‹å†…å®¹ï¼š
- ä»–ä»¬å¯ä»¥ç»§ç»­ä½¿ç”¨ Trainer çš„è¿­ä»£ï¼Œå¦‚ FSDPã€DeepSpeed ç­‰ï¼Œè€Œæ— éœ€åšä»»ä½•æ›´æ”¹ã€‚
- ç°åœ¨å¯ä»¥åœ¨ Trainer ä¸­ä½¿ç”¨ Accelerate Launcherï¼ˆå»ºè®®ä½¿ç”¨ï¼‰ã€‚

é€šè¿‡ Accelerate Launcher ä½¿ç”¨ Trainer çš„æ­¥éª¤ï¼š
1. ç¡®ä¿å·²å®‰è£… ğŸ¤— Accelerateï¼Œæ— è®ºå¦‚ä½•ï¼Œå¦‚æœæ²¡æœ‰å®ƒï¼Œä½ æ— æ³•ä½¿ç”¨ `Trainer`ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·æ‰§è¡Œ `pip install accelerate`ã€‚ä½ å¯èƒ½è¿˜éœ€è¦æ›´æ–° Accelerate çš„ç‰ˆæœ¬ï¼š`pip install accelerate --upgrade`ã€‚
2. è¿è¡Œ `accelerate config` å¹¶å¡«å†™é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›åŠ é€Ÿé…ç½®çš„ç¤ºä¾‹ï¼š
   
  a. DDP å¤šèŠ‚ç‚¹å¤š GPU é…ç½®ï¼š

    ```yaml
    compute_environment: LOCAL_MACHINE                                                                                             
    distributed_type: MULTI_GPU                                                                                                    
    downcast_bf16: 'no'
    gpu_ids: all
    machine_rank: 0 #change rank as per the node
    main_process_ip: 192.168.20.1
    main_process_port: 9898
    main_training_function: main
    mixed_precision: fp16
    num_machines: 2
    num_processes: 8
    rdzv_backend: static
    same_network: true
    tpu_env: []
    tpu_use_cluster: false
    tpu_use_sudo: false
    use_cpu: false
    ```

  b. FSDP é…ç½®ï¼š

    ```yaml
    compute_environment: LOCAL_MACHINE
    distributed_type: FSDP
    downcast_bf16: 'no'
    fsdp_config:
      fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
      fsdp_backward_prefetch_policy: BACKWARD_PRE
      fsdp_forward_prefetch: true
      fsdp_offload_params: false
      fsdp_sharding_strategy: 1
      fsdp_state_dict_type: FULL_STATE_DICT
      fsdp_sync_module_states: true
      fsdp_transformer_layer_cls_to_wrap: BertLayer
      fsdp_use_orig_params: true
    machine_rank: 0
    main_training_function: main
    mixed_precision: bf16
    num_machines: 1
    num_processes: 2
    rdzv_backend: static
    same_network: true
    tpu_env: []
    tpu_use_cluster: false
    tpu_use_sudo: false
    use_cpu: false
    ```
 
  c. æŒ‡å‘æ–‡ä»¶çš„ DeepSpeed é…ç½®ï¼š

    ```yaml
    compute_environment: LOCAL_MACHINE
    deepspeed_config:
      deepspeed_config_file: /home/user/configs/ds_zero3_config.json
      zero3_init_flag: true
    distributed_type: DEEPSPEED
    downcast_bf16: 'no'
    machine_rank: 0
    main_training_function: main
    num_machines: 1
    num_processes: 4
    rdzv_backend: static
    same_network: true
    tpu_env: []
    tpu_use_cluster: false
    tpu_use_sudo: false
    use_cpu: false
    ```

  d. ä½¿ç”¨ accelerate æ’ä»¶çš„ DeepSpeed é…ç½®ï¼š

    ```yaml
    compute_environment: LOCAL_MACHINE                                                                                             
    deepspeed_config:                                                                                                              
      gradient_accumulation_steps: 1
      gradient_clipping: 0.7
      offload_optimizer_device: cpu
      offload_param_device: cpu
      zero3_init_flag: true
      zero_stage: 2
    distributed_type: DEEPSPEED
    downcast_bf16: 'no'
    machine_rank: 0
    main_training_function: main
    mixed_precision: bf16
    num_machines: 1
    num_processes: 4
    rdzv_backend: static
    same_network: true
    tpu_env: []
    tpu_use_cluster: false
    tpu_use_sudo: false
    use_cpu: false
    ```

3. ä½¿ç”¨accelerateé…ç½®æ–‡ä»¶å‚æ•°æˆ–å¯åŠ¨å™¨å‚æ•°ä»¥å¤–çš„å‚æ•°è¿è¡ŒTrainerè„šæœ¬ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨ä¸Šè¿°FSDPé…ç½®ä»accelerateå¯åŠ¨å™¨è¿è¡Œ`run_glue.py`çš„ç¤ºä¾‹ã€‚

```bash
cd transformers

accelerate launch \
./examples/pytorch/text-classification/run_glue.py \
--model_name_or_path google-bert/bert-base-cased \
--task_name $TASK_NAME \
--do_train \
--do_eval \
--max_seq_length 128 \
--per_device_train_batch_size 16 \
--learning_rate 5e-5 \
--num_train_epochs 3 \
--output_dir /tmp/$TASK_NAME/ \
--overwrite_output_dir
```

4. ä½ ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨`accelerate launch`çš„cmdå‚æ•°ã€‚ä¸Šé¢çš„ç¤ºä¾‹å°†æ˜ å°„åˆ°ï¼š

```bash
cd transformers

accelerate launch --num_processes=2 \
--use_fsdp \
--mixed_precision=bf16 \
--fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP  \
--fsdp_transformer_layer_cls_to_wrap="BertLayer" \
--fsdp_sharding_strategy=1 \
--fsdp_state_dict_type=FULL_STATE_DICT \
./examples/pytorch/text-classification/run_glue.py
--model_name_or_path google-bert/bert-base-cased \
--task_name $TASK_NAME \
--do_train \
--do_eval \
--max_seq_length 128 \
--per_device_train_batch_size 16 \
--learning_rate 5e-5 \
--num_train_epochs 3 \
--output_dir /tmp/$TASK_NAME/ \
--overwrite_output_dir
```

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… ğŸ¤— Accelerate CLI æŒ‡å—ï¼š[å¯åŠ¨æ‚¨çš„ ğŸ¤— Accelerate è„šæœ¬](https://huggingface.co/docs/accelerate/basic_tutorials/launch)ã€‚

å·²ç§»åŠ¨çš„éƒ¨åˆ†ï¼š

[ <a href="./deepspeed#deepspeed-trainer-integration">DeepSpeed</a><a id="deepspeed"></a> | <a href="./deepspeed#deepspeed-installation">Installation</a><a id="installation"></a> | <a href="./deepspeed#deepspeed-multi-gpu">Deployment with multiple GPUs</a><a id="deployment-with-multiple-gpus"></a> | <a href="./deepspeed#deepspeed-one-gpu">Deployment with one GPU</a><a id="deployment-with-one-gpu"></a> | <a href="./deepspeed#deepspeed-notebook">Deployment in Notebooks</a><a id="deployment-in-notebooks"></a> | <a href="./deepspeed#deepspeed-config">Configuration</a><a id="configuration"></a> | <a href="./deepspeed#deepspeed-config-passing">Passing Configuration</a><a id="passing-configuration"></a> | <a href="./deepspeed#deepspeed-config-shared">Shared Configuration</a><a id="shared-configuration"></a> | <a href="./deepspeed#deepspeed-zero">ZeRO</a><a id="zero"></a> | <a href="./deepspeed#deepspeed-zero2-config">ZeRO-2 Config</a><a id="zero-2-config"></a> | <a href="./deepspeed#deepspeed-zero3-config">ZeRO-3 Config</a><a id="zero-3-config"></a> | <a href="./deepspeed#deepspeed-nvme">NVMe Support</a><a id="nvme-support"></a> | <a href="./deepspeed#deepspeed-zero2-zero3-performance">ZeRO-2 vs ZeRO-3 Performance</a><a id="zero-2-vs-zero-3-performance"></a> | <a href="./deepspeed#deepspeed-zero2-example">ZeRO-2 Example</a><a id="zero-2-example"></a> | <a href="./deepspeed#deepspeed-zero3-example">ZeRO-3 Example</a><a id="zero-3-example"></a> | <a href="./deepspeed#deepspeed-optimizer">Optimizer</a><a id="optimizer"></a> | <a href="./deepspeed#deepspeed-scheduler">Scheduler</a><a id="scheduler"></a> | <a href="./deepspeed#deepspeed-fp32">fp32 Precision</a><a id="fp32-precision"></a> | <a href="./deepspeed#deepspeed-amp">Automatic Mixed Precision</a><a id="automatic-mixed-precision"></a> | <a href="./deepspeed#deepspeed-bs">Batch Size</a><a id="batch-size"></a> | <a href="./deepspeed#deepspeed-grad-acc">Gradient Accumulation</a><a id="gradient-accumulation"></a> | <a href="./deepspeed#deepspeed-grad-clip">Gradient Clipping</a><a id="gradient-clipping"></a> | <a href="./deepspeed#deepspeed-weight-extraction">Getting The Model Weights Out</a><a id="getting-the-model-weights-out"></a>]


## é€šè¿‡ NEFTune æå‡å¾®è°ƒæ€§èƒ½

NEFTune æ˜¯ä¸€ç§æå‡èŠå¤©æ¨¡å‹æ€§èƒ½çš„æŠ€æœ¯ï¼Œç”± Jain ç­‰äººåœ¨è®ºæ–‡â€œNEFTune: Noisy Embeddings Improve Instruction Finetuningâ€ ä¸­å¼•å…¥ã€‚è¯¥æŠ€æœ¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‘embeddingå‘é‡æ·»åŠ å™ªéŸ³ã€‚æ ¹æ®è®ºæ–‡æ‘˜è¦ï¼š

> ä½¿ç”¨ Alpaca å¯¹ LLaMA-2-7B è¿›è¡Œæ ‡å‡†å¾®è°ƒï¼Œå¯ä»¥åœ¨ AlpacaEval ä¸Šè¾¾åˆ° 29.79%ï¼Œè€Œä½¿ç”¨å¸¦æœ‰å™ªéŸ³embeddingçš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½æé«˜è‡³ 64.69%ã€‚NEFTune è¿˜åœ¨modern instructionæ•°æ®é›†ä¸Šå¤§å¤§ä¼˜äºåŸºçº¿ã€‚Evol-Instruct è®­ç»ƒçš„æ¨¡å‹è¡¨ç°æé«˜äº† 10%ï¼ŒShareGPT æé«˜äº† 8%ï¼ŒOpenPlatypus æé«˜äº† 8%ã€‚å³ä½¿åƒ LLaMA-2-Chat è¿™æ ·é€šè¿‡ RLHF è¿›ä¸€æ­¥ç»†åŒ–çš„å¼ºå¤§æ¨¡å‹ï¼Œé€šè¿‡ NEFTune çš„é¢å¤–è®­ç»ƒä¹Ÿèƒ½å—ç›Šã€‚

<div style="text-align: center">
<img src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/neft-screenshot.png">
</div>

è¦åœ¨ `Trainer` ä¸­ä½¿ç”¨å®ƒï¼Œåªéœ€åœ¨åˆ›å»º `TrainingArguments` å®ä¾‹æ—¶ä¼ é€’ `neftune_noise_alpha`ã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†é¿å…ä»»ä½•æ„å¤–è¡Œä¸ºï¼ŒNEFTuneåœ¨è®­ç»ƒåè¢«ç¦æ­¢ï¼Œä»¥æ­¤æ¢å¤åŸå§‹çš„embeddingå±‚ã€‚

```python
from transformers import Trainer, TrainingArguments

args = TrainingArguments(..., neftune_noise_alpha=0.1)
trainer = Trainer(..., args=args)

...

trainer.train()
```
