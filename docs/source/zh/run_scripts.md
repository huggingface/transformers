<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ä½¿ç”¨è„šæœ¬è¿›è¡Œè®­ç»ƒ

é™¤äº† ğŸ¤— Transformers [notebooks](./notebooks)ï¼Œè¿˜æœ‰ç¤ºä¾‹è„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨[PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch)ã€[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow)æˆ–[JAX/Flax](https://github.com/huggingface/transformers/tree/main/examples/flax)è®­ç»ƒæ¨¡å‹ä»¥è§£å†³ç‰¹å®šä»»åŠ¡ã€‚

æ‚¨è¿˜å¯ä»¥åœ¨è¿™äº›ç¤ºä¾‹ä¸­æ‰¾åˆ°æˆ‘ä»¬åœ¨[ç ”ç©¶é¡¹ç›®](https://github.com/huggingface/transformers/tree/main/examples/research_projects)å’Œ[é—ç•™ç¤ºä¾‹](https://github.com/huggingface/transformers/tree/main/examples/legacy)ä¸­ä½¿ç”¨è¿‡çš„è„šæœ¬ï¼Œè¿™äº›è„šæœ¬ä¸»è¦æ˜¯ç”±ç¤¾åŒºè´¡çŒ®çš„ã€‚è¿™äº›è„šæœ¬å·²ä¸å†è¢«ç§¯æç»´æŠ¤ï¼Œéœ€è¦ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬çš„ğŸ¤— Transformersï¼Œ å¯èƒ½ä¸åº“çš„æœ€æ–°ç‰ˆæœ¬ä¸å…¼å®¹ã€‚

ç¤ºä¾‹è„šæœ¬å¯èƒ½æ— æ³•åœ¨åˆå§‹é…ç½®ä¸‹ç›´æ¥è§£å†³æ¯ä¸ªé—®é¢˜ï¼Œæ‚¨å¯èƒ½éœ€è¦æ ¹æ®è¦è§£å†³çš„é—®é¢˜è°ƒæ•´è„šæœ¬ã€‚ä¸ºäº†å¸®åŠ©æ‚¨ï¼Œå¤§å¤šæ•°è„šæœ¬éƒ½å®Œå…¨æš´éœ²äº†æ•°æ®é¢„å¤„ç†çš„æ–¹å¼ï¼Œå…è®¸æ‚¨æ ¹æ®éœ€è¦å¯¹å…¶è¿›è¡Œç¼–è¾‘ã€‚

å¦‚æœæ‚¨æƒ³åœ¨ç¤ºä¾‹è„šæœ¬ä¸­å®ç°ä»»ä½•åŠŸèƒ½ï¼Œè¯·åœ¨[è®ºå›](https://discuss.huggingface.co/)æˆ–[issue](https://github.com/huggingface/transformers/issues)ä¸Šè®¨è®ºï¼Œç„¶åå†æäº¤Pull Requestã€‚è™½ç„¶æˆ‘ä»¬æ¬¢è¿ä¿®å¤é”™è¯¯ï¼Œä½†ä¸å¤ªå¯èƒ½åˆå¹¶æ·»åŠ æ›´å¤šåŠŸèƒ½çš„Pull Requestï¼Œå› ä¸ºè¿™ä¼šé™ä½å¯è¯»æ€§ã€‚

æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åœ¨[PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)å’Œ[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization)ä¸­è¿è¡Œç¤ºä¾‹æ‘˜è¦è®­ç»ƒè„šæœ¬ã€‚é™¤éå¦æœ‰è¯´æ˜ï¼Œå¦åˆ™æ‰€æœ‰ç¤ºä¾‹éƒ½å¯ä»¥åœ¨ä¸¤ä¸ªæ¡†æ¶ä¸­å·¥ä½œã€‚

## è®¾ç½®

è¦æˆåŠŸè¿è¡Œç¤ºä¾‹è„šæœ¬çš„æœ€æ–°ç‰ˆæœ¬ï¼Œæ‚¨å¿…é¡»åœ¨æ–°è™šæ‹Ÿç¯å¢ƒä¸­**ä»æºä»£ç å®‰è£… ğŸ¤— Transformers**ï¼š

```bash
git clone https://github.com/huggingface/transformers
cd transformers
pip install .
```

å¯¹äºæ—§ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼Œè¯·ç‚¹å‡»ä¸‹é¢çš„åˆ‡æ¢æŒ‰é’®ï¼š

<details>
  <summary>è€ç‰ˆæœ¬ğŸ¤— Transformersç¤ºä¾‹ </summary>
	<ul>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.5.1/examples">v4.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.4.2/examples">v4.4.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.3.3/examples">v4.3.3</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.2.2/examples">v4.2.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.1.1/examples">v4.1.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.0.1/examples">v4.0.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.5.1/examples">v3.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.4.0/examples">v3.4.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.3.1/examples">v3.3.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.2.0/examples">v3.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.1.0/examples">v3.1.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.0.2/examples">v3.0.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.11.0/examples">v2.11.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.10.0/examples">v2.10.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.9.1/examples">v2.9.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.8.0/examples">v2.8.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.7.0/examples">v2.7.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.6.0/examples">v2.6.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.5.1/examples">v2.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.4.0/examples">v2.4.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.3.0/examples">v2.3.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.2.0/examples">v2.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.1.0/examples">v2.1.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.0.0/examples">v2.0.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.2.0/examples">v1.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.1.0/examples">v1.1.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.0.0/examples">v1.0.0</a></li>
	</ul>
</details>

ç„¶ååˆ‡æ¢æ‚¨cloneçš„ ğŸ¤— Transformers ä»“åˆ°ç‰¹å®šçš„ç‰ˆæœ¬ï¼Œä¾‹å¦‚v3.5.1ï¼š

```bash
git checkout tags/v3.5.1
```

åœ¨å®‰è£…äº†æ­£ç¡®çš„åº“ç‰ˆæœ¬åï¼Œè¿›å…¥æ‚¨é€‰æ‹©çš„ç‰ˆæœ¬çš„`example`æ–‡ä»¶å¤¹å¹¶å®‰è£…ä¾‹å­è¦æ±‚çš„ç¯å¢ƒï¼š

```bash
pip install -r requirements.txt
```

## è¿è¡Œè„šæœ¬

<frameworkcontent>
<pt>

ç¤ºä¾‹è„šæœ¬ä»ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/)åº“ä¸‹è½½å¹¶é¢„å¤„ç†æ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬é€šè¿‡[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)ä½¿ç”¨æ”¯æŒæ‘˜è¦ä»»åŠ¡çš„æ¶æ„å¯¹æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail)æ•°æ®é›†ä¸Šå¾®è°ƒ[T5-small](https://huggingface.co/google-t5/t5-small)ã€‚ç”±äºT5æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼Œå®ƒéœ€è¦ä¸€ä¸ªé¢å¤–çš„`source_prefix`å‚æ•°ã€‚è¿™ä¸ªæç¤ºè®©T5çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚

```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```
</pt>
<tf>

ç¤ºä¾‹è„šæœ¬ä»  ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/) åº“ä¸‹è½½å¹¶é¢„å¤„ç†æ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬ä½¿ç”¨ Keras åœ¨æ”¯æŒæ‘˜è¦çš„æ¶æ„ä¸Šå¾®è°ƒæ•°æ®é›†ã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨ [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) æ•°æ®é›†ä¸Šå¾®è°ƒ [T5-small](https://huggingface.co/google-t5/t5-small)ã€‚T5 æ¨¡å‹ç”±äºè®­ç»ƒæ–¹å¼éœ€è¦é¢å¤–çš„ `source_prefix` å‚æ•°ã€‚è¿™ä¸ªæç¤ºè®© T5 çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚

```bash
python examples/tensorflow/summarization/run_summarization.py  \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```
</tf>
</frameworkcontent>

## åˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦

[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦ï¼Œè¿™æ„å‘³ç€ä½ ä¹Ÿå¯ä»¥åœ¨è„šæœ¬ä¸­ä½¿ç”¨å®ƒã€‚è¦å¯ç”¨è¿™ä¸¤ä¸ªåŠŸèƒ½ï¼Œå¯ä»¥åšå¦‚ä¸‹è®¾ç½®ï¼š

- æ·»åŠ  `fp16` å‚æ•°ä»¥å¯ç”¨æ··åˆç²¾åº¦ã€‚
- ä½¿ç”¨ `nproc_per_node` å‚æ•°è®¾ç½®ä½¿ç”¨çš„GPUæ•°é‡ã€‚


```bash
torchrun \
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \
    --fp16 \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

TensorFlowè„šæœ¬ä½¿ç”¨[`MirroredStrategy`](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy)è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ‚¨æ— éœ€åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ ä»»ä½•å…¶ä»–å‚æ•°ã€‚å¦‚æœå¯ç”¨ï¼ŒTensorFlowè„šæœ¬å°†é»˜è®¤ä½¿ç”¨å¤šä¸ªGPUã€‚

## åœ¨TPUä¸Šè¿è¡Œè„šæœ¬

<frameworkcontent>
<pt>

å¼ é‡å¤„ç†å•å…ƒï¼ˆTPUsï¼‰æ˜¯ä¸“é—¨è®¾è®¡ç”¨äºåŠ é€Ÿæ€§èƒ½çš„ã€‚PyTorchä½¿ç”¨[XLA](https://www.tensorflow.org/xla)æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨æ”¯æŒTPUï¼ˆæ›´å¤šç»†èŠ‚è¯·å‚è§[è¿™é‡Œ](https://github.com/pytorch/xla/blob/master/README.md)ï¼‰ã€‚è¦ä½¿ç”¨TPUï¼Œè¯·å¯åŠ¨`xla_spawn.py`è„šæœ¬å¹¶ä½¿ç”¨`num_cores`å‚æ•°è®¾ç½®è¦ä½¿ç”¨çš„TPUæ ¸å¿ƒæ•°é‡ã€‚

```bash
python xla_spawn.py --num_cores 8 \
    summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```
</pt>
<tf>

å¼ é‡å¤„ç†å•å…ƒï¼ˆTPUsï¼‰æ˜¯ä¸“é—¨è®¾è®¡ç”¨äºåŠ é€Ÿæ€§èƒ½çš„ã€‚TensorFlowè„šæœ¬ä½¿ç”¨[`TPUStrategy`](https://www.tensorflow.org/guide/distributed_training#tpustrategy)åœ¨TPUä¸Šè¿›è¡Œè®­ç»ƒã€‚è¦ä½¿ç”¨TPUï¼Œè¯·å°†TPUèµ„æºçš„åç§°ä¼ é€’ç»™`tpu`å‚æ•°ã€‚

```bash
python run_summarization.py  \
    --tpu name_of_tpu_resource \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```
</tf>
</frameworkcontent>

## åŸºäºğŸ¤— Accelerateè¿è¡Œè„šæœ¬

ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate) æ˜¯ä¸€ä¸ªä»…æ”¯æŒ PyTorch çš„åº“ï¼Œå®ƒæä¾›äº†ä¸€ç§ç»Ÿä¸€çš„æ–¹æ³•æ¥åœ¨ä¸åŒç±»å‹çš„è®¾ç½®ï¼ˆä»… CPUã€å¤šä¸ª GPUã€å¤šä¸ªTPUï¼‰ä¸Šè®­ç»ƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒå¯¹ PyTorch è®­ç»ƒå¾ªç¯çš„å®Œå…¨å¯è§æ€§ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£… ğŸ¤— Accelerateï¼Œè¯·ç¡®ä¿ä½ å·²ç»å®‰è£…äº†å®ƒï¼š

> æ³¨æ„ï¼šç”±äº Accelerate æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œå› æ­¤å¿…é¡»å®‰è£… git ç‰ˆæœ¬çš„ accelerate æ¥è¿è¡Œè„šæœ¬ã€‚

```bash
pip install git+https://github.com/huggingface/accelerate
```

ä½ éœ€è¦ä½¿ç”¨`run_summarization_no_trainer.py`è„šæœ¬ï¼Œè€Œä¸æ˜¯`run_summarization.py`è„šæœ¬ã€‚ğŸ¤— Accelerateæ”¯æŒçš„è„šæœ¬éœ€è¦åœ¨æ–‡ä»¶å¤¹ä¸­æœ‰ä¸€ä¸ª`task_no_trainer.py`æ–‡ä»¶ã€‚é¦–å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åˆ›å»ºå¹¶ä¿å­˜é…ç½®æ–‡ä»¶ï¼š

```bash
accelerate config
```
æ£€æµ‹æ‚¨çš„è®¾ç½®ä»¥ç¡®ä¿é…ç½®æ­£ç¡®ï¼š

```bash
accelerate test
```

ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ï¼š

```bash
accelerate launch run_summarization_no_trainer.py \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir ~/tmp/tst-summarization
```

## ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†

æ‘˜è¦è„šæœ¬æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†ï¼Œåªè¦å®ƒä»¬æ˜¯CSVæˆ–JSON Lineæ–‡ä»¶ã€‚å½“ä½ ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†æ—¶ï¼Œéœ€è¦æŒ‡å®šä¸€äº›é¢å¤–çš„å‚æ•°ï¼š
- `train_file` å’Œ `validation_file` åˆ†åˆ«æŒ‡å®šæ‚¨çš„è®­ç»ƒå’ŒéªŒè¯æ–‡ä»¶çš„è·¯å¾„ã€‚
- `text_column` æ˜¯è¾“å…¥è¦è¿›è¡Œæ‘˜è¦çš„æ–‡æœ¬ã€‚
- `summary_column` æ˜¯ç›®æ ‡è¾“å‡ºçš„æ–‡æœ¬ã€‚

ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†çš„æ‘˜è¦è„šæœ¬çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼š


```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --train_file path_to_csv_or_jsonlines_file \
    --validation_file path_to_csv_or_jsonlines_file \
    --text_column text_column_name \
    --summary_column summary_column_name \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --overwrite_output_dir \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --predict_with_generate
```

## æµ‹è¯•è„šæœ¬

é€šå¸¸ï¼Œåœ¨æäº¤æ•´ä¸ªæ•°æ®é›†ä¹‹å‰ï¼Œæœ€å¥½å…ˆåœ¨è¾ƒå°‘çš„æ•°æ®é›†ç¤ºä¾‹ä¸Šè¿è¡Œè„šæœ¬ï¼Œä»¥ç¡®ä¿ä¸€åˆ‡æŒ‰é¢„æœŸå·¥ä½œ,å› ä¸ºå®Œæ•´æ•°æ®é›†çš„å¤„ç†å¯èƒ½éœ€è¦èŠ±è´¹å‡ ä¸ªå°æ—¶çš„æ—¶é—´ã€‚ä½¿ç”¨ä»¥ä¸‹å‚æ•°å°†æ•°æ®é›†æˆªæ–­ä¸ºæœ€å¤§æ ·æœ¬æ•°ï¼š

- `max_train_samples`
- `max_eval_samples`
- `max_predict_samples`


```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --max_train_samples 50 \
    --max_eval_samples 50 \
    --max_predict_samples 50 \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

å¹¶éæ‰€æœ‰ç¤ºä¾‹è„šæœ¬éƒ½æ”¯æŒ`max_predict_samples`å‚æ•°ã€‚å¦‚æœæ‚¨ä¸ç¡®å®šæ‚¨çš„è„šæœ¬æ˜¯å¦æ”¯æŒæ­¤å‚æ•°ï¼Œè¯·æ·»åŠ `-h`å‚æ•°è¿›è¡Œæ£€æŸ¥ï¼š

```bash
examples/pytorch/summarization/run_summarization.py -h
```

## ä»checkpointæ¢å¤è®­ç»ƒ

å¦ä¸€ä¸ªæœ‰ç”¨çš„é€‰é¡¹æ˜¯ä»ä¹‹å‰çš„checkpointæ¢å¤è®­ç»ƒã€‚è¿™å°†ç¡®ä¿åœ¨è®­ç»ƒä¸­æ–­æ—¶ï¼Œæ‚¨å¯ä»¥ä»ä¹‹å‰åœæ­¢çš„åœ°æ–¹ç»§ç»­è¿›è¡Œï¼Œè€Œæ— éœ€é‡æ–°å¼€å§‹ã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥ä»checkpointæ¢å¤è®­ç»ƒã€‚

ç¬¬ä¸€ç§æ–¹æ³•ä½¿ç”¨`output_dir previous_output_dir`å‚æ•°ä»å­˜å‚¨åœ¨`output_dir`ä¸­çš„æœ€æ–°çš„checkpointæ¢å¤è®­ç»ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥åˆ é™¤`overwrite_output_dir`ï¼š

```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --output_dir previous_output_dir \
    --predict_with_generate
```

ç¬¬äºŒç§æ–¹æ³•ä½¿ç”¨`resume_from_checkpoint path_to_specific_checkpoint`å‚æ•°ä»ç‰¹å®šçš„checkpointæ–‡ä»¶å¤¹æ¢å¤è®­ç»ƒã€‚


```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --resume_from_checkpoint path_to_specific_checkpoint \
    --predict_with_generate
```

## åˆ†äº«æ¨¡å‹

æ‰€æœ‰è„šæœ¬éƒ½å¯ä»¥å°†æ‚¨çš„æœ€ç»ˆæ¨¡å‹ä¸Šä¼ åˆ°[Model Hub](https://huggingface.co/models)ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ç™»å½•Hugging Faceï¼š

```bash
huggingface-cli login
```

ç„¶åï¼Œåœ¨è„šæœ¬ä¸­æ·»åŠ `push_to_hub`å‚æ•°ã€‚è¿™ä¸ªå‚æ•°ä¼šåˆ›å»ºä¸€ä¸ªå¸¦æœ‰æ‚¨Hugging Faceç”¨æˆ·åå’Œ`output_dir`ä¸­æŒ‡å®šçš„æ–‡ä»¶å¤¹åç§°çš„ä»“åº“ã€‚

ä¸ºäº†ç»™æ‚¨çš„ä»“åº“æŒ‡å®šä¸€ä¸ªç‰¹å®šçš„åç§°ï¼Œä½¿ç”¨`push_to_hub_model_id`å‚æ•°æ¥æ·»åŠ å®ƒã€‚è¯¥ä»“åº“å°†è‡ªåŠ¨åˆ—å‡ºåœ¨æ‚¨çš„å‘½åç©ºé—´ä¸‹ã€‚

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä¸Šä¼ å…·æœ‰ç‰¹å®šä»“åº“åç§°çš„æ¨¡å‹ï¼š


```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --push_to_hub \
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```