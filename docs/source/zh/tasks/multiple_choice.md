<!--ç‰ˆæƒæ‰€æœ‰ 2022 å¹´ The HuggingFace å›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚
æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰è¿›è¡Œè®¸å¯ï¼›é™¤éç¬¦åˆè®¸å¯è¯ï¼Œå¦åˆ™æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯å‰¯æœ¬ï¼šhttp://www.apache.org/licenses/LICENSE-2.0
é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯åŸºäºâ€œæŒ‰åŸæ ·â€åˆ†å‘çš„ï¼Œä¸é™„å¸¦ä»»ä½•å½¢å¼çš„ä¿è¯æˆ–æ¡ä»¶ã€‚è¯·å‚é˜…è®¸å¯è¯ä»¥è·å–ç‰¹å®šè¯­è¨€ä¸‹çš„æƒé™å’Œé™åˆ¶ã€‚âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯ Markdown æ ¼å¼ï¼Œä½†åŒ…å«æˆ‘ä»¬çš„æ–‡æ¡£æ„å»ºå™¨ï¼ˆç±»ä¼¼äº MDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½æ— æ³•åœ¨æ‚¨çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ˜¾ç¤ºã€‚-->

# å¤šé¡¹é€‰æ‹©
# Multiple choice

[[åœ¨ Colab ä¸­æ‰“å¼€]]

å¤šé¡¹é€‰æ‹©ä»»åŠ¡ç±»ä¼¼äºé—®ç­”ï¼Œåªæ˜¯é™¤äº†ä¸Šä¸‹æ–‡è¿˜æä¾›äº†å‡ ä¸ªå€™é€‰ç­”æ¡ˆï¼Œæ¨¡å‹ç»è¿‡è®­ç»ƒåå¯ä»¥é€‰æ‹©æ­£ç¡®ç­”æ¡ˆã€‚

æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ï¼š

1. åœ¨ `regular` é…ç½®çš„ [SWAG](https://huggingface.co/datasets/swag) æ•°æ®é›†ä¸Šå¾®è°ƒ [BERT](https://huggingface.co/bert-base-uncased)ï¼Œä»¥é€‰æ‹©æœ€ä½³ç­”æ¡ˆï¼Œç»™å®šå¤šä¸ªé€‰é¡¹å’Œä¸€äº›ä¸Šä¸‹æ–‡ã€‚
2. ä½¿ç”¨æ‚¨å¾®è°ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚

<Tip> 

æ­¤æ•™ç¨‹ä¸­æ¼”ç¤ºçš„ä»»åŠ¡æ”¯æŒä»¥ä¸‹æ¨¡å‹æ¶æ„ï¼š
<!--æ­¤æç¤ºç”±`make fix-copies`è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨å¡«å†™ï¼-->
[ALBERT](../model_doc/albert)ï¼Œ[BERT](../model_doc/bert)ï¼Œ[BigBird](../model_doc/big_bird)ï¼Œ[CamemBERT](../model_doc/camembert)ï¼Œ[CANINE](../model_doc/canine)ï¼Œ[ConvBERT](../model_doc/convbert)ï¼Œ[Data2VecText](../model_doc/data2vec-text)ï¼Œ[DeBERTa-v2](../model_doc/deberta-v2)ï¼Œ[DistilBERT](../model_doc/distilbert)ï¼Œ[ELECTRA](../model_doc/electra)ï¼Œ[ERNIE](../model_doc/ernie)ï¼Œ[ErnieM](../model_doc/ernie_m)ï¼Œ[FlauBERT](../model_doc/flaubert)ï¼Œ[FNet](../model_doc/fnet)ï¼Œ[Funnel Transformer](../model_doc/funnel)ï¼Œ[I-BERT](../model_doc/ibert)ï¼Œ[Longformer](../model_doc/longformer)ï¼Œ[LUKE](../model_doc/luke)ï¼Œ[MEGA](../model_doc/mega)ï¼Œ[Megatron-BERT](../model_doc/megatron-bert)ï¼Œ[MobileBERT](../model_doc/mobilebert)ï¼Œ[MPNet](../model_doc/mpnet)ï¼Œ[Nezha](../model_doc/nezha)ï¼Œ[Nystr Ã¶ mformer](../model_doc/nystromformer)ï¼Œ[QDQBert](../model_doc/qdqbert)ï¼Œ[RemBERT](../model_doc/rembert)ï¼Œ[RoBERTa](../model_doc/roberta)ï¼Œ[RoBERTa-PreLayerNorm](../model_doc/roberta-prelayernorm)ï¼Œ[RoCBert](../model_doc/roc_bert)ï¼Œ[RoFormer](../model_doc/roformer)ï¼Œ[SqueezeBERT](../model_doc/squeezebert)ï¼Œ[XLM](../model_doc/xlm)ï¼Œ[XLM-RoBERTa](../model_doc/xlm-roberta)ï¼Œ[XLM-RoBERTa-XL](../model_doc/xlm-roberta-xl)ï¼Œ[XLNet](../model_doc/xlnet)ï¼Œ[X-MOD](../model_doc/xmod)ï¼Œ[YOSO](../model_doc/yoso)
<!--ç”Ÿæˆæç¤ºç»“æŸ-->
</Tip>

å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼š
```bash
pip install transformers datasets evaluate
```

æˆ‘ä»¬é¼“åŠ±æ‚¨ç™»å½•æ‚¨çš„ Hugging Face å¸æˆ·ï¼Œè¿™æ ·æ‚¨å¯ä»¥ä¸ç¤¾åŒºå…±äº«å’Œä¸Šä¼ æ‚¨çš„æ¨¡å‹ã€‚åœ¨æç¤ºæ—¶ï¼Œè¯·è¾“å…¥æ‚¨çš„ä»¤ç‰Œè¿›è¡Œç™»å½•ï¼š
```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## åŠ è½½ SWAG æ•°æ®é›†
é¦–å…ˆä»ğŸ¤— Datasets åº“åŠ è½½ SWAG æ•°æ®é›†çš„ `regular` é…ç½®ï¼š
```py
>>> from datasets import load_dataset

>>> swag = load_dataset("swag", "regular")
```

ç„¶åæŸ¥çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š
```py
>>> swag["train"][0]
{'ending0': 'passes by walking down the street playing their instruments.',
 'ending1': 'has heard approaching them.',
 'ending2': "arrives and they're outside dancing and asleep.",
 'ending3': 'turns the lead singer watches the performance.',
 'fold-ind': '3416',
 'gold-source': 'gold',
 'label': 0,
 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',
 'sent2': 'A drum line',
 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',
 'video-id': 'anetv_jkn6uvmqwh4'}
```

è™½ç„¶è¿™é‡Œçœ‹èµ·æ¥æœ‰å¾ˆå¤šå­—æ®µï¼Œä½†å®é™…ä¸Šå¾ˆç®€å•ï¼š

- `sent1` å’Œ `sent2`ï¼šè¿™äº›å­—æ®µæ˜¾ç¤ºä¸€ä¸ªå¥å­çš„å¼€å¤´ï¼Œå¦‚æœå°†å®ƒä»¬æ”¾åœ¨ä¸€èµ·ï¼Œå°±å¯ä»¥å¾—åˆ° `startphrase` å­—æ®µã€‚- `ending`ï¼šå»ºè®®ä¸€ä¸ªå¥å­çš„å¯èƒ½ç»“å°¾ï¼Œä½†åªæœ‰ä¸€ä¸ªæ˜¯æ­£ç¡®çš„ã€‚- `label`ï¼šæ ‡è¯†æ­£ç¡®çš„å¥å­ç»“å°¾ã€‚

## é¢„å¤„ç†

ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ BERT åˆ†è¯å™¨ (Tokenizer)ï¼Œä»¥å¤„ç†å¥å­å¼€å¤´å’Œå››ä¸ªå¯èƒ½çš„ç»“å°¾ï¼š
```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
```

æ‚¨è¦åˆ›å»ºçš„é¢„å¤„ç†å‡½æ•°éœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
1. å¤åˆ¶ `sent1` å­—æ®µå››æ¬¡ï¼Œå¹¶å°†æ¯ä¸ªå‰¯æœ¬ä¸ `sent2` ç»„åˆä»¥é‡æ–°åˆ›å»ºå¥å­çš„å¼€å¤´ã€‚
2. å°† `sent2` ä¸å››ä¸ªå¯èƒ½çš„å¥å­ç»“å°¾ä¹‹ä¸€ç»„åˆã€‚
3. æ‰å¹³åŒ–è¿™ä¸¤ä¸ªåˆ—è¡¨ï¼Œä»¥ä¾¿å¯ä»¥å¯¹å®ƒä»¬è¿›è¡Œåˆ†è¯ï¼Œç„¶ååœ¨åˆ†è¯åé‡æ–°ç»„åˆå®ƒä»¬ï¼Œä»¥ä¾¿æ¯ä¸ªç¤ºä¾‹éƒ½æœ‰ç›¸åº”çš„ `input_ids`ã€`attention_mask` å’Œ `labels` å­—æ®µã€‚
```py
>>> ending_names = ["ending0", "ending1", "ending2", "ending3"]


>>> def preprocess_function(examples):
...     first_sentences = [[context] * 4 for context in examples["sent1"]]
...     question_headers = examples["sent2"]
...     second_sentences = [
...         [f"{header} {examples[end][i]}" for end in ending_names] for i, header in enumerate(question_headers)
...     ]

...     first_sentences = sum(first_sentences, [])
...     second_sentences = sum(second_sentences, [])

...     tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)
...     return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}
```

è¦åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨é¢„å¤„ç†å‡½æ•°ï¼Œä½¿ç”¨ğŸ¤— Datasets çš„ [`~datasets.Dataset.map`] æ–¹æ³•ã€‚

é€šè¿‡å°† `batched=True` è®¾ç½®ä¸ºä¸€æ¬¡å¤„ç†æ•°æ®é›†çš„å¤šä¸ªå…ƒç´ ï¼Œå¯ä»¥åŠ å¿« `map` å‡½æ•°çš„é€Ÿåº¦ï¼š
```py
tokenized_swag = swag.map(preprocess_function, batched=True)
```

ğŸ¤— Transformers æ²¡æœ‰é€‚ç”¨äºå¤šé¡¹é€‰æ‹©çš„æ•°æ®æ•´ç†å™¨ï¼Œå› æ­¤æ‚¨éœ€è¦è°ƒæ•´ [`DataCollatorWithPadding`] ä»¥åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹ã€‚åœ¨æ•´ç†è¿‡ç¨‹ä¸­ï¼Œå°†å¥å­åŠ¨æ€å¡«å……åˆ°æ‰¹æ¬¡ä¸­çš„æœ€å¤§é•¿åº¦ä¸Šï¼Œè€Œä¸æ˜¯å°†æ•´ä¸ªæ•°æ®é›†å¡«å……åˆ°æœ€å¤§é•¿åº¦ã€‚

`DataCollatorForMultipleChoice` å¯¹æ‰€æœ‰æ¨¡å‹è¾“å…¥è¿›è¡Œæ‰å¹³åŒ–å¤„ç†ï¼Œåº”ç”¨å¡«å……ï¼Œç„¶åå°†ç»“æœé‡æ–°å±•å¼€ï¼š

<frameworkcontent> 
<pt> 

 ```py
>>> from dataclasses import dataclass
>>> from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy
>>> from typing import Optional, Union
>>> import torch


>>> @dataclass
... class DataCollatorForMultipleChoice:
...     """
...     Data collator that will dynamically pad the inputs for multiple choice received.
...     """

...     tokenizer: PreTrainedTokenizerBase
...     padding: Union[bool, str, PaddingStrategy] = True
...     max_length: Optional[int] = None
...     pad_to_multiple_of: Optional[int] = None

...     def __call__(self, features):
...         label_name = "label" if "label" in features[0].keys() else "labels"
...         labels = [feature.pop(label_name) for feature in features]
...         batch_size = len(features)
...         num_choices = len(features[0]["input_ids"])
...         flattened_features = [
...             [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features
...         ]
...         flattened_features = sum(flattened_features, [])

...         batch = self.tokenizer.pad(
...             flattened_features,
...             padding=self.padding,
...             max_length=self.max_length,
...             pad_to_multiple_of=self.pad_to_multiple_of,
...             return_tensors="pt",
...         )

...         batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}
...         batch["labels"] = torch.tensor(labels, dtype=torch.int64)
...         return batch
```
</pt> 
<tf> 

```py
>>> from dataclasses import dataclass
>>> from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy
>>> from typing import Optional, Union
>>> import tensorflow as tf


>>> @dataclass
... class DataCollatorForMultipleChoice:
...     """
...     Data collator that will dynamically pad the inputs for multiple choice received.
...     """

...     tokenizer: PreTrainedTokenizerBase
...     padding: Union[bool, str, PaddingStrategy] = True
...     max_length: Optional[int] = None
...     pad_to_multiple_of: Optional[int] = None

...     def __call__(self, features):
...         label_name = "label" if "label" in features[0].keys() else "labels"
...         labels = [feature.pop(label_name) for feature in features]
...         batch_size = len(features)
...         num_choices = len(features[0]["input_ids"])
...         flattened_features = [
...             [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features
...         ]
...         flattened_features = sum(flattened_features, [])

...         batch = self.tokenizer.pad(
...             flattened_features,
...             padding=self.padding,
...             max_length=self.max_length,
...             pad_to_multiple_of=self.pad_to_multiple_of,
...             return_tensors="tf",
...         )

...         batch = {k: tf.reshape(v, (batch_size, num_choices, -1)) for k, v in batch.items()}
...         batch["labels"] = tf.convert_to_tensor(labels, dtype=tf.int64)
...         return batch
```
</tf>
</frameworkcontent>


## è¯„ä¼°

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒ…å«åº¦é‡æ ‡å‡†é€šå¸¸æœ‰åŠ©äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) åº“å¿«é€ŸåŠ è½½è¯„ä¼°æ–¹æ³•ã€‚å¯¹äºæ­¤ä»»åŠ¡ï¼Œè¯·åŠ è½½ [å‡†ç¡®åº¦](https://huggingface.co/spaces/evaluate-metric/accuracy) åº¦é‡æ ‡å‡†ï¼ˆè¯¦ç»†äº†è§£å¦‚ä½•åŠ è½½å’Œè®¡ç®—åº¦é‡æ ‡å‡†ï¼Œè¯·å‚é˜…ğŸ¤— Evaluate çš„ [å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/evaluate/a_quick_tour)ï¼‰ï¼š

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

ç„¶ååˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå°†æ‚¨çš„é¢„æµ‹å’Œæ ‡ç­¾ä¼ é€’ç»™ [`~evaluate.EvaluationModule.compute`] ä»¥è®¡ç®—å‡†ç¡®åº¦ï¼š
```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions, labels = eval_pred
...     predictions = np.argmax(predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=labels)
```

ç°åœ¨æ‚¨çš„ `compute_metrics` å‡½æ•°å·²ç»å‡†å¤‡å°±ç»ªï¼Œåœ¨è®¾ç½®è®­ç»ƒæ—¶å°†è¿”å›å®ƒã€‚

## è®­ç»ƒ

<frameworkcontent> 
<pt> 
<Tip>

å¦‚æœæ‚¨å¯¹ä½¿ç”¨ [`Trainer`] å¾®è°ƒæ¨¡å‹ä¸ç†Ÿæ‚‰ï¼Œè¯·æŸ¥çœ‹åŸºæœ¬æ•™ç¨‹ [æ­¤å¤„](../training#train-with-pytorch-trainer)ï¼
</Tip>

ç°åœ¨æ‚¨å·²å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ï¼ä½¿ç”¨ [`AutoModelForMultipleChoice`] åŠ è½½ BERTï¼š
```py
>>> from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer

>>> model = AutoModelForMultipleChoice.from_pretrained("bert-base-uncased")
```

æ­¤æ—¶ï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š
1. åœ¨ [`TrainingArguments`] ä¸­å®šä¹‰è®­ç»ƒè¶…å‚æ•°ã€‚å”¯ä¸€å¿…éœ€çš„å‚æ•°æ˜¯ `output_dir`ï¼Œç”¨äºæŒ‡å®šä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚é€šè¿‡è®¾ç½® `push_to_hub=True` å°†æ­¤æ¨¡å‹æ¨é€åˆ° Hubï¼ˆæ‚¨éœ€è¦ç™»å½• Hugging Face æ‰èƒ½ä¸Šä¼ æ¨¡å‹ï¼‰ã€‚åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ï¼Œ[`Trainer`] å°†è¯„ä¼°å‡†ç¡®åº¦å¹¶ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚
2. å°†è®­ç»ƒå‚æ•°ä¸æ¨¡å‹ã€æ•°æ®é›†ã€åˆ†è¯å™¨ (Tokenizer)ã€æ•°æ®æ•´ç†å™¨å’Œ `compute_metrics` å‡½æ•°ä¸€èµ·ä¼ é€’ç»™ [`Trainer`]ã€‚
3. è°ƒç”¨ [`~Trainer.train`] ä»¥å¾®è°ƒæ¨¡å‹ã€‚
```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_swag_model",
...     evaluation_strategy="epoch",
...     save_strategy="epoch",
...     load_best_model_at_end=True,
...     learning_rate=5e-5,
...     per_device_train_batch_size=16,
...     per_device_eval_batch_size=16,
...     num_train_epochs=3,
...     weight_decay=0.01,
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=tokenized_swag["train"],
...     eval_dataset=tokenized_swag["validation"],
...     tokenizer=tokenizer,
...     data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

å®Œæˆè®­ç»ƒåï¼Œä½¿ç”¨ [`~transformers.Trainer.push_to_hub`] æ–¹æ³•å°†æ‚¨çš„æ¨¡å‹åˆ†äº«åˆ° Hubï¼Œä»¥ä¾¿æ¯ä¸ªäººéƒ½å¯ä»¥ä½¿ç”¨æ‚¨çš„æ¨¡å‹ï¼š
```py
>>> trainer.push_to_hub()
```
</pt> 
<tf> 

<Tip>
å¦‚æœæ‚¨å¯¹ä½¿ç”¨ Keras å¾®è°ƒæ¨¡å‹ä¸ç†Ÿæ‚‰ï¼Œè¯·æŸ¥çœ‹åŸºæœ¬æ•™ç¨‹ [æ­¤å¤„](../training#train-a-tensorflow-model-with-keras)ï¼
</Tip> 

è¦åœ¨ TensorFlow ä¸­å¾®è°ƒæ¨¡å‹ï¼Œé¦–å…ˆè®¾ç½®ä¼˜åŒ–å™¨å‡½æ•°ã€å­¦ä¹ ç‡è®¡åˆ’å’Œä¸€äº›è®­ç»ƒè¶…å‚æ•°ï¼š

```py
>>> from transformers import create_optimizer

>>> batch_size = 16
>>> num_train_epochs = 2
>>> total_train_steps = (len(tokenized_swag["train"]) // batch_size) * num_train_epochs
>>> optimizer, schedule = create_optimizer(init_lr=5e-5, num_warmup_steps=0, num_train_steps=total_train_steps)
```

ç„¶åæ‚¨å¯ä»¥ä½¿ç”¨ [`TFAutoModelForMultipleChoice`] åŠ è½½ BERTï¼š
```py
>>> from transformers import TFAutoModelForMultipleChoice

>>> model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-uncased")
```

ä½¿ç”¨ [`~transformers.TFPreTrainedModel.prepare_tf_dataset`] å°†æ•°æ®é›†è½¬æ¢ä¸º `tf.data.Dataset` æ ¼å¼ï¼š
```py
>>> data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)
>>> tf_train_set = model.prepare_tf_dataset(
...     tokenized_swag["train"],
...     shuffle=True,
...     batch_size=batch_size,
...     collate_fn=data_collator,
... )

>>> tf_validation_set = model.prepare_tf_dataset(
...     tokenized_swag["validation"],
...     shuffle=False,
...     batch_size=batch_size,
...     collate_fn=data_collator,
... )
```

ä½¿ç”¨ [`compile`](https://keras.io/api/models/model_training_apis/#compile-method) é…ç½®è®­ç»ƒæ¨¡å‹ã€‚

è¯·æ³¨æ„ï¼ŒTransformer æ¨¡å‹éƒ½æœ‰ä¸€ä¸ªé»˜è®¤çš„ä¸ä»»åŠ¡ç›¸å…³çš„æŸå¤±å‡½æ•°ï¼Œæ‰€ä»¥é™¤éæ‚¨æƒ³è¦æŒ‡å®šä¸€ä¸ªï¼Œå¦åˆ™ä¸éœ€è¦æŒ‡å®šã€‚

```py
>>> model.compile(optimizer=optimizer)  # No loss argument!
```

åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œéœ€è¦å®Œæˆæœ€åä¸¤é¡¹è®¾ç½®ï¼Œå³ä»é¢„æµ‹ç»“æœä¸­è®¡ç®—å‡†ç¡®ç‡ï¼Œå¹¶æä¾›ä¸€ç§å°†æ¨¡å‹æ¨é€åˆ° Hub çš„æ–¹å¼ã€‚è¿™ä¸¤é¡¹è®¾ç½®å¯ä»¥é€šè¿‡ä½¿ç”¨ [Keras å›è°ƒå‡½æ•°](../main_classes/keras_callbacks) æ¥å®ç°ã€‚

å°†æ‚¨çš„ `compute_metrics` å‡½æ•°ä¼ é€’ç»™ [`~transformers.KerasMetricCallback`]ï¼š

```py
>>> from transformers.keras_callbacks import KerasMetricCallback

>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)
```

åœ¨ [`~transformers.PushToHubCallback`] ä¸­æŒ‡å®šå°†æ¨¡å‹å’Œåˆ†è¯å™¨ (Tokenizer)æ¨é€åˆ°ä½•å¤„ï¼š
```py
>>> from transformers.keras_callbacks import PushToHubCallback

>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="my_awesome_model",
...     tokenizer=tokenizer,
... )
```

ç„¶åå°†å›è°ƒå‡½æ•°æ†ç»‘åœ¨ä¸€èµ·ï¼š
```py
>>> callbacks = [metric_callback, push_to_hub_callback]
```

æœ€åï¼Œæ‚¨å¯ä»¥é€šè¿‡è°ƒç”¨ [`fit`](https://keras.io/api/models/model_training_apis/#fit-method) æ¥å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ŒåŒæ—¶ä¼ é€’è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€è®­ç»ƒè½®æ•°ä»¥åŠå›è°ƒå‡½æ•°æ¥å¾®è°ƒæ¨¡å‹ï¼š
```py
>>> model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=2, callbacks=callbacks)
```

è®­ç»ƒå®Œæˆåï¼Œæ‚¨çš„æ¨¡å‹å°†è‡ªåŠ¨ä¸Šä¼ åˆ° Hubï¼Œä»¥ä¾›æ‰€æœ‰äººä½¿ç”¨ï¼
</tf>
</frameworkcontent>

<Tip>

å¦‚æœæ‚¨æƒ³è¦äº†è§£æœ‰å…³å¦‚ä½•ä¸ºå¤šé¡¹é€‰æ‹©é—®é¢˜å¾®è°ƒæ¨¡å‹çš„æ›´è¯¦ç»†ç¤ºä¾‹ï¼Œè¯·å‚è€ƒç›¸åº”çš„ [PyTorch ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb) æˆ–è€… [TensorFlow ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)ã€‚
</Tip>

## æ¨ç†

å¤ªæ£’äº†ï¼Œç°åœ¨æ‚¨å·²ç»å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼
å‡†å¤‡ä¸€äº›æ–‡æœ¬å’Œä¸¤ä¸ªå€™é€‰ç­”æ¡ˆï¼š

```py
>>> prompt = "France has a bread law, Le DÃ©cret Pain, with strict rules on what is allowed in a traditional baguette."
>>> candidate1 = "The law does not apply to croissants and brioche."
>>> candidate2 = "The law applies to baguettes."
```


<frameworkcontent> 
<pt> 

 å¯¹æ¯ä¸ªæç¤ºå’Œå€™é€‰ç­”æ¡ˆå¯¹è¿›è¡Œåˆ†è¯ï¼Œå¹¶è¿”å› PyTorch å¼ é‡ã€‚è¿˜åº”è¯¥åˆ›å»ºä¸€äº› `labels`ï¼š

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("my_awesome_swag_model")
>>> inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors="pt", padding=True)
>>> labels = torch.tensor(0).unsqueeze(0)
```

å°†è¾“å…¥å’Œæ ‡ç­¾ä¼ é€’ç»™æ¨¡å‹ï¼Œå¹¶è¿”å› `logits`ï¼š
```py
>>> from transformers import AutoModelForMultipleChoice

>>> model = AutoModelForMultipleChoice.from_pretrained("my_awesome_swag_model")
>>> outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)
>>> logits = outputs.logits
```

è·å–å…·æœ‰æœ€é«˜æ¦‚ç‡çš„ç±»åˆ«ï¼š
```py
>>> predicted_class = logits.argmax().item()
>>> predicted_class
'0'
```
</pt> 
<tf> 

å¯¹æ¯ä¸ªæç¤ºå’Œå€™é€‰ç­”æ¡ˆå¯¹è¿›è¡Œåˆ†è¯ï¼Œå¹¶è¿”å› TensorFlow å¼ é‡ï¼š

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("my_awesome_swag_model")
>>> inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors="tf", padding=True)
```

å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹ï¼Œå¹¶è¿”å› `logits`ï¼š
```py
>>> from transformers import TFAutoModelForMultipleChoice

>>> model = TFAutoModelForMultipleChoice.from_pretrained("my_awesome_swag_model")
>>> inputs = {k: tf.expand_dims(v, 0) for k, v in inputs.items()}
>>> outputs = model(inputs)
>>> logits = outputs.logits
```

è·å–å…·æœ‰æœ€é«˜æ¦‚ç‡çš„ç±»åˆ«ï¼š
```py
>>> predicted_class = int(tf.math.argmax(logits, axis=-1)[0])
>>> predicted_class
'0'
```
</tf>
</frameworkcontent>

