<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# ğŸ¤— Transformers

Î¥Ï€ÎµÏÏƒÏÎ³Ï‡ÏÎ¿Î½Î¿ Machine Learning Î³Î¹Î± [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), and [JAX](https://jax.readthedocs.io/en/latest/).

ğŸ¤— Î¤Î¿ Transformers Ï€Î±ÏÎ­Ï‡ÎµÎ¹ APIs ÎºÎ±Î¹ ÎµÏÎ³Î±Î»ÎµÎ¯Î± Î³Î¹Î± Î½Î± ÎºÎ±Ï„ÎµÎ²Î¬ÏƒÎµÏ„Îµ ÎºÎ±Î¹ Î½Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏÏƒÎµÏ„Îµ Ï…Ï€ÎµÏÏƒÏÎ³Ï‡ÏÎ¿Î½Î± Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î±. Î— Ï‡ÏÎ®ÏƒÎ· Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼ÎµÎ¹ÏÏƒÎµÎ¹ Ï„Î¿ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î¹ÎºÏŒ ÏƒÎ±Ï‚ ÎºÏŒÏƒÏ„Î¿Ï‚, Ï„Î¿ Î±Ï€Î¿Ï„ÏÏ€Ï‰Î¼Î± Î´Î¹Î¿Î¾ÎµÎ´Î¯Î¿Ï… Ï„Î¿Ï… Î¬Î½Î¸ÏÎ±ÎºÎ±, ÎºÎ±Î¹ Î½Î± ÏƒÎ±Ï‚ Î³Î»Î¹Ï„ÏÏƒÎµÎ¹ Ï„Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚ ÎºÎ±Î¹ Ï„Î¿Î½ Ï‡ÏÏŒÎ½Î¿ Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ Î³Î¹Î± Ï„Î·Î½ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÎµÎ½ÏŒÏ‚ Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Î±Ï€ÏŒ Î¼Î·Î´Î­Î½. Î¤Î± Î¼Î¿Î½Ï„Î­Î»Î± Î±Ï…Ï„Î¬ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶Î¿Ï…Î½ ÏƒÏ…Î½Î·Î¸Î¹ÏƒÎ¼Î­Î½Î± ÎºÎ±Î¸Î®ÎºÎ¿Î½Ï„Î±(tasks) Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ÏÏ‚ Ï„ÏÏŒÏ€Î¿Ï…Ï‚, ÏŒÏ€Ï‰Ï‚:

ğŸ“ **Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î“Î»ÏÏƒÏƒÎ±Ï‚**: ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…, Î¿Î½Î¿Î¼Î±ÏƒÏ„Î¹ÎºÎ® Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Î¿Î½Ï„Î¿Ï„Î®Ï„Ï‰Î½, Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÎµ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚, Î³Î»Ï‰ÏƒÏƒÎ¹ÎºÎ® Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·, Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·, Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·, Ï€Î¿Î»Î»Î±Ï€Î»Î® ÎµÏ€Î¹Î»Î¿Î³Î®, ÎºÎ±Î¹ Ï€Î±ÏÎ±Î³Ï‰Î³Î® ÎºÎµÎ¹Î¼Î­Î½Î¿Ï….</br>
ğŸ–¼ï¸ **ÎŒÏÎ±ÏƒÎ· Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î®**: ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Î±Ï‚, Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½, ÎºÎ±Î¹ ÎºÎ±Ï„Î¬Ï„Î¼Î·ÏƒÎ·.<br>
ğŸ—£ï¸ **Î‰Ï‡Î¿Ï‚**: Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Î¿Î¼Î¹Î»Î¯Î±Ï‚ ÎºÎ±Î¹ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î®Ï‡Î¿Ï….<br>
ğŸ™ **Î Î¿Î»Ï…Ï„ÏÎ¿Ï€Î¹ÎºÎ¬**: Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÎµÏÏ‰Ï„Î®ÏƒÎµÏ‰Î½ Î±Ï€ÏŒ Ï€Î¯Î½Î±ÎºÎµÏ‚, Î¿Ï€Ï„Î¹ÎºÎ® Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÏ‰Î½, ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±Ï‚ Î±Ï€ÏŒ ÏƒÎºÎ±Î½Î±ÏÎ¹ÏƒÎ¼Î­Î½Î± Î­Î³Î³ÏÎ±Ï†Î±, ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î²Î¯Î½Ï„ÎµÎ¿, ÎºÎ±Î¹ Î¿Ï€Ï„Î¹ÎºÎ® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÎµ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚.<br>

ğŸ¤— Î¤Î¿ Transformers Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ Î´Î¹Î±Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÏŒÏ„Î·Ï„Î± framework Î±Î½Î¬Î¼ÎµÏƒÎ± ÏƒÏ„Î± PyTorch, TensorFlow, and JAX. Î‘Ï…Ï„ÏŒ Î¼Î±Ï‚ Î´Î¯Î½ÎµÎ¹ Ï„Î·Î½ ÎµÎ»ÎµÏ…Î¸ÎµÏÎ¯Î± Ï„Î·Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿Ï framework ÏƒÎµ ÎºÎ¬Î¸Îµ ÏƒÏ„Î¬Î´Î¹Î¿ Ï„Î·Ï‚ "Î¶Ï‰Î®Ï‚" ÎµÎ½ÏŒÏ‚ Î¼Î¿Î½Ï„Î­Î»Î¿Ï…; Î•ÎºÏ€Î±Î¹Î´ÎµÏÏƒÏ„Îµ Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ Î¼Îµ Ï„ÏÎµÎ¯Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚ ÎºÏÎ´Î¹ÎºÎ± ÏƒÎµ Î­Î½Î± framework ÎºÎ±Î¹ Ï†Î¿ÏÏ„ÏÏƒÏ„Îµ Ï„Î¿ Î³Î¹Î± ÏƒÏ…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î± ÏƒÎµ Î­Î½Î± Î¬Î»Î»Î¿. Î¤Î± Î¼Î¿Î½Ï„Î­Î»Î± Î¼Ï€Î¿ÏÎ¿ÏÎ½ ÎµÏ€Î¯ÏƒÎ·Ï‚ Î½Î± ÎµÎ¾Î±Ï‡Î¸Î¿ÏÎ½ ÏƒÎµ format ÏŒÏ€Ï‰Ï‚ ONNX ÎºÎ±Î¹ TorchScript Î³Î¹Î± deployment ÏƒÎµ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± production.

Î“Î¯Î½Îµ Î¼Î­Î»Î¿Ï‚ Ï„Î·Ï‚ ÏƒÏ…Î½ÎµÏ‡ÏÏ‚ Î±Ï…Î¾Î±Î½ÏŒÎ¼ÎµÎ½Î·Ï‚ ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚ ÏƒÏ„ÏŒ [Hub](https://huggingface.co/models), [forum](https://discuss.huggingface.co/), Î® [Discord](https://discord.com/invite/JfAtkvEtRb) ÏƒÎ®Î¼ÎµÏÎ±!

## Î‘Î½ ÏˆÎ¬Ï‡Î½ÎµÎ¹Ï‚ ÎµÎ¾Î±Ï„Î¿Î¼Î¹ÎºÎµÏ…Î¼Î­Î½Î· Ï…Ï€Î¿ÏƒÏ„Î¯ÏÎ¹Î¾Î· Î±Ï€Î¿ Ï„Î·Î½ Î¿Î¼Î¬Î´Î± Ï„Î¿Ï… Hugging Face

<a target="_blank" href="https://huggingface.co/support">
    <img alt="HuggingFace Expert Acceleration Program" src="https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png" style="max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);">
</a>
</br>

## Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î±

Î— Ï„ÎµÎºÎ¼Î·ÏÎ¯Ï‰ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Î¿ÏÎ³Î±Î½Ï‰Î¼Î­Î½Î· ÏƒÎµ Ï€Î­Î½Ï„Îµ ÎµÎ½ÏŒÏ„Î·Ï„ÎµÏ‚:

- **ÎÎ•ÎšÎ™ÎÎ©ÎÎ¤Î‘Î£** Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î¼Î¹Î± Î³ÏÎ®Î³Î¿ÏÎ· Ï€ÎµÏÎ¹Î®Î³Î·ÏƒÎ· Ï„Î·Ï‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·Ï‚ ÎºÎ±Î¸ÏÏ‚ ÎºÎ±Î¹ Î¿Î´Î·Î³Î¯ÎµÏ‚ ÎµÎ³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î·Ï‚.
- **TUTORIALS** ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î­ÏÎ¿Ï‚ Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹Ï‚ ÏÏ‚ Î±ÏÏ‡Î¬ÏÎ¹Î¿Ï‚. Î‘Ï…Ï„Î® Î· ÎµÎ½ÏŒÏ„Î·Ï„Î± Î¸Î± ÏƒÎµ Î²Î¿Î·Î¸Î®ÏƒÎµÎ¹ Î½Î± Ï€Î¬ÏÎµÎ¹Ï‚ Ï„Î¹Ï‚ Î²Î±ÏƒÎ¹ÎºÎ­Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Ï€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î½Ï„Î±Î¹ Î³Î¹Î± Î½Î± Î±ÏÏ‡Î¯ÏƒÎµÎ¹Ï‚ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï‚ Ï„Î·Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·.
- **ÎŸÎ”Î—Î“ÎŸÎ™ HOW-TO** ÏƒÎ¿Ï… Î´ÎµÎ¯Ï‡Î½Î¿Ï…Î½ Ï€Ï‰Ï‚ Î¼Ï€Î¿ÏÎµÎ¯Ï‚ Î½Î± Ï€ÎµÏ„ÏÏ‡ÎµÎ¹Ï‚ Î­Î½Î±Î½ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ ÏƒÏ„ÏŒÏ‡Î¿, ÏŒÏ€Ï‰Ï‚ Î· Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î® ÎµÎ½ÏŒÏ‚ Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Î³Î¹Î± Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î³Î»ÏÏƒÏƒÎ±Ï‚ Î® Ï„Î¿ Ï€ÏÏ‚ Î½Î± Î³ÏÎ¬ÏˆÎµÎ¹Ï‚ ÎºÎ±Î¹ Î½Î± Î¼Î¿Î¹ÏÎ±ÏƒÏ„ÎµÎ¯Ï‚ Î­Î½Î± custom Î¼Î¿Î½Ï„Î­Î»Î¿.
- **Î•ÎÎÎŸÎ™ÎŸÎ›ÎŸÎ“Î™ÎšÎŸÎ£ ÎŸÎ”Î—Î“ÎŸÎ£** Ï€ÏÎ¿ÏƒÏ†Î­ÏÎµÎ¹ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ· ÎµÎ¾Î®Î³Î·ÏƒÎ· Ï„Ï‰Î½ Ï…Ï€Î¿ÎºÎµÎ¯Î¼ÎµÎ½Ï‰Î½ ÎµÎ½Î½Î¿Î¹ÏÎ½ ÎºÎ±Î¹ Î¹Î´ÎµÏÎ½ Ï€Î¯ÏƒÏ‰ Î±Ï€ÏŒ Ï„Î± Î¼Î¿Î½Ï„Î­Î»Î±, tasks, ÎºÎ±Î¹ Ï„Î·Î½ Ï†Î¹Î»Î¿ÏƒÎ¿Ï†Î¯Î± ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï Ï„Î¿Ï… ğŸ¤— Transformers.
- **API** describes all classes and functions:

  - **Î’Î‘Î£Î™ÎšÎ•Î£ ÎšÎ›Î‘Î£Î•Î™Î£** Ï€ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÎ¹ Î¼Îµ Î»ÎµÏ€Ï„Î¿Î¼Î­ÏÎ¹Î± Ï„Î¹Ï‚ Ï€Î¹Î¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚ Ï„Î¿Ï… ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ ÏŒÏ€Ï‰Ï‚ configuration, model, tokenizer, ÎºÎ±Î¹ pipeline.
  - **ÎœÎŸÎÎ¤Î•Î›Î‘** Ï€ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÎ¹ Ï„Î¹Ï‚ ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯ÎµÏ‚ Ï€Î¿Ï… ÏƒÏ‡ÎµÏ„Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼Îµ ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€Î¿Ï… Ï…Î»Î¿Ï€Î¿Î¹Î®Ï„Î±Î¹ ÏƒÏ„Î·Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·.
  - **Î•Î£Î©Î¤Î•Î¡Î™ÎšÎŸÎ™ Î’ÎŸÎ—Î˜ÎŸÎ™** Ï€ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÎ¹ Ï„Î¹Ï‚ ÎµÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ­Ï‚ ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ Ï‡ÏÎ·ÏƒÏ„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚.

### Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î± ÎœÎ¿Î½Ï„Î­Î»Î±

<!--This list is updated automatically from the README with _make fix-copies_. Do not update manually! -->

1. **[ALBERT](model_doc/albert)** (Î±Ï€ÏŒ Google Research ÎºÎ±Î¹ Ï„Î·Î½ Toyota Technological Institute ÏƒÏ„Î¿ Î£Î¹ÎºÎ¬Î³Î¿) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942), Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.
1. **[BART](model_doc/bart)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.
1. **[BARThez](model_doc/barthez)** (Î±Ï€ÏŒ Ã‰cole polytechnique) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [BARThez: a Skilled Pretrained French Sequence-to-Sequence Model](https://arxiv.org/abs/2010.12321) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.
1. **[BARTpho](model_doc/bartpho)** (Î±Ï€ÏŒ VinAI Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese](https://arxiv.org/abs/2109.09701) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.
1. **[BEiT](model_doc/beit)** (Î±Ï€ÏŒ Microsoft) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Hangbo Bao, Li Dong, Furu Wei.
1. **[BERT](model_doc/bert)** (Î±Ï€ÏŒ Google) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.
1. **[BERT For Sequence Generation](model_doc/bert-generation)** (Î±Ï€ÏŒ Google) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Leveraging Pre-trained Checkpoints for Sequence Generation Tasks](https://arxiv.org/abs/1907.12461) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sascha Rothe, Shashi Narayan, Aliaksei Severyn.
1. **[BERTweet](model_doc/bertweet)** (Î±Ï€ÏŒ VinAI Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [BERTweet: A pre-trained language model for English Tweets](https://aclanthology.org/2020.emnlp-demos.2/) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.
1. **[BigBird-Pegasus](model_doc/bigbird_pegasus)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.
1. **[BigBird-RoBERTa](model_doc/big_bird)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.
1. **[Blenderbot](model_doc/blenderbot)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.
1. **[BlenderbotSmall](model_doc/blenderbot-small)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.
1. **[BLOOM](model_doc/bloom)** (Î±Ï€ÏŒ BigScience workshop) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î±Ï€ÏŒ Ï„Î¿ [BigSicence Workshop](https://bigscience.huggingface.co/).
1. **[BORT](model_doc/bort)** (Î±Ï€ÏŒ Alexa) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Optimal Subarchitecture Extraction For BERT](https://arxiv.org/abs/2010.10499) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Adrian de Wynter and Daniel J. Perry.
1. **[ByT5](model_doc/byt5)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ByT5: Towards a token-free future with pre-trained byte-to-byte models](https://arxiv.org/abs/2105.13626) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.
1. **[CamemBERT](model_doc/camembert)** (Î±Ï€ÏŒ Inria/Facebook/Sorbonne) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [CamemBERT: a Tasty French Language Model](https://arxiv.org/abs/1911.03894) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.
1. **[CANINE](model_doc/canine)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation](https://arxiv.org/abs/2103.06874) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.
1. **[CLIP](model_doc/clip)** (Î±Ï€ÏŒ OpenAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.
1. **[CodeGen](model_doc/codegen)** (Î±Ï€ÏŒ Salesforce) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.
1. **[Conditional DETR](model_doc/conditional_detr)** (Î±Ï€ÏŒ Microsoft Research Î‘ÏƒÎ¯Î±) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.
1. **[ConvBERT](model_doc/convbert)** (Î±Ï€ÏŒ YituTech) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ConvBERT: Improving BERT with Span-based Dynamic Convolution](https://arxiv.org/abs/2008.02496) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.
1. **[ConvNeXT](model_doc/convnext)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.
1. **[CPM](model_doc/cpm)** (Î±Ï€ÏŒ Tsinghua University) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [CPM: A Large-scale Generative Chinese Pre-trained Language Model](https://arxiv.org/abs/2012.00413) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.
1. **[CTRL](model_doc/ctrl)** (Î±Ï€ÏŒ Salesforce) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [CTRL: A Conditional Transformer Language Model for Controllable Generation](https://arxiv.org/abs/1909.05858) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.
1. **[CvT](model_doc/cvt)** (Î±Ï€ÏŒ Microsoft) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [CvT: Introducing Convolutions to Vision Transformers](https://arxiv.org/abs/2103.15808) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.
1. **[Data2Vec](model_doc/data2vec)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language](https://arxiv.org/abs/2202.03555) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.
1. **[DeBERTa](model_doc/deberta)** (Î±Ï€ÏŒ Microsoft) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.
1. **[DeBERTa-v2](model_doc/deberta-v2)** (Î±Ï€ÏŒ Microsoft) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.
1. **[Decision Transformer](model_doc/decision_transformer)** (Î±Ï€ÏŒ Berkeley/Facebook/Google) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/abs/2106.01345) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.
1. **[Deformable DETR](model_doc/deformable_detr)** (Î±Ï€ÏŒ SenseTime Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.
1. **[DeiT](model_doc/deit)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, HervÃ© JÃ©gou.
1. **[DETR](model_doc/detr)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.
1. **[DialoGPT](model_doc/dialogpt)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation](https://arxiv.org/abs/1911.00536) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.
1. **[DistilBERT](model_doc/distilbert)** (Î±Ï€ÏŒ HuggingFace), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Î±Î¶Î¯ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into [DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), RoBERTa into [DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), Multilingual BERT into [DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation) and a German version of DistilBERT.
1. **[DiT](model_doc/dit)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [DiT: Self-supervised Pre-training for Document Image Transformer](https://arxiv.org/abs/2203.02378) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.
1. **[Donut](model_doc/donut)** (Î±Ï€ÏŒ NAVER), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Î±Î¶Î¯ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.
1. **[DPR](model_doc/dpr)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Vladimir Karpukhin, Barlas OÄŸuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.
1. **[DPT](master/model_doc/dpt)** (Î±Ï€ÏŒ Intel Labs) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ RenÃ© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.
1. **[ELECTRA](model_doc/electra)** (Î±Ï€ÏŒ Google Research/Stanford University) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ELECTRA: Pre-training text encoders as discriminators rather than generators](https://arxiv.org/abs/2003.10555) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.
1. **[EncoderDecoder](model_doc/encoder-decoder)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Leveraging Pre-trained Checkpoints for Sequence Generation Tasks](https://arxiv.org/abs/1907.12461) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sascha Rothe, Shashi Narayan, Aliaksei Severyn.
1. **[ERNIE](model_doc/ernie)** (Î±Ï€ÏŒ Baidu) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ERNIE: Enhanced Representation through Knowledge Integration](https://arxiv.org/abs/1904.09223) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.
1. **[ESM](model_doc/esm)** (Î±Ï€ÏŒ Meta AI) are transformer protein language models.  **ESM-1b** was ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences](https://www.pnas.org/content/118/15/e2016239118) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. **ESM-1v** was ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Language models enable zero-shot prediction of the effects of mutations on protein function](https://doi.org/10.1101/2021.07.09.450648) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. **ESM-2** was ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Language models of protein sequences at the scale of evolution enable accurate structure prediction](https://doi.org/10.1101/2022.07.20.500902) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.
1. **[FlauBERT](model_doc/flaubert)** (Î±Ï€ÏŒ CNRS) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [FlauBERT: Unsupervised Language Model Pre-training for French](https://arxiv.org/abs/1912.05372) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Hang Le, LoÃ¯c Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, BenoÃ®t CrabbÃ©, Laurent Besacier, Didier Schwab.
1. **[FLAVA](model_doc/flava)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [FLAVA: A Foundational Language And Vision Alignment Model](https://arxiv.org/abs/2112.04482) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.
1. **[FNet](model_doc/fnet)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.
1. **[Funnel Transformer](model_doc/funnel)** (Î±Ï€ÏŒ CMU/Google Brain) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing](https://arxiv.org/abs/2006.03236) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.
1. **[GLPN](model_doc/glpn)** (Î±Ï€ÏŒ KAIST) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth](https://arxiv.org/abs/2201.07436) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.
1. **[GPT](model_doc/openai-gpt)** (Î±Ï€ÏŒ OpenAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Improving Language Understanding by Generative Pre-Training](https://blog.openai.com/language-unsupervised/) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.
1. **[GPT Neo](model_doc/gpt_neo)** (Î±Ï€ÏŒ EleutherAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ ÏƒÏ„Î¿ Î±Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿ [EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.
1. **[GPT NeoX](model_doc/gpt_neox)** (Î±Ï€ÏŒ EleutherAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](https://arxiv.org/abs/2204.06745) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach
1. **[GPT NeoX Japanese](model_doc/gpt_neox_japanese)** (Î±Ï€ÏŒ ABEJA) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.
1. **[GPT-2](model_doc/gpt2)** (Î±Ï€ÏŒ OpenAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Language Models are Unsupervised Multitask Learners](https://blog.openai.com/better-language-models/) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.
1. **[GPT-J](model_doc/gptj)** (Î±Ï€ÏŒ EleutherAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ ÏƒÏ„Î¿ Î±Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿ [kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax/) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ben Wang and Aran Komatsuzaki.
1. **[GroupViT](model_doc/groupvit)** (Î±Ï€ÏŒ UCSD, NVIDIA) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/abs/2202.11094) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.
1. **[Hubert](model_doc/hubert)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.
1. **[I-BERT](model_doc/ibert)** (Î±Ï€ÏŒ Berkeley) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [I-BERT: Integer-only BERT Quantization](https://arxiv.org/abs/2101.01321) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.
1. **[ImageGPT](model_doc/imagegpt)** (Î±Ï€ÏŒ OpenAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Generative Pretraining from Pixels](https://openai.com/blog/image-gpt/) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.
1. **[LayoutLM](model_doc/layoutlm)** (Î±Ï€ÏŒ Microsoft Research Asia) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.
1. **[LayoutLMv2](model_doc/layoutlmv2)** (Î±Ï€ÏŒ Microsoft Research Asia) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.
1. **[LayoutLMv3](model_doc/layoutlmv3)** (Î±Ï€ÏŒ Microsoft Research Asia) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.
1. **[LayoutXLM](model_doc/layoutxlm)** (Î±Ï€ÏŒ Microsoft Research Asia) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding](https://arxiv.org/abs/2104.08836) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.
1. **[LED](model_doc/led)** (Î±Ï€ÏŒ AllenAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Iz Beltagy, Matthew E. Peters, Arman Cohan.
1. **[LeViT](model_doc/levit)** (Î±Ï€ÏŒ Meta AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference](https://arxiv.org/abs/2104.01136) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, HervÃ© JÃ©gou, Matthijs Douze.
1. **[LiLT](model_doc/lilt)** (Î±Ï€ÏŒ South China University of Technology) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding](https://arxiv.org/abs/2202.13669) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jiapeng Wang, Lianwen Jin, Kai Ding.
1. **[Longformer](model_doc/longformer)** (Î±Ï€ÏŒ AllenAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Iz Beltagy, Matthew E. Peters, Arman Cohan.
1. **[LongT5](model_doc/longt5)** (Î±Ï€ÏŒ Google AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LongT5: Efficient Text-To-Text Transformer for Long Sequences](https://arxiv.org/abs/2112.07916) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.
1. **[LUKE](model_doc/luke)** (Î±Ï€ÏŒ Studio Ousia) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention](https://arxiv.org/abs/2010.01057) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.
1. **[LXMERT](model_doc/lxmert)** (Î±Ï€ÏŒ UNC Chapel Hill) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering](https://arxiv.org/abs/1908.07490) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Hao Tan and Mohit Bansal.
1. **[M-CTC-T](model_doc/mctct)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Pseudo-Labeling For Massively Multilingual Speech Recognition](https://arxiv.org/abs/2111.00161) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.
1. **[M2M100](model_doc/m2m_100)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Beyond English-Centric Multilingual Machine Translation](https://arxiv.org/abs/2010.11125) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.
1. **[MarianMT](model_doc/marian)** Machine translation models trained using [OPUS](http://opus.nlpl.eu/) Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ JÃ¶rg Tiedemann. The [Marian Framework](https://marian-nmt.github.io/) is being developed Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ the Microsoft Translator Team.
1. **[MarkupLM](model_doc/markuplm)** (Î±Ï€ÏŒ Microsoft Research Asia) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding](https://arxiv.org/abs/2110.08518) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.
1. **[MaskFormer](model_doc/maskformer)** (Î±Ï€ÏŒ Meta and UIUC) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Per-Pixel Classification is Not All You Need for Semantic Segmentation](https://arxiv.org/abs/2107.06278) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.
1. **[mBART](model_doc/mbart)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Multilingual Denoising Pre-training for Neural Machine Translation](https://arxiv.org/abs/2001.08210) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.
1. **[mBART-50](model_doc/mbart)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Multilingual Translation with Extensible Multilingual Pretraining and Finetuning](https://arxiv.org/abs/2008.00401) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.
1. **[Megatron-BERT](model_doc/megatron-bert)** (Î±Ï€ÏŒ NVIDIA) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.
1. **[Megatron-GPT2](model_doc/megatron_gpt2)** (Î±Ï€ÏŒ NVIDIA) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.
1. **[mLUKE](model_doc/mluke)** (Î±Ï€ÏŒ Studio Ousia) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models](https://arxiv.org/abs/2110.08151) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.
1. **[MobileBERT](model_doc/mobilebert)** (Î±Ï€ÏŒ CMU/Google Brain) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices](https://arxiv.org/abs/2004.02984) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.
1. **[MobileViT](model_doc/mobilevit)** (Î±Ï€ÏŒ Apple) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sachin Mehta and Mohammad Rastegari.
1. **[MPNet](model_doc/mpnet)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [MPNet: Masked and Permuted Pre-training for Language Understanding](https://arxiv.org/abs/2004.09297) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.
1. **[MT5](model_doc/mt5)** (Î±Ï€ÏŒ Google AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [mT5: A massively multilingual pre-trained text-to-text transformer](https://arxiv.org/abs/2010.11934) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.
1. **[MVP](model_doc/mvp)** (Î±Ï€ÏŒ RUC AI Box) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [MVP: Multi-task Supervised Pre-training for Natural Language Generation](https://arxiv.org/abs/2206.12131) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.
1. **[Nezha](model_doc/nezha)** (Î±Ï€ÏŒ Huawei Noahâ€™s Ark Lab) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [NEZHA: Neural Contextualized Representation for Chinese Language Understanding](https://arxiv.org/abs/1909.00204) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.
1. **[NLLB](model_doc/nllb)** (Î±Ï€ÏŒ Meta) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [No Language Left Behind: Scaling Human-Centered Machine Translation](https://arxiv.org/abs/2207.04672) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ the NLLB team.
1. **[NystrÃ¶mformer](model_doc/nystromformer)** (Î±Ï€ÏŒ the University of Wisconsin - Madison) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [NystrÃ¶mformer: A NystrÃ¶m-Based Algorithm for Approximating Self-Attention](https://arxiv.org/abs/2102.03902) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.
1. **[OPT](master/model_doc/opt)** (Î±Ï€ÏŒ Meta AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.
1. **[OWL-ViT](model_doc/owlvit)** (Î±Ï€ÏŒ Google AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Simple Open-Vocabulary Object Detection with Vision Transformers](https://arxiv.org/abs/2205.06230) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.
1. **[Pegasus](model_doc/pegasus)** (Î±Ï€ÏŒ Google) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization](https://arxiv.org/abs/1912.08777) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.
1. **[PEGASUS-X](model_doc/pegasus_x)** (Î±Ï€ÏŒ Google) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Investigating Efficiently Extending Transformers for Long Input Summarization](https://arxiv.org/abs/2208.04347) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jason Phang, Yao Zhao, and Peter J. Liu.
1. **[Perceiver IO](model_doc/perceiver)** (Î±Ï€ÏŒ Deepmind) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Perceiver IO: A General Architecture for Structured Inputs & Outputs](https://arxiv.org/abs/2107.14795) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier HÃ©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, JoÃ£o Carreira.
1. **[PhoBERT](model_doc/phobert)** (Î±Ï€ÏŒ VinAI Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [PhoBERT: Pre-trained language models for Vietnamese](https://www.aclweb.org/anthology/2020.findings-emnlp.92/) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Dat Quoc Nguyen and Anh Tuan Nguyen.
1. **[PLBart](model_doc/plbart)** (Î±Ï€ÏŒ UCLA NLP) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Unified Pre-training for Program Understanding and Generation](https://arxiv.org/abs/2103.06333) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.
1. **[PoolFormer](model_doc/poolformer)** (Î±Ï€ÏŒ Sea AI Labs) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [MetaFormer is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.
1. **[ProphetNet](model_doc/prophetnet)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](https://arxiv.org/abs/2001.04063) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.
1. **[QDQBert](model_doc/qdqbert)** (Î±Ï€ÏŒ NVIDIA) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation](https://arxiv.org/abs/2004.09602) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.
1. **[RAG](model_doc/rag)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, Douwe Kiela.
1. **[REALM](model_doc/realm.html)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.
1. **[Reformer](model_doc/reformer)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Reformer: The Efficient Transformer](https://arxiv.org/abs/2001.04451) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Nikita Kitaev, Åukasz Kaiser, Anselm Levskaya.
1. **[RegNet](model_doc/regnet)** (Î±Ï€ÏŒ META Platforms) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Designing Network Design Space](https://arxiv.org/abs/2003.13678) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr DollÃ¡r.
1. **[RemBERT](model_doc/rembert)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Rethinking embedding coupling in pre-trained language models](https://arxiv.org/abs/2010.12821) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Hyung Won Chung, Thibault FÃ©vry, Henry Tsai, M. Johnson, Sebastian Ruder.
1. **[ResNet](model_doc/resnet)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.
1. **[RoBERTa](model_doc/roberta)** (Î±Ï€ÏŒ Facebook), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.
1. **[RoFormer](model_doc/roformer)** (Î±Ï€ÏŒ ZhuiyiTechnology), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.
1. **[SegFormer](model_doc/segformer)** (Î±Ï€ÏŒ NVIDIA) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.
1. **[SEW](model_doc/sew)** (Î±Ï€ÏŒ ASAPP) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](https://arxiv.org/abs/2109.06870) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.
1. **[SEW-D](model_doc/sew_d)** (Î±Ï€ÏŒ ASAPP) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](https://arxiv.org/abs/2109.06870) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.
1. **[SpeechToTextTransformer](model_doc/speech_to_text)** (Î±Ï€ÏŒ Facebook), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [fairseq S2T: Fast Speech-to-Text Modeling with fairseq](https://arxiv.org/abs/2010.05171) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.
1. **[SpeechToTextTransformer2](model_doc/speech_to_text_2)** (Î±Ï€ÏŒ Facebook), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Large-Scale Self- and Semi-Supervised Learning for Speech Translation](https://arxiv.org/abs/2104.06678) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.
1. **[Splinter](model_doc/splinter)** (Î±Ï€ÏŒ Tel Aviv University), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Few-Shot Question Answering by Pretraining Span Selection](https://arxiv.org/abs/2101.00438) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.
1. **[SqueezeBERT](model_doc/squeezebert)** (Î±Ï€ÏŒ Berkeley) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [SqueezeBERT: What can computer vision teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.
1. **[Swin Transformer](model_doc/swin)** (Î±Ï€ÏŒ Microsoft) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.
1. **[Swin Transformer V2](model_doc/swinv2)** (Î±Ï€ÏŒ Microsoft) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/abs/2111.09883) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.
1. **[T5](model_doc/t5)** (Î±Ï€ÏŒ Google AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.
1. **[T5v1.1](model_doc/t5v1.1)** (Î±Ï€ÏŒ Google AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ ÏƒÏ„Î¿ Î±Ï€Î¿Î¸ÎµÏ„Î®ÏÎ¹Î¿ [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.
1. **[Table Transformer](model_doc/table-transformer)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents](https://arxiv.org/abs/2110.00061) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Brandon Smock, Rohith Pesala, Robin Abraham.
1. **[TAPAS](model_doc/tapas)** (Î±Ï€ÏŒ Google AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [TAPAS: Weakly Supervised Table Parsing via Pre-training](https://arxiv.org/abs/2004.02349) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas MÃ¼ller, Francesco Piccinno and Julian Martin Eisenschlos.
1. **[TAPEX](model_doc/tapex)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [TAPEX: Table Pre-training via Learning a Neural SQL Executor](https://arxiv.org/abs/2107.07653) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.
1. **[Time Series Transformer](model_doc/time_series_transformer)**  (Î±Ï€ÏŒ HuggingFace).
1. **[Trajectory Transformer](model_doc/trajectory_transformers)** (Î±Ï€ÏŒ the University of California at Berkeley) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Offline Reinforcement Learning as One Big Sequence Modeling Problem](https://arxiv.org/abs/2106.02039) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Michael Janner, Qiyang Li, Sergey Levine
1. **[Transformer-XL](model_doc/transfo-xl)** (Î±Ï€ÏŒ Google/CMU) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.
1. **[TrOCR](model_doc/trocr)** (Î±Ï€ÏŒ Microsoft), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.
1. **[UL2](model_doc/ul2)** (Î±Ï€ÏŒ Google Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Unifying Language Learning Paradigms](https://arxiv.org/abs/2205.05131v1) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald Metzler
1. **[UniSpeech](model_doc/unispeech)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data](https://arxiv.org/abs/2101.07597) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.
1. **[UniSpeechSat](model_doc/unispeech-sat)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING](https://arxiv.org/abs/2110.05752) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.
1. **[VAN](model_doc/van)** (Î±Ï€ÏŒ Tsinghua University and Nankai University) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Visual Attention Network](https://arxiv.org/abs/2202.09741) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.
1. **[VideoMAE](model_doc/videomae)** (Î±Ï€ÏŒ Multimedia Computing Group, Nanjing University) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training](https://arxiv.org/abs/2203.12602) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zhan Tong, Yibing Song, Jue Wang, Limin Wang.
1. **[ViLT](model_doc/vilt)** (Î±Ï€ÏŒ NAVER AI Lab/Kakao Enterprise/Kakao Brain) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision](https://arxiv.org/abs/2102.03334) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Wonjae Kim, Bokyung Son, Ildoo Kim.
1. **[Vision Transformer (ViT)](model_doc/vit)** (Î±Ï€ÏŒ Google AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.
1. **[VisualBERT](model_doc/visual_bert)** (Î±Ï€ÏŒ UCLA NLP) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [VisualBERT: A Simple and Performant Baseline for Vision and Language](https://arxiv.org/pdf/1908.03557) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.
1. **[ViTMAE](model_doc/vit_mae)** (Î±Ï€ÏŒ Meta AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, Ross Girshick.
1. **[ViTMSN](model_doc/vit_msn)** (Î±Ï€ÏŒ Meta AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Masked Siamese Networks for Label-Efficient Learning](https://arxiv.org/abs/2204.07141) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.
1. **[Wav2Vec2](model_doc/wav2vec2)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.
1. **[Wav2Vec2-Conformer](model_doc/wav2vec2-conformer)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ](https://arxiv.org/abs/2010.05171) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.
1. **[Wav2Vec2Phoneme](model_doc/wav2vec2_phoneme)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Simple and Effective Zero-shot Cross-lingual Phoneme Recognition](https://arxiv.org/abs/2109.11680) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Qiantong Xu, Alexei Baevski, Michael Auli.
1. **[WavLM](model_doc/wavlm)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing](https://arxiv.org/abs/2110.13900) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.
1. **[Whisper](model_doc/whisper)** (Î±Ï€ÏŒ OpenAI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Robust Speech Recognition via Large-Scale Weak Supervision](https://cdn.openai.com/papers/whisper.pdf) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.
1. **[X-CLIP](model_doc/xclip)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Expanding Language-Image Pretrained Models for General Video Recognition](https://arxiv.org/abs/2208.02816) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.
1. **[XGLM](model_doc/xglm)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Few-shot Learning with Multilingual Language Models](https://arxiv.org/abs/2112.10668) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.
1. **[XLM](model_doc/xlm)** (Î±Ï€ÏŒ Facebook) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Guillaume Lample ÎºÎ±Î¹ Alexis Conneau.
1. **[XLM-ProphetNet](model_doc/xlm-prophetnet)** (Î±Ï€ÏŒ Microsoft Research) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](https://arxiv.org/abs/2001.04063) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.
1. **[XLM-RoBERTa](model_doc/xlm-roberta)** (Î±Ï€ÏŒ Facebook AI), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Unsupervised Cross-lingual Representation Learning at Scale](https://arxiv.org/abs/1911.02116) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.
1. **[XLM-RoBERTa-XL](model_doc/xlm-roberta-xl)** (Î±Ï€ÏŒ Facebook AI), ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Larger-Scale Transformers for Multilingual Masked Language Modeling](https://arxiv.org/abs/2105.00572) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.
1. **[XLNet](model_doc/xlnet)** (Î±Ï€ÏŒ Google/CMU) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.
1. **[XLS-R](model_doc/xls_r)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale](https://arxiv.org/abs/2111.09296) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.
1. **[XLSR-Wav2Vec2](model_doc/xlsr_wav2vec2)** (Î±Ï€ÏŒ Facebook AI) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [Unsupervised Cross-Lingual Representation Learning For Speech Recognition](https://arxiv.org/abs/2006.13979) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.
1. **[YOLOS](model_doc/yolos)** (Î±Ï€ÏŒ Huazhong University of Science & Technology) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection](https://arxiv.org/abs/2106.00666) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.
1. **[YOSO](model_doc/yoso)** (Î±Ï€ÏŒ the University of Wisconsin - Madison) ÎºÏ…ÎºÎ»Î¿Ï†ÏŒÏÎ·ÏƒÎµ Î¼Îµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± [You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling](https://arxiv.org/abs/2111.09714) Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.


### Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î± frameworks

ÎŸ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï„Î·Î½ Ï„Ï‰ÏÎ¹Î½Î® Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Ï„Î·Ï‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·Ï‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿, Î¬Î½ Î­Ï‡Î¿Ï…Î½ Î­Î½Î± Python Tokenizer (Î»Î­Î³ÎµÏ„Î±Î¹ slow). ÎˆÎ½Î± "Fast" Tokenizer 
The table below represents the current support in the library for each of those models, whether they have a Python
tokenizer (called "slow"). A "fast" tokenizer Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î¿ Î±Ï€ÏŒ Ï„Î·Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· ğŸ¤— Tokenizers, Î¬Î½ Î­Ï‡Î¿Ï…Î½ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· ÏƒÎµ Jax (Î¼Î­ÏƒÏ‰
Flax), PyTorch, ÎºÎ±Î¹/Î® TensorFlow.

<!--This table is updated automatically from the auto modules with _make fix-copies_. Do not update manually!-->

|            ÎœÎ¿Î½Ï„Î­Î»Î¿            | Tokenizer slow | Tokenizer fast | Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· PyTorch | Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· TensorFlow | Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Flax |
|:---------------------------:|:--------------:|:--------------:|:---------------:|:------------------:|:------------:|
|           ALBERT            |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|            BART             |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|            BEiT             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âœ…      |
|            BERT             |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|       Bert Generation       |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           BigBird           |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âœ…      |
|       BigBird-Pegasus       |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         Blenderbot          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|       BlenderbotSmall       |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|            BLOOM            |       âŒ       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|          CamemBERT          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|           CANINE            |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            CLIP             |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|           CodeGen           |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|      Conditional DETR       |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          ConvBERT           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|          ConvNeXT           |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|            CTRL             |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|             CvT             |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|        Data2VecAudio        |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|        Data2VecText         |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|       Data2VecVision        |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|           DeBERTa           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|         DeBERTa-v2          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|    Decision Transformer     |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|       Deformable DETR       |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            DeiT             |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|            DETR             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         DistilBERT          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|          DonutSwin          |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|             DPR             |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|             DPT             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           ELECTRA           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|       Encoder decoder       |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âœ…      |
|            ERNIE            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|             ESM             |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
| FairSeq Machine-Translation |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          FlauBERT           |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|            FLAVA            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            FNet             |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|     Funnel Transformer      |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|            GLPN             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           GPT Neo           |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âœ…      |
|          GPT NeoX           |       âŒ       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|      GPT NeoX Japanese      |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            GPT-J            |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âœ…      |
|          GroupViT           |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|           Hubert            |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|           I-BERT            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          ImageGPT           |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          LayoutLM           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|         LayoutLMv2          |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|         LayoutLMv3          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|             LED             |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|            LeViT            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            LiLT             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         Longformer          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|           LongT5            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âœ…      |
|            LUKE             |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           LXMERT            |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|           M-CTC-T           |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           M2M100            |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           Marian            |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âœ…      |
|          MarkupLM           |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|         MaskFormer          |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            mBART            |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|        Megatron-BERT        |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         MobileBERT          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|          MobileViT          |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|            MPNet            |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|             MT5             |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|             MVP             |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|            Nezha            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|        NystrÃ¶mformer        |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         OpenAI GPT          |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|        OpenAI GPT-2         |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|             OPT             |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âœ…      |
|           OWL-ViT           |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           Pegasus           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|          PEGASUS-X          |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          Perceiver          |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           PLBart            |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         PoolFormer          |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         ProphetNet          |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           QDQBert           |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|             RAG             |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|            REALM            |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|          Reformer           |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|           RegNet            |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|           RemBERT           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|           ResNet            |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|          RetriBERT          |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|           RoBERTa           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|          RoFormer           |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|          SegFormer          |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|             SEW             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            SEW-D            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|   Speech Encoder decoder    |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âœ…      |
|         Speech2Text         |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|        Speech2Text2         |       âœ…       |       âŒ       |       âŒ        |         âŒ         |      âŒ      |
|          Splinter           |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|         SqueezeBERT         |       âœ…       |       âœ…       |       âœ…        |         âŒ         |      âŒ      |
|      Swin Transformer       |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|     Swin Transformer V2     |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|             T5              |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|      Table Transformer      |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            TAPAS            |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|   Time Series Transformer   |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|   Trajectory Transformer    |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|       Transformer-XL        |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|            TrOCR            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          UniSpeech          |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|        UniSpeechSat         |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|             VAN             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          VideoMAE           |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            ViLT             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|   Vision Encoder decoder    |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âœ…      |
|    VisionTextDualEncoder    |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âœ…      |
|         VisualBERT          |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|             ViT             |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âœ…      |
|           ViTMAE            |       âŒ       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|           ViTMSN            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|          Wav2Vec2           |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âœ…      |
|     Wav2Vec2-Conformer      |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            WavLM            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|           Whisper           |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|           X-CLIP            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            XGLM             |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|             XLM             |       âœ…       |       âŒ       |       âœ…        |         âœ…         |      âŒ      |
|       XLM-ProphetNet        |       âœ…       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|         XLM-RoBERTa         |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âœ…      |
|       XLM-RoBERTa-XL        |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            XLNet            |       âœ…       |       âœ…       |       âœ…        |         âœ…         |      âŒ      |
|            YOLOS            |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |
|            YOSO             |       âŒ       |       âŒ       |       âœ…        |         âŒ         |      âŒ      |

<!-- End table-->
