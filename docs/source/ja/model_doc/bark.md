<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Bark

## Overview

Bark ã¯ã€[suno-ai/bark](https://github.com/suno-ai/bark) ã§ Suno AI ã«ã‚ˆã£ã¦ææ¡ˆã•ã‚ŒãŸãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚


Bark ã¯ 4 ã¤ã®ä¸»è¦ãªãƒ¢ãƒ‡ãƒ«ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚

- [`BarkSemanticModel`] ('ãƒ†ã‚­ã‚¹ãƒˆ'ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚å‘¼ã°ã‚Œã‚‹): ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³ã‚’æ‰ãˆã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ ãƒ†ã‚­ã‚¹ãƒˆ ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹å› æœçš„è‡ªå·±å›å¸°å¤‰æ›ãƒ¢ãƒ‡ãƒ«ã€‚
- [`BarkCoarseModel`] ('ç²—ã„éŸ³éŸ¿' ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚å‘¼ã°ã‚Œã‚‹): [`BarkSemanticModel`] ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹å› æœçš„è‡ªå·±å›å¸°å¤‰æ›å™¨ã€‚ EnCodec ã«å¿…è¦ãªæœ€åˆã® 2 ã¤ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
- [`BarkFineModel`] ('å¾®ç´°éŸ³éŸ¿' ãƒ¢ãƒ‡ãƒ«)ã€ä»Šå›ã¯éå› æœçš„ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã§ã€ä»¥å‰ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿ã®åˆè¨ˆã«åŸºã¥ã„ã¦æœ€å¾Œã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚’ç¹°ã‚Šè¿”ã—äºˆæ¸¬ã—ã¾ã™ã€‚
- [`EncodecModel`] ã‹ã‚‰ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ ãƒãƒ£ãƒãƒ«ã‚’äºˆæ¸¬ã—ãŸã®ã§ã€Bark ã¯ãã‚Œã‚’ä½¿ç”¨ã—ã¦å‡ºåŠ›ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªé…åˆ—ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

æœ€åˆã® 3 ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ãã‚Œãã‚Œã€ç‰¹å®šã®äº‹å‰å®šç¾©ã•ã‚ŒãŸéŸ³å£°ã«å¾“ã£ã¦å‡ºåŠ›ã‚µã‚¦ãƒ³ãƒ‰ã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®æ¡ä»¶ä»˜ãã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã§ãã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

### Optimizing Bark

Bark ã¯ã€ã‚³ãƒ¼ãƒ‰ã‚’æ•°è¡Œè¿½åŠ ã™ã‚‹ã ã‘ã§æœ€é©åŒ–ã§ãã€**ãƒ¡ãƒ¢ãƒª ãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆãŒå¤§å¹…ã«å‰Šæ¸›**ã•ã‚Œã€**æ¨è«–ãŒé«˜é€ŸåŒ–**ã•ã‚Œã¾ã™ã€‚

#### Using half-precision

ãƒ¢ãƒ‡ãƒ«ã‚’åŠç²¾åº¦ã§ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§ã€æ¨è«–ã‚’é«˜é€ŸåŒ–ã—ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ 50% å‰Šæ¸›ã§ãã¾ã™ã€‚

```python
from transformers import BarkModel
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16).to(device)
```

#### Using ğŸ¤— Better Transformer

Better Transformer ã¯ã€å†…éƒ¨ã§ã‚«ãƒ¼ãƒãƒ«èåˆã‚’å®Ÿè¡Œã™ã‚‹ ğŸ¤— æœ€é©ãªæ©Ÿèƒ½ã§ã™ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãªãã€é€Ÿåº¦ã‚’ 20% ï½ 30% å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ ğŸ¤— Better Transformer ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã®ã«å¿…è¦ãªã‚³ãƒ¼ãƒ‰ã¯ 1 è¡Œã ã‘ã§ã™ã€‚

```python
model =  model.to_bettertransformer()
```

ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å‰ã« ğŸ¤— Optimum ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã¯ã“ã¡ã‚‰](https://huggingface.co/docs/optimum/installation)

#### Using CPU offload

å‰è¿°ã—ãŸã‚ˆã†ã«ã€Bark ã¯ 4 ã¤ã®ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªç”Ÿæˆä¸­ã«é †ç•ªã«å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚è¨€ã„æ›ãˆã‚Œã°ã€1 ã¤ã®ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹é–“ã€ä»–ã®ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã¯ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹ã«ãªã‚Šã¾ã™ã€‚

CUDA ãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€ãƒ¡ãƒ¢ãƒª ãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆã® 80% å‰Šæ¸›ã«ã‚ˆã‚‹æ©æµã‚’å—ã‘ã‚‹ç°¡å˜ãªè§£æ±ºç­–ã¯ã€ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹ã® GPU ã®ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã®æ“ä½œã¯ CPU ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã¨å‘¼ã°ã‚Œã¾ã™ã€‚ 1è¡Œã®ã‚³ãƒ¼ãƒ‰ã§ä½¿ç”¨ã§ãã¾ã™ã€‚

```python
model.enable_cpu_offload()
```

ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€ğŸ¤— Accelerate ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã¯ã“ã¡ã‚‰](https://huggingface.co/docs/accelerate/basic_tutorials/install)

#### Combining optimization techniques

æœ€é©åŒ–æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦ã€CPU ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã€åŠç²¾åº¦ã€ğŸ¤— Better Transformer ã‚’ã™ã¹ã¦ä¸€åº¦ã«ä½¿ç”¨ã§ãã¾ã™ã€‚

```python
from transformers import BarkModel
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"

# load in fp16
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16).to(device)

# convert to bettertransformer
model = BetterTransformer.transform(model, keep_original_model=False)

# enable CPU offload
model.enable_cpu_offload()
```

æ¨è«–æœ€é©åŒ–æ‰‹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã“ã¡ã‚‰](https://huggingface.co/docs/transformers/perf_infer_gpu_one) ã‚’ã”è¦§ãã ã•ã„ã€‚

### Tips

Suno ã¯ã€å¤šãã®è¨€èªã§éŸ³å£°ãƒ—ãƒªã‚»ãƒƒãƒˆã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æä¾›ã—ã¦ã„ã¾ã™ [ã“ã¡ã‚‰](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)ã€‚
ã“ã‚Œã‚‰ã®ãƒ—ãƒªã‚»ãƒƒãƒˆã¯ã€ãƒãƒ– [ã“ã¡ã‚‰](https://huggingface.co/suno/bark-small/tree/main/speaker_embeddings) ã¾ãŸã¯ [ã“ã¡ã‚‰](https://huggingface.co/suno/bark/tree/main/speaker_embeddings)ã€‚

```python
>>> from transformers import AutoProcessor, BarkModel

>>> processor = AutoProcessor.from_pretrained("suno/bark")
>>> model = BarkModel.from_pretrained("suno/bark")

>>> voice_preset = "v2/en_speaker_6"

>>> inputs = processor("Hello, my dog is cute", voice_preset=voice_preset)

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

Bark ã¯ã€éå¸¸ã«ãƒªã‚¢ãƒ«ãª **å¤šè¨€èª** éŸ³å£°ã ã‘ã§ãªãã€éŸ³æ¥½ã€èƒŒæ™¯ãƒã‚¤ã‚ºã€å˜ç´”ãªåŠ¹æœéŸ³ãªã©ã®ä»–ã®éŸ³å£°ã‚‚ç”Ÿæˆã§ãã¾ã™ã€‚

```python
>>> # Multilingual speech - simplified Chinese
>>> inputs = processor("æƒŠäººçš„ï¼æˆ‘ä¼šè¯´ä¸­æ–‡")

>>> # Multilingual speech - French - let's use a voice_preset as well
>>> inputs = processor("Incroyable! Je peux gÃ©nÃ©rer du son.", voice_preset="fr_speaker_5")

>>> # Bark can also generate music. You can help it out by adding music notes around your lyrics.
>>> inputs = processor("â™ª Hello, my dog is cute â™ª")

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ç¬‘ã†ã€ãŸã‚æ¯ã€æ³£ããªã©ã®**éè¨€èªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³**ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚


```python
>>> # Adding non-speech cues to the input text
>>> inputs = processor("Hello uh ... [clears throat], my dog is cute [laughter]")

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ä¿å­˜ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«è¨­å®šã¨ scipy ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ« ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—ã™ã‚‹ã ã‘ã§ã™ã€‚

```python
>>> from scipy.io.wavfile import write as write_wav

>>> # save audio to disk, but first take the sample rate from the model config
>>> sample_rate = model.generation_config.sample_rate
>>> write_wav("bark_generation.wav", sample_rate, audio_array)
```

ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€[Yoach Lacombe (ylacombe)](https://huggingface.co/ylacombe) ãŠã‚ˆã³ [Sanchit Gandhi (sanchit-gandhi)](https://github.com/sanchit-gandhi) ã«ã‚ˆã£ã¦æä¾›ã•ã‚Œã¾ã—ãŸã€‚
å…ƒã®ã‚³ãƒ¼ãƒ‰ã¯ [ã“ã“](https://github.com/suno-ai/bark) ã«ã‚ã‚Šã¾ã™ã€‚

## BarkConfig

[[autodoc]] BarkConfig
    - all

## BarkProcessor

[[autodoc]] BarkProcessor
    - all
    - __call__

## BarkModel

[[autodoc]] BarkModel
    - generate
    - enable_cpu_offload

## BarkSemanticModel

[[autodoc]] BarkSemanticModel
    - forward

## BarkCoarseModel

[[autodoc]] BarkCoarseModel
    - forward

## BarkFineModel

[[autodoc]] BarkFineModel
    - forward

## BarkCausalModel

[[autodoc]] BarkCausalModel
    - forward

## BarkCoarseConfig

[[autodoc]] BarkCoarseConfig
    - all

## BarkFineConfig

[[autodoc]] BarkFineConfig
    - all

## BarkSemanticConfig

[[autodoc]] BarkSemanticConfig
    - all
