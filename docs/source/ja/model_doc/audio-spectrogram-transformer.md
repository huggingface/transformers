<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Audio Spectrogram Transformer

## æ¦‚è¦

Audio Spectrogram Transformerãƒ¢ãƒ‡ãƒ«ã¯ã€ã€Œ[AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778)ã€ã¨ã„ã†è«–æ–‡ã§Yuan Gongã€Yu-An Chungã€James Glassã«ã‚ˆã£ã¦ææ¡ˆã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã¯ã€éŸ³å£°ã‚’ç”»åƒï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼‰ã«å¤‰æ›ã™ã‚‹ã“ã¨ã§ã€éŸ³å£°ã«[Vision Transformer](vit)ã‚’é©ç”¨ã—ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯éŸ³å£°åˆ†é¡ã«ãŠã„ã¦æœ€å…ˆç«¯ã®çµæœã‚’å¾—ã¦ã„ã¾ã™ã€‚

è«–æ–‡ã®è¦æ—¨ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š

*In the past decade, convolutional neural networks (CNNs) have been widely adopted as the main building block for end-to-end audio classification models, which aim to learn a direct mapping from audio spectrograms to corresponding labels. To better capture long-range global context, a recent trend is to add a self-attention mechanism on top of the CNN, forming a CNN-attention hybrid model. However, it is unclear whether the reliance on a CNN is necessary, and if neural networks purely based on attention are sufficient to obtain good performance in audio classification. In this paper, we answer the question by introducing the Audio Spectrogram Transformer (AST), the first convolution-free, purely attention-based model for audio classification. We evaluate AST on various audio classification benchmarks, where it achieves new state-of-the-art results of 0.485 mAP on AudioSet, 95.6% accuracy on ESC-50, and 98.1% accuracy on Speech Commands V2.*

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/audio_spectogram_transformer_architecture.png"
alt="drawing" width="600"/>

<small> Audio pectrogram Transformerã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‚<a href="https://arxiv.org/abs/2104.01778">å…ƒè«–æ–‡</a>ã‚ˆã‚ŠæŠœç²‹ã€‚</small>

ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯[nielsr](https://huggingface.co/nielsr)ã‚ˆã‚Šæä¾›ã•ã‚Œã¾ã—ãŸã€‚
ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã‚³ãƒ¼ãƒ‰ã¯[ã“ã¡ã‚‰](https://github.com/YuanGongND/ast)ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

## ä½¿ç”¨ä¸Šã®ãƒ’ãƒ³ãƒˆ

- ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Audio Spectrogram Transformerï¼ˆASTï¼‰ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆã€å…¥åŠ›ã®æ­£è¦åŒ–ï¼ˆå…¥åŠ›ã®å¹³å‡ã‚’0ã€æ¨™æº–åå·®ã‚’0.5ã«ã™ã‚‹ã“ã¨ï¼‰å‡¦ç†ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚[`ASTFeatureExtractor`]ã¯ã“ã‚Œã‚’å‡¦ç†ã—ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯AudioSetã®å¹³å‡ã¨æ¨™æº–åå·®ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚è‘—è€…ãŒä¸‹æµã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆã‚’ã©ã®ã‚ˆã†ã«è¨ˆç®—ã—ã¦ã„ã‚‹ã‹ã¯ã€[`ast/src/get_norm_stats.py`](https://github.com/YuanGongND/ast/blob/master/src/get_norm_stats.py)ã§ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- ASTã¯ä½ã„å­¦ç¿’ç‡ãŒå¿…è¦ã§ã‚ã‚Šï¼ˆè‘—è€…ã¯[PSLAè«–æ–‡](https://arxiv.org/abs/2102.01243)ã§ææ¡ˆã•ã‚ŒãŸCNNãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦10å€å°ã•ã„å­¦ç¿’ç‡ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼‰ã€ç´ æ—©ãåæŸã™ã‚‹ãŸã‚ã€ã‚¿ã‚¹ã‚¯ã«é©ã—ãŸå­¦ç¿’ç‡ã¨å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’æ¢ã™ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

## å‚è€ƒè³‡æ–™

Audio Spectrogram Transformerã®ä½¿ç”¨ã‚’é–‹å§‹ã™ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ã®Hugging FaceãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ï¼ˆğŸŒã§ç¤ºã•ã‚Œã¦ã„ã‚‹ï¼‰ã®å‚è€ƒè³‡æ–™ã®ä¸€è¦§ã§ã™ã€‚

<PipelineTag pipeline="audio-classification"/>

- ASTã‚’ç”¨ã„ãŸéŸ³å£°åˆ†é¡ã®æ¨è«–ã‚’èª¬æ˜ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯[ã“ã¡ã‚‰](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/AST)ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- [`ASTForAudioClassification`]ã¯ã€ã“ã®[ä¾‹ç¤ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/audio-classification)ã¨[ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)ã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚
- ã“ã¡ã‚‰ã‚‚å‚ç…§ï¼š[éŸ³å£°åˆ†é¡ã‚¿ã‚¹ã‚¯](../tasks/audio_classification)ã€‚

ã“ã“ã«å‚è€ƒè³‡æ–™ã‚’æå‡ºã—ãŸã„å ´åˆã¯ã€æ°—å…¼ã­ãªãPull Requestã‚’é–‹ã„ã¦ãã ã•ã„ã€‚ç§ãŸã¡ã¯ãã‚Œã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã„ãŸã—ã¾ã™ï¼å‚è€ƒè³‡æ–™ã¯ã€æ—¢å­˜ã®ã‚‚ã®ã‚’è¤‡è£½ã™ã‚‹ã®ã§ã¯ãªãã€ä½•ã‹æ–°ã—ã„ã“ã¨ã‚’ç¤ºã™ã“ã¨ãŒç†æƒ³çš„ã§ã™ã€‚

## ASTConfig

[[autodoc]] ASTConfig

## ASTFeatureExtractor

[[autodoc]] ASTFeatureExtractor
    - __call__

## ASTModel

[[autodoc]] ASTModel
    - forward

## ASTForAudioClassification

[[autodoc]] ASTForAudioClassification
    - forward
