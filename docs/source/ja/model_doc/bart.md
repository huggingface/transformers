<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# BART

<div class="flex flex-wrap space-x-1">
<a href="https://huggingface.co/models?filter=bart">
<img alt="Models" src="https://img.shields.io/badge/All_model_pages-bart-blueviolet">
</a>
<a href="https://huggingface.co/spaces/docs-demos/bart-large-mnli">
<img alt="Spaces" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue">
</a>
</div>

**å…è²¬äº‹é …:** ä½•ã‹å¥‡å¦™ãªã‚‚ã®ã‚’è¦‹ã¤ã‘ãŸå ´åˆã¯ã€[Github å•é¡Œ](https://github.com/huggingface/transformers/issues/new?assignees=&labels=&template=bug-report.md&title) ã‚’æå‡ºã—ã€å‰²ã‚Šå½“ã¦ã¦ãã ã•ã„ã€‚
@patrickvonplaten

## Overview

Bart ãƒ¢ãƒ‡ãƒ«ã¯ã€[BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generationã€
ç¿»è¨³ã¨ç†è§£](https://arxiv.org/abs/1910.13461) Mike Lewisã€Yinhan Liuã€Naman Goyalã€Marjan è‘—
ã‚¬ã‚ºãƒ“ãƒ‹ãƒã‚¸ãƒ£ãƒ‰ã€ã‚¢ãƒ–ãƒ‡ãƒ«ãƒ©ãƒ•ãƒãƒ³ãƒ»ãƒ¢ãƒãƒ¡ãƒ‰ã€ã‚ªãƒ¡ãƒ«ãƒ»ãƒ¬ãƒ´ã‚£ã€ãƒ™ã‚¹ãƒ»ã‚¹ãƒˆãƒ¤ãƒãƒ•ã€ãƒ«ãƒ¼ã‚¯ãƒ»ã‚¼ãƒˆãƒ«ãƒ¢ã‚¤ãƒ¤ãƒ¼ã€2019å¹´10æœˆ29æ—¥ã€‚

è¦ç´„ã«ã‚ˆã‚‹ã¨ã€

- Bart ã¯ã€åŒæ–¹å‘ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ (BERT ãªã©) ã‚’å‚™ãˆãŸæ¨™æº–ã® seq2seq/æ©Ÿæ¢°ç¿»è¨³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
  å·¦ã‹ã‚‰å³ã¸ã®ãƒ‡ã‚³ãƒ¼ãƒ€ (GPT ãªã©)ã€‚
- äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ã‚¿ã‚¹ã‚¯ã«ã¯ã€å…ƒã®æ–‡ã®é †åºã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã€æ–°ã—ã„åŸ‹ã‚è¾¼ã¿ã‚¹ã‚­ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¾ã™ã€‚
  ã“ã“ã§ã€ãƒ†ã‚­ã‚¹ãƒˆã®ç¯„å›²ã¯å˜ä¸€ã®ãƒã‚¹ã‚¯ ãƒˆãƒ¼ã‚¯ãƒ³ã«ç½®ãæ›ãˆã‚‰ã‚Œã¾ã™ã€‚
- BART ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å¾®èª¿æ•´ã—ãŸå ´åˆã«ç‰¹ã«åŠ¹æœçš„ã§ã™ãŒã€ç†è§£ã‚¿ã‚¹ã‚¯ã«ã‚‚é©ã—ã¦ã„ã¾ã™ã€‚ãã‚Œ
  RoBERTa ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ GLUE ãŠã‚ˆã³ SQuAD ã®åŒç­‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒªã‚½ãƒ¼ã‚¹ã¨åŒç­‰ã«ã—ã€æ–°ãŸãªæˆæœã‚’é”æˆã—ã¾ã™ã€‚
  ã•ã¾ã–ã¾ãªæŠ½è±¡çš„ãªå¯¾è©±ã€è³ªå•å¿œç­”ã€è¦ç´„ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æœ€å…ˆç«¯ã®çµæœãŒå¾—ã‚‰ã‚Œã€æˆæœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚
  ãƒ«ãƒ¼ã‚¸ãƒ¥ã¯æœ€å¤§6æšã¾ã§ã€‚

ãƒãƒƒãƒ—ï¼š

- BART ã¯çµ¶å¯¾ä½ç½®åŸ‹ã‚è¾¼ã¿ã‚’å‚™ãˆãŸãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ãŸã‚ã€é€šå¸¸ã¯å…¥åŠ›ã‚’å³å´ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
  å·¦ã€‚
- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å‚™ãˆãŸã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ„ãƒ¼ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ ãƒ¢ãƒ‡ãƒ«ã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã«ã¯ç ´æã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¾›çµ¦ã•ã‚Œã€ãƒ‡ã‚³ãƒ¼ãƒ€ã«ã¯å…ƒã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¾›çµ¦ã•ã‚Œã¾ã™ï¼ˆãŸã ã—ã€é€šå¸¸ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ ãƒ‡ã‚³ãƒ¼ãƒ€ã¨åŒæ§˜ã«ã€å°†æ¥ã®ãƒ¯ãƒ¼ãƒ‰ã‚’éš ã™ãŸã‚ã®ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚æ¬¡ã®å¤‰æ›ã®æ§‹æˆã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ã‚¿ã‚¹ã‚¯ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚

  * ãƒ©ãƒ³ãƒ€ãƒ ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒã‚¹ã‚¯ã—ã¾ã™ (BERT ã¨åŒæ§˜)
  * ãƒ©ãƒ³ãƒ€ãƒ ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‰Šé™¤ã—ã¾ã™
  * k å€‹ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ãƒ‘ãƒ³ã‚’ 1 ã¤ã®ãƒã‚¹ã‚¯ ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒã‚¹ã‚¯ã—ã¾ã™ (0 ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ãƒ‘ãƒ³ã¯ãƒã‚¹ã‚¯ ãƒˆãƒ¼ã‚¯ãƒ³ã®æŒ¿å…¥ã§ã™)
  * æ–‡ã‚’ä¸¦ã¹æ›¿ãˆã¾ã™
  * ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å›è»¢ã—ã¦ç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰é–‹å§‹ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã™

ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ [sshleifer](https://huggingface.co/sshleifer) ã«ã‚ˆã£ã¦æä¾›ã•ã‚Œã¾ã—ãŸã€‚è‘—è€…ã®ã‚³ãƒ¼ãƒ‰ã¯ [ã“ã“](https://github.com/pytorch/fairseq/tree/master/examples/bart) ã«ã‚ã‚Šã¾ã™ã€‚

### Examples

- ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–“ã‚¿ã‚¹ã‚¯ç”¨ã® BART ãŠã‚ˆã³ãã®ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã®ä¾‹ã¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€æ¬¡ã®å ´æ‰€ã«ã‚ã‚Šã¾ã™ã€‚
  [examples/pytorch/summarization/](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization/README.md)ã€‚
- Hugging Face `datasets` ã‚’ä½¿ç”¨ã—ã¦ [`BartForConditionalGeneration`] ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã®ä¾‹
  ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã“ã® [ãƒ•ã‚©ãƒ¼ãƒ©ãƒ  ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³](https://discuss.huggingface.co/t/train-bart-for-conditional-generation-e-g-summarization/1904) ã§è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- [æŠ½å‡ºã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ](https://huggingface.co/models?search=distilbart) ã¯ã€ã“ã® [è«–æ–‡](https://arxiv.org/abs/2010.13002) ã§èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚

## Implementation Notes

- Bart ã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®åˆ†é¡ã« `token_type_ids` ã‚’ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚ [`BartTokenizer`] ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€
  [`~BartTokenizer.encode`] ã‚’ä½¿ç”¨ã—ã¦é©åˆ‡ã«åˆ†å‰²ã—ã¾ã™ã€‚
- [`BartModel`] ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã¯ã€æ¸¡ã•ã‚Œãªã‹ã£ãŸå ´åˆã€`decoder_input_ids` ã‚’ä½œæˆã—ã¾ã™ã€‚
  ã“ã‚Œã¯ã€ä»–ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚° API ã¨ã¯ç•°ãªã‚Šã¾ã™ã€‚ã“ã®æ©Ÿèƒ½ã®ä¸€èˆ¬çš„ãªä½¿ç”¨ä¾‹ã¯ã€ãƒã‚¹ã‚¯ã®å¡—ã‚Šã¤ã¶ã—ã§ã™ã€‚
- ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã¯ã€æ¬¡ã®å ´åˆã«å…ƒã®å®Ÿè£…ã¨åŒä¸€ã«ãªã‚‹ã‚ˆã†ã«æ„å›³ã•ã‚Œã¦ã„ã¾ã™ã€‚
  `forced_bos_token_id=0`ã€‚ãŸã ã—ã€ã“ã‚Œã¯ã€æ¸¡ã™æ–‡å­—åˆ—ãŒæ¬¡ã®å ´åˆã«ã®ã¿æ©Ÿèƒ½ã—ã¾ã™ã€‚
  [`fairseq.encode`] ã¯ã‚¹ãƒšãƒ¼ã‚¹ã§å§‹ã¾ã‚Šã¾ã™ã€‚
- [`~generation.GenerationMixin.generate`] ã¯ã€æ¬¡ã®ã‚ˆã†ãªæ¡ä»¶ä»˜ãç”Ÿæˆã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
  è¦ç´„ã«ã¤ã„ã¦ã¯ã€ãã® docstring ã®ä¾‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
- *facebook/bart-large-cnn* é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ã¯ `mask_token_id` ãŒãªã„ã‹ã€å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚
  ãƒã‚¹ã‚¯ã‚’åŸ‹ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã€‚

## Mask Filling

`facebook/bart-base` ãŠã‚ˆã³ `facebook/bart-large` ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ«ãƒãƒˆãƒ¼ã‚¯ãƒ³ ãƒã‚¹ã‚¯ã‚’åŸ‹ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
from transformers import BartForConditionalGeneration, BartTokenizer

model = BartForConditionalGeneration.from_pretrained("facebook/bart-large", forced_bos_token_id=0)
tok = BartTokenizer.from_pretrained("facebook/bart-large")
example_english_phrase = "UN Chief Says There Is No <mask> in Syria"
batch = tok(example_english_phrase, return_tensors="pt")
generated_ids = model.generate(batch["input_ids"])
assert tok.batch_decode(generated_ids, skip_special_tokens=True) == [
    "UN Chief Says There Is No Plan to Stop Chemical Weapons in Syria"
]
```

## Resources

BART ã‚’å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ (ğŸŒ ã§ç¤ºã•ã‚Œã¦ã„ã‚‹) ãƒªã‚½ãƒ¼ã‚¹ã®ãƒªã‚¹ãƒˆã€‚ã“ã“ã«å«ã‚ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã®é€ä¿¡ã«èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯ã€ãŠæ°—è»½ã«ãƒ—ãƒ« ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é–‹ã„ã¦ãã ã•ã„ã€‚å¯©æŸ»ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãƒªã‚½ãƒ¼ã‚¹ã¯ã€æ—¢å­˜ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’è¤‡è£½ã™ã‚‹ã®ã§ã¯ãªãã€ä½•ã‹æ–°ã—ã„ã‚‚ã®ã‚’ç¤ºã™ã“ã¨ãŒç†æƒ³çš„ã§ã™ã€‚

<PipelineTag pipeline="summarization"/>

- ã«é–¢ã™ã‚‹ãƒ–ãƒ­ã‚°æŠ•ç¨¿ [åˆ†æ•£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°: ğŸ¤— Transformers ã¨ Amazon SageMaker ã‚’ä½¿ç”¨ã—ãŸè¦ç´„ã®ãŸã‚ã® BART/T5 ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°](https://huggingface.co/blog/sagemaker-distributed-training-seq2seq)ã€‚
- æ–¹æ³•ã«é–¢ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ [blurr ã‚’ä½¿ç”¨ã—ã¦ fastai ã§è¦ç´„ã™ã‚‹ãŸã‚ã« BART ã‚’å¾®èª¿æ•´ã™ã‚‹](https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb). ğŸŒ ğŸŒ
- æ–¹æ³•ã«é–¢ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ [ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ 2 ã¤ã®è¨€èªã§è¦ç´„ã™ã‚‹ãŸã‚ã« BART ã‚’å¾®èª¿æ•´ã™ã‚‹](https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb)ã€‚ ğŸŒ
- [`BartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization) ãŠã‚ˆã³ [ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)ã€‚
- [`TFBartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization) ãŠã‚ˆã³ [ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)ã€‚
- [`FlaxBartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/flax/summarization) ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚
- [è¦ç´„](https://huggingface.co/course/chapter7/5?fw=pt#summarization) ğŸ¤— ãƒã‚°ãƒ•ã‚§ã‚¤ã‚¹ã‚³ãƒ¼ã‚¹ã®ç« ã€‚
- [è¦ç´„ã‚¿ã‚¹ã‚¯ã‚¬ã‚¤ãƒ‰](../tasks/summarization.md)

<PipelineTag pipeline="fill-mask"/>

- [`BartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling#robertabertdistilbert-and-masked-language-modeling) ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ãŠã‚Šã€ [ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)ã€‚
- [`TFBartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/language-modeling#run_mlmpy) ãŠã‚ˆã³ [ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)ã€‚
- [`FlaxBartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#masked-language-modeling) ãŠã‚ˆã³ [ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯]( https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/masked_language_modeling_flax.ipynb)ã€‚
- [ãƒã‚¹ã‚¯ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°](https://huggingface.co/course/chapter7/3?fw=pt) ğŸ¤— é¡”ãƒã‚° ã‚³ãƒ¼ã‚¹ã®ç« ã€‚
- [ãƒã‚¹ã‚¯ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚° ã‚¿ã‚¹ã‚¯ ã‚¬ã‚¤ãƒ‰](../tasks/masked_lang_modeling)

<PipelineTag pipeline="translation"/>

- [ãƒ’ãƒ³ãƒ‡ã‚£ãƒ¼èªã‹ã‚‰è‹±èªã¸ã®ç¿»è¨³ã« Seq2SeqTrainer ã‚’ä½¿ç”¨ã—ã¦ mBART ã‚’å¾®èª¿æ•´ã™ã‚‹æ–¹æ³•ã«é–¢ã™ã‚‹ãƒãƒ¼ãƒˆ](https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb)ã€‚ ğŸŒ
- [`BartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/translation) ãŠã‚ˆã³ [ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)ã€‚
- [`TFBartForConditionalGeneration`] ã¯ã€ã“ã® [ã‚µãƒ³ãƒ—ãƒ« ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/translation) ãŠã‚ˆã³ [ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)ã€‚
- [ç¿»è¨³ã‚¿ã‚¹ã‚¯ã‚¬ã‚¤ãƒ‰](../tasks/translation)

ä»¥ä¸‹ã‚‚å‚ç…§ã—ã¦ãã ã•ã„ã€‚
- [ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ã‚¿ã‚¹ã‚¯ã‚¬ã‚¤ãƒ‰](../tasks/sequence_classification)
- [è³ªå•å›ç­”ã‚¿ã‚¹ã‚¯ ã‚¬ã‚¤ãƒ‰](../tasks/question_answering)
- [å› æœè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚° ã‚¿ã‚¹ã‚¯ ã‚¬ã‚¤ãƒ‰](../tasks/language_modeling)
- [æŠ½å‡ºã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ](https://huggingface.co/models?search=distilbart) ã¯ã€ã“ã® [è«–æ–‡](https://arxiv.org/abs/2010.13002) ã§èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚

## BartConfig

[[autodoc]] BartConfig
    - all

## BartTokenizer

[[autodoc]] BartTokenizer
    - all

## BartTokenizerFast

[[autodoc]] BartTokenizerFast
    - all

## BartModel

[[autodoc]] BartModel
    - forward

## BartForConditionalGeneration

[[autodoc]] BartForConditionalGeneration
    - forward

## BartForSequenceClassification

[[autodoc]] BartForSequenceClassification
    - forward

## BartForQuestionAnswering

[[autodoc]] BartForQuestionAnswering
    - forward

## BartForCausalLM

[[autodoc]] BartForCausalLM
    - forward

## TFBartModel

[[autodoc]] TFBartModel
    - call

## TFBartForConditionalGeneration

[[autodoc]] TFBartForConditionalGeneration
    - call

## TFBartForSequenceClassification

[[autodoc]] TFBartForSequenceClassification
    - call

## FlaxBartModel

[[autodoc]] FlaxBartModel
    - __call__
    - encode
    - decode

## FlaxBartForConditionalGeneration

[[autodoc]] FlaxBartForConditionalGeneration
    - __call__
    - encode
    - decode

## FlaxBartForSequenceClassification

[[autodoc]] FlaxBartForSequenceClassification
    - __call__
    - encode
    - decode

## FlaxBartForQuestionAnswering

[[autodoc]] FlaxBartForQuestionAnswering
    - __call__
    - encode
    - decode

## FlaxBartForCausalLM

[[autodoc]] FlaxBartForCausalLM
    - __call__
