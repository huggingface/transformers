<!--
Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯Markdownå½¢å¼ã§ã™ãŒã€å½“ç¤¾ã®doc-builderï¼ˆMDXã«ä¼¼ãŸæ§‹æ–‡ï¼‰ã‚’å«ã‚€ãŸã‚ã€Markdownãƒ“ãƒ¥ãƒ¼ã‚¢ã§æ­£ã—ãè¡¨ç¤ºã•ã‚Œãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

-->

# Pipelines for inference

[`pipeline`]ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€[Hub](https://huggingface.co/models)ã‹ã‚‰ã®ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨€èªã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€éŸ³å£°ã€ãŠã‚ˆã³ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã®æ¨è«–ã«ç°¡å˜ã«ä½¿ç”¨ã§ãã¾ã™ã€‚
ç‰¹å®šã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹çµŒé¨“ãŒãªã„å ´åˆã‚„ã€ãƒ¢ãƒ‡ãƒ«ã®èƒŒå¾Œã«ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã«ç²¾é€šã—ã¦ã„ãªã„å ´åˆã§ã‚‚ã€[`pipeline`]ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã§ãã¾ã™ï¼
ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€æ¬¡ã®ã“ã¨ã‚’å­¦ã³ã¾ã™ï¼š

- æ¨è«–ã®ãŸã‚ã®[`pipeline`]ã®ä½¿ç”¨æ–¹æ³•ã€‚
- ç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚„ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨æ–¹æ³•ã€‚
- ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã€ãƒ“ã‚¸ãƒ§ãƒ³ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®[`pipeline`]ã®ä½¿ç”¨æ–¹æ³•ã€‚

<Tip>

ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã¨åˆ©ç”¨å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å®Œå…¨ãªä¸€è¦§ã«ã¤ã„ã¦ã¯ã€[`pipeline`]ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã”è¦§ãã ã•ã„ã€‚

</Tip>

## Pipeline usage

å„ã‚¿ã‚¹ã‚¯ã«ã¯é–¢é€£ã™ã‚‹[`pipeline`]ãŒã‚ã‚Šã¾ã™ãŒã€ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®[`pipeline`]ã‚’ä½¿ç”¨ã™ã‚‹ä»£ã‚ã‚Šã«ã€ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å«ã‚€ä¸€èˆ¬çš„ãª[`pipeline`]ã®æŠ½è±¡åŒ–ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ã‚ˆã‚Šç°¡å˜ã§ã™ã€‚[`pipeline`]ã¯è‡ªå‹•çš„ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã¨ã€ã‚¿ã‚¹ã‚¯ã®æ¨è«–ãŒå¯èƒ½ãªå‰å‡¦ç†ã‚¯ãƒ©ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

1. [`pipeline`]ã‚’ä½œæˆã—ã€æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’æŒ‡å®šã—ã¦å§‹ã‚ã¾ã™ï¼š

```py
>>> from transformers import pipeline

>>> generator = pipeline(task="automatic-speech-recognition")
```

2. [`pipeline`]ã«å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã—ã¾ã™ï¼š

```python
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}
```

ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆã§ããªã‹ã£ãŸã‹ï¼Ÿ [Hubã®æœ€ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè‡ªå‹•éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads) ã®ã„ãã¤ã‹ã‚’è¦‹ã¦ã€ã‚ˆã‚Šè‰¯ã„è»¢å†™ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¦ã¿ã¦ãã ã•ã„ã€‚
[openai/whisper-large](https://huggingface.co/openai/whisper-large) ã‚’è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
>>> generator = pipeline(model="openai/whisper-large")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

ã“ã®çµæœã¯ã‚ˆã‚Šæ­£ç¢ºã«è¦‹ãˆã¾ã™ã­ï¼
ç•°ãªã‚‹è¨€èªã€å°‚é–€åˆ†é‡ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã€ãã®ä»–ã®ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯ã€Hubã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ã‚’å¼·ããŠå‹§ã‚ã—ã¾ã™ã€‚
Hubã§ã¯ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ç›´æ¥ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é©ã—ã¦ã„ã‚‹ã‹ã€ç‰¹æ®Šãªã‚±ãƒ¼ã‚¹ã‚’ã‚ˆã‚Šã‚ˆãå‡¦ç†ã§ãã‚‹ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚
ãã—ã¦ã€ã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã„ã¤ã§ã‚‚[ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°](training)ã‚’é–‹å§‹ã§ãã¾ã™ï¼

è¤‡æ•°ã®å…¥åŠ›ãŒã‚ã‚‹å ´åˆã€å…¥åŠ›ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™ï¼š

```py
generator(
    [
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac",
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac",
    ]
)
```

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’ç¹°ã‚Šè¿”ã—å‡¦ç†ã—ãŸã‚Šã€ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã§æ¨è«–ã«ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€å°‚ç”¨ã®éƒ¨åˆ†ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

[ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹](#using-pipeline-in-a-dataset)

[ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹](./pipeline_webserver)



## ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

[`pipeline`]ã¯å¤šãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€ä¸€éƒ¨ã¯ã‚¿ã‚¹ã‚¯å›ºæœ‰ã§ã‚ã‚Šã€ä¸€éƒ¨ã¯ã™ã¹ã¦ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«å…±é€šã§ã™ã€‚
ä¸€èˆ¬çš„ã«ã¯ã€ã©ã“ã§ã‚‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã§ãã¾ã™ï¼š

```py
generator = pipeline(model="openai/whisper-large", my_parameter=1)
out = generator(...)  # ã“ã‚Œã¯ `my_parameter=1` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
out = generator(..., my_parameter=2)  # ã“ã‚Œã¯ä¸Šæ›¸ãã—ã¦ `my_parameter=2` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
out = generator(...)  # ã“ã‚Œã¯å†ã³ `my_parameter=1` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
```

3ã¤ã®é‡è¦ãªã‚‚ã®ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ï¼š

### Device

`device=n` ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ãŸãƒ‡ãƒã‚¤ã‚¹ã«è‡ªå‹•çš„ã«é…ç½®ã—ã¾ã™ã€‚
ã“ã‚Œã¯ã€PyTorchã¾ãŸã¯Tensorflowã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã«é–¢ä¿‚ãªãæ©Ÿèƒ½ã—ã¾ã™ã€‚

```py
generator = pipeline(model="openai/whisper-large", device=0)
```

ã‚‚ã—ãƒ¢ãƒ‡ãƒ«ãŒå˜ä¸€ã®GPUã«ã¯å¤§ãã™ãã‚‹å ´åˆã€`device_map="auto"`ã‚’è¨­å®šã—ã¦ã€ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate) ã«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ã©ã®ã‚ˆã†ã«ãƒ­ãƒ¼ãƒ‰ã—ã€ä¿å­˜ã™ã‚‹ã‹ã‚’è‡ªå‹•çš„ã«æ±ºå®šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
#!pip install accelerate
generator = pipeline(model="openai/whisper-large", device_map="auto")
```

æ³¨æ„: `device_map="auto"` ãŒæ¸¡ã•ã‚ŒãŸå ´åˆã€`pipeline` ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹éš›ã« `device=device` å¼•æ•°ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãã†ã—ãªã„ã¨ã€äºˆæœŸã—ãªã„å‹•ä½œã«é­é‡ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼

### Batch size

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯è©³ç´°ã«ã¤ã„ã¦[ã“ã¡ã‚‰](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)ã§èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ç†ç”±ã‹ã‚‰ã€æ¨è«–ã‚’ãƒãƒƒãƒå‡¦ç†ã—ã¾ã›ã‚“ã€‚ãã®ç†ç”±ã¯ã€ãƒãƒƒãƒå‡¦ç†ãŒå¿…ãšã—ã‚‚é€Ÿããªã„ãŸã‚ã§ã‚ã‚Šã€å®Ÿéš›ã«ã¯ã„ãã¤ã‹ã®ã‚±ãƒ¼ã‚¹ã§ã‹ãªã‚Šé…ããªã‚‹ã“ã¨ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

ãŸã ã—ã€ã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§æ©Ÿèƒ½ã™ã‚‹å ´åˆã¯ã€æ¬¡ã®ã‚ˆã†ã«ä½¿ç”¨ã§ãã¾ã™ï¼š

```py
generator = pipeline(model="openai/whisper-large", device=0, batch_size=2)
audio_filenames = [f"audio_{i}.flac" for i in range(10)]
texts = generator(audio_filenames)
```

ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯æä¾›ã•ã‚ŒãŸ10å€‹ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™ãŒã€
ãƒ¢ãƒ‡ãƒ«ã«ã¯ãƒãƒƒãƒå‡¦ç†ãŒã‚ˆã‚ŠåŠ¹æœçš„ã§ã‚ã‚‹GPUä¸Šã«ã‚ã‚Šã€ãƒãƒƒãƒå‡¦ç†ã‚’è¡Œã†ãŸã‚ã®è¿½åŠ ã®ã‚³ãƒ¼ãƒ‰ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚
å‡ºåŠ›ã¯å¸¸ã«ãƒãƒƒãƒå‡¦ç†ãªã—ã§å—ã‘å–ã£ãŸã‚‚ã®ã¨ä¸€è‡´ã™ã‚‹ã¯ãšã§ã™ã€‚ã“ã‚Œã¯å˜ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã‚ˆã‚Šé«˜é€Ÿãªå‡¦ç†ã‚’å¾—ã‚‹ãŸã‚ã®æ–¹æ³•ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€ãƒãƒƒãƒå‡¦ç†ã®ã„ãã¤ã‹ã®è¤‡é›‘ã•ã‚’è»½æ¸›ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãªãœãªã‚‰ã€ä¸€éƒ¨ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯ã€
ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†ã™ã‚‹ãŸã‚ã«1ã¤ã®ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆé•·ã„ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã‚’è¤‡æ•°ã®éƒ¨åˆ†ã«åˆ†å‰²ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã“ã‚Œã‚’ã‚ãªãŸã®ãŸã‚ã«å®Ÿè¡Œã—ã¾ã™ã€‚[*ãƒãƒ£ãƒ³ã‚¯ãƒãƒƒãƒå‡¦ç†*](./main_classes/pipelines#pipeline-chunk-batching)ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã‚‹ã‚‚ã®ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

### Task specific parameters

ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã¯ã€ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æä¾›ã—ã€è¿½åŠ ã®æŸ”è»Ÿæ€§ã¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¦ã€ä½œæ¥­ã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«é€²ã‚ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚
ãŸã¨ãˆã°ã€[`transformers.AutomaticSpeechRecognitionPipeline.__call__`]ãƒ¡ã‚½ãƒƒãƒ‰ã«ã¯ã€ãƒ“ãƒ‡ã‚ªã®å­—å¹•ä½œæˆã«æœ‰ç”¨ãª`return_timestamps`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚

```py
>>> # Not using whisper, as it cannot provide timestamps.
>>> generator = pipeline(model="facebook/wav2vec2-large-960h-lv60-self", return_timestamps="word")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP AND LIVE OUT THE TRUE MEANING OF ITS CREED', 'chunks': [{'text': 'I', 'timestamp': (1.22, 1.24)}, {'text': 'HAVE', 'timestamp': (1.42, 1.58)}, {'text': 'A', 'timestamp': (1.66, 1.68)}, {'text': 'DREAM', 'timestamp': (1.76, 2.14)}, {'text': 'BUT', 'timestamp': (3.68, 3.8)}, {'text': 'ONE', 'timestamp': (3.94, 4.06)}, {'text': 'DAY', 'timestamp': (4.16, 4.3)}, {'text': 'THIS', 'timestamp': (6.36, 6.54)}, {'text': 'NATION', 'timestamp': (6.68, 7.1)}, {'text': 'WILL', 'timestamp': (7.32, 7.56)}, {'text': 'RISE', 'timestamp': (7.8, 8.26)}, {'text': 'UP', 'timestamp': (8.38, 8.48)}, {'text': 'AND', 'timestamp': (10.08, 10.18)}, {'text': 'LIVE', 'timestamp': (10.26, 10.48)}, {'text': 'OUT', 'timestamp': (10.58, 10.7)}, {'text': 'THE', 'timestamp': (10.82, 10.9)}, {'text': 'TRUE', 'timestamp': (10.98, 11.18)}, {'text': 'MEANING', 'timestamp': (11.26, 11.58)}, {'text': 'OF', 'timestamp': (11.66, 11.7)}, {'text': 'ITS', 'timestamp': (11.76, 11.88)}, {'text': 'CREED', 'timestamp': (12.0, 12.38)}]}
```

ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¨æ¸¬ã—ã€æ–‡ã®ä¸­ã§å„å˜èªãŒã„ã¤ç™ºéŸ³ã•ã‚ŒãŸã‹ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚

å„ã‚¿ã‚¹ã‚¯ã”ã¨ã«åˆ©ç”¨å¯èƒ½ãªå¤šãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã®ã§ã€ä½•ã‚’èª¿æ•´ã§ãã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«å„ã‚¿ã‚¹ã‚¯ã®APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼
ãŸã¨ãˆã°ã€[`~transformers.AutomaticSpeechRecognitionPipeline`]ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«å˜ä½“ã§ã¯å‡¦ç†ã§ããªã„éå¸¸ã«é•·ã„ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãŸã¨ãˆã°ã€æ˜ ç”»å…¨ä½“ã‚„1æ™‚é–“ã®ãƒ“ãƒ‡ã‚ªã®å­—å¹•ä»˜ã‘ãªã©ï¼‰ã§å½¹ç«‹ã¤`chunk_length_s`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚

<!--å½¹ç«‹ã¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€[ãƒªã‚¯ã‚¨ã‚¹ãƒˆ](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)ã—ã¦ãã ã•ã„ï¼-->

å½¹ç«‹ã¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€[ãƒªã‚¯ã‚¨ã‚¹ãƒˆ](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)ã—ã¦ãã ã•ã„ï¼

## Using pipeline in a dataset

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã‚Œã‚’è¡Œã†æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•ã¯ã€ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ï¼š

```py
def data():
    for i in range(1000):
        yield f"My example {i}"


pipe = pipeline(model="openai-community/gpt2", device=0)
generated_characters = 0
for out in pipe(data()):
    generated_characters += len(out[0]["generated_text"])
```

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ãƒ¼ `data()` ã¯å„çµæœã‚’ç”Ÿæˆã—ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯è‡ªå‹•çš„ã«å…¥åŠ›ãŒåå¾©å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’èªè­˜ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ç¶šã‘ãªãŒã‚‰GPUä¸Šã§å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼ˆã“ã‚Œã¯[DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ã‚’å†…éƒ¨ã§ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼‰ã€‚
ã“ã‚Œã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«ãƒ¡ãƒ¢ãƒªã‚’å‰²ã‚Šå½“ã¦ã‚‹å¿…è¦ãŒãªãã€GPUã«ã§ãã‚‹ã ã‘é€Ÿããƒ‡ãƒ¼ã‚¿ã‚’ä¾›çµ¦ã§ãã‚‹ãŸã‚é‡è¦ã§ã™ã€‚

ãƒãƒƒãƒå‡¦ç†ã¯å‡¦ç†ã‚’é«˜é€ŸåŒ–ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã“ã“ã§`batch_size`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦è©¦ã™ã“ã¨ãŒå½¹ç«‹ã¤ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åå¾©å‡¦ç†ã™ã‚‹æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•ã¯ã€ğŸ¤— [Datasets](https://github.com/huggingface/datasets/)ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€ã“ã¨ã§ã™ï¼š

```py
# KeyDataset is a util that will just output the item we're interested in.
from transformers.pipelines.pt_utils import KeyDataset
from datasets import load_dataset

pipe = pipeline(model="hf-internal-testing/tiny-random-wav2vec2", device=0)
dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation[:10]")

for out in pipe(KeyDataset(dataset, "audio")):
    print(out)
```

## Using pipelines for a webserver

<Tip>
æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆã™ã‚‹ã“ã¨ã¯è¤‡é›‘ãªãƒˆãƒ”ãƒƒã‚¯ã§ã€ç‹¬è‡ªã®ãƒšãƒ¼ã‚¸ãŒå¿…è¦ã§ã™ã€‚
</Tip>

[ãƒªãƒ³ã‚¯](./pipeline_webserver)

## Vision pipeline

ãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ç”¨ã®[`pipeline`]ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã¯ã»ã¼åŒã˜ã§ã™ã€‚

ã‚¿ã‚¹ã‚¯ã‚’æŒ‡å®šã—ã€ç”»åƒã‚’ã‚¯ãƒ©ã‚·ãƒ•ã‚¡ã‚¤ã‚¢ã«æ¸¡ã—ã¾ã™ã€‚ç”»åƒã¯ãƒªãƒ³ã‚¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã€ã¾ãŸã¯Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã§ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¾‹ãˆã°ã€ä»¥ä¸‹ã®ç”»åƒã¯ã©ã®ç¨®é¡ã®çŒ«ã§ã™ã‹ï¼Ÿ

![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)

```py
>>> from transformers import pipeline

>>> vision_classifier = pipeline(model="google/vit-base-patch16-224")
>>> preds = vision_classifier(
...     images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]
```

## Text pipeline

[`pipeline`]ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ã€NLPã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã»ã¼åŒã˜ã§ã™ã€‚

```py
>>> from transformers import pipeline

>>> # This model is a `zero-shot-classification` model.
>>> # It will classify text, except you are free to choose any label you might imagine
>>> classifier = pipeline(model="facebook/bart-large-mnli")
>>> classifier(
...     "I have a problem with my iphone that needs to be resolved asap!!",
...     candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
... )
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

## Multimodal pipeline

[`pipeline`]ã¯ã€1ã¤ä»¥ä¸Šã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãŸã¨ãˆã°ã€è¦–è¦šçš„ãªè³ªå•å¿œç­”ï¼ˆVQAï¼‰ã‚¿ã‚¹ã‚¯ã¯ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’çµ„ã¿åˆã‚ã›ã¦ã„ã¾ã™ã€‚
å¥½ããªç”»åƒãƒªãƒ³ã‚¯ã¨ç”»åƒã«é–¢ã™ã‚‹è³ªå•ã‚’è‡ªç”±ã«ä½¿ã£ã¦ãã ã•ã„ã€‚ç”»åƒã¯URLã¾ãŸã¯ç”»åƒã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã§æŒ‡å®šã§ãã¾ã™ã€‚

ä¾‹ãˆã°ã€ã“ã®[è«‹æ±‚æ›¸ç”»åƒ](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼š

```py
>>> from transformers import pipeline

>>> vqa = pipeline(model="impira/layoutlm-document-qa")
>>> output = vqa(
...     image="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png",
...     question="What is the invoice number?",
... )
>>> output[0]["score"] = round(output[0]["score"], 3)
>>> output
[{'score': 0.425, 'answer': 'us-001', 'start': 16, 'end': 16}]
```

<Tip>

ä¸Šè¨˜ã®ä¾‹ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ğŸ¤— Transformersã«åŠ ãˆã¦ [`pytesseract`](https://pypi.org/project/pytesseract/) ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```bash
sudo apt install -y tesseract-ocr
pip install pytesseract
```

</Tip>

## Using `pipeline` on large models with ğŸ¤— `accelerate`:

ã¾ãšã€`accelerate` ã‚’`pip install accelerate` ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

æ¬¡ã«ã€`device_map="auto"` ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ã“ã®ä¾‹ã§ã¯ `facebook/opt-1.3b` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
# pip install accelerate
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", dtype=torch.bfloat16, device_map="auto")
output = pipe("ã“ã‚Œã¯ç´ æ™´ã‚‰ã—ã„ä¾‹ã§ã™ï¼", do_sample=True, top_p=0.95)
```

ã‚‚ã— `bitsandbytes` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€`load_in_8bit=True` å¼•æ•°ã‚’è¿½åŠ ã™ã‚Œã°ã€8ãƒ“ãƒƒãƒˆã§èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¸¡ã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

```py
# pip install accelerate bitsandbytes
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", device_map="auto", model_kwargs={"load_in_8bit": True})
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

æ³¨æ„: BLOOMãªã©ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹Hugging Faceãƒ¢ãƒ‡ãƒ«ã®ã„ãšã‚Œã‹ã§ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç½®ãæ›ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼
