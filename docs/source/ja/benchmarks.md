<!--
Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯Markdownã§ã™ãŒã€Hugging Faceã®doc-builderï¼ˆMDXã«é¡ä¼¼ï¼‰å‘ã‘ã®ç‰¹å®šã®æ§‹æ–‡ã‚’å«ã‚“ã§ã„ã‚‹ãŸã‚ã€
Markdownãƒ“ãƒ¥ãƒ¼ã‚¢ã§ã¯æ­£ã—ãè¡¨ç¤ºã•ã‚Œãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
-->

# Benchmarks

<Tip warning={true}>

Hugging Faceã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ„ãƒ¼ãƒ«ã¯éæ¨å¥¨ã§ã‚ã‚Šã€Transformerãƒ¢ãƒ‡ãƒ«ã®é€Ÿåº¦ã¨ãƒ¡ãƒ¢ãƒªã®è¤‡é›‘ã•ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«å¤–éƒ¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

</Tip>

[[open-in-colab]]

ğŸ¤— Transformersãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã€ã™ã§ã«åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã¤ã„ã¦è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

ğŸ¤— Transformersãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯[ã“ã¡ã‚‰](https://github.com/huggingface/notebooks/tree/main/examples/benchmark.ipynb)ã§åˆ©ç”¨ã§ãã¾ã™ã€‚

## How to benchmark ğŸ¤— Transformers models

[`PyTorchBenchmark`]ã‚¯ãƒ©ã‚¹ã¨[`TensorFlowBenchmark`]ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ğŸ¤— Transformersãƒ¢ãƒ‡ãƒ«ã‚’æŸ”è»Ÿã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãã¾ã™ã€‚
ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€_ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡_ ãŠã‚ˆã³ _å¿…è¦ãªæ™‚é–“_ ã‚’ _æ¨è«–_ ãŠã‚ˆã³ _ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°_ ã®ä¸¡æ–¹ã«ã¤ã„ã¦æ¸¬å®šã§ãã¾ã™ã€‚

<Tip>

ã“ã“ã§ã® _æ¨è«–_ ã¯ã€å˜ä¸€ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã«ã‚ˆã£ã¦å®šç¾©ã•ã‚Œã€ _ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°_ ã¯å˜ä¸€ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã¨
ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã«ã‚ˆã£ã¦å®šç¾©ã•ã‚Œã¾ã™ã€‚

</Tip>

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹[`PyTorchBenchmark`]ã¨[`TensorFlowBenchmark`]ã¯ã€ãã‚Œãã‚Œã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹ã«å¯¾ã™ã‚‹é©åˆ‡ãªè¨­å®šã‚’å«ã‚€ [`PyTorchBenchmarkArguments`] ãŠã‚ˆã³ [`TensorFlowBenchmarkArguments`] ã‚¿ã‚¤ãƒ—ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚
[`PyTorchBenchmarkArguments`] ãŠã‚ˆã³ [`TensorFlowBenchmarkArguments`] ã¯ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã§ã‚ã‚Šã€ãã‚Œãã‚Œã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹ã«å¯¾ã™ã‚‹ã™ã¹ã¦ã®é–¢é€£ã™ã‚‹è¨­å®šã‚’å«ã‚“ã§ã„ã¾ã™ã€‚
æ¬¡ã®ä¾‹ã§ã¯ã€ã‚¿ã‚¤ãƒ— _bert-base-cased_ ã®BERTãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã™ã‚‹æ–¹æ³•ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚

<frameworkcontent>
<pt>
```py
>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments

>>> args = PyTorchBenchmarkArguments(models=["google-bert/bert-base-uncased"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512])
>>> benchmark = PyTorchBenchmark(args)
```
</pt>
<tf>
```py
>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments

>>> args = TensorFlowBenchmarkArguments(
...     models=["google-bert/bert-base-uncased"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> benchmark = TensorFlowBenchmark(args)
```
</tf>
</frameworkcontent>


ã“ã“ã§ã¯ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¼•æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã«å¯¾ã—ã¦ã€`models`ã€`batch_sizes`
ãŠã‚ˆã³`sequence_lengths`ã®3ã¤ã®å¼•æ•°ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã™ã€‚å¼•æ•°`models`ã¯å¿…é ˆã§ã€
[ãƒ¢ãƒ‡ãƒ«ãƒãƒ–](https://huggingface.co/models)ã‹ã‚‰ã®ãƒ¢ãƒ‡ãƒ«è­˜åˆ¥å­ã®`ãƒªã‚¹ãƒˆ`ã‚’æœŸå¾…ã—
ã¾ã™ã€‚`batch_sizes`ã¨`sequence_lengths`ã®2ã¤ã®`ãƒªã‚¹ãƒˆ`å¼•æ•°ã¯
ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¯¾è±¡ã¨ãªã‚‹`input_ids`ã®ã‚µã‚¤ã‚ºã‚’å®šç¾©ã—ã¾ã™ã€‚
ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¼•æ•°ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã‚’ä»‹ã—ã¦è¨­å®šã§ãã‚‹ä»–ã®å¤šãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«
`src/transformers/benchmark/benchmark_args_utils.py`ã€
`src/transformers/benchmark/benchmark_args.py`ï¼ˆPyTorchç”¨ï¼‰ã€ãŠã‚ˆã³`src/transformers/benchmark/benchmark_args_tf.py`ï¼ˆTensorflowç”¨ï¼‰
ã‚’å‚ç…§ã™ã‚‹ã‹ã€æ¬¡ã®ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’ãƒ«ãƒ¼ãƒˆã‹ã‚‰å®Ÿè¡Œã™ã‚‹ã¨ã€PyTorchã¨Tensorflowã®ãã‚Œãã‚Œã«å¯¾ã—ã¦è¨­å®šå¯èƒ½ãªã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜è¿°çš„ãªãƒªã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

<frameworkcontent>
<pt>
```bash
python examples/pytorch/benchmarking/run_benchmark.py --help
```

ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã€å˜ã« `benchmark.run()` ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§å®Ÿè¡Œã§ãã¾ã™ã€‚


```py
>>> results = benchmark.run()
>>> print(results)
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length     Time in s                  
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             0.006     
google-bert/bert-base-uncased          8               32            0.006     
google-bert/bert-base-uncased          8              128            0.018     
google-bert/bert-base-uncased          8              512            0.088     
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length    Memory in MB 
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             1227
google-bert/bert-base-uncased          8               32            1281
google-bert/bert-base-uncased          8              128            1307
google-bert/bert-base-uncased          8              512            1539
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: PyTorch
- use_torchscript: False
- framework_version: 1.4.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 08:58:43.371351
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</pt>
<tf>
```bash
python examples/tensorflow/benchmarking/run_benchmark_tf.py --help
```

ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã€å˜ã« `benchmark.run()` ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§å®Ÿè¡Œã§ãã¾ã™ã€‚



```py
>>> results = benchmark.run()
>>> print(results)
>>> results = benchmark.run()
>>> print(results)
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length     Time in s                  
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             0.005
google-bert/bert-base-uncased          8               32            0.008
google-bert/bert-base-uncased          8              128            0.022
google-bert/bert-base-uncased          8              512            0.105
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length    Memory in MB 
--------------------------------------------------------------------------------
google-bert/bert-base-uncased          8               8             1330
google-bert/bert-base-uncased          8               32            1330
google-bert/bert-base-uncased          8              128            1330
google-bert/bert-base-uncased          8              512            1770
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: Tensorflow
- use_xla: False
- framework_version: 2.2.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:26:35.617317
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</tf>
</frameworkcontent>

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€_æ¨è«–æ™‚é–“_ ã¨ _å¿…è¦ãªãƒ¡ãƒ¢ãƒª_ ãŒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã•ã‚Œã¾ã™ã€‚
ä¸Šè¨˜ã®ä¾‹ã®å‡ºåŠ›ã§ã¯ã€æœ€åˆã®2ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒ _æ¨è«–æ™‚é–“_ ã¨ _æ¨è«–ãƒ¡ãƒ¢ãƒª_ 
ã«å¯¾å¿œã™ã‚‹çµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€è¨ˆç®—ç’°å¢ƒã«é–¢ã™ã‚‹ã™ã¹ã¦ã®é–¢é€£æƒ…å ±ã€
ä¾‹ãˆã° GPU ã‚¿ã‚¤ãƒ—ã€ã‚·ã‚¹ãƒ†ãƒ ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©ãŒã€_ENVIRONMENT INFORMATION_ ã®ä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ã€[`PyTorchBenchmarkArguments`] 
ãŠã‚ˆã³ [`TensorFlowBenchmarkArguments`] ã«å¼•æ•° `save_to_csv=True` 
ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ _.csv_ ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®å ´åˆã€å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯åˆ¥ã€…ã® _.csv_ ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚_.csv_ 
ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å®šç¾©ã§ãã¾ã™ã€‚

ãƒ¢ãƒ‡ãƒ«è­˜åˆ¥å­ã€ä¾‹ãˆã° `google-bert/bert-base-uncased` ã‚’ä½¿ç”¨ã—ã¦äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã™ã‚‹ä»£ã‚ã‚Šã«ã€åˆ©ç”¨å¯èƒ½ãªä»»æ„ã®ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã®ä»»æ„ã®è¨­å®šã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã®å ´åˆã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¼•æ•°ã¨å…±ã«è¨­å®šã® `list` ã‚’æŒ¿å…¥ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚


<frameworkcontent>
<pt>
```py
>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments, BertConfig

>>> args = PyTorchBenchmarkArguments(
...     models=["bert-base", "bert-384-hid", "bert-6-lay"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> config_base = BertConfig()
>>> config_384_hid = BertConfig(hidden_size=384)
>>> config_6_lay = BertConfig(num_hidden_layers=6)

>>> benchmark = PyTorchBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])
>>> benchmark.run()
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length       Time in s                  
--------------------------------------------------------------------------------
bert-base                  8              128            0.006
bert-base                  8              512            0.006
bert-base                  8              128            0.018     
bert-base                  8              512            0.088     
bert-384-hid              8               8             0.006     
bert-384-hid              8               32            0.006     
bert-384-hid              8              128            0.011     
bert-384-hid              8              512            0.054     
bert-6-lay                 8               8             0.003     
bert-6-lay                 8               32            0.004     
bert-6-lay                 8              128            0.009     
bert-6-lay                 8              512            0.044
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length      Memory in MB 
--------------------------------------------------------------------------------
bert-base                  8               8             1277
bert-base                  8               32            1281
bert-base                  8              128            1307     
bert-base                  8              512            1539     
bert-384-hid              8               8             1005     
bert-384-hid              8               32            1027     
bert-384-hid              8              128            1035     
bert-384-hid              8              512            1255     
bert-6-lay                 8               8             1097     
bert-6-lay                 8               32            1101     
bert-6-lay                 8              128            1127     
bert-6-lay                 8              512            1359
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: PyTorch
- use_torchscript: False
- framework_version: 1.4.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:35:25.143267
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</pt>
<tf>
```py
>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments, BertConfig

>>> args = TensorFlowBenchmarkArguments(
...     models=["bert-base", "bert-384-hid", "bert-6-lay"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> config_base = BertConfig()
>>> config_384_hid = BertConfig(hidden_size=384)
>>> config_6_lay = BertConfig(num_hidden_layers=6)

>>> benchmark = TensorFlowBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])
>>> benchmark.run()
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length       Time in s                  
--------------------------------------------------------------------------------
bert-base                  8               8             0.005
bert-base                  8               32            0.008
bert-base                  8              128            0.022
bert-base                  8              512            0.106
bert-384-hid              8               8             0.005
bert-384-hid              8               32            0.007
bert-384-hid              8              128            0.018
bert-384-hid              8              512            0.064
bert-6-lay                 8               8             0.002
bert-6-lay                 8               32            0.003
bert-6-lay                 8              128            0.0011
bert-6-lay                 8              512            0.074
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length      Memory in MB 
--------------------------------------------------------------------------------
bert-base                  8               8             1330
bert-base                  8               32            1330
bert-base                  8              128            1330
bert-base                  8              512            1770
bert-384-hid              8               8             1330
bert-384-hid              8               32            1330
bert-384-hid              8              128            1330
bert-384-hid              8              512            1540
bert-6-lay                 8               8             1330
bert-6-lay                 8               32            1330
bert-6-lay                 8              128            1330
bert-6-lay                 8              512            1540
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: Tensorflow
- use_xla: False
- framework_version: 2.2.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:38:15.487125
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</tf>
</frameworkcontent>

ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸBertModelã‚¯ãƒ©ã‚¹ã®æ§‹æˆã«å¯¾ã™ã‚‹æ¨è«–æ™‚é–“ã¨å¿…è¦ãªãƒ¡ãƒ¢ãƒªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

ã“ã®æ©Ÿèƒ½ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹éš›ã«ã©ã®æ§‹æˆã‚’é¸æŠã™ã¹ãã‹ã‚’æ±ºå®šã™ã‚‹éš›ã«ç‰¹ã«å½¹ç«‹ã¤ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

## Benchmark best practices

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã™ã‚‹éš›ã«æ³¨æ„ã™ã¹ãã„ãã¤ã‹ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™ã€‚

- ç¾åœ¨ã€å˜ä¸€ãƒ‡ãƒã‚¤ã‚¹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã‹ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚GPUã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹å ´åˆã€ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
  ã“ã‚Œã¯ã‚·ã‚§ãƒ«ã§`CUDA_VISIBLE_DEVICES`ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§è¡Œãˆã¾ã™ã€‚ä¾‹ï¼š`export CUDA_VISIBLE_DEVICES=0`ã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
- `no_multi_processing`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ã€ãƒ†ã‚¹ãƒˆãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã®ã¿`True`ã«è¨­å®šã™ã¹ãã§ã™ã€‚æ­£ç¢ºãªãƒ¡ãƒ¢ãƒªè¨ˆæ¸¬ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ã€å„ãƒ¡ãƒ¢ãƒªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’åˆ¥ã€…ã®ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€`no_multi_processing`ãŒ`True`ã«è¨­å®šã•ã‚Œã¾ã™ã€‚
- ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’å…±æœ‰ã™ã‚‹éš›ã«ã¯ã€å¸¸ã«ç’°å¢ƒæƒ…å ±ã‚’è¨˜è¿°ã™ã‚‹ã¹ãã§ã™ã€‚ç•°ãªã‚‹GPUãƒ‡ãƒã‚¤ã‚¹ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãŒå¤§ããç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœå˜ä½“ã§ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã¨ã£ã¦ã‚ã¾ã‚Šæœ‰ç”¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

## Sharing your benchmark

ä»¥å‰ã€ã™ã¹ã¦ã®åˆ©ç”¨å¯èƒ½ãªã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«ï¼ˆå½“æ™‚10ãƒ¢ãƒ‡ãƒ«ï¼‰ã«å¯¾ã—ã¦ã€å¤šãã®ç•°ãªã‚‹è¨­å®šã§æ¨è«–æ™‚é–“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒè¡Œã‚ã‚Œã¾ã—ãŸï¼šPyTorchã‚’ä½¿ç”¨ã—ã€TorchScriptã®æœ‰ç„¡ã€TensorFlowã‚’ä½¿ç”¨ã—ã€XLAã®æœ‰ç„¡ãªã©ã§ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ†ã‚¹ãƒˆã¯ã™ã¹ã¦CPUã§è¡Œã‚ã‚Œã¾ã—ãŸï¼ˆTensorFlow XLAã‚’é™¤ãï¼‰ã€‚

ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[æ¬¡ã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆ](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2)ã«è©³ã—ãèª¬æ˜ã•ã‚Œã¦ãŠã‚Šã€çµæœã¯[ã“ã¡ã‚‰](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit?usp=sharing)ã§åˆ©ç”¨ã§ãã¾ã™ã€‚

æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’å…±æœ‰ã™ã‚‹ã“ã¨ãŒã“ã‚Œã¾ã§ä»¥ä¸Šã«ç°¡å˜ã«ãªã‚Šã¾ã™ã€‚

- [PyTorchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/benchmarking/README.md)ã€‚
- [TensorFlowãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/benchmarking/README.md)ã€‚
