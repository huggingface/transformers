<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# XLA Integration for TensorFlow Models

[[open-in-colab]]

åŠ é€Ÿç·šå½¢ä»£æ•°ï¼ˆAccelerated Linear Algebraï¼‰ã€é€šç§°XLAã¯ã€TensorFlowãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã§ã™ã€‚[å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://www.tensorflow.org/xla)ã«ã‚ˆã‚Œã°ã€XLAï¼ˆAccelerated Linear Algebraï¼‰ã¯ç·šå½¢ä»£æ•°ã®ãŸã‚ã®ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã§ã€TensorFlowãƒ¢ãƒ‡ãƒ«ã‚’æ½œåœ¨çš„ã«ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®å¤‰æ›´ãªã—ã§é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚

TensorFlowã§XLAã‚’ä½¿ç”¨ã™ã‚‹ã®ã¯ç°¡å˜ã§ã™ã€‚XLAã¯`tensorflow`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå†…ã«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã•ã‚Œã¦ãŠã‚Šã€[`tf.function`](https://www.tensorflow.org/guide/intro_to_graphs)ãªã©ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹é–¢æ•°å†…ã§`jit_compile`å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒªã‚¬ãƒ¼ã§ãã¾ã™ã€‚`fit()`ã‚„`predict()`ãªã©ã®Kerasãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€`model.compile()`ã«`jit_compile`å¼•æ•°ã‚’æ¸¡ã™ã ã‘ã§XLAã‚’æœ‰åŠ¹ã«ã§ãã¾ã™ã€‚ãŸã ã—ã€XLAã¯ã“ã‚Œã‚‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«é™å®šã•ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ä»»æ„ã®`tf.function`ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚

ğŸ¤— Transformerså†…ã®ã„ãã¤ã‹ã®TensorFlowãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€XLAã¨äº’æ›æ€§ãŒã‚ã‚‹ã‚ˆã†ã«æ›¸ãç›´ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã¯ã€[GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)ã€[T5](https://huggingface.co/docs/transformers/model_doc/t5)ã€[OPT](https://huggingface.co/docs/transformers/model_doc/opt)ãªã©ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚„ã€[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)ãªã©ã®éŸ³å£°å‡¦ç†ãƒ¢ãƒ‡ãƒ«ã‚‚å«ã¾ã‚Œã¾ã™ã€‚

é€Ÿåº¦å‘ä¸Šã®å…·ä½“çš„ãªé‡ã¯ãƒ¢ãƒ‡ãƒ«ã«éå¸¸ã«ä¾å­˜ã—ã¾ã™ãŒã€ğŸ¤— Transformerså†…ã®TensorFlowãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ç´„100å€ã®é€Ÿåº¦å‘ä¸Šã‚’ç¢ºèªã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã«XLAã‚’ä½¿ç”¨ã—ã¦æœ€å¤§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¾—ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚ã¾ãŸã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨XLAçµ±åˆã®ãƒ‡ã‚¶ã‚¤ãƒ³å“²å­¦ã«ã¤ã„ã¦è©³ã—ãå­¦ã³ãŸã„å ´åˆã®è¿½åŠ ãƒªã‚½ãƒ¼ã‚¹ã¸ã®ãƒªãƒ³ã‚¯ã‚‚æä¾›ã—ã¾ã™ã€‚

## Running TF functions with XLA

ä»¥ä¸‹ã®TensorFlowãƒ¢ãƒ‡ãƒ«ã‚’è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ï¼š


```py
import tensorflow as tf

model = tf.keras.Sequential(
    [tf.keras.layers.Dense(10, input_shape=(10,), activation="relu"), tf.keras.layers.Dense(5, activation="softmax")]
)
```

ä¸Šè¨˜ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€æ¬¡å…ƒãŒ`(10, )`ã®å…¥åŠ›ã‚’å—ã‘å…¥ã‚Œã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§å®Ÿè¡Œã™ã‚‹ã«ã¯ã€æ¬¡ã®ã‚ˆã†ã«ã—ã¾ã™ï¼š


```py
# Generate random inputs for the model.
batch_size = 16
input_vector_dim = 10
random_inputs = tf.random.normal((batch_size, input_vector_dim))

# Run a forward pass.
_ = model(random_inputs)
```

XLAã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¾ã™ï¼š


```py
xla_fn = tf.function(model, jit_compile=True)
_ = xla_fn(random_inputs)
```

`model`ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® `call()` é–¢æ•°ã¯XLAã‚°ãƒ©ãƒ•ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ãŸã ã—ã€XLAã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ãŸã„ä»–ã®ãƒ¢ãƒ‡ãƒ«é–¢æ•°ãŒã‚ã‚‹å ´åˆã€ãã‚Œã‚‚å¯èƒ½ã§ã™ã€‚ä»¥ä¸‹ã¯ãã®æ–¹æ³•ã§ã™ï¼š


```py
my_xla_fn = tf.function(model.my_xla_fn, jit_compile=True)
```

## Running a TF text generation model with XLA from ğŸ¤— Transformers

ğŸ¤— Transformerså†…ã§XLAã§ã®é«˜é€ŸåŒ–ã•ã‚ŒãŸç”Ÿæˆã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®`transformers`ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ï¼š

```bash
pip install transformers --upgrade
```

æ¬¡ã«ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã¾ã™ï¼š


```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

# Will error if the minimal version of Transformers is not installed.
from transformers.utils import check_min_version

check_min_version("4.21.0")


tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")
input_string = ["TensorFlow is"]

# One line to create an XLA generation function
xla_generate = tf.function(model.generate, jit_compile=True)

tokenized_input = tokenizer(input_string, return_tensors="tf")
generated_tokens = xla_generate(**tokenized_input, num_beams=2)

decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
# Generated -- TensorFlow is an open-source, open-source, distributed-source application # framework for the
```

`generate()`ã§XLAã‚’æœ‰åŠ¹ã«ã™ã‚‹ã®ã¯ã€ãŸã£ãŸä¸€è¡Œã®ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®æ®‹ã‚Šéƒ¨åˆ†ã¯å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãŸã ã—ã€XLAå›ºæœ‰ã®ã„ãã¤ã‹ã®æ³¨æ„ç‚¹ãŒä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã«ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã«æ³¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€XLAãŒã‚‚ãŸã‚‰ã™é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ãã‚Œã‚‰ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã“ã‚Œã‚‰ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚


## Gotchas to be aware of

XLAã‚’æœ‰åŠ¹ã«ã—ãŸé–¢æ•°ï¼ˆä¸Šè¨˜ã®`xla_generate()`ãªã©ï¼‰ã‚’åˆã‚ã¦å®Ÿè¡Œã™ã‚‹ã¨ã€å†…éƒ¨ã§è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’æ¨è«–ã—ã‚ˆã†ã¨ã—ã¾ã™ãŒã€ã“ã‚Œã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯["ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°"ï¼ˆtracingï¼‰](https://www.tensorflow.org/guide/intro_to_graphs#when_is_a_function_tracing)ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

ç”Ÿæˆæ™‚é–“ãŒé«˜é€Ÿã§ã¯ãªã„ã“ã¨ã«æ°—ä»˜ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚`xla_generate()`ï¼ˆã¾ãŸã¯ä»–ã®XLAå¯¾å¿œé–¢æ•°ï¼‰ã®é€£ç¶šå‘¼ã³å‡ºã—ã§ã¯ã€é–¢æ•°ã¸ã®å…¥åŠ›ãŒæœ€åˆã«è¨ˆç®—ã‚°ãƒ©ãƒ•ãŒæ§‹ç¯‰ã•ã‚ŒãŸã¨ãã¨åŒã˜å½¢çŠ¶ã«å¾“ã£ã¦ã„ã‚‹å ´åˆã€è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’æ¨è«–ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã‚Œã¯ã€å…¥åŠ›å½¢çŠ¶ãŒå›ºå®šã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ï¼ˆä¾‹ï¼šç”»åƒï¼‰ã«ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ãŒã€å¤‰æ•°ã®å…¥åŠ›å½¢çŠ¶ãƒ¢ãƒ€ãƒªãƒ†ã‚£ï¼ˆä¾‹ï¼šãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’æ‰±ã†å ´åˆã«ã¯æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚

`xla_generate()`ãŒå¸¸ã«åŒã˜å…¥åŠ›å½¢çŠ¶ã§å‹•ä½œã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã«ã¯ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’å‘¼ã³å‡ºã™éš›ã«`padding`å¼•æ•°ã‚’æŒ‡å®šã§ãã¾ã™ã€‚

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")
input_string = ["TensorFlow is"]

xla_generate = tf.function(model.generate, jit_compile=True)

# Here, we call the tokenizer with padding options.
tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")

generated_tokens = xla_generate(**tokenized_input, num_beams=2)
decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
```

ã“ã‚Œã«ã‚ˆã‚Šã€`xla_generate()`ã¸ã®å…¥åŠ›ãŒå¸¸ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚ŒãŸå½¢çŠ¶ã®å…¥åŠ›ã‚’å—ã‘å–ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ç”Ÿæˆæ™‚é–“ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§ã“ã‚Œã‚’ç¢ºèªã§ãã¾ã™ï¼š

```py
import time
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")

xla_generate = tf.function(model.generate, jit_compile=True)

for input_string in ["TensorFlow is", "TensorFlow is a", "TFLite is a"]:
    tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")
    start = time.time_ns()
    generated_tokens = xla_generate(**tokenized_input, num_beams=2)
    end = time.time_ns()
    print(f"Execution time -- {(end - start) / 1e6:.1f} ms\n")
```

Tesla T4 GPUã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€æ¬¡ã®ã‚ˆã†ãªå‡ºåŠ›ãŒæœŸå¾…ã•ã‚Œã¾ã™ï¼š

```bash
Execution time -- 30819.6 ms

Execution time -- 79.0 ms

Execution time -- 78.9 ms
```

æœ€åˆã®`xla_generate()`å‘¼ã³å‡ºã—ã¯ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®ãŸã‚ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ãŒã€é€£ç¶šã™ã‚‹å‘¼ã³å‡ºã—ã¯æ¡é•ã„ã«é«˜é€Ÿã§ã™ã€‚ç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ã„ã‹ãªã‚‹å¤‰æ›´ã‚‚ã€å†ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’å¼•ãèµ·ã“ã—ã€ç”Ÿæˆæ™‚é–“ã®é…å»¶ã‚’å¼•ãèµ·ã“ã™ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€ğŸ¤— TransformersãŒæä¾›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ã™ã¹ã¦ç¶²ç¾…ã—ã¦ã„ã¾ã›ã‚“ã€‚é«˜åº¦ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«ã¤ã„ã¦ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

## Additional Resources

ã“ã“ã§ã¯ã€ğŸ¤— Transformersã¨ä¸€èˆ¬çš„ãªXLAã«ã¤ã„ã¦ã•ã‚‰ã«è©³ã—ãå­¦ã³ãŸã„å ´åˆã®ã„ãã¤ã‹ã®è¿½åŠ ãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚

* [ã“ã®Colab Notebook](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/91_tf_xla_generate.ipynb)ã§ã¯ã€XLAå¯¾å¿œã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆ[T5](https://huggingface.co/docs/transformers/model_doc/t5)ãªã©ï¼‰ãŠã‚ˆã³ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å°‚ç”¨ï¼ˆ[GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)ãªã©ï¼‰ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™ãŸã‚ã®å¯¾è©±å‹ãƒ‡ãƒ¢ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚
* [ã“ã®ãƒ–ãƒ­ã‚°è¨˜äº‹](https://huggingface.co/blog/tf-xla-generate)ã§ã¯ã€XLAå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ¦‚è¦ã¨ã€TensorFlowã§ã®XLAã«ã¤ã„ã¦ã®å‹å¥½çš„ãªç´¹ä»‹ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚
* [ã“ã®ãƒ–ãƒ­ã‚°è¨˜äº‹](https://blog.tensorflow.org/2022/11/how-hugging-face-improved-text-generation-performance-with-xla.html)ã§ã¯ã€ğŸ¤— Transformersã®TensorFlowãƒ¢ãƒ‡ãƒ«ã«XLAã‚µãƒãƒ¼ãƒˆã‚’è¿½åŠ ã™ã‚‹éš›ã®è¨­è¨ˆå“²å­¦ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚
* ä¸€èˆ¬çš„ãªXLAã¨TensorFlowã‚°ãƒ©ãƒ•ã«ã¤ã„ã¦è©³ã—ãå­¦ã¶ãŸã‚ã®ãŠã™ã™ã‚ã®æŠ•ç¨¿ï¼š
    * [XLA: æ©Ÿæ¢°å­¦ç¿’ç”¨ã®æœ€é©åŒ–ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©](https://www.tensorflow.org/xla)
    * [ã‚°ãƒ©ãƒ•ã¨`tf.function`ã®ç´¹ä»‹](https://www.tensorflow.org/guide/intro_to_graphs)
    * [`tf.function`ã‚’ä½¿ç”¨ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š](https://www.tensorflow.org/guide/function)
