<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Train with a script

ğŸ¤— Transformersã®[notebooks](./notebooks/README)ã¨ä¸€ç·’ã«ã€[PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch)ã€[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow)ã€ã¾ãŸã¯[JAX/Flax](https://github.com/huggingface/transformers/tree/main/examples/flax)ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚ã‚ã‚Šã¾ã™ã€‚

ã¾ãŸã€ç§ãŸã¡ã®[ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples/research_projects)ã‚„[ãƒ¬ã‚¬ã‚·ãƒ¼ã®ä¾‹](https://github.com/huggingface/transformers/tree/main/examples/legacy)ã§ä½¿ç”¨ã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚è¦‹ã¤ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ç¾åœ¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã•ã‚Œã¦ãŠã‚‰ãšã€ãŠãã‚‰ãæœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨äº’æ›æ€§ãŒãªã„ç‰¹å®šã®ğŸ¤— Transformersã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¿…è¦ã§ã™ã€‚

ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã™ã¹ã¦ã®å•é¡Œã§ãã®ã¾ã¾å‹•ä½œã™ã‚‹ã“ã¨ã¯æœŸå¾…ã•ã‚Œã¦ãŠã‚‰ãšã€è§£æ±ºã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹å•é¡Œã«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é©å¿œã•ã›ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã“ã®ç‚¹ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ã€ã»ã¨ã‚“ã©ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ãƒ‡ãƒ¼ã‚¿ãŒã©ã®ã‚ˆã†ã«å‰å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’å®Œå…¨ã«å…¬é–‹ã—ã€å¿…è¦ã«å¿œã˜ã¦ç·¨é›†ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å®Ÿè£…ã—ãŸã„æ©Ÿèƒ½ãŒã‚ã‚‹å ´åˆã¯ã€[ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ](https://discuss.huggingface.co/)ã‹[ã‚¤ã‚·ãƒ¥ãƒ¼ãƒˆãƒ©ãƒƒã‚«ãƒ¼](https://github.com/huggingface/transformers/issues)ã§è­°è«–ã—ã¦ã‹ã‚‰ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æå‡ºã—ã¦ãã ã•ã„ã€‚ãƒã‚°ä¿®æ­£ã¯æ­“è¿ã—ã¾ã™ãŒã€èª­ã¿ã‚„ã™ã•ã®ã‚³ã‚¹ãƒˆã§æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ã»ã¨ã‚“ã©ãƒãƒ¼ã‚¸ã•ã‚Œãªã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€[PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)ã¨[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization)ã§å®Ÿè¡Œã™ã‚‹ã‚µãƒãƒªã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œæ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ã™ã¹ã¦ã®ä¾‹ã¯ã€æ˜ç¤ºçš„ã«æŒ‡å®šã•ã‚Œã¦ã„ãªã„é™ã‚Šã€ä¸¡æ–¹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã‚‚ã«å‹•ä½œã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚

## Setup

æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ­£å¸¸ã«å®Ÿè¡Œã™ã‚‹ã«ã¯ã€æ–°ã—ã„ä»®æƒ³ç’°å¢ƒã«ğŸ¤— Transformersã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:


```bash
git clone https://github.com/huggingface/transformers
cd transformers
pip install .
```

ä»¥å‰ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦ã¯ã€ä»¥ä¸‹ã®ãƒˆã‚°ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼š

<details>
  <summary>ä»¥å‰ã®ğŸ¤— Transformersã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«é–¢ã™ã‚‹ä¾‹</summary>
	<ul>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.5.1/examples">v4.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.4.2/examples">v4.4.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.3.3/examples">v4.3.3</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.2.2/examples">v4.2.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.1.1/examples">v4.1.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.0.1/examples">v4.0.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.5.1/examples">v3.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.4.0/examples">v3.4.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.3.1/examples">v3.3.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.2.0/examples">v3.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.1.0/examples">v3.1.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.0.2/examples">v3.0.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.11.0/examples">v2.11.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.10.0/examples">v2.10.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.9.1/examples">v2.9.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.8.0/examples">v2.8.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.7.0/examples">v2.7.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.6.0/examples">v2.6.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.5.1/examples">v2.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.4.0/examples">v2.4.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.3.0/examples">v2.3.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.2.0/examples">v2.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.1.0/examples">v2.1.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.0.0/examples">v2.0.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.2.0/examples">v1.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.1.0/examples">v1.1.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.0.0/examples">v1.0.0</a></li>
	</ul>
</details>

æ¬¡ã«ã€ç¾åœ¨ã®ğŸ¤— Transformersã®ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ç‰¹å®šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚ãŸã¨ãˆã°ã€v3.5.1ãªã©ã§ã™ã€‚


```bash
git checkout tags/v3.5.1
```


é©åˆ‡ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¨­å®šã—ãŸã‚‰ã€ä»»æ„ã®ä¾‹ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•ã—ã€ä¾‹å›ºæœ‰ã®è¦ä»¶ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š



```bash
pip install -r requirements.txt
```

## Run a script

<frameworkcontent>
<pt>
ã“ã®ä¾‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/) ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€å‰å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚æ¬¡ã«ã€[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) ã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸Šã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã§ã¯ã€[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§ [T5-small](https://huggingface.co/google-t5/t5-small) ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚T5 ãƒ¢ãƒ‡ãƒ«ã¯ã€ãã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ã«èµ·å› ã—ã¦è¿½åŠ ã® `source_prefix` å¼•æ•°ãŒå¿…è¦ã§ã™ã€‚ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚Šã€T5 ã¯ã“ã‚ŒãŒè¦ç´„ã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã“ã¨ã‚’çŸ¥ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚


```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

</pt>
<tf>
ã“ã®ä¾‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/) ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‰å‡¦ç†ã—ã¾ã™ã€‚ãã®å¾Œã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯è¦ç´„ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸Šã§ Keras ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã§ã¯ã€[T5-small](https://huggingface.co/google-t5/t5-small) ã‚’ [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚T5 ãƒ¢ãƒ‡ãƒ«ã¯ã€ãã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ã«èµ·å› ã—ã¦è¿½åŠ ã® `source_prefix` å¼•æ•°ãŒå¿…è¦ã§ã™ã€‚ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€T5 ã«ã“ã‚ŒãŒè¦ç´„ã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã“ã¨ã‚’çŸ¥ã‚‰ã›ã¾ã™ã€‚


```bash
python examples/tensorflow/summarization/run_summarization.py  \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```
</tf>
</frameworkcontent>

## Distributed training and mixed precision

[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)ã¯ã€åˆ†æ•£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ··åˆç²¾åº¦ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ã¤ã¾ã‚Šã€ã“ã®æ©Ÿèƒ½ã‚’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€æ¬¡ã®æ‰‹é †ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

- `fp16`å¼•æ•°ã‚’è¿½åŠ ã—ã¦æ··åˆç²¾åº¦ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚
- `nproc_per_node`å¼•æ•°ã§ä½¿ç”¨ã™ã‚‹GPUã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚

ä»¥ä¸‹ã¯æä¾›ã•ã‚ŒãŸBashã‚³ãƒ¼ãƒ‰ã§ã™ã€‚ã“ã®ã‚³ãƒ¼ãƒ‰ã®æ—¥æœ¬èªè¨³ã‚’Markdownå½¢å¼ã§è¨˜è¼‰ã—ã¾ã™ã€‚

```bash
torchrun \
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \
    --fp16 \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```


TensorFlowã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€åˆ†æ•£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«[`MirroredStrategy`](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy)ã‚’ä½¿ç”¨ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«è¿½åŠ ã®å¼•æ•°ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚TensorFlowã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¤‡æ•°ã®GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã«ãã‚Œã‚‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

## Run a script on a TPU

<frameworkcontent>
<pt>
Tensor Processing Units (TPUs)ã¯ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŠ é€Ÿã•ã›ã‚‹ãŸã‚ã«ç‰¹åˆ¥ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚PyTorchã¯ã€[XLA](https://www.tensorflow.org/xla)ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã‚’ä½¿ç”¨ã—ã¦TPUsã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€è©³ç´°ã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](https://github.com/pytorch/xla/blob/master/README.md)ã‚’ã”è¦§ãã ã•ã„ã€‚TPUã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€`xla_spawn.py`ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’èµ·å‹•ã—ã€`num_cores`å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ä½¿ç”¨ã™ã‚‹TPUã‚³ã‚¢ã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚
```bash
python xla_spawn.py --num_cores 8 \
    summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```
</pt>
<tf>
ã‚‚ã¡ã‚ã‚“ã€Tensor Processing Unitsï¼ˆTPUsï¼‰ã¯æ€§èƒ½ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ç‰¹åˆ¥ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚TensorFlowã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€TPUsã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«[`TPUStrategy`](https://www.tensorflow.org/guide/distributed_training#tpustrategy)ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚TPUã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€TPUãƒªã‚½ãƒ¼ã‚¹ã®åå‰ã‚’`tpu`å¼•æ•°ã«æ¸¡ã—ã¾ã™ã€‚

```bash
python run_summarization.py  \
    --tpu name_of_tpu_resource \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```
</tf>
</frameworkcontent>

## Run a script with ğŸ¤— Accelerate

ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate)ã¯ã€PyTorchå°‚ç”¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€CPUã®ã¿ã€è¤‡æ•°ã®GPUã€TPUãªã©ã€ã•ã¾ã–ã¾ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸæ–¹æ³•ã‚’æä¾›ã—ã¾ã™ã€‚PyTorchã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å®Œå…¨ã«å¯è¦–åŒ–ã—ãªãŒã‚‰å®Ÿè¡Œã§ãã¾ã™ã€‚ã¾ã ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ãªã„å ´åˆã¯ã€ğŸ¤— Accelerateã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š

> æ³¨æ„ï¼šAccelerateã¯æ€¥é€Ÿã«é–‹ç™ºãŒé€²è¡Œã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯accelerateã®gitãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
```bash
pip install git+https://github.com/huggingface/accelerate
```

ä»£ã‚ã‚Šã«ã€`run_summarization_no_trainer.py` ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ ğŸ¤— Accelerate ãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã¯ã€ãƒ•ã‚©ãƒ«ãƒ€å†…ã« `task_no_trainer.py` ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãšã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ä¿å­˜ã—ã¾ã™ï¼š

```bash
accelerate config
```

ãƒ†ã‚¹ãƒˆã‚’è¡Œã„ã€è¨­å®šãŒæ­£ã—ãæ§‹æˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ï¼š


```bash
accelerate test
```

Now you are ready to launch the training:


```bash
accelerate launch run_summarization_no_trainer.py \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir ~/tmp/tst-summarization
```

## Use a custom dataset

è¦ç´„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€CSVã¾ãŸã¯JSON Lineãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚ã‚Œã°ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€ã„ãã¤ã‹ã®è¿½åŠ ã®å¼•æ•°ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

- `train_file`ãŠã‚ˆã³`validation_file`ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚
- `text_column`ã¯è¦ç´„ã™ã‚‹ãŸã‚ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚
- `summary_column`ã¯å‡ºåŠ›ã™ã‚‹å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚

ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸè¦ç´„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š

```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --train_file path_to_csv_or_jsonlines_file \
    --validation_file path_to_csv_or_jsonlines_file \
    --text_column text_column_name \
    --summary_column summary_column_name \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --overwrite_output_dir \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --predict_with_generate
```

## Test a script

ã™ã¹ã¦ãŒäºˆæƒ³é€šã‚Šã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’å‡¦ç†ã™ã‚‹å‰ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸€éƒ¨ã®ä¾‹ã§ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã¯è‰¯ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã™ã€‚ä»¥ä¸‹ã®å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°ã«åˆ‡ã‚Šè©°ã‚ã¾ã™ï¼š

- `max_train_samples`
- `max_eval_samples`
- `max_predict_samples`

```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --max_train_samples 50 \
    --max_eval_samples 50 \
    --max_predict_samples 50 \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

ä¸€éƒ¨ã®ä¾‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€`max_predict_samples`å¼•æ•°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å¼•æ•°ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ãŒã‚ã‹ã‚‰ãªã„å ´åˆã¯ã€`-h`å¼•æ•°ã‚’è¿½åŠ ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚

```bash
examples/pytorch/summarization/run_summarization.py -h
```

## Resume training from checkpoint

ä»¥å‰ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å†é–‹ã™ã‚‹ãŸã‚ã®å½¹ç«‹ã¤ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚‚ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒä¸­æ–­ã•ã‚ŒãŸå ´åˆã§ã‚‚ã€æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™ã“ã¨ãªãã€ä¸­æ–­ã—ãŸã¨ã“ã‚ã‹ã‚‰å†é–‹ã§ãã¾ã™ã€‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å†é–‹ã™ã‚‹ãŸã‚ã®2ã¤ã®æ–¹æ³•ãŒã‚ã‚Šã¾ã™ã€‚

æœ€åˆã®æ–¹æ³•ã¯ã€`output_dir previous_output_dir` å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ã€`output_dir` ã«ä¿å­˜ã•ã‚ŒãŸæœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å†é–‹ã™ã‚‹æ–¹æ³•ã§ã™ã€‚ã“ã®å ´åˆã€`overwrite_output_dir` ã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --output_dir previous_output_dir \
    --predict_with_generate
```

2ç•ªç›®ã®æ–¹æ³•ã§ã¯ã€`resume_from_checkpoint path_to_specific_checkpoint` å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹å®šã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å†é–‹ã—ã¾ã™ã€‚


```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --resume_from_checkpoint path_to_specific_checkpoint \
    --predict_with_generate
```

## Share your model

ã™ã¹ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã‚’ [Model Hub](https://huggingface.co/models) ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚é–‹å§‹ã™ã‚‹å‰ã« Hugging Face ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

```bash
huggingface-cli login
```

æ¬¡ã«ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã« `push_to_hub` å¼•æ•°ã‚’è¿½åŠ ã—ã¾ã™ã€‚ã“ã®å¼•æ•°ã¯ã€Hugging Face ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ `output_dir` ã§æŒ‡å®šã—ãŸãƒ•ã‚©ãƒ«ãƒ€åã§ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™ã€‚

ç‰¹å®šã®åå‰ã‚’ãƒªãƒã‚¸ãƒˆãƒªã«ä»˜ã‘ã‚‹ã«ã¯ã€`push_to_hub_model_id` å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦è¿½åŠ ã—ã¾ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯è‡ªå‹•çš„ã«ã‚ãªãŸã®åå‰ç©ºé–“ã®ä¸‹ã«ãƒªã‚¹ãƒˆã•ã‚Œã¾ã™ã€‚

ä»¥ä¸‹ã®ä¾‹ã¯ã€ç‰¹å®šã®ãƒªãƒã‚¸ãƒˆãƒªåã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™:



```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --push_to_hub \
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```




