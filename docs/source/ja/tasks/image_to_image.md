<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Image-to-Image Task Guide

[[open-in-colab]]

Image-to-Image ã‚¿ã‚¹ã‚¯ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒç”»åƒã‚’å—ä¿¡ã—ã€åˆ¥ã®ç”»åƒã‚’å‡ºåŠ›ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚ã“ã‚Œã«ã¯ã€ç”»åƒå¼·åŒ– (è¶…è§£åƒåº¦ã€ä½å…‰é‡å¼·åŒ–ã€ãƒ‡ã‚£ãƒ¬ã‚¤ãƒ³ãªã©)ã€ç”»åƒä¿®å¾©ãªã©ã‚’å«ã‚€ã•ã¾ã–ã¾ãªã‚µãƒ–ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€æ¬¡ã®æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚
- è¶…è§£åƒåº¦ã‚¿ã‚¹ã‚¯ã«ç”»åƒé–“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã›ãšã«ã€åŒã˜ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã‚¤ãƒ¡ãƒ¼ã‚¸é–“ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

ã“ã®ã‚¬ã‚¤ãƒ‰ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸæ™‚ç‚¹ã§ã¯ã€`image-to-image`ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯è¶…è§£åƒåº¦ã‚¿ã‚¹ã‚¯ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚

```bash
pip install transformers
```

[Swin2SR ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/caidas/swin2SR-lightweight-x2-64) ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚æ¬¡ã«ã€ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ¨è«–ã§ãã¾ã™ã€‚ç¾æ™‚ç‚¹ã§ã¯ã€[Swin2SR ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/models?sort=trending&search=swin2sr) ã®ã¿ãŒã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚

```python
from transformers import pipeline

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
pipe = pipeline(task="image-to-image", model="caidas/swin2SR-lightweight-x2-64", device=device)
```

ã§ã¯ã€ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ã‚‡ã†ã€‚

```python
from PIL import Image
import requests

url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg"
image = Image.open(requests.get(url, stream=True).raw)

print(image.size)
```
```bash
# (532, 432)
```
<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg" alt="Photo of a cat"/>
</div>


ã“ã‚Œã§ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚çŒ«ã®ç”»åƒã®æ‹¡å¤§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—ã—ã¾ã™ã€‚

```python
upscaled = pipe(image)
print(upscaled.size)
```
```bash
# (1072, 880)
```

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã›ãšã«è‡ªåˆ†ã§æ¨è«–ã‚’å®Ÿè¡Œã—ãŸã„å ´åˆã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã® `Swin2SRForImageSuperResolution` ã‚¯ãƒ©ã‚¹ã¨ `Swin2SRImageProcessor` ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã‚Œã«ã¯åŒã˜ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’åˆæœŸåŒ–ã—ã¾ã—ã‚‡ã†ã€‚

```python
from transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor 

model = Swin2SRForImageSuperResolution.from_pretrained("caidas/swin2SR-lightweight-x2-64").to(device)
processor = Swin2SRImageProcessor("caidas/swin2SR-lightweight-x2-64")
```

`pipeline`ã€ã¯ã€è‡ªåˆ†ã§è¡Œã†å¿…è¦ãŒã‚ã‚‹å‰å‡¦ç†ã¨å¾Œå‡¦ç†ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æŠ½è±¡åŒ–ã™ã‚‹ã®ã§ã€ç”»åƒã‚’å‰å‡¦ç†ã—ã¾ã—ã‚‡ã†ã€‚ç”»åƒã‚’ãƒ—ãƒ­ã‚»ãƒƒã‚µã«æ¸¡ã—ã¦ã‹ã‚‰ã€ãƒ”ã‚¯ã‚»ãƒ«å€¤ã‚’ GPU ã«ç§»å‹•ã—ã¾ã™ã€‚

```python
pixel_values = processor(image, return_tensors="pt").pixel_values
print(pixel_values.shape)

pixel_values = pixel_values.to(device)
```

ã“ã‚Œã§ã€ãƒ”ã‚¯ã‚»ãƒ«å€¤ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™ã“ã¨ã§ç”»åƒã‚’æ¨æ¸¬ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

```python
import torch

with torch.no_grad():
  outputs = model(pixel_values)
```

å‡ºåŠ›ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãª `ImageSuperResolutionOutput` ã‚¿ã‚¤ãƒ—ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã™ ğŸ‘‡

```
(loss=None, reconstruction=tensor([[[[0.8270, 0.8269, 0.8275,  ..., 0.7463, 0.7446, 0.7453],
          [0.8287, 0.8278, 0.8283,  ..., 0.7451, 0.7448, 0.7457],
          [0.8280, 0.8273, 0.8269,  ..., 0.7447, 0.7446, 0.7452],
          ...,
          [0.5923, 0.5933, 0.5924,  ..., 0.0697, 0.0695, 0.0706],
          [0.5926, 0.5932, 0.5926,  ..., 0.0673, 0.0687, 0.0705],
          [0.5927, 0.5914, 0.5922,  ..., 0.0664, 0.0694, 0.0718]]]],
       device='cuda:0'), hidden_states=None, attentions=None)
```

`reconstruction`ã‚’å–å¾—ã—ã€ãã‚Œã‚’è¦–è¦šåŒ–ã™ã‚‹ãŸã‚ã«å¾Œå‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã©ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã‹è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
outputs.reconstruction.data.shape
# torch.Size([1, 3, 880, 1072])
```

å‡ºåŠ›ã‚’åœ§ç¸®ã—ã¦è»¸ 0 ã‚’å‰Šé™¤ã—ã€å€¤ã‚’ã‚¯ãƒªãƒƒãƒ—ã—ã¦ã‹ã‚‰ã€ãã‚Œã‚’ numpy float ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚æ¬¡ã«ã€è»¸ã‚’ [1072, 880] ã®å½¢çŠ¶ã«ãªã‚‹ã‚ˆã†ã«é…ç½®ã—ã€æœ€å¾Œã«å‡ºåŠ›ã‚’ç¯„å›² [0, 255] ã«æˆ»ã—ã¾ã™ã€‚

```python
import numpy as np

# squeeze, take to CPU and clip the values
output = outputs.reconstruction.data.squeeze().cpu().clamp_(0, 1).numpy()
# rearrange the axes
output = np.moveaxis(output, source=0, destination=-1)
# bring values back to pixel values range
output = (output * 255.0).round().astype(np.uint8)
Image.fromarray(output)
```
<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat_upscaled.png" alt="Upscaled photo of a cat"/>
</div>