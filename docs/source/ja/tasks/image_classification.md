<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->


# Image classification

[[open-in-colab]]

<Youtube id="tjAIM7BOYhw"/>

ç”»åƒåˆ†é¡ã§ã¯ã€ç”»åƒã«ãƒ©ãƒ™ãƒ«ã¾ãŸã¯ã‚¯ãƒ©ã‚¹ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚„éŸ³å£°ã®åˆ†é¡ã¨ã¯ç•°ãªã‚Šã€å…¥åŠ›ã¯
ç”»åƒã‚’æ§‹æˆã™ã‚‹ãƒ”ã‚¯ã‚»ãƒ«å€¤ã€‚æå‚·ã®æ¤œå‡ºãªã©ã€ç”»åƒåˆ†é¡ã«ã¯å¤šãã®ç”¨é€”ãŒã‚ã‚Šã¾ã™
è‡ªç„¶ç½å®³ã®å¾Œã€ä½œç‰©ã®å¥åº·çŠ¶æ…‹ã‚’ç›£è¦–ã—ãŸã‚Šã€ç—…æ°—ã®å…†å€™ãŒãªã„ã‹åŒ»ç™‚ç”»åƒã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã‚Šã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€æ¬¡ã®æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

1. [Food-101](https://huggingface.co/datasets/food101) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® [ViT](model_doc/vit) ã‚’å¾®èª¿æ•´ã—ã¦ã€ç”»åƒå†…ã®é£Ÿå“ã‚’åˆ†é¡ã—ã¾ã™ã€‚
2. å¾®èª¿æ•´ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã«ä½¿ç”¨ã—ã¾ã™ã€‚

<Tip>

ã“ã®ã‚¿ã‚¹ã‚¯ã¨äº’æ›æ€§ã®ã‚ã‚‹ã™ã¹ã¦ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€[ã‚¿ã‚¹ã‚¯ãƒšãƒ¼ã‚¸](https://huggingface.co/tasks/image-classification) ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

</Tip>

å§‹ã‚ã‚‹å‰ã«ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

```bash
pip install transformers datasets evaluate
```

Hugging Face ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## Load Food-101 dataset

Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å°ã•ã„ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¬¡ã®æ©Ÿä¼šãŒå¾—ã‚‰ã‚Œã¾ã™
å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã•ã‚‰ã«æ™‚é–“ã‚’è²»ã‚„ã™å‰ã«ã€å®Ÿé¨“ã—ã¦ã™ã¹ã¦ãŒæ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

```py
>>> from datasets import load_dataset

>>> food = load_dataset("food101", split="train[:5000]")
```

[`~datasets.Dataset.train_test_split`] ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® `train` åˆ†å‰²ã‚’ãƒˆãƒ¬ã‚¤ãƒ³ ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã«åˆ†å‰²ã—ã¾ã™ã€‚


```py
>>> food = food.train_test_split(test_size=0.2)
```

æ¬¡ã«ã€ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```py
>>> food["train"][0]
{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x7F52AFC8AC50>,
 'label': 79}
```

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®å„ä¾‹ã«ã¯ 2 ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚

- `image`: é£Ÿå“ã® PIL ç”»åƒ
- `label`: é£Ÿå“ã®ãƒ©ãƒ™ãƒ«ã‚¯ãƒ©ã‚¹

ãƒ¢ãƒ‡ãƒ«ãŒãƒ©ãƒ™ãƒ« ID ã‹ã‚‰ãƒ©ãƒ™ãƒ«åã‚’å–å¾—ã—ã‚„ã™ãã™ã‚‹ãŸã‚ã«ã€ãƒ©ãƒ™ãƒ«åã‚’ãƒãƒƒãƒ—ã™ã‚‹è¾æ›¸ã‚’ä½œæˆã—ã¾ã™ã€‚
æ•´æ•°ã¸ã®å¤‰æ›ã€ã¾ãŸã¯ãã®é€†:

```py
>>> labels = food["train"].features["label"].names
>>> label2id, id2label = dict(), dict()
>>> for i, label in enumerate(labels):
...     label2id[label] = str(i)
...     id2label[str(i)] = label
```

ã“ã‚Œã§ã€ãƒ©ãƒ™ãƒ« ID ã‚’ãƒ©ãƒ™ãƒ«åã«å¤‰æ›ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

```py
>>> id2label[str(79)]
'prime_rib'
```

## Preprocess

æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ViT ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å‡¦ç†ã—ã¾ã™ã€‚

```py
>>> from transformers import AutoImageProcessor

>>> checkpoint = "google/vit-base-patch16-224-in21k"
>>> image_processor = AutoImageProcessor.from_pretrained(checkpoint)
```


<frameworkcontent>
<pt>

ã„ãã¤ã‹ã®ç”»åƒå¤‰æ›ã‚’ç”»åƒã«é©ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®éå­¦ç¿’ã«å¯¾ã™ã‚‹å …ç‰¢æ€§ã‚’é«˜ã‚ã¾ã™ã€‚ã“ã“ã§ã¯ torchvision ã® [`transforms`](https://pytorch.org/vision/stable/transforms.html) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€ä»»æ„ã®ç”»åƒãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ç”»åƒã®ãƒ©ãƒ³ãƒ€ãƒ ãªéƒ¨åˆ†ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ã—ã€ã‚µã‚¤ã‚ºã‚’å¤‰æ›´ã—ã€ç”»åƒã®å¹³å‡ã¨æ¨™æº–åå·®ã§æ­£è¦åŒ–ã—ã¾ã™ã€‚


```py
>>> from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor

>>> normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )
>>> _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])
```

æ¬¡ã«ã€å¤‰æ›ã‚’é©ç”¨ã—ã€ç”»åƒã® `pixel_values` (ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›) ã‚’è¿”ã™å‰å‡¦ç†é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     del examples["image"]
...     return examples
```

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«å‰å‡¦ç†é–¢æ•°ã‚’é©ç”¨ã™ã‚‹ã«ã¯ã€ğŸ¤— Datasets [`~datasets.Dataset.with_transform`] ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚å¤‰æ›ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¦ç´ ã‚’èª­ã¿è¾¼ã‚€ã¨ãã«ã‚ªãƒ³ã‚¶ãƒ•ãƒ©ã‚¤ã§é©ç”¨ã•ã‚Œã¾ã™ã€‚

```py
>>> food = food.with_transform(transforms)
```

æ¬¡ã«ã€[`DefaultDataCollatâ€‹â€‹or`] ã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ä½œæˆã—ã¾ã™ã€‚ ğŸ¤— Transformers ã®ä»–ã®ãƒ‡ãƒ¼ã‚¿ç…§åˆå™¨ã¨ã¯ç•°ãªã‚Šã€`DefaultDataCollatâ€‹â€‹or` ã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®è¿½åŠ ã®å‰å‡¦ç†ã‚’é©ç”¨ã—ã¾ã›ã‚“ã€‚

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator()
```
</pt>
</frameworkcontent>


<frameworkcontent>
<tf>

éå‰°é©åˆã‚’å›é¿ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ˆã‚Šå …ç‰¢ã«ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°éƒ¨åˆ†ã«ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’è¿½åŠ ã—ã¾ã™ã€‚
ã“ã“ã§ã¯ã€Keras å‰å‡¦ç†ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ› (ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å«ã‚€) ã‚’å®šç¾©ã—ã¾ã™ã€‚
æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ› (ä¸­å¤®ã®ãƒˆãƒªãƒŸãƒ³ã‚°ã€ã‚µã‚¤ã‚ºå¤‰æ›´ã€æ­£è¦åŒ–ã®ã¿)ã€‚ `tf.image` ã¾ãŸã¯
ä»–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚


```py
>>> from tensorflow import keras
>>> from tensorflow.keras import layers

>>> size = (image_processor.size["height"], image_processor.size["width"])

>>> train_data_augmentation = keras.Sequential(
...     [
...         layers.RandomCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...         layers.RandomFlip("horizontal"),
...         layers.RandomRotation(factor=0.02),
...         layers.RandomZoom(height_factor=0.2, width_factor=0.2),
...     ],
...     name="train_data_augmentation",
... )

>>> val_data_augmentation = keras.Sequential(
...     [
...         layers.CenterCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...     ],
...     name="val_data_augmentation",
... )
```

æ¬¡ã«ã€ä¸€åº¦ã« 1 ã¤ã®ç”»åƒã§ã¯ãªãã€ç”»åƒã®ãƒãƒƒãƒã«é©åˆ‡ãªå¤‰æ›ã‚’é©ç”¨ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚

```py
>>> import numpy as np
>>> import tensorflow as tf
>>> from PIL import Image


>>> def convert_to_tf_tensor(image: Image):
...     np_image = np.array(image)
...     tf_image = tf.convert_to_tensor(np_image)
...     # `expand_dims()` is used to add a batch dimension since
...     # the TF augmentation layers operates on batched inputs.
...     return tf.expand_dims(tf_image, 0)


>>> def preprocess_train(example_batch):
...     """Apply train_transforms across a batch."""
...     images = [
...         train_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch


... def preprocess_val(example_batch):
...     """Apply val_transforms across a batch."""
...     images = [
...         val_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch
```

ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ [`~datasets.Dataset.set_transform`] ã‚’ä½¿ç”¨ã—ã¦ã€ãã®å ´ã§å¤‰æ›ã‚’é©ç”¨ã—ã¾ã™ã€‚

```py
food["train"].set_transform(preprocess_train)
food["test"].set_transform(preprocess_val)
```

æœ€å¾Œã®å‰å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€`DefaultDataCollatâ€‹â€‹or`ã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ä½œæˆã—ã¾ã™ã€‚ ğŸ¤— Transformers ã®ä»–ã®ãƒ‡ãƒ¼ã‚¿ç…§åˆæ©Ÿèƒ½ã¨ã¯ç•°ãªã‚Šã€
`DefaultDataCollatâ€‹â€‹or` ã¯ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®è¿½åŠ ã®å‰å‡¦ç†ã‚’é©ç”¨ã—ã¾ã›ã‚“ã€‚

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator(return_tensors="tf")
```
</tf>
</frameworkcontent>

## Evaluate

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å«ã‚ã‚‹ã¨ã€å¤šãã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚ã™ãã«ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™
ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸè©•ä¾¡æ–¹æ³•ã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã§ã¯ã€ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
[accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) æŒ‡æ¨™ (è©³ç´°ã«ã¤ã„ã¦ã¯ã€ğŸ¤— è©•ä¾¡ [ã‚¯ã‚¤ãƒƒã‚¯ ãƒ„ã‚¢ãƒ¼](https://huggingface.co/docs/evaluate/a_quick_tour) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¨ˆç®—ã™ã‚‹æ–¹æ³•):

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

æ¬¡ã«ã€äºˆæ¸¬ã¨ãƒ©ãƒ™ãƒ«ã‚’ [`~evaluate.EvaluationModule.compute`] ã«æ¸¡ã—ã¦ç²¾åº¦ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚

```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions, labels = eval_pred
...     predictions = np.argmax(predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=labels)
```

ã“ã‚Œã§ `compute_metrics`é–¢æ•°ã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¨­å®šã™ã‚‹ã¨ãã«ã“ã®é–¢æ•°ã«æˆ»ã‚Šã¾ã™ã€‚

## Train

<frameworkcontent>
<pt>
<Tip>

[`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã¡ã‚‰](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚

</Tip>

ã“ã‚Œã§ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ [`AutoModelForImageClassification`] ã‚’ä½¿ç”¨ã—ã¦ ViT ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ãƒ©ãƒ™ãƒ«ã®æ•°ã¨äºˆæƒ³ã•ã‚Œã‚‹ãƒ©ãƒ™ãƒ«ã®æ•°ã€ãŠã‚ˆã³ãƒ©ãƒ™ãƒ« ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æŒ‡å®šã—ã¾ã™ã€‚

```py
>>> from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

>>> model = AutoModelForImageClassification.from_pretrained(
...     checkpoint,
...     num_labels=len(labels),
...     id2label=id2label,
...     label2id=label2id,
... )
```

ã“ã®æ™‚ç‚¹ã§æ®‹ã£ã¦ã„ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã¯ 3 ã¤ã ã‘ã§ã™ã€‚

1. [`TrainingArguments`] ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã¾ã™ã€‚ `image` åˆ—ãŒå‰Šé™¤ã•ã‚Œã‚‹ãŸã‚ã€æœªä½¿ç”¨ã®åˆ—ã‚’å‰Šé™¤ã—ãªã„ã“ã¨ãŒé‡è¦ã§ã™ã€‚ `image` åˆ—ãŒãªã„ã¨ã€`pixel_values` ã‚’ä½œæˆã§ãã¾ã›ã‚“ã€‚ã“ã®å‹•ä½œã‚’é˜²ãã«ã¯ã€`remove_unused_columns=False`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ä»–ã«å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å ´æ‰€ã‚’æŒ‡å®šã™ã‚‹ `output_dir` ã ã‘ã§ã™ã€‚ `push_to_hub=True`ã‚’è¨­å®šã—ã¦ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€Hugging Face ã«ã‚µã‚¤ãƒ³ã‚¤ãƒ³ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™)ã€‚å„ã‚¨ãƒãƒƒã‚¯ã®çµ‚äº†æ™‚ã«ã€[`Trainer`] ã¯ç²¾åº¦ã‚’è©•ä¾¡ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ã—ã¾ã™ã€‚
2. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã‚’ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ç…§åˆå™¨ã€ãŠã‚ˆã³ `compute_metrics` é–¢æ•°ã¨ã¨ã‚‚ã« [`Trainer`] ã«æ¸¡ã—ã¾ã™ã€‚
3. [`~Trainer.train`] ã‚’å‘¼ã³å‡ºã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã¾ã™ã€‚

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_food_model",
...     remove_unused_columns=False,
...     eval_strategy="epoch",
...     save_strategy="epoch",
...     learning_rate=5e-5,
...     per_device_train_batch_size=16,
...     gradient_accumulation_steps=4,
...     per_device_eval_batch_size=16,
...     num_train_epochs=3,
...     warmup_ratio=0.1,
...     logging_steps=10,
...     load_best_model_at_end=True,
...     metric_for_best_model="accuracy",
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     data_collator=data_collator,
...     train_dataset=food["train"],
...     eval_dataset=food["test"],
...     tokenizer=image_processor,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ãŸã‚‰ã€ [`~transformers.Trainer.push_to_hub`] ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ–ã«å…±æœ‰ã—ã€èª°ã‚‚ãŒãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```py
>>> trainer.push_to_hub()
```
</pt>
</frameworkcontent>

<frameworkcontent>
<tf>

<Tip>


Keras ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã¾ãš [åŸºæœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](./training#train-a-tensorflow-model-with-keras) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

</Tip>


TensorFlow ã§ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã«ã¯ã€æ¬¡ã®æ‰‹é †ã«å¾“ã„ã¾ã™ã€‚
1. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¨å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚
2. äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ã€‚
3. ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ `tf.data.Dataset` ã«å¤‰æ›ã—ã¾ã™ã€‚
4. ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¾ã™ã€‚
5. ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿½åŠ ã—ã€`fit()` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
6. ãƒ¢ãƒ‡ãƒ«ã‚’ ğŸ¤— Hub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã—ã¾ã™ã€‚

ã¾ãšã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã€å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®šç¾©ã—ã¾ã™ã€‚

```py
>>> from transformers import create_optimizer

>>> batch_size = 16
>>> num_epochs = 5
>>> num_train_steps = len(food["train"]) * num_epochs
>>> learning_rate = 3e-5
>>> weight_decay_rate = 0.01

>>> optimizer, lr_schedule = create_optimizer(
...     init_lr=learning_rate,
...     num_train_steps=num_train_steps,
...     weight_decay_rate=weight_decay_rate,
...     num_warmup_steps=0,
... )
```

æ¬¡ã«ã€ãƒ©ãƒ™ãƒ« ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ã¨ã‚‚ã« [`TFAutoModelForImageClassification`] ã‚’ä½¿ç”¨ã—ã¦ ViT ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained(
...     checkpoint,
...     id2label=id2label,
...     label2id=label2id,
... )
```

Convert your datasets to the `tf.data.Dataset` format using the [`~datasets.Dataset.to_tf_dataset`] and your `data_collator`:

```py
>>> # converting our train dataset to tf.data.Dataset
>>> tf_train_dataset = food["train"].to_tf_dataset(
...     columns="pixel_values", label_cols="label", shuffle=True, batch_size=batch_size, collate_fn=data_collator
... )

>>> # converting our test dataset to tf.data.Dataset
>>> tf_eval_dataset = food["test"].to_tf_dataset(
...     columns="pixel_values", label_cols="label", shuffle=True, batch_size=batch_size, collate_fn=data_collator
... )
```

`compile()` ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚

```py
>>> from tensorflow.keras.losses import SparseCategoricalCrossentropy

>>> loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
>>> model.compile(optimizer=optimizer, loss=loss)
```

äºˆæ¸¬ã‹ã‚‰ç²¾åº¦ã‚’è¨ˆç®—ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ ğŸ¤— ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã«ã¯ã€[Keras callbacks](../main_classes/keras_callbacks) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
`compute_metrics` é–¢æ•°ã‚’ [KerasMetricCallback](../main_classes/keras_callbacks#transformers.KerasMetricCallback) ã«æ¸¡ã—ã¾ã™ã€‚
[PushToHubCallback](../main_classes/keras_callbacks#transformers.PushToHubCallback) ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```py
>>> from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback

>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)
>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="food_classifier",
...     tokenizer=image_processor,
...     save_strategy="no",
... )
>>> callbacks = [metric_callback, push_to_hub_callback]
```

ã¤ã„ã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã‚¨ãƒãƒƒã‚¯æ•°ã€
ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯:

```py
>>> model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)
Epoch 1/5
250/250 [==============================] - 313s 1s/step - loss: 2.5623 - val_loss: 1.4161 - accuracy: 0.9290
Epoch 2/5
250/250 [==============================] - 265s 1s/step - loss: 0.9181 - val_loss: 0.6808 - accuracy: 0.9690
Epoch 3/5
250/250 [==============================] - 252s 1s/step - loss: 0.3910 - val_loss: 0.4303 - accuracy: 0.9820
Epoch 4/5
250/250 [==============================] - 251s 1s/step - loss: 0.2028 - val_loss: 0.3191 - accuracy: 0.9900
Epoch 5/5
250/250 [==============================] - 238s 949ms/step - loss: 0.1232 - val_loss: 0.3259 - accuracy: 0.9890
```

ãŠã‚ã§ã¨ã†ï¼ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€ğŸ¤— Hub ã§å…±æœ‰ã—ã¾ã—ãŸã€‚ã“ã‚Œã§æ¨è«–ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
</tf>
</frameworkcontent>


<Tip>

ç”»åƒåˆ†é¡ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹æ–¹æ³•ã®è©³ç´°ãªä¾‹ã«ã¤ã„ã¦ã¯ã€å¯¾å¿œã™ã‚‹ [PyTorch ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)

</Tip>

## Inference

ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ãŸã®ã§ã€ãã‚Œã‚’æ¨è«–ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

æ¨è«–ã‚’å®Ÿè¡Œã—ãŸã„ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

```py
>>> ds = load_dataset("food101", split="validation[:10]")
>>> image = ds["image"][0]
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png" alt="image of beignets"/>
</div>

æ¨è«–ç”¨ã«å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•ã¯ã€ãã‚Œã‚’ [`pipeline`] ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç”»åƒåˆ†é¡ç”¨ã®`pipeline`ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã€ãã‚Œã«ç”»åƒã‚’æ¸¡ã—ã¾ã™ã€‚

```py
>>> from transformers import pipeline

>>> classifier = pipeline("image-classification", model="my_awesome_food_model")
>>> classifier(image)
[{'score': 0.31856709718704224, 'label': 'beignets'},
 {'score': 0.015232225880026817, 'label': 'bruschetta'},
 {'score': 0.01519392803311348, 'label': 'chicken_wings'},
 {'score': 0.013022331520915031, 'label': 'pork_chop'},
 {'score': 0.012728818692266941, 'label': 'prime_rib'}]
```

å¿…è¦ã«å¿œã˜ã¦ã€`pipeline`ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

<frameworkcontent>
<pt>

ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”»åƒã‚’å‰å‡¦ç†ã—ã€`input`ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

```py
>>> from transformers import AutoImageProcessor
>>> import torch

>>> image_processor = AutoImageProcessor.from_pretrained("my_awesome_food_model")
>>> inputs = image_processor(image, return_tensors="pt")
```

å…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ã€ãƒ­ã‚¸ãƒƒãƒˆã‚’è¿”ã—ã¾ã™ã€‚

```py
>>> from transformers import AutoModelForImageClassification

>>> model = AutoModelForImageClassification.from_pretrained("my_awesome_food_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

æœ€ã‚‚é«˜ã„ç¢ºç‡ã§äºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ã® `id2label` ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ãƒ©ãƒ™ãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚

```py
>>> predicted_label = logits.argmax(-1).item()
>>> model.config.id2label[predicted_label]
'beignets'
```
</pt>
</frameworkcontent>

<frameworkcontent>
<tf>

ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”»åƒã‚’å‰å‡¦ç†ã—ã€`input`ã‚’ TensorFlow ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("MariaK/food_classifier")
>>> inputs = image_processor(image, return_tensors="tf")
```

å…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ã€ãƒ­ã‚¸ãƒƒãƒˆã‚’è¿”ã—ã¾ã™ã€‚

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained("MariaK/food_classifier")
>>> logits = model(**inputs).logits
```

æœ€ã‚‚é«˜ã„ç¢ºç‡ã§äºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ã® `id2label` ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ãƒ©ãƒ™ãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚


```py
>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])
>>> model.config.id2label[predicted_class_id]
'beignets'
```

</tf>
</frameworkcontent>

