<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->
# Knowledge Distillation for Computer Vision

[[open-in-colab]]

çŸ¥è­˜ã®è’¸ç•™ã¯ã€ã‚ˆã‚Šå¤§è¦æ¨¡ã§è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ« (æ•™å¸«) ã‹ã‚‰ã‚ˆã‚Šå°è¦æ¨¡ã§å˜ç´”ãªãƒ¢ãƒ‡ãƒ« (ç”Ÿå¾’) ã«çŸ¥è­˜ã‚’ä¼é”ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹æ‰‹æ³•ã§ã™ã€‚ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã«çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹ã«ã¯ã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ (ã“ã®å ´åˆã¯ç”»åƒåˆ†é¡) ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€ç”»åƒåˆ†é¡ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã‚‹ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã—ã¾ã™ã€‚æ¬¡ã«ã€å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€ãã®å‡ºåŠ›ã¨æ•™å¸«ã®å‡ºåŠ›ã®å·®ã‚’æœ€å°é™ã«æŠ‘ãˆã€å‹•ä½œã‚’æ¨¡å€£ã—ã¾ã™ã€‚ã“ã‚Œã¯ [Distilling the Knowledge in a Neural Network by Hinton et al](https://arxiv.org/abs/1503.02531) ã§æœ€åˆã«å°å…¥ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®çŸ¥è­˜ã®è’¸ç•™ã‚’è¡Œã„ã¾ã™ã€‚ã“ã‚Œã«ã¯ [Beans ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://huggingface.co/datasets/beans) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€[å¾®èª¿æ•´ã•ã‚ŒãŸ ViT ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/merve/vit-mobilenet-beans-224) (æ•™å¸«ãƒ¢ãƒ‡ãƒ«) ã‚’æŠ½å‡ºã—ã¦ [MobileNet](https://huggingface.co/google/mobilenet_v2_1.4_224) (å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«) ğŸ¤— Transformers ã® [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

è’¸ç•™ã¨ãƒ—ãƒ­ã‚»ã‚¹ã®è©•ä¾¡ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ã‚‡ã†ã€‚

```bash
pip install transformers datasets accelerate tensorboard evaluate --upgrade
```

ã“ã®ä¾‹ã§ã¯ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦`merve/beans-vit-224`ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€Bean ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«åŸºã¥ã„ã¦å¾®èª¿æ•´ã•ã‚ŒãŸ`google/vit-base-patch16-224-in21k`ã«åŸºã¥ãç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚ŒãŸ MobileNetV2 ã«æŠ½å‡ºã—ã¾ã™ã€‚

æ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```python
from datasets import load_dataset

dataset = load_dataset("beans")
```

ã“ã®å ´åˆã€åŒã˜è§£åƒåº¦ã§åŒã˜å‡ºåŠ›ãŒè¿”ã•ã‚Œã‚‹ãŸã‚ã€ã©ã¡ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚ `dataset`ã®`map()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã™ã¹ã¦ã®åˆ†å‰²ã«å‰å‡¦ç†ã‚’é©ç”¨ã—ã¾ã™ã€‚

```python
from transformers import AutoImageProcessor
teacher_processor = AutoImageProcessor.from_pretrained("merve/beans-vit-224")

def process(examples):
    processed_inputs = teacher_processor(examples["image"])
    return processed_inputs

processed_datasets = dataset.map(process, batched=True)
```

åŸºæœ¬çš„ã«ã€æˆ‘ã€…ã¯ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚ŒãŸMobileNetï¼‰ãŒæ•™å¸«ãƒ¢ãƒ‡ãƒ«ï¼ˆå¾®èª¿æ•´ã•ã‚ŒãŸãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›å™¨ï¼‰ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã‚’æœ›ã‚€ã€‚ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã¾ãšæ•™å¸«ã¨ç”Ÿå¾’ã‹ã‚‰ãƒ­ã‚¸ãƒƒãƒˆå‡ºåŠ›ã‚’å¾—ã‚‹ã€‚æ¬¡ã«ã€ãã‚Œãã‚Œã®ã‚½ãƒ•ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é‡è¦åº¦ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿`temperature`ã§åˆ†å‰²ã™ã‚‹ã€‚`lambda`ã¨å‘¼ã°ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯è’¸ç•™ãƒ­ã‚¹ã®é‡è¦åº¦ã‚’é‡ã‚‹ã€‚ã“ã®ä¾‹ã§ã¯ã€`temperature=5`ã€`lambda=0.5`ã¨ã™ã‚‹ã€‚ç”Ÿå¾’ã¨æ•™å¸«ã®é–“ã®ç™ºæ•£ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«ã€Kullback-Leiblerç™ºæ•£æå¤±ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚2ã¤ã®ãƒ‡ãƒ¼ã‚¿Pã¨QãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯Qã‚’ä½¿ã£ã¦Pã‚’è¡¨ç¾ã™ã‚‹ãŸã‚ã«ã©ã‚Œã ã‘ã®ä½™åˆ†ãªæƒ…å ±ãŒå¿…è¦ã‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚ã‚‚ã—2ã¤ãŒåŒã˜ã§ã‚ã‚Œã°ã€Qã‹ã‚‰Pã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«å¿…è¦ãªä»–ã®æƒ…å ±ã¯ãªã„ã®ã§ã€ãã‚Œã‚‰ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ã‚¼ãƒ­ã«ãªã‚Šã¾ã™ã€‚


```python
from transformers import TrainingArguments, Trainer
import torch
import torch.nn as nn
import torch.nn.functional as F


class ImageDistilTrainer(Trainer):
    def __init__(self, *args, teacher_model=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.teacher = teacher_model
        self.student = student_model
        self.loss_function = nn.KLDivLoss(reduction="batchmean")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.teacher.to(device)
        self.teacher.eval()
        self.temperature = temperature
        self.lambda_param = lambda_param

    def compute_loss(self, student, inputs, return_outputs=False):
        student_output = self.student(**inputs)

        with torch.no_grad():
          teacher_output = self.teacher(**inputs)

        # Compute soft targets for teacher and student
        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)
        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)

        # Compute the loss
        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)

        # Compute the true label loss
        student_target_loss = student_output.loss

        # Calculate final loss
        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss
        return (loss, student_output) if return_outputs else loss
```

æ¬¡ã«ã€Hugging Face Hub ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã€`trainer`ã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ Hugging Face Hub ã«ãƒ—ãƒƒã‚·ãƒ¥ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```python
from huggingface_hub import notebook_login

notebook_login()
```

æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹`TrainingArguments`ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚

```python
from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification

training_args = TrainingArguments(
    output_dir="my-awesome-model",
    num_train_epochs=30,
    fp16=True,
    logging_dir=f"{repo_name}/logs",
    logging_strategy="epoch",
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="tensorboard",
    push_to_hub=True,
    hub_strategy="every_save",
    hub_model_id=repo_name,
    )

num_labels = len(processed_datasets["train"].features["labels"].names)

# initialize models
teacher_model = AutoModelForImageClassification.from_pretrained(
    "merve/beans-vit-224",
    num_labels=num_labels,
    ignore_mismatched_sizes=True
)

# training MobileNetV2 from scratch
student_config = MobileNetV2Config()
student_config.num_labels = num_labels
student_model = MobileNetV2ForImageClassification(student_config)
```

`compute_metrics` é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã§ãã¾ã™ã€‚ã“ã®é–¢æ•°ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«ãƒ¢ãƒ‡ãƒ«ã®`accuracy`ã¨`f1`ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

```python
import evaluate
import numpy as np

accuracy = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))
    return {"accuracy": acc["accuracy"]}
```

å®šç¾©ã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦`Trainer`ã‚’åˆæœŸåŒ–ã—ã¾ã—ã‚‡ã†ã€‚ãƒ‡ãƒ¼ã‚¿ç…§åˆè£…ç½®ã‚‚åˆæœŸåŒ–ã—ã¾ã™ã€‚


```python
from transformers import DefaultDataCollator

data_collator = DefaultDataCollator()
trainer = ImageDistilTrainer(
    student_model=student_model,
    teacher_model=teacher_model,
    training_args=training_args,
    train_dataset=processed_datasets["train"],
    eval_dataset=processed_datasets["validation"],
    data_collator=data_collator,
    processing_class=teacher_extractor,
    compute_metrics=compute_metrics,
    temperature=5,
    lambda_param=0.5
)
```

ã“ã‚Œã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

```python
trainer.train()
```

ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã§ãã¾ã™ã€‚


```python
trainer.evaluate(processed_datasets["test"])
```

ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã¯ 72% ã«é”ã—ã¾ã™ã€‚è’¸ç•™åŠ¹ç‡ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ãŸã‚ã«ã€åŒã˜ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ Bean ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ MobileNet ã‚’æœ€åˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã§ 63% ã®ç²¾åº¦ã‚’è¦³å¯Ÿã—ã¾ã—ãŸã€‚èª­è€…ã®çš†æ§˜ã«ã¯ã€ã•ã¾ã–ã¾ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã€å­¦ç”Ÿã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€è’¸ç•™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è©¦ã—ã¦ã„ãŸã ãã€ãã®çµæœã‚’å ±å‘Šã—ã¦ã„ãŸã ãã‚ˆã†ãŠå‹§ã‚ã—ã¾ã™ã€‚æŠ½å‡ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ­ã‚°ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ [ã“ã®ãƒªãƒã‚¸ãƒˆãƒª](https://huggingface.co/merve/vit-mobilenet-beans-224) ã«ã‚ã‚Šã€æœ€åˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ MobileNetV2 ã¯ã“ã® [ãƒªãƒã‚¸ãƒˆãƒª](https://huggingface.co/merve/resnet-mobilenet-beans-5)ã€‚
