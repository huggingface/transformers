# ุงูุชุตุฏูุฑ ุฅูู TorchScript

<Tip>

ูุฐู ูู ุจุฏุงูุฉ ุชุฌุงุฑุจูุง ูุน TorchScript ููุง ุฒููุง ูุณุชูุดู ูุฏุฑุงุชู ูุน ููุงุฐุฌ ุงููุฏุฎูุงุช ุงููุชุบูุฑุฉ ุงูุญุฌู. ุฅูู ูุฌุงู ุงูุชูุงููุง ูุณูุนูู ุชุญููููุง ูู ุงูุฅุตุฏุงุฑุงุช ุงููุงุฏูุฉุ ูุน ุงููุฒูุฏ ูู ุงูุฃูุซูุฉ ุงูุจุฑูุฌูุฉุ ูุชูููุฐ ุฃูุซุฑ ูุฑููุฉุ ูููุงููุณ ููุงุฑูุฉ ุจูู  ุงูุฃููุงุฏ ุงููุงุฆูุฉ ุนูู Python ูุน ุฃููุงุฏ TorchScript ุงูููุฌููุนุฉ.

</Tip>

ููููุง ูู [ูุซุงุฆู TorchScript](https://pytorch.org/docs/stable/jit.html):

> TorchScript ูู ุทุฑููุฉ ูุฅูุดุงุก ููุงุฐุฌ ูุงุจูุฉ ููุชุณูุณู ูุงูุชุญุณูู ูู ุชุนูููุงุช PyTorch ุงูุจุฑูุฌูุฉ.

ููุงู ูุญุฏุชุงู ูู PyTorchุ [JIT and TRACE](https://pytorch.org/docs/stable/jit.html)ุ ุชุชูุญุงู ูููุทูุฑูู ุชุตุฏูุฑ ููุงุฐุฌูู ูุฅุนุงุฏุฉ ุงุณุชุฎุฏุงููุง ูู ุจุฑุงูุฌ ุฃุฎุฑู ูุซู ุจุฑุงูุฌ C++ ุงูููุญุณููุฉ ููุฃุฏุงุก.

ููุฏู ูุงุฌูุฉ ุชุชูุญ ูู ุชุตุฏูุฑ ููุงุฐุฌ ๐ค Transformers ุฅูู TorchScript ุจุญูุซ ูููู ุฅุนุงุฏุฉ ุงุณุชุฎุฏุงููุง ูู ุจูุฆุฉ ูุฎุชููุฉ ุนู ุจุฑุงูุฌ Python ุงููุงุฆูุฉ ุฅูู PyTorch. ููุง ูุดุฑุญ ููููุฉ ุชุตุฏูุฑ ููุงุฐุฌูุง ูุงุณุชุฎุฏุงููุง ุจุงุณุชุฎุฏุงู TorchScript.

ูุชุทูุจ ุชุตุฏูุฑ ูููุฐุฌ ุฃูุฑูู:

- ุชููุฆุฉ ูุซูู ูููููุฐุฌ ุจุงุณุชุฎุฏุงู ุนูุงูุฉ `torchscript`
- ุชูุฑูุฑ ููุฏุฎูุงุช ููููุฉ (dummy inputs) ุฎูุงู ุงููููุฐุฌ

ุชูุทูู ูุฐู ุงูุถุฑูุฑุงุช ุนูู ุนุฏุฉ ุฃููุฑ ูุฌุจ ุนูู ุงููุทูุฑูู ุชูุฎู ุงูุญุฐุฑ ุจุดุฃููุง ููุง ูู ููุตู ุฃุฏูุงู.

## ุนูุงูุฉ TorchScript ูุงูุฃูุฒุงู ุงููุฑุชุจุทุฉ

ุนูุงูุฉ `torchscript` ุถุฑูุฑูุฉ ูุฃู ูุนุธู ููุงุฐุฌ ุงููุบุฉ ๐ค Transformers ููุง ุฃูุฒุงู ูุฑุชุจุทุฉ ุจูู ุทุจูุฉ `Embedding` ูุทุจูุฉ `Decoding`. ูุง ูุณูุญ ูู TorchScript ุจุชุตุฏูุฑ ุงูููุงุฐุฌ ุฐุงุช ุงูุฃูุฒุงู ุงููุฑุชุจุทุฉุ ูุฐูู ูู ุงูุถุฑูุฑู ูุตู ุงูุฃูุฒุงู ููุณุฎูุง ูุณุจููุง.

ุงูููุงุฐุฌ ุงูููููุฃุฉ ุจุงุณุชุฎุฏุงู ุนูุงูุฉ `torchscript` ููุง ุทุจูุฉ `Embedding` ูุทุจูุฉ`Decoding` ูููุตูุชููุ ููุง ูุนูู ุฃูู ูุง ููุจุบู ุชุฏุฑูุจูุง ูุงุญููุง. ุณูุคุฏู ุงูุชุฏุฑูุจ ุฅูู ุนุฏู ุชุฒุงูู ุงูุทุจูุชููุ ููุง ูุคุฏู ุฅูู ูุชุงุฆุฌ ุบูุฑ ูุชููุนุฉ.

ูุฐุง ูุง ููุทุจู ุนูู ุงูููุงุฐุฌ ุงูุชู ูุง ุชุญุชูู ุนูู ุฑุฃุณ ูููุฐุฌ ุงููุบุฉุ ุญูุซ ูุง ุชููู ุฃูุฒุงููุง ูุฑุชุจุทุฉ. ูููู ุชุตุฏูุฑ ูุฐู ุงูููุงุฐุฌ ุจุฃูุงู ุฏูู ุนูุงูุฉ `torchscript`.

## ุงููุฏุฎูุงุช ุงูููููุฉ ูุงูุฃุทูุงู ุงูููุงุณูุฉ

ุชูุณุชุฎุฏู ุงูููุฏุฎูุงุช ุงูููููุฉ ูุชูุฑูุฑ ุฃูุงูู ุฎูุงู ุงููููุฐุฌ. ุฃุซูุงุก ุงูุชุดุงุฑ ููู ุงูููุฏุฎูุงุช ุนุจุฑ ุงูุทุจูุงุชุ ูุชุชุจุน PyTorch ุงูุนูููุงุช ุงููุฎุชููุฉ ุงูุชู ูุชู ุชูููุฐูุง ุนูู ูู ูุตูููุฉ(tensor). ุซู ูุชู ุงุณุชุฎุฏุงู ูุฐู ุงูุนูููุงุช ุงูููุณุฌูุฉ ุจุนุฏ ุฐูู ูุฅูุดุงุก *ุฃุซุฑ* ุงููููุฐุฌ.

ูุชู ุฅูุดุงุก ุงูุชุชุจุน ุจุงููุณุจุฉ ูุฃุจุนุงุฏ ุงูููุฏุฎูุงุช. ูุจุงูุชุงููุ ููู ูููููุฏ ุจุฃุจุนุงุฏ ุงูููุฏุฎูุงุช ุงูููููุฉุ ููู ูุนูู ูุฃู ุทูู ุชุณูุณู ุฃู ุญุฌู ุฏูุนุฉ ูุฎุชูู. ุนูุฏ ุงููุญุงููุฉ ุจุญุฌู ูุฎุชููุ ูุชู ุฑูุน ุงูุฎุทุฃ ุงูุชุงูู:

```
`The expanded size of the tensor (3) must match the existing size (7) at non-singleton dimension 2`
```

ููุตู ุจุชุชุจุน ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู ุญุฌู ููุฏุฎูุงุช ููููุฉ ูุง ููู ุนู ุฃูุจุฑ ููุฏุฎู ุณูุชู ุชูุฏููู ูููููุฐุฌ ุฃุซูุงุก ุงูุงุณุชุฏูุงู. ูููู ุฃู ุชุณุงุนุฏ ุงูุญุดูุฉ(padding) ูู ููุก ุงูููู ุงูููููุฏุฉ. ููุน ุฐููุ ูุธุฑูุง ูุชุชุจุน ุงููููุฐุฌ ุจุญุฌู ููุฏุฎู ุฃูุจุฑุ ุณุชููู ุฃุจุนุงุฏ ุงููุตูููุฉ ุณุชููู ูุจูุฑุฉ ุฃูุถูุงุ ููุง ูุคุฏู ุนูู ุงููุฒูุฏ ูู ุงูุญุณุงุจุงุช.

ุงูุชุจู ุฅูู ุฅุฌูุงูู ุนุฏุฏ ุงูุนูููุงุช ุงูููููุฐุฉ ุนูู ูู ููุฏุฎู ูุชุงุจุน ุงูุฃุฏุงุก ุนู ูุซุจ ุนูุฏ ุชุตุฏูุฑ ููุงุฐุฌ ูุชุบูุฑุฉ ุทูู ุงูุชุณูุณู.

## ุงุณุชุฎุฏุงู TorchScript ูู Python

ููุถุญ ูุฐุง ุงููุณู ููููุฉ ุญูุธ ุงูููุงุฐุฌ ูุชุญููููุงุ ุจุงูุฅุถุงูุฉ ุฅูู ููููุฉ ุงุณุชุฎุฏุงู ุงูุชุชุจุน ููุงุณุชุฏูุงู.

### ุญูุธ ูููุฐุฌ

ูุชุตุฏูุฑ `BertModel` ุจุงุณุชุฎุฏุงู TorchScriptุ ูู ุจุชููุฆุฉ ู `BertModel` ูู ูุฆุฉ `BertConfig` ุซู ุงุญูุธู ุนูู ุงููุฑุต ุชุญุช ุงุณู ุงูููู `traced_bert.pt`:

```python
from transformers import BertModel, BertTokenizer, BertConfig
import torch

enc = BertTokenizer.from_pretrained("google-bert/bert-base-uncased")

# Tokenizing input text
text = "[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]"
tokenized_text = enc.tokenize(text)

# Masking one of the input tokens
masked_index = 8
tokenized_text[masked_index] = "[MASK]"
indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)
segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]

# Creating a dummy input
tokens_tensor = torch.tensor([indexed_tokens])
segments_tensors = torch.tensor([segments_ids])
dummy_input = [tokens_tensor, segments_tensors]

# Initializing the model with the torchscript flag
# Flag set to True even though it is not necessary as this model does not have an LM Head.
config = BertConfig(
    vocab_size_or_config_json_file=32000,
    hidden_size=768,
    num_hidden_layers=12,
    num_attention_heads=12,
    intermediate_size=3072,
    torchscript=True,
)

# Instantiating the model
model = BertModel(config)

# The model needs to be in evaluation mode
model.eval()

# If you are instantiating the model with *from_pretrained* you can also easily set the TorchScript flag
model = BertModel.from_pretrained("google-bert/bert-base-uncased", torchscript=True)

# Creating the trace
traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])
torch.jit.save(traced_model, "traced_bert.pt")
```

### ุชุญููู ูููุฐุฌ

ููููู ุงูุขู ุชุญููู `BertModel` ุงูููุญูุธ ุณุงุจููุงุ `traced_bert.pt`ุ ูู ุงููุฑุต ูุงุณุชุฎุฏุงูู ุนูู `dummy_input` ุงูููููุฃ ุณุงุจููุง:

```python
loaded_model = torch.jit.load("traced_bert.pt")
loaded_model.eval()

all_encoder_layers, pooled_output = loaded_model(*dummy_input)
```

### ุงุณุชุฎุฏุงู ูููุฐุฌ ููุชุชุจุน ููุงุณุชุฏูุงู

ุงุณุชุฎุฏู ุงููููุฐุฌ ุงูููุชุชุจุน ููุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู ุฃุณููุจ `__call__` ุงูุฎุงุต ุจู:

```python
traced_model(tokens_tensor, segments_tensors)
```

## ูุดุฑ ููุงุฐุฌ Hugging Face TorchScript ุนูู AWS ุจุงุณุชุฎุฏุงู Neuron SDK

ูุฏูุช AWS ุนุงุฆูุฉ [Amazon EC2 Inf1](https://aws.amazon.com/ec2/instance-types/inf1/) ูู ุง๏ปทุฌูุฒุฉ ูุฎูุถ ุงูุชูููุฉ ูุฃุฏุงุก ุงูุชุนูู ุงูุขูู ุนุงูู ุงูุฃุฏุงุก ูู ุงูุจูุฆุฉ ุงูุณุญุงุจูุฉ. ุชุนูู ุฃุฌูุฒุฉ Inf1 ุจูุงุณุทุฉ ุดุฑูุญุฉ Inferentia ูู AWSุ ููู ููุณุฑูุน ุฃุฌูุฒุฉ ููุฎุตุตุ ูุชุฎุตุต ูู ุฃุนุจุงุก ุนูู ุงูุงุณุชุฏูุงู ููุชุนูู ุงูุนููู. [AWS Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/#) ูู SDK ูู Inferentia ุงูุชู ุชุฏุนู ุชุชุจุน ููุงุฐุฌ ุงููุญููุงุช ูุชุญุณูููุง ูููุดุฑ ุนูู Inf1. ุชููุฑ Neuron SDK ูุง ููู:

1. ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช ุณููุฉ ุงูุงุณุชุฎุฏุงู ูุน ุชุบููุฑ ุณุทุฑ ูุงุญุฏ ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูุชุชุจุน ูููุฐุฌ TorchScript ูุชุญุณููู ููุงุณุชุฏูุงู ูู ุงูุจูุฆุฉ ุงูุณุญุงุจูุฉ.
2. ุชุญุณููุงุช ุงูุฃุฏุงุก ุงูุฌุงูุฒุฉ ููุงุณุชุฎุฏุงู [ุชุญุณูู ุงูุชูููุฉ ูุงูุฃุฏุงุก](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/benchmark/>).
3. ุฏุนู ููุงุฐุฌ Hugging Face ุงููุญููุงุช ุงููุจููุฉ ุจุงุณุชุฎุฏุงู ุฅูุง [PyTorch](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.html) ุฃู [TensorFlow](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/tensorflow/huggingface_bert/huggingface_bert.html).

### ุงูุขุซุงุฑ ุงููุชุฑุชุจุฉ

ุชุนูู ููุงุฐุฌ ุงููุญููุงุช ุงููุณุชูุฏุฉ ุฅูู ุจููุฉ [BERT (ุชูุซููุงุช ุงูุชุฑููุฒ ุซูุงุฆูุฉ ุงูุงุชุฌุงู ูู ุงููุญููุงุช)](https://huggingface.co/docs/transformers/main/model_doc/bert) ุฃู ูุชุบูุฑุงุชูุง ูุซู [distilBERT](https://huggingface.co/docs/transformers/main/model_doc/distilbert) ู [roBERTa](https://huggingface.co/docs/transformers/main/model_doc/roberta) ุจุดูู ุฃูุถู ุนูู Inf1 ููููุงู ุบูุฑ ุงูุชูููุฏูุฉ ูุซู ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูุงุณุชุฎุฑุงุฌูุฉุ ูุชุตููู ุงูุชุณูุณูุงุชุ ูุชุตููู ุงูุฑููุฒ (tokens). ููุน ุฐููุ ูููู ุชูููู ููุงู ุชูููุฏ ุงููุตูุต ููุนูู ุนูู Inf1 ููููุง ููุฐุง [ุจุฑูุงูุฌ ุชุนูููู AWS Neuron MarianMT](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/transformers-marianmt.html). ูููู ุงูุนุซูุฑ ุนูู ูุฒูุฏ ูู ุงููุนูููุงุช ุญูู ุงูููุงุฐุฌ ุงูุชู ูููู ุชุญููููุง ุฌุงูุฒุฉ ุนูู Inferentia ูู ูุณู [ููุงุกูุฉ ุจููุฉ ุงููููุฐุฌ](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/models/models-inferentia.html#models-inferentia) ูู ูุซุงุฆู Neuron.

### ุงูุชุจุนูุงุช (Dependencies)

ูุชุทูุจ ุงุณุชุฎุฏุงู AWS Neuron ูุชุญููู ุงูููุงุฐุฌ [ุจูุฆุฉ SDK Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/pytorch-neuron/index.html#installation-guide) ูุงูุชู ุชุฃุชู ูุณุจููุง ุนูู [AMI ููุชุนูู ุงูุนููู ูู AWS](https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-inferentia-launching.html).

### ุชุญููู ูููุฐุฌ ูู AWS Neuron

ูู ุจุชุญููู ูููุฐุฌ ูู AWS NEURON ุจุงุณุชุฎุฏุงู ููุณ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูู [ุงุณุชุฎุฏุงู TorchScript ูู Python](torchscript#using-torchscript-in-python) ูุชุชุจุน `BertModel`. ูู ุจุงุณุชูุฑุงุฏ ุงูุชุฏุงุฏ ุฅุทุงุฑ ุนูู `torch.neuron` ูููุตูู ุฅูู ููููุงุช Neuron SDK ูู ุฎูุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช Python:

```python
from transformers import BertModel, BertTokenizer, BertConfig
import torch
import torch.neuron
```

ูู ูุง ุนููู ูุนูู ูู ุชุนุฏูู ุงูุณุทุฑ ุงูุชุงูู:

```diff
- torch.jit.trace(model, [tokens_tensor, segments_tensors])
+ torch.neuron.trace(model, [token_tensor, segments_tensors])
```

ูุชูุญ ุฐูู ูู Neuron SDK ุชุชุจุน ุงููููุฐุฌ ูุชุญุณููู ููุซููุงุช Inf1.

ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ููุฒุงุช AWS Neuron SDK ูุงูุฃุฏูุงุช ูุฏุฑูุณ ุงูุจุฑุงูุฌ ุงูุชุนููููุฉ ูุงูุชุญุฏูุซุงุช ุงูุฃุฎูุฑุฉุ ูุฑุฌู ุงูุงุทูุงุน ุนูู [ูุซุงุฆู AWS NeuronSDK](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html).
