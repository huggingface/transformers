<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->
# ØªÙ‚Ø·ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù„Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©

[[open-in-colab]]

ØªÙ‚Ø·ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù‡Ùˆ ØªÙ‚Ù†ÙŠØ© Ù„Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¨ÙŠØ± ÙˆÙ…Ø¹Ù‚Ø¯ (Ø§Ù„Ù…ÙØ¹Ù„Ù‘ÙÙ…) Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ø£ØµØºØ± ÙˆØ£Ø¨Ø³Ø· (Ø§Ù„Ø·Ø§Ù„Ø¨). Ù„Ø¹Ù…Ù„ Ø§Ù„ØªÙ‚Ø·ÙŠØ±ØŒ Ù†Ø£Ø®Ø° Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¹Ù„Ù‘ÙÙ… Ù…ÙØ¯Ø±Ù‘ÙØ¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø© Ù…Ø¹ÙŠÙ†Ø© (ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„) ÙˆÙ†Ù‡ÙŠÙ‘Ø¦ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø·Ø§Ù„Ø¨ Ù„ØªØ¯Ø±ÙŠØ¨Ù‡ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ù…Ù‡Ù…Ø©. Ø«Ù… Ù†Ø¯Ø±Ù‘ÙØ¨ Ø§Ù„Ø·Ø§Ù„Ø¨ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ÙØ§Ø±Ù‚ Ø¨ÙŠÙ† Ù…Ø®Ø±Ø¬Ø§ØªÙ‡ ÙˆÙ…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ÙØ¹Ù„Ù‘ÙÙ…ØŒ Ø¨Ø­ÙŠØ« ÙŠÙØ­Ø§ÙƒÙŠ Ø³Ù„ÙˆÙƒÙ‡. Ø·ÙØ±Ø­Øª Ù‡Ø°Ù‡ Ø§Ù„ÙÙƒØ±Ø© Ù„Ø£ÙˆÙ„ Ù…Ø±Ø© ÙÙŠ [Distilling the Knowledge in a Neural Network by Hinton et al](https://huggingface.co/papers/1503.02531). ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø³Ù†Ù‚ÙˆÙ… Ø¨ØªÙ‚Ø·ÙŠØ± Ù…Ø¹Ø±ÙØ© Ù…Ø®ØµØµ Ù„Ù„Ù…Ù‡Ù…Ø©. Ø³Ù†Ø³ØªØ®Ø¯Ù… [Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§ØµÙˆÙ„ÙŠØ§](https://huggingface.co/datasets/beans).

ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ© ØªÙ‚Ø·ÙŠØ± [Ù†Ù…ÙˆØ°Ø¬ ViT Ù…ÙØ­Ø³Ù‘ÙÙ†](https://huggingface.co/merve/vit-mobilenet-beans-224) (Ù…ÙØ¹Ù„Ù‘ÙÙ…) Ø¥Ù„Ù‰ [MobileNet](https://huggingface.co/google/mobilenet_v2_1.4_224) (Ø·Ø§Ù„Ø¨) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer) Ù…Ù† ğŸ¤— Transformers.

Ù„Ù†Ø«Ø¨Ù‘Øª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ù„ØªÙ‚Ø·ÙŠØ± ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.

```bash
pip install transformers datasets accelerate tensorboard evaluate --upgrade
```

ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ `merve/beans-vit-224` ÙƒÙ†Ù…ÙˆØ°Ø¬ Ù…ÙØ¹Ù„Ù‘ÙÙ…. Ø¥Ù†Ù‡ Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ `google/vit-base-patch16-224-in21k` ÙˆÙ…ÙØ­Ø³Ù‘Ù† Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§ØµÙˆÙ„ÙŠØ§. Ø³Ù†Ù‚Ø·Ù‘Ø± Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ MobileNetV2 Ù…ÙÙ‡ÙŠÙ‘Ø£ Ù…Ù† Ø§Ù„ØµÙØ±.

Ø§Ù„Ø¢Ù† Ø³Ù†Ø­Ù…Ù‘Ù„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

```python
from datasets import load_dataset

dataset = load_dataset("beans")
```

ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± (image processor) Ù„Ø£Ø­Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†ØŒ Ø¥Ø° Ø£Ù†Ù‡Ù…Ø§ ÙŠØ¹ÙŠØ¯Ø§Ù† Ù†ÙØ³ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ù…Ø¹ Ù†ÙØ³ Ø§Ù„Ø¯Ù‚Ø©. Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¯Ø§Ù„Ø© `map()` Ù…Ù† `dataset` Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡.

```python
from transformers import AutoImageProcessor
teacher_processor = AutoImageProcessor.from_pretrained("merve/beans-vit-224")

def process(examples):
    processed_inputs = teacher_processor(examples["image"])
    return processed_inputs

processed_datasets = dataset.map(process, batched=True)
```

Ø¨Ø§Ù„Ù…Ø­ØµÙ„Ø©ØŒ Ù†Ø±ÙŠØ¯ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø·Ø§Ù„Ø¨ (MobileNet Ù…ÙÙ‡ÙŠÙ‘Ø£ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§) Ø£Ù† ÙŠÙØ­Ø§ÙƒÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¹Ù„Ù‘ÙÙ… (Vision Transformer Ù…ÙØ­Ø³Ù‘ÙÙ†). Ù„ØªØ­Ù‚ÙŠÙ‚ Ø°Ù„ÙƒØŒ Ù†Ø­ØµÙ„ Ø£ÙˆÙ„Ù‹Ø§ Ø¹Ù„Ù‰ Ù„ÙˆØ¬ÙØªØ³ (logits) Ø§Ù„Ù…ÙØ¹Ù„Ù‘ÙÙ… ÙˆØ§Ù„Ø·Ø§Ù„Ø¨ØŒ Ø«Ù… Ù†Ù‚Ø³Ù… ÙƒÙ„Ù‹Ø§ Ù…Ù†Ù‡Ù…Ø§ Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù…Ù„ `temperature` Ø§Ù„Ø°ÙŠ ÙŠØªØ­ÙƒÙ… Ø¨Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ù„ÙŠÙ†Ø©. ÙƒÙ…Ø§ Ù†Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø§Ù…Ù„Ù‹Ø§ ÙŠÙØ¯Ø¹Ù‰ `lambda` Ù„ÙˆØ²Ù† Ø£Ù‡Ù…ÙŠØ© Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªÙ‚Ø·ÙŠØ±. ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„ Ø³Ù†Ø³ØªØ®Ø¯Ù… `temperature=5` Ùˆ`lambda=0.5`. Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø®Ø³Ø§Ø±Ø© ØªØ¨Ø§Ø¹Ø¯ ÙƒÙˆÙ„Ø¨Ø§Ùƒ-Ù„Ø§ÙŠØ¨Ù„Ø± (KL Divergence) Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„ØªØ¨Ø§Ø¹Ø¯ Ø¨ÙŠÙ† Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆØ§Ù„Ù…ÙØ¹Ù„Ù‘ÙÙ…. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Ù† Ù…ØªØ·Ø§Ø¨Ù‚ÙŠÙ† ÙØ³ÙŠÙƒÙˆÙ† Ø§Ù„ØªØ¨Ø§Ø¹Ø¯ ØµÙØ±Ù‹Ø§. Ù„Ø°Ø§ ÙÙ‡Ùˆ Ù…Ù†Ø§Ø³Ø¨ Ù„ØªÙ‚Ø·ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ©.

```python
from transformers import TrainingArguments, Trainer
import torch
import torch.nn as nn
import torch.nn.functional as F
from accelerate.test_utils.testing import get_backend

class ImageDistilTrainer(Trainer):
    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None,  *args, **kwargs):
        super().__init__(model=student_model, *args, **kwargs)
        self.teacher = teacher_model
        self.student = student_model
        self.loss_function = nn.KLDivLoss(reduction="batchmean")
        device, _, _ = get_backend() # automatically detects the underlying device type (CUDA, CPU, XPU, MPS, etc.)
        self.teacher.to(device)
        self.teacher.eval()
        self.temperature = temperature
        self.lambda_param = lambda_param

    def compute_loss(self, student, inputs, return_outputs=False):
        student_output = self.student(**inputs)

        with torch.no_grad():
          teacher_output = self.teacher(**inputs)

        # Compute soft targets for teacher and student
        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)
        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)

        # Compute the loss
        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)

        # Compute the true label loss
        student_target_loss = student_output.loss

        # Calculate final loss
        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss
        return (loss, student_output) if return_outputs else loss
```

Ø³Ù†Ù‚ÙˆÙ… Ø§Ù„Ø¢Ù† Ø¨ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Hugging Face Hub ÙƒÙŠ Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø¯ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø¨Ø± `Trainer`.

```python
from huggingface_hub import notebook_login

notebook_login()
```

Ù„Ù†ÙØ¹Ø¯Ù‘ `TrainingArguments` ÙˆÙ†Ø­Ø¯Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¹Ù„Ù‘ÙÙ… ÙˆÙ†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø·Ø§Ù„Ø¨.

```python
from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification

training_args = TrainingArguments(
    output_dir="my-awesome-model",
    num_train_epochs=30,
    fp16=True,
    logging_dir=f"{repo_name}/logs",
    logging_strategy="epoch",
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="tensorboard",
    push_to_hub=True,
    hub_strategy="every_save",
    hub_model_id=repo_name,
    )

num_labels = len(processed_datasets["train"].features["labels"].names)

# initialize models
teacher_model = AutoModelForImageClassification.from_pretrained(
    "merve/beans-vit-224",
    num_labels=num_labels,
    ignore_mismatched_sizes=True
)

# training MobileNetV2 from scratch
student_config = MobileNetV2Config()
student_config.num_labels = num_labels
student_model = MobileNetV2ForImageClassification(student_config)
```

ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© `compute_metrics` Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±. Ø³ØªØ­Ø³Ø¨ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© `accuracy` Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

```python
import evaluate
import numpy as np

accuracy = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))
    return {"accuracy": acc["accuracy"]}
```

Ù„Ù†ÙÙ‡ÙŠÙ‘Ø¦ `Trainer` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙŠ Ø¹Ø±ÙÙ†Ø§Ù‡Ø§ØŒ ÙˆÙƒØ°Ù„Ùƒ Ø§Ù„Ù…ÙØ¬Ù…Ù‘ÙØ¹ (data collator).

```python
from transformers import DefaultDataCollator

data_collator = DefaultDataCollator()
trainer = ImageDistilTrainer(
    student_model=student_model,
    teacher_model=teacher_model,
    training_args=training_args,
    train_dataset=processed_datasets["train"],
    eval_dataset=processed_datasets["validation"],
    data_collator=data_collator,
    processing_class=teacher_processor,
    compute_metrics=compute_metrics,
    temperature=5,
    lambda_param=0.5
)
```

ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ø¢Ù† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.

```python
trainer.train()
```

ÙˆÙŠÙ…ÙƒÙ†Ù†Ø§ ØªÙ‚ÙŠÙŠÙ…Ù‡ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.

```python
trainer.evaluate(processed_datasets["test"])
```

Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø­Ù‚Ù‚ Ù†Ù…ÙˆØ°Ø¬Ù†Ø§ Ø¯Ù‚Ø© ØªØ¨Ù„Øº Ùª72. ÙˆÙ„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„ØªÙ‚Ø·ÙŠØ±ØŒ Ù‚Ù…Ù†Ø§ Ø£ÙŠØ¶Ù‹Ø§ Ø¨ØªØ¯Ø±ÙŠØ¨ MobileNet Ù…Ù† Ø§Ù„ØµÙØ± Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¨Ù†ÙØ³ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ„Ø§Ø­Ø¸Ù†Ø§ Ø¯Ù‚Ø© Ù‚Ø¯Ø±Ù‡Ø§ Ùª63. Ù†Ø¯Ø¹Ùˆ Ø§Ù„Ù‚ÙØ±Ù‘Ø§Ø¡ Ù„ØªØ¬Ø±Ø¨Ø© Ù†Ù…Ø§Ø°Ø¬ Ù…ÙØ¹Ù„Ù‘ÙÙ… Ù…Ø®ØªÙ„ÙØ© ÙˆØ¨ÙÙ†Ù‰ Ø·Ù„Ø§Ø¨ Ù…ØªÙ†ÙˆØ¹Ø© ÙˆÙ…Ø¹Ø§Ù…Ù„Ø§Øª ØªÙ‚Ø·ÙŠØ± Ù…Ø®ØªÙ„ÙØ© ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬. Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆÙ†Ù‚Ø§Ø· Ø§Ù„Ø­ÙØ¸ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù‚Ø·Ù‘ÙØ± Ù…ØªØ§Ø­Ø© ÙÙŠ [Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹](https://huggingface.co/merve/vit-mobilenet-beans-224)ØŒ ÙˆMobileNetV2 Ø§Ù„Ù…Ø¯Ø±Ù‘ÙØ¨ Ù…Ù† Ø§Ù„ØµÙØ± ÙÙŠ [Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹](https://huggingface.co/merve/resnet-mobilenet-beans-5).
