<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

โ๏ธ Note that this file is in Markdown but contains specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ุชุตููู ุงูุตูุช (Audio Classification)

[[open-in-colab]]

<Youtube id="KWwzcmG98Ds"/>

ุชุตููู ุงูุตูุช โ ุชูุงููุง ูุซู ุงููุต โ ููุณูุฏ ุชุณููุฉ ูุฆููุฉ (class label) ูููุฎุฑุฌ ุงูุทูุงููุง ูู ุจูุงูุงุช ุงูุฅุฏุฎุงู. ุงููุงุฑู ุงููุญูุฏ ูู ุฃูู ุจุฏููุง ูู ููุฏุฎูุงุช ูุตูุฉุ ูุฏูู ุฃุดูุงู ููุฌูุฉ ุตูุชูุฉ ุฎุงู. ูู ุงูุชุทุจููุงุช ุงูุนูููุฉ ูุชุตููู ุงูุตูุช: ุชุญุฏูุฏ ููุฉ ุงููุชุญุฏุซุ ูุชุตููู ุงููุบุฉุ ูุญุชู ุชูููุฒ ุฃููุงุน ุงูุญููุงูุงุช ูู ุฎูุงู ุฃุตูุงุชูุง.

ุณููุฑุดุฏู ูุฐุง ุงูุฏููู ุฅูู ููููุฉ:

1. ุฅุฌุฑุงุก ุถุจุท ุฏููู (fine-tuning) ูู [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูุชุตููู ููุฉ ุงููุชุญุฏุซ.
2. ุงุณุชุฎุฏุงู ูููุฐุฌู ุงููุถุจูุท ููุงุณุชุฏูุงู (inference).

<Tip>

ููุนุฑูุฉ ุฌููุน ุงูุจููู ูููุงุท ุงูุชุญูู ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุงุทูุงุน ุนูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/audio-classification).

</Tip>

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install transformers datasets evaluate
```

ููุตูู ุจุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจู ุนูู Hugging Face ุญุชู ุชุชููู ูู ุฑูุน ูููุฐุฌู ููุดุงุฑูุชู ูุน ุงููุฌุชูุน. ุนูุฏ ุงููุทุงูุจุฉุ ุฃุฏุฎู ุงูุฑูุฒ ุงููููุฒ ูุชุณุฌูู ุงูุฏุฎูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช MInDS-14

ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช MInDS-14 ูู ููุชุจุฉ ๐ค Datasets:

```py
>>> from datasets import load_dataset, Audio

>>> minds = load_dataset("PolyAI/minds14", name="en-US", split="train")
```

ูุณูู ุฌุฒุก `train` ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ูุฌููุนุฉ ุชุฏุฑูุจ ูุงุฎุชุจุงุฑ ุฃุตุบุฑ ุจุงุณุชุฎุฏุงู ุงูุทุฑููุฉ [`~datasets.Dataset.train_test_split`]. ุณูููุญู ูุฐุง ูุฑุตุฉ ููุชุฌุฑุจุฉ ูุงูุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุนูู ูุจู ูุถุงุก ุงููุฒูุฏ ูู ุงูููุช ุนูู ุงููุฌููุนุฉ ุงููุงููุฉ.

```py
>>> minds = minds.train_test_split(test_size=0.2)
```

ุซู ุฃููู ูุธุฑุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> minds
DatasetDict({
    train: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 450
    })
    test: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 113
    })
})
```

ุจูููุง ุชุญุชูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุนูู ุงููุซูุฑ ูู ุงููุนูููุงุช ุงููููุฏุฉุ ูุซู `lang_id` ู`english_transcription`ุ ุณุชุฑููุฒ ูู ูุฐุง ุงูุฏููู ุนูู `audio` ู`intent_class`. ุฃุฒูู ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู ุจุงุณุชุฎุฏุงู ุงูุทุฑููุฉ [`~datasets.Dataset.remove_columns`]:

```py
>>> minds = minds.remove_columns(["path", "transcription", "english_transcription", "lang_id"])
```

ุฅููู ูุซุงููุง:

```py
>>> minds["train"][0]
{'audio': {'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,
         -0.00024414, -0.00024414], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',
  'sampling_rate': 8000},
 'intent_class': 2}
```

ููุงู ุญููุงู:

- `audio`: ูุตูููุฉ ุฃุญุงุฏูุฉ ุงูุจูุนุฏ `array` ููุฅุดุงุฑุฉ ุงูุตูุชูุฉ ูุฌุจ ุงุณุชุฏุนุงุคูุง ูุชุญููู ููู ุงูุตูุช ูุฅุนุงุฏุฉ ุชุดููู ูุนุฏู ุงูุนูููุฉ.
- `intent_class`: ููุซูู ูุนุฑูู ุงููุฆุฉ (class id) ุงูุฎุงุต ุจูููุฉ ุงููุชุญุฏุซ.

ูุชุณููู ุญุตูู ุงููููุฐุฌ ุนูู ุงุณู ุงูุชุณููุฉ (label name) ูู ูุนุฑูู ุงูุชุณููุฉ (label id)ุ ุฃูุดุฆ ูุงููุณูุง ูุฑุจุท ุงุณู ุงูุชุณููุฉ ุจุนุฏุฏ ุตุญูุญ ูุงูุนูุณ ุตุญูุญ:

```py
>>> labels = minds["train"].features["intent_class"].names
>>> label2id, id2label = dict(), dict()
>>> for i, label in enumerate(labels):
...     label2id[label] = str(i)
...     id2label[str(i)] = label
```

ููููู ุงูุขู ุชุญููู ูุนุฑูู ุงูุชุณููุฉ ุฅูู ุงุณู ุงูุชุณููุฉ:

```py
>>> id2label[str(2)]
'app_error'
```

## ุงููุนุงูุฌุฉ ุงููุณุจูุฉ (Preprocess)

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุณุชุฎุฑุฌ ุงูุฎุตุงุฆุต (feature extractor) ุงูุฎุงุต ุจู Wav2Vec2 ููุนุงูุฌุฉ ุงูุฅุดุงุฑุฉ ุงูุตูุชูุฉ:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

ุชููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ูุนุฏู ุนูููุฉ 8kHz (ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุฉ ูู [ุจุทุงูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช](https://huggingface.co/datasets/PolyAI/minds14))ุ ูุง ูุนูู ุฃูู ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุชุดููููุง ุฅูู 16kHz ูุงุณุชุฎุฏุงู ูููุฐุฌ Wav2Vec2 ุงูููุฏุฑูุจ ูุณุจููุง:

```py
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,
         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',
  'sampling_rate': 16000},
 'intent_class': 2}
```

ุฃูุดุฆ ุงูุขู ุฏุงูุฉ ูููุนุงูุฌุฉ ุงููุณุจูุฉ ุชููู ุจูุง ููู:

1. ุชุณุชุฏุนู ุนููุฏ `audio` ูุชุญููู ููู ุงูุตูุชุ ูุฅุฐุง ูุฒู ุงูุฃูุฑุ ุฅุนุงุฏุฉ ุชุดููู ูุนุฏู ุงูุนูููุฉ.
2. ุชุชุญูู ููุง ุฅุฐุง ูุงู ูุนุฏู ุนูููุฉ ููู ุงูุตูุช ูุทุงุจู ูุนุฏู ุนูููุฉ ุจูุงูุงุช ุงูุตูุช ุงูุชู ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุนูููุง ูุณุจููุง. ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุฉ ูู [ุจุทุงูุฉ ุงููููุฐุฌ](https://huggingface.co/facebook/wav2vec2-base) ุงูุฎุงุตุฉ ุจู Wav2Vec2.
3. ุชุนููู ุทูู ุฅุฏุฎุงู ุฃูุตู (maximum input length) ูุชุฌููุน ููุฏุฎูุงุช ุฃุทูู ุฏูู ุงูุชุทุงุนูุง.

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True
...     )
...     return inputs
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุฉุ ุงุณุชุฎุฏู ุฏุงูุฉ [`~datasets.Dataset.map`] ูู ๐ค Datasets. ููููู ุชุณุฑูุน `map` ุจุชุนููู `batched=True` ููุนุงูุฌุฉ ุนุฏุฉ ุนูุงุตุฑ ุฏูุนุฉ ูุงุญุฏุฉ. ุฃุฒูู ุงูุฃุนูุฏุฉ ุบูุฑ ุงูุถุฑูุฑูุฉ ูุฃุนุฏ ุชุณููุฉ `intent_class` ุฅูู `label` ููุง ูุชุทูุจ ุงููููุฐุฌ:

```py
>>> encoded_minds = minds.map(preprocess_function, remove_columns="audio", batched=True)
>>> encoded_minds = encoded_minds.rename_column("intent_class", "label")
```

## ุงูุชูููู (Evaluate)

ุบุงูุจูุง ูุง ูููู ุชุถููู ูููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ ูููุฏูุง ูุชูููู ุฃุฏุงุก ูููุฐุฌู. ููููู ุจุณุฑุนุฉ ุชุญููู ุทุฑููุฉ ุชูููู ุนุจุฑ ููุชุจุฉ ๐ค [Evaluate](https://huggingface.co/docs/evaluate/index). ููุฐู ุงููููุฉุ ุญููู ูููุงุณ [ุงูุฏููุฉ (Accuracy)](https://huggingface.co/spaces/evaluate-metric/accuracy) (ุฑุงุฌุน [ุงูุฌููุฉ ุงูุณุฑูุนุฉ](https://huggingface.co/docs/evaluate/a_quick_tour) ูู ๐ค Evaluate ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ุงูุชุญููู ูุงูุญุณุงุจ):

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

ุซู ุฃูุดุฆ ุฏุงูุฉ ุชููุฑูุฑ ุชูุจุคุงุชู ูุชุณููุงุชู ุฅูู [`~evaluate.EvaluationModule.compute`] ูุญุณุงุจ ุงูุฏููุฉ:

```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions = np.argmax(eval_pred.predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)
```

ุฃุตุจุญุช ุฏุงูุฉ `compute_metrics` ุฌุงูุฒุฉ ุงูุขูุ ูุณูุนูุฏ ุฅูููุง ุนูุฏ ุฅุนุฏุงุฏ ุงูุชุฏุฑูุจ.

## ุงูุชุฏุฑูุจ (Train)

<frameworkcontent>
<pt>
<Tip>

ุฅุฐุง ูู ุชูู ูุนุชุงุฏูุง ุนูู ุฅุฌุฑุงุก ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`]ุ ุฃููู ูุธุฑุฉ ุนูู ุงูุฏููู ุงูุฃุณุงุณู [ููุง](../training#train-with-pytorch-trainer)!

</Tip>

ุฃูุช ุงูุขู ุฌุงูุฒ ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู Wav2Vec2 ุจุงุณุชุฎุฏุงู [`AutoModelForAudioClassification`] ูุน ุนุฏุฏ ุงูุชุณููุงุช ุงููุชููุนุฉ (labels) ูุฑุจุท ุงูุชุณููุงุช (label mappings):

```py
>>> from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer

>>> num_labels = len(id2label)
>>> model = AutoModelForAudioClassification.from_pretrained(
...     "facebook/wav2vec2-base", num_labels=num_labels, label2id=label2id, id2label=id2label
... )
```

ูู ูุฐู ุงููุฑุญูุฉุ ุชุจููุช ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุนุฑูู ูุฑุท-ูุนุงููุงุช ุงูุชุฏุฑูุจ (hyperparameters) ูู [`TrainingArguments`]. ุงููุนุงูู ุงููุญูุฏ ุงููุทููุจ ูู `output_dir`ุ ูุงูุฐู ูุญุฏุฏ ููุงู ุญูุธ ูููุฐุฌู. ุณุชุฏูุน ูุฐุง ุงููููุฐุฌ ุฅูู Hub ุจุชุนููู `push_to_hub=True` (ุชุญุชุงุฌ ุฅูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Face ูุฑูุน ูููุฐุฌู). ูู ููุงูุฉ ูู ุญูุจุฉ (epoch)ุ ุณูููููู [`Trainer`] ูููุฉ ุงูุฏููุฉ ููุญูุธ ููุทุฉ ุงูุชุญูู ุงูุชุฏุฑูุจูุฉ.
2. ูุฑูุฑ ูุนุงููุงุช ุงูุชุฏุฑูุจ ุฅูู [`Trainer`] ูุน ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ูุงูููุนุงูุฌ/ุงูู ูููุฒ (tokenizer/feature extractor) ูุฏุงูุฉ `compute_metrics`.
3. ุงุณุชุฏุนู [`~Trainer.train`] ูุฅุฌุฑุงุก ุงูุถุจุท ุงูุฏููู ููููุฐุฌู.


```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_mind_model",
...     eval_strategy="epoch",
...     save_strategy="epoch",
...     learning_rate=3e-5,
...     per_device_train_batch_size=32,
...     gradient_accumulation_steps=4,
...     per_device_eval_batch_size=32,
...     num_train_epochs=10,
...     warmup_ratio=0.1,
...     logging_steps=10,
...     load_best_model_at_end=True,
...     metric_for_best_model="accuracy",
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=encoded_minds["train"],
...     eval_dataset=encoded_minds["test"],
...     processing_class=feature_extractor,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ุนูู Hub ุจุงุณุชุฎุฏุงู ุงูุทุฑููุฉ [`~transformers.Trainer.push_to_hub`] ููุชููู ุงูุฌููุน ูู ุงุณุชุฎุฏุงูู:

```py
>>> trainer.push_to_hub()
```
</pt>
</frameworkcontent>

<Tip>

ููุญุตูู ุนูู ูุซุงู ุฃูุซุฑ ุชูุตูููุง ุญูู ููููุฉ ุฅุฌุฑุงุก ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ูุชุตููู ุงูุตูุชุ ุงุทููุน ุนูู [ุฏูุชุฑ Jupyter ุงูุฎุงุต ุจู PyTorch](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb).

</Tip>

## ุงูุงุณุชุฏูุงู (Inference)

ุฑุงุฆุน! ุจุนุฏ ุฃู ุฃุฌุฑูุช ุงูุถุจุท ุงูุฏููู ููููุฐุฌูุ ููููู ุงุณุชุฎุฏุงูู ุงูุขู ููุงุณุชุฏูุงู.

ุญููู ููููุง ุตูุชููุง ูุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู. ุชุฐููุฑ ุฅุนุงุฏุฉ ุชุดููู ูุนุฏู ุงูุนูููุฉ ูููู ุงูุตูุช ููุชูุงูู ูุน ูุนุฏู ุงูุนูููุฉ ุงูุฎุงุต ุจุงููููุฐุฌ ุฅุฐุง ูุฒู ุงูุฃูุฑ.

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> sampling_rate = dataset.features["audio"].sampling_rate
>>> audio_file = dataset[0]["audio"]["path"]
```

ุฃุณูู ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงููุถุจูุท ูู ุฃุฌู ุงูุงุณุชุฏูุงู ูู ุงุณุชุฎุฏุงูู ุถูู [`pipeline`]. ูู ุจุฅูุดุงุก `pipeline` ุฎุงุต ุจุชุตููู ุงูุตูุช ุจุงุณุชุฎุฏุงู ูููุฐุฌูุ ุซู ูุฑูุฑ ูู ููู ุงูุตูุช:

```py
>>> from transformers import pipeline

>>> classifier = pipeline("audio-classification", model="stevhliu/my_awesome_minds_model")
>>> classifier(audio_file)
[
    {'score': 0.09766869246959686, 'label': 'cash_deposit'},
    {'score': 0.07998877018690109, 'label': 'app_error'},
    {'score': 0.0781070664525032, 'label': 'joint_account'},
    {'score': 0.07667109370231628, 'label': 'pay_bill'},
    {'score': 0.0755252093076706, 'label': 'balance'}
]
```

ููููู ุฃูุถูุง ุฅุนุงุฏุฉ ุชูููุฐ ูุชุงุฆุฌ `pipeline` ูุฏูููุง ุฅุฐุง ุฑุบุจุช ุจุฐูู:

<frameworkcontent>
<pt>
ุญููู ูุณุชุฎุฑุฌ ุฎุตุงุฆุต (feature extractor) ูุชููุฆุฉ ููู ุงูุตูุช ูุฅุฑุฌุงุน `input` ุนูู ุดูู ููุชุฑุงุช PyTorch:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("stevhliu/my_awesome_minds_model")
>>> inputs = feature_extractor(dataset[0]["audio"]["array"], sampling_rate=sampling_rate, return_tensors="pt")
```

ูุฑูุฑ ุงูููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ ูุงุณุชุฑุฌุน ุงูููู ุงูููุบุงุฑูุฉ (logits):

```py
>>> from transformers import AutoModelForAudioClassification

>>> model = AutoModelForAudioClassification.from_pretrained("stevhliu/my_awesome_minds_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

ุงุญุตู ุนูู ุงููุฆุฉ ุฐุงุช ุงูุงุญุชูุงููุฉ ุงูุฃุนููุ ุซู ุงุณุชุฎุฏู ุฑุจุท `id2label` ุงูุฎุงุต ุจุงููููุฐุฌ ูุชุญููููุง ุฅูู ุชุณููุฉ (label):

```py
>>> import torch

>>> predicted_class_ids = torch.argmax(logits).item()
>>> predicted_label = model.config.id2label[predicted_class_ids]
>>> predicted_label
'cash_deposit'
```
</pt>
</frameworkcontent>
