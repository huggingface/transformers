# ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู

[[open-in-colab]]

<Youtube id="TksaY_FDgnk"/>

ูุญูู ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR) ุฅุดุงุฑุฉ ุงูููุงู ุฅูู ูุตุ ุนู ุทุฑูู ุฑุณู ุฎุฑูุทุฉ ูุณูุณูุฉ ูู ุงููุฏุฎูุงุช ุงูุตูุชูุฉ ุฅูู ูุฎุฑุฌุงุช ูุตูุฉ. ุชุณุชุฎุฏู ุงููุณุงุนุฏุงุช ุงูุงูุชุฑุงุถูุฉ ูุซู Siri ูAlexa ููุงุฐุฌ ASR ููุณุงุนุฏุฉ ุงููุณุชุฎุฏููู ูููููุงุ ูููุงู ุงูุนุฏูุฏ ูู ุงูุชุทุจููุงุช ุงููููุฏุฉ ุงูุฃุฎุฑู ุงูุชู ุชูุงุฌู ุงููุณุชุฎุฏููู ูุซู ุงูุชุนููู ุงููุจุงุดุฑ ูุชุฏููู ุงูููุงุญุธุงุช ุฃุซูุงุก ุงูุงุฌุชูุงุนุงุช.

ุณููุถุญ ูุฐุง ุงูุฏููู ูู ููููุฉ:

1. ุถุจุท ูููุฐุฌ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) ุงูุฏููู ุนูู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ููุณุฎ ุงูุตูุช ุฅูู ูุต.
2. ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงูุฏููู ููุงุณุชูุชุงุฌ.

<Tip>

ููุดุงูุฏุฉ ุฌููุน ุงูุชุตูููุงุช ูููุงุท ุงูุชูุชูุด ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุชุญูู ูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/automatic-speech-recognition)

</Tip>

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install transformers datasets evaluate jiwer
```

ูุดุฌุนู ุนูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ุญุชู ุชุชููู ูู ุชุญููู ููุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุนูุฏูุง ููุทูุจ ููู ุฐููุ ุฃุฏุฎู ุฑูุฒู ููุชุณุฌูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14

ุงุจุฏุฃ ุจุชุญููู ุฌุฒุก ูุฑุนู ุฃุตุบุฑ ูู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูู ููุชุจุฉ Datasets ๐ค. ุณูุนุทูู ูุฐุง ูุฑุตุฉ ูุชุฌุฑุจุฉ ูุงูุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุนูู ูุจู ูุถุงุก ุงููุฒูุฏ ูู ุงูููุช ูู ุงูุชุฏุฑูุจ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ.

```py
>>> from datasets import load_dataset, Audio

>>> minds = load_dataset("PolyAI/minds14", name="en-US", split="train[:100]")
```

ูุณููู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ูุฌููุนุงุช ูุฑุนูุฉ ููุชุฏุฑูุจ ูุงูุงุฎุชุจุงุฑ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~Dataset.train_test_split`] :

```py
>>> minds = minds.train_test_split(test_size=0.2)
```

ุซู ุงูู ูุธุฑุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> minds
DatasetDict({
    train: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 16
    })
    test: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 4
    })
})
```

ูู ุญูู ุฃู ูุฌููุนุฉ ุงูุจูุงูุงุช ุชุญุชูู ุนูู ุงููุซูุฑ ูู ุงููุนูููุงุช ุงููููุฏุฉุ ูุซู `lang_id` ู`english_transcription`ุ ูุณูู ุชุฑูุฒ ุนูู `audio` ู`transcription` ูู ูุฐุง ุงูุฏููู. ุฃุฒู ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.remove_columns`] :

```py
>>> minds = minds.remove_columns(["english_transcription", "intent_class", "lang_id"])
```

ุงูู ูุธุฑุฉ ุนูู ุงููุซุงู ูุฑุฉ ุฃุฎุฑู:

```py
>>> minds["train"][0]
{'audio': {'array': array([-0.00024414,  0.        ,  0.        , ...,  0.00024414,
          0.00024414,  0.00024414], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
  'sampling_rate': 8000},
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948eMultiplier: 1.0
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([-2.38064706e-04, -1.58618059e-04, -5.43987835e-06, ...,
          2.78103951e-04,  2.38446111e-04,  1.18740834e-04], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
  'sampling_rate': 16000},
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
 'transcription': "hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing"}
```

ููุงู ุญููุงู:

- `audio`: ูุตูููุฉ ุฃุญุงุฏูุฉ ุงูุจุนุฏ ูุฅุดุงุฑุฉ ุงูููุงู ุงูุชู ูุฌุจ ุงุณุชุฏุนุงุคูุง ูุชุญููู ูุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ููู ุงูุตูุช.
- `transcription`: ุงููุต ุงููุณุชูุฏู.

## ูุนุงูุฌุฉ ูุณุจูุฉ

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุนุงูุฌ Wav2Vec2 ููุนุงูุฌุฉ ุฅุดุงุฑุฉ ุงูุตูุช:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base")
```

ุชุญุชูู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ุนูู ูุนุฏู ุฃุฎุฐ ุนููุงุช ูุจูุบ 8000 ูููู ูุฑุชุฒ (ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุงุช ูู [ุจุทุงูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช](https://huggingface.co/datasets/PolyAI/minds14))ุ ููุง ูุนูู ุฃูู ุณูุชุนูู ุนููู ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู 16000 ูููู ูุฑุชุฒ ูุงุณุชุฎุฏุงู ูููุฐุฌ Wav2Vec2 ุงููุฏุฑุจ ูุณุจููุง:

```py
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([-2.38064706e-04, -1.58618059e-04, -5.43987835e-06, ...,
          2.78103951e-04,  2.38446111e-04,  1.18740834e-04], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
  'sampling_rate': 16000},
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
 'transcription': "hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing"}
```

ููุง ูู ููุถุญ ูู `transcription` ุฃุนูุงูุ ูุญุชูู ุงููุต ุนูู ูุฒูุฌ ูู ุงูุฃุญุฑู ุงููุจูุฑุฉ ูุงูุตุบูุฑุฉ. ุชู ุชุฏุฑูุจ ูุนุฌู Wav2Vec2 ููุท ุนูู ุงูุฃุญุฑู ุงููุจูุฑุฉุ ูุฐูู ุณูุชุนูู ุนููู ุงูุชุฃูุฏ ูู ุฃู ุงููุต ูุชุทุงุจู ูุน ููุฑุฏุงุช ุงููุนุฌู:

```py
>>> def uppercase(example):
...     return {"transcription": example["transcription"].upper()}


>>> minds = minds.map(uppercase)
```

ุงูุขู ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุนุงูุฌุฉ ูุณุจูุฉ ุชููู ุจูุง ููู:

1. ุงุณุชุฏุนุงุก ุนููุฏ `audio` ูุชุญููู ูุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ููู ุงูุตูุช.
2. ุงุณุชุฎุฑุงุฌ `input_values` ูู ููู ุงูุตูุช ูุฑูุฒ `transcription` ุจุงุณุชุฎุฏุงู ุงููุนุงูุฌ.

```py
>>> def prepare_dataset(batch):
...     audio = batch["audio"]
...     batch = processor(audio["array"], sampling_rate=audio["sampling_rate"], text=batch["transcription"])
...     batch["input_length"] = len(batch["input_values"][0])
...     return batch
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ุงุณุชุฎุฏู ูุธููุฉ [`~datasets.Dataset.map`] ูู ููุชุจุฉ Datasets ๐ค. ููููู ุชุณุฑูุน `map` ุนู ุทุฑูู ุฒูุงุฏุฉ ุนุฏุฏ ุงูุนูููุงุช ุจุงุณุชุฎุฏุงู ูุนููุฉ `num_proc` . ุฃุฒู ุงูุฃุนูุฏุฉ ุงูุชู ูุง ุชุญุชุงุฌูุง ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.remove_columns`] :

```py
>>> encoded_minds = minds.map(prepare_dataset, remove_columns=minds.column_names["train"], num_proc=4)
```

ูุง ุชุญุชูู ููุชุจุฉ ๐ค Transformers ุนูู ุฌุงูุน ุจูุงูุงุช ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR)ุ ูุฐูู ุณูุชุนูู ุนููู ุชูููู [`DataCollatorWithPadding`] ูุฅูุดุงุก ุฏูุนุฉ ูู ุงูุฃูุซูุฉ. ููุง ุฃูู ุณูููู ุชููุงุฆููุง ุจุชุจุทูู ูุตู ูุชุณููุงุชู ุฅูู ุทูู ุงูุนูุตุฑ ุงูุฃุทูู ูู ุฏูุนุชูุง (ุจุฏูุงู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง) ุจุญูุซ ูููู ููุง ุทูู ููุญุฏ. ูู ุญูู ุฃูู ูู ุงููููู ุชุจุทูู ูุตู ูู ุฏุงูุฉ `tokenizer` ุนู ุทุฑูู ุชุนููู `padding=True`ุ ูุฅู ุงูุชุจุทูู ุงูุฏููุงูููู ุฃูุซุฑ ููุงุกุฉ.

ุนูู ุนูุณ ุฌุงูุนู ุงูุจูุงูุงุช ุงูุขุฎุฑููุ ูุญุชุงุฌ ุฌุงูุน ุงูุจูุงูุงุช ูุฐุง ุฅูู ุชุทุจูู ุทุฑููุฉ ุชุจุทูู ูุฎุชููุฉ ุนูู `input_values` ู`labels` :

```py
>>> import torch

>>> from dataclasses import dataclass, field
>>> from typing import Any, Dict, List, Optional, Union


>>> @dataclass
... class DataCollatorCTCWithPadding:
...     processor: AutoProcessor
...     padding: Union[bool, str] = "longest"

...     def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
...         # split inputs and labels since they have to be of different lengths and need
...         # different padding methods
...         input_features = [{"input_values": feature["input_values"][0]} for feature in features]
...         label_features = [{"input_ids": feature["labels"]} for feature in features]

...         batch = self.processor.pad(input_features, padding=self.padding, return_tensors="pt")

...         labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors="pt")

...         # replace padding with -100 to ignore loss correctly
...         labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

...         batch["labels"] = labels

...         return batch
```

## ุชูููู

ุบุงูุจูุง ูุง ูููู ุชุถููู ูููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ ูููุฏูุง ูุชูููู ุฃุฏุงุก ูููุฐุฌู. ููููู ุชุญููู ุทุฑููุฉ ุชูููู ุจุณุฑุนุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ ๐ค [Evaluate](https://huggingface.co/docs/evaluate/index) . ุจุงููุณุจุฉ ููุฐู ุงููููุฉุ ูู ุจุชุญููู ูููุงุณ [ุฎุทุฃ ูููุฉ](https://huggingface.co/spaces/evaluate-metric/wer) (WER) (ุฑุงุฌุน ุฌููุฉ ๐ค Evaluate [ุงูุณุฑูุนุฉ](https://huggingface.co/docs/evaluate/a_quick_tour) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ููููุฉ ุชุญููู ูุญุณุงุจ ูููุงุณ):

```py
>>> import evaluate

>>> wer = evaluate.load("wer")
```

ุซู ูู ุจุฅูุดุงุก ุฏุงูุฉ ุชูุฑุฑ ุชูุจุคุงุชู ูุชุณููุงุชู ุฅูู [`~evaluate.EvaluationModule.compute`] ูุญุณุงุจ WER:

```py
>>> import numpy as np


>>> def compute_metrics(pred):
...     pred_logits = pred.predictions
...     pred_ids = np.argmax(pred_logits, axis=-1)

...     pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id

...     pred_str = processor.batch_decode(pred_ids)
...     label_str = processor.batch_decode(pred.label_idsุ group_tokens=False)

...     wer = wer.compute(predictions=pred_strุ references=label_str)

...     return {"wer": wer}
```

ุฏุงูุชู `compute_metrics` ุฌุงูุฒุฉ ุงูุขูุ ูุณุชุนูุฏ ุฅูููุง ุนูุฏ ุฅุนุฏุงุฏ ุชุฏุฑูุจู.

## ุชุฏุฑูุจ

<frameworkcontent>
<pt>
<Tip>

ุฅุฐุง ูู ุชูู ุนูู ุฏุฑุงูุฉ ุจุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`]ุ ูุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃุณุงุณู [ููุง](../training#train-with-pytorch-trainer)!

</Tip>

ุฃูุช ูุณุชุนุฏ ุงูุขู ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู Wav2Vec2 ุจุงุณุชุฎุฏุงู [`AutoModelForCTC`]. ุญุฏุฏ ุงูุชุฎููุถ ุงูุฐู ุณูุชู ุชุทุจููู ุจุงุณุชุฎุฏุงู ูุนููุฉ `ctc_loss_reduction` . ุบุงูุจูุง ูุง ูููู ูู ุงูุฃูุถู ุงุณุชุฎุฏุงู ุงููุชูุณุท ุจุฏูุงู ูู ุงูุฌูุน ุงูุงูุชุฑุงุถู:

```py
>>> from transformers import AutoModelForCTCุ TrainingArgumentsุ Trainer

>>> model = AutoModelForCTC.from_pretrained(
...     "facebook/wav2vec2-base",
...     ctc_loss_reduction="mean",
...     pad_token_id=processor.tokenizer.pad_token_id,
... )
```

ูู ูุฐู ุงููุฑุญูุฉุ ููุงู ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุญุฏุฏ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู ูู [`TrainingArguments`]. ุงููุนููุฉ ุงููุญูุฏุฉ ุงููุทููุจุฉ ูู `output_dir` ุงูุชู ุชุญุฏุฏ ููุงู ุญูุธ ูููุฐุฌู. ุณูู ุชููู ุจุฏูุน ูุฐุง ุงููููุฐุฌ ุฅูู Hub ุนู ุทุฑูู ุชุนููู `push_to_hub=True` (ูุฌุจ ุฃู ุชููู ูุณุฌู ุงูุฏุฎูู ุฅูู Hugging Face ูุชุญููู ูููุฐุฌู). ูู ููุงูุฉ ูู ุญูุจุฉุ ุณูููู [`Trainer`] ุจุชูููู WER ูุญูุธ ููุทุฉ ุงูุชุฏุฑูุจ.
2. ูู ุจุชูุฑูุฑ ุงูุญุฌุฌ ุงูุชุฏุฑูุจ ุฅูู [`Trainer`] ุฌูุจูุง ุฅูู ุฌูุจ ูุน ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุนุฌู ูุฌุงูุน ุงูุจูุงูุงุช ููุธููุฉ `compute_metrics` .
3. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุถุจุท ูููุฐุฌู ุจุดูู ุฏููู.

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_asr_mind_model",
...     per_device_train_batch_size=8,
...     gradient_accumulation_steps=2,
...     learning_rate=1e-5,
...     warmup_steps=500,
...     max_steps=2000,
...     gradient_checkpointing=True,
...     fp16=True,
...     group_by_length=True,
...     eval_strategy="steps",
...     per_device_eval_batch_size=8,
...     save_steps=1000,
...     eval_steps=1000,
...     logging_steps=25,
...     load_best_model_at_end=True,
...     metric_for_best_model="wer",
...     greater_is_better=False,
...     push_to_hub=True,
... )
>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=encoded_minds["train"],
...     eval_dataset=encoded_minds["test"],
...     tokenizer=processor,
...     data_collator=data_collator,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ูู ุงููุฑูุฒ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~transformers.Trainer.push_to_hub`] ุญุชู ูุชููู ุงูุฌููุน ูู ุงุณุชุฎุฏุงู ูููุฐุฌู:

```py
>>> trainer.push_to_hub()
```
</pt>
</frameworkcontent>

<Tip>

ููุญุตูู ุนูู ูุซุงู ุฃูุซุฑ ุชุนูููุง ุญูู ููููุฉ ุถุจุท ูููุฐุฌ ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงูุ ุฑุงุฌุน ููุดูุฑ ุงููุฏููุฉ [ูุฐุง](https://huggingface.co/blog/fine-tune-wav2vec2-english) ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ ููุฐุง [ุงูููุดูุฑ](https://huggingface.co/blog/fine-tune-xlsr-wav2vec2) ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ูุชุนุฏุฏ ุงููุบุงุช.

</Tip>

## ุงูุงุณุชูุชุงุฌ

ุฑุงุฆุนุ ุงูุขู ุจุนุฏ ุฃู ููุช ุจุถุจุท ุฏููู ููููุฐุฌุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชูุชุงุฌ!

ูู ุจุชุญููู ููู ุตูุชู ุชุฑูุฏ ุชุดุบูู ุงูุงุณุชูุชุงุฌ ุนููู. ุชุฐูุฑ ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูููู ุงูุตูุช ููุทุงุจูุฉ ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูููููุฐุฌ ุฅุฐุง ููุช ุจุญุงุฌุฉ ุฅูู ุฐูู!

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> sampling_rate = dataset.features["audio"].sampling_rate
>>> audio_file = dataset[0]["audio"]["path"]
```

ุฃุจุณุท ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงููุถุจูุท ุงูุฏููู ููุงุณุชูุชุงุฌ ูู ุงุณุชุฎุฏุงูู ูู [`pipeline`]. ูู ุจุชูููุฐ ูุซูู `pipeline` ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ุจุงุณุชุฎุฏุงู ูููุฐุฌูุ ููุฑุฑ ููู ุงูุตูุช ุงูุฎุงุต ุจู ุฅููู:

```py
>>> from transformers import pipeline

>>> transcriber = pipeline("automatic-speech-recognition", model="stevhliu/my_awesome_asr_minds_model")
>>> transcriber(audio_file)
{'text': 'I WOUD LIKE O SET UP JOINT ACOUNT WTH Y PARTNER'}
```

<Tip>

ุงููุณุฎ ุงููุตู ุฌูุฏุ ููููู ูููู ุฃู ูููู ุฃูุถู! ุฌุฑุจ ุถุจุท ูููุฐุฌู ุนูู ุงููุฒูุฏ ูู ุงูุฃูุซูุฉ ููุญุตูู ุนูู ูุชุงุฆุฌ ุฃูุถู!

</Tip>

ููููู ุฃูุถูุง ูุญุงูุงุฉ ูุชุงุฆุฌ `pipeline` ูุฏูููุง ุฅุฐุง ุฃุฑุฏุช:

<frameworkcontent>
<pt>
ูู ุจุชุญููู ูุนุงูุฌ ููุนุงูุฌุฉ ููู ุงูุตูุช ูุงููุณุฎ ุงููุตู ูุฅุฑุฌุงุน `input` ูุฑููุฒ ุชุนุจูุฑูุฉ PyTorch:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("stevhliu/my_awesome_asr_mind_model")
>>> inputs = processor(dataset[0]["audio"]["array"], sampling_rate=sampling_rate, return_tensors="pt")
```

ูุฑุฑ ุงููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ ูุฃุนุฏ ุงูุฎุฑุฌุงุช:

```py
>>> from transformers import AutoModelForCTC

>>> model = AutoModelForCTC.from_pretrained("stevhliu/my_awesome_asr_mind_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

ุงุญุตู ุนูู `input_ids` ุงููุชููุน ูุน ุฃุนูู ุงุญุชูุงูุ ูุงุณุชุฎุฏู ุงููุนุงูุฌ ูุชุฑููุฒ `input_ids` ุงููุชููุน ูุฑุฉ ุฃุฎุฑู ุฅูู ูุต:

```py
>>> import torch

>>> predicted_ids = torch.argmax(logits, dim=-1)
>>> transcription = processor.batch_decode(predicted_ids)
>>> transcription
['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']
```
</pt>
</frameworkcontent>