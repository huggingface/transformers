<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

โ๏ธ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ุงูุชุนุฑูู ุงูุชููุงุฆู ุนูู ุงูููุงู (Automatic Speech Recognition - ASR)

[[open-in-colab]]

<Youtube id="TksaY_FDgnk"/>

ูุญููู ุงูุชุนุฑูู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR) ุงูุฅุดุงุฑุฉ ุงูุตูุชูุฉ ุฅูู ูุตุ ูุฐูู ุนุจุฑ ููุงุกูุฉ ุชุณูุณู ูู ููุฏุฎูุงุช ุงูุตูุช ูุน ููุฎุฑุฌุงุช ูุตูุฉ. ุชุณุชุฎุฏู ุงููุณุงุนุฏุงุช ุงูุตูุชูุฉ ูุซู Siri ูAlexa ููุงุฐุฌ ASR ููุณุงุนุฏุฉ ุงููุณุชุฎุฏููู ูููููุงุ ูููุงู ุงูุนุฏูุฏ ูู ุชุทุจููุงุช ุงููุณุชุฎุฏู ุงูููุงุฆู ุงููููุฏุฉ ุงูุฃุฎุฑู ูุซู ุงูุชุฑุฌูุฉ ุงููุตูุฉ ุงูุญูุฉ ูุชุฏููู ุงูููุงุญุธุงุช ุฃุซูุงุก ุงูุงุฌุชูุงุนุงุช.

ุณููุฑุดุฏู ูุฐุง ุงูุฏููู ุฅูู ููููุฉ:

1. ุฅุฌุฑุงุก ุถุจุท ุฏููู (fine-tuning) ูู [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูุชุญููู ุงูุตูุช ุฅูู ูุต.
2. ุงุณุชุฎุฏุงู ูููุฐุฌู ุงููุถุจูุท ููุงุณุชุฎูุงุต (inference).

<Tip>

ููุนุฑูุฉ ุฌููุน ุงูุจููู ูููุงุท ุงูุชุญูู ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุงุทูุงุน ุนูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/automatic-speech-recognition).

</Tip>

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install transformers datasets evaluate jiwer
```

ููุตูู ุจุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจู ุนูู Hugging Face ุญุชู ุชุชููู ูู ุฑูุน ูููุฐุฌู ููุดุงุฑูุชู ูุน ุงููุฌุชูุน. ุนูุฏ ุงููุทุงูุจุฉุ ุฃุฏุฎู ุงูุฑูุฒ ุงููููุฒ ูุชุณุฌูู ุงูุฏุฎูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช MInDS-14

ุงุจุฏุฃ ุจุชุญููู ุฌุฒุก ุฃุตุบุฑ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูู ููุชุจุฉ ๐ค Datasets. ุณูููุญู ูุฐุง ูุฑุตุฉ ููุชุฌุฑุจุฉ ูุงูุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุนูู ูุจู ูุถุงุก ุงููุฒูุฏ ูู ุงูููุช ูู ุงูุชุฏุฑูุจ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ.

```py
>>> from datasets import load_dataset, Audio

>>> minds = load_dataset("PolyAI/minds14", name="en-US", split="train[:100]")
```

ูุณูู ุฌุฒุก `train` ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ูุฌููุนุฉ ุชุฏุฑูุจ ูุงุฎุชุจุงุฑ ุจุงุณุชุฎุฏุงู ุงูุทุฑููุฉ [`~Dataset.train_test_split`]:

```py
>>> minds = minds.train_test_split(test_size=0.2)
```

ุซู ุฃููู ูุธุฑุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> minds
DatasetDict({
    train: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 16
    })
    test: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 4
    })
})
```

ุจูููุง ุชุญุชูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุนูู ุงููุซูุฑ ูู ุงููุนูููุงุช ุงููููุฏุฉ ูุซู `lang_id` ู`english_transcription`ุ ูุฑููุฒ ูุฐุง ุงูุฏููู ุนูู ุญููู `audio` ู`transcription`. ุฃุฒูู ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู ุจุงุณุชุฎุฏุงู ุงูุทุฑููุฉ [`~datasets.Dataset.remove_columns`]:

```py
>>> minds = minds.remove_columns(["english_transcription", "intent_class", "lang_id"])
```

ุฑุงุฌุน ุงููุซุงู ูุฑุฉ ุฃุฎุฑู:

```py
>>> minds["train"][0]
{'audio': {'array': array([-0.00024414,  0.        ,  0.        , ...,  0.00024414,
          0.00024414,  0.00024414], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
  'sampling_rate': 8000},
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
 'transcription': "hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing"}
```

ููุงู ุญููุงู:

- `audio`: ูุตูููุฉ ุฃุญุงุฏูุฉ ุงูุจูุนุฏ `array` ููุฅุดุงุฑุฉ ุงูุตูุชูุฉ ูุฌุจ ุงุณุชุฏุนุงุคูุง ูุชุญููู ููู ุงูุตูุช ูุฅุนุงุฏุฉ ุชุดููู ูุนุฏู ุงูุนูููุฉ.
- `transcription`: ุงููุต ุงููุฏู.

## ุงููุนุงูุฌุฉ ุงููุณุจูุฉ (Preprocess)

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุนุงูุฌ (processor) Wav2Vec2 ููุนุงูุฌุฉ ุงูุฅุดุงุฑุฉ ุงูุตูุชูุฉ:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base")
```

ุชููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ูุนุฏู ุนูููุฉ 8000 ูุฑุชุฒ (ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุฉ ูู [ุจุทุงูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช](https://huggingface.co/datasets/PolyAI/minds14))ุ ูุง ูุนูู ุฃูู ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุชุดููููุง ุฅูู 16000 ูุฑุชุฒ ูุงุณุชุฎุฏุงู ูููุฐุฌ Wav2Vec2 ุงูููุฏุฑูุจ ูุณุจููุง:

```py
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([-2.38064706e-04, -1.58618059e-04, -5.43987835e-06, ...,
          2.78103951e-04,  2.38446111e-04,  1.18740834e-04], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
  'sampling_rate': 16000},
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
 'transcription': "hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing"}
```

ููุง ุชุฑู ูู ุงูุญูู `transcription` ุฃุนูุงูุ ูุญุชูู ุงููุต ุนูู ูุฒูุฌ ูู ุงูุฃุญุฑู ุงููุจูุฑุฉ ูุงูุตุบูุฑุฉ. ุชู ุชุฏุฑูุจ ุงููููุณููู (tokenizer) ุงูุฎุงุต ุจู Wav2Vec2 ุนูู ุฃุญุฑู ูุจูุฑุฉ ููุทุ ูุฐุง ุนููู ุงูุชุฃูุฏ ูู ุฃู ุงููุต ูุทุงุจู ููุฑุฏุงุช ุงููููุณููู:

```py
>>> def uppercase(example):
...     return {"transcription": example["transcription"].upper()}


>>> minds = minds.map(uppercase)
```

ุฃูุดุฆ ุงูุขู ุฏุงูุฉ ูููุนุงูุฌุฉ ุงููุณุจูุฉ ุชููู ุจูุง ููู:

1. ุชุณุชุฏุนู ุนููุฏ `audio` ูุชุญููู ููู ุงูุตูุช ูุฅุนุงุฏุฉ ุชุดููู ูุนุฏู ุงูุนูููุฉ.
2. ุชุณุชุฎุฑุฌ `input_values` ูู ููู ุงูุตูุช ูุชูุฌุฒูุฆ ุนููุฏ `transcription` ุจุงุณุชุฎุฏุงู ุงููุนุงูุฌ (processor).

```py
>>> def prepare_dataset(batch):
...     audio = batch["audio"]
...     batch = processor(audio["array"], sampling_rate=audio["sampling_rate"], text=batch["transcription"]) 
...     batch["input_length"] = len(batch["input_values"][0])
...     return batch
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุฉุ ุงุณุชุฎุฏู ุฏุงูุฉ [`~datasets.Dataset.map`] ูู ๐ค Datasets. ููููู ุชุณุฑูุน `map` ุจุฒูุงุฏุฉ ุนุฏุฏ ุงูุนูููุงุช ุนุจุฑ ุงููุนุงูู `num_proc`. ุฃุฒูู ุงูุฃุนูุฏุฉ ุงูุชู ูุง ุชุญุชุงุฌูุง ุจุงุณุชุฎุฏุงู ุงูุทุฑููุฉ [`~datasets.Dataset.remove_columns`]:

```py
>>> encoded_minds = minds.map(prepare_dataset, remove_columns=minds.column_names["train"], num_proc=4)
```

ูุง ุชูููุฑ ๐ค Transformers ููุฌูููุน ุจูุงูุงุช (data collator) ูุฎุตูุตูุง ูู ASRุ ูุฐุง ุณุชุญุชุงุฌ ุฅูู ุชูููู [`DataCollatorWithPadding`] ูุฅูุดุงุก ุฏูุนุฉ ุฃูุซูุฉ (batch). ููุง ุณูููู ูุฐุง ุงููุฌูููุน ุจุญุดู (padding) ุงููุตูุต ูุงูุชุณููุงุช ุฏููุงูููููุง ุฅูู ุทูู ุฃุทูู ุนูุตุฑ ุฏุงุฎู ุงูุฏูุนุฉ (ุจุฏููุง ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูููุง) ูุชููู ุจุทูู ููุญูุฏ. ุฑุบู ุฅููุงููุฉ ุชูููุฐ ุงูุญุดู ูู ุฏุงูุฉ `tokenizer` ุนุจุฑ `padding=True`ุ ุฅูุง ุฃู ุงูุญุดู ุงูุฏููุงูููู ุฃูุซุฑ ููุงุกุฉ.

ุนูู ุนูุณ ููุฌูููุนุงุช ุงูุจูุงูุงุช ุงูุฃุฎุฑูุ ูุญุชุงุฌ ูุฐุง ุงููุฌูููุน ุชุญุฏูุฏูุง ุฅูู ุชุทุจูู ุทุฑููุฉ ุญุดู ูุฎุชููุฉ ุนูู `input_values` ู`labels`:

```py
>>> import torch

>>> from dataclasses import dataclass, field
>>> from typing import Any, Dict, List, Optional, Union


>>> @dataclass
... class DataCollatorCTCWithPadding:
...     processor: AutoProcessor
...     padding: Union[bool, str] = "longest"

...     def __call__(self, features: list[dict[str, Union[list[int], torch.Tensor]]]) -> dict[str, torch.Tensor]:
...         # split inputs and labels since they have to be of different lengths and need
...         # different padding methods
...         input_features = [{"input_values": feature["input_values"][0]} for feature in features]
...         label_features = [{"input_ids": feature["labels"]} for feature in features]

...         batch = self.processor.pad(input_features, padding=self.padding, return_tensors="pt")

...         labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors="pt")

...         # replace padding with -100 to ignore loss correctly
...         labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

...         batch["labels"] = labels

...         return batch
```

ุงูุขู ูู ุจุชููุฆุฉ `DataCollatorCTCWithPadding`:

```py
>>> data_collator = DataCollatorCTCWithPadding(processor=processor, padding="longest")
```

## ุงูุชูููู (Evaluate)

ุบุงูุจูุง ูุง ูููู ุชุถููู ูููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ ูููุฏูุง ูุชูููู ุฃุฏุงุก ูููุฐุฌู. ููููู ุจุณุฑุนุฉ ุชุญููู ุทุฑููุฉ ุชูููู ุนุจุฑ ููุชุจุฉ ๐ค [Evaluate](https://huggingface.co/docs/evaluate/index). ููุฐู ุงููููุฉุ ุญููู ูููุงุณ [ูุนุฏู ุงูุฎุทุฃ ูู ุงููููุงุช (Word Error Rate - WER)](https://huggingface.co/spaces/evaluate-metric/wer) (ุฑุงุฌุน [ุงูุฌููุฉ ุงูุณุฑูุนุฉ](https://huggingface.co/docs/evaluate/a_quick_tour) ูู ๐ค Evaluate ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ุงูุชุญููู ูุงูุญุณุงุจ):

```py
>>> import evaluate

>>> wer = evaluate.load("wer")
```

ุซู ุฃูุดุฆ ุฏุงูุฉ ุชููุฑูุฑ ุชูุจุคุงุชู ูุชุณููุงุชู ุฅูู [`~evaluate.EvaluationModule.compute`] ูุญุณุงุจ WER:

```py
>>> import numpy as np


>>> def compute_metrics(pred):
...     pred_logits = pred.predictions
...     pred_ids = np.argmax(pred_logits, axis=-1)

...     pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id

...     pred_str = processor.batch_decode(pred_ids)
...     label_str = processor.batch_decode(pred.label_ids, group_tokens=False)

...     wer = wer.compute(predictions=pred_str, references=label_str)

...     return {"wer": wer}
```

ุฃุตุจุญุช ุฏุงูุฉ `compute_metrics` ุฌุงูุฒุฉ ุงูุขูุ ูุณูุนูุฏ ุฅูููุง ุนูุฏ ุฅุนุฏุงุฏ ุงูุชุฏุฑูุจ.

## ุงูุชุฏุฑูุจ (Train)

<frameworkcontent>
<pt>
<Tip>

ุฅุฐุง ูู ุชูู ูุนุชุงุฏูุง ุนูู ุฅุฌุฑุงุก ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`]ุ ุฃููู ูุธุฑุฉ ุนูู ุงูุฏููู ุงูุฃุณุงุณู [ููุง](../training#train-with-pytorch-trainer)!

</Tip>

ุฃูุช ุงูุขู ุฌุงูุฒ ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู Wav2Vec2 ุจุงุณุชุฎุฏุงู [`AutoModelForCTC`]. ุญุฏูุฏ ุทุฑููุฉ ุงูุงุฎุชุฒุงู (reduction) ุนุจุฑ ุงููุนุงูู `ctc_loss_reduction`. ุบุงูุจูุง ูุง ูููู ุงุณุชุฎุฏุงู ุงููุชูุณุท ุฃูุถู ูู ุงูุฌูุน ุงูุงูุชุฑุงุถู:

```py
>>> from transformers import AutoModelForCTC, TrainingArguments, Trainer

>>> model = AutoModelForCTC.from_pretrained(
...     "facebook/wav2vec2-base",
...     ctc_loss_reduction="mean",
...     pad_token_id=processor.tokenizer.pad_token_id,
... )
```

ูู ูุฐู ุงููุฑุญูุฉุ ุชุจููุช ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุนุฑูู ูุฑุท-ูุนุงููุงุช ุงูุชุฏุฑูุจ (hyperparameters) ูู [`TrainingArguments`]. ุงููุนุงูู ุงููุญูุฏ ุงููุทููุจ ูู `output_dir` ุงูุฐู ูุญุฏุฏ ููุงู ุญูุธ ูููุฐุฌู. ุณุชุฏูุน ูุฐุง ุงููููุฐุฌ ุฅูู Hub ุจุชุนููู `push_to_hub=True` (ุชุญุชุงุฌ ุฅูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Face ูุฑูุน ูููุฐุฌู). ูู ููุงูุฉ ูู ุญูุจุฉ (epoch)ุ ุณูููููู [`Trainer`] ูููุฉ WER ููุญูุธ ููุทุฉ ุงูุชุญูู ุงูุชุฏุฑูุจูุฉ.
2. ูุฑูุฑ ูุนุงููุงุช ุงูุชุฏุฑูุจ ุฅูู [`Trainer`] ูุน ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุนุงูุฌ (tokenizer/processor) ููุฌููุน ุงูุจูุงูุงุช ูุฏุงูุฉ `compute_metrics`.
3. ุงุณุชุฏุนู [`~Trainer.train`] ูุฅุฌุฑุงุก ุงูุถุจุท ุงูุฏููู ููููุฐุฌู.

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_asr_mind_model",
...     per_device_train_batch_size=8,
...     gradient_accumulation_steps=2,
...     learning_rate=1e-5,
...     warmup_steps=500,
...     max_steps=2000,
...     gradient_checkpointing=True,
...     fp16=True,
...     group_by_length=True,
...     eval_strategy="steps",
...     per_device_eval_batch_size=8,
...     save_steps=1000,
...     eval_steps=1000,
...     logging_steps=25,
...     load_best_model_at_end=True,
...     metric_for_best_model="wer",
...     greater_is_better=False,
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=encoded_minds["train"],
...     eval_dataset=encoded_minds["test"],
...     processing_class=processor,
...     data_collator=data_collator,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ุนูู Hub ุจุงุณุชุฎุฏุงู ุงูุทุฑููุฉ [`~transformers.Trainer.push_to_hub`] ููููู ูุชุงุญูุง ููุฌููุน:

```py
>>> trainer.push_to_hub()
```
</pt>
</frameworkcontent>

<Tip>

ููุญุตูู ุนูู ูุซุงู ุฃูุซุฑ ุชูุตูููุง ุญูู ููููุฉ ุฅุฌุฑุงุก ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ููุชุนุฑูู ุงูุชููุงุฆู ุนูู ุงูููุงูุ ุงุทููุน ุนูู [ูุฐู ุงูุชุฏูููุฉ](https://huggingface.co/blog/fine-tune-wav2vec2-english) ูู ASR ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ ูุนูู [ูุฐู ุงูุชุฏูููุฉ](https://huggingface.co/blog/fine-tune-xlsr-wav2vec2) ุงูุฎุงุตุฉ ุจู ASR ูุชุนุฏุฏ ุงููุบุงุช.

</Tip>

## ุงูุงุณุชุฏูุงู (Inference)

ุฑุงุฆุน! ุจุนุฏ ุฃู ุฃุฌุฑูุช ุงูุถุจุท ุงูุฏููู ููููุฐุฌูุ ููููู ุงุณุชุฎุฏุงูู ุงูุขู ููุงุณุชุฏูุงู.

ุญููู ููููุง ุตูุชููุง ุชุฑุบุจ ุจุชุดุบูู ุงูุงุณุชุฏูุงู ุนููู. ุชุฐููุฑ ุฅุนุงุฏุฉ ุชุดููู ูุนุฏู ุงูุนูููุฉ ูููู ุงูุตูุช ููุชูุงูู ูุน ูุนุฏู ุงูุนูููุฉ ุงูุฎุงุต ุจุงููููุฐุฌ ุฅุฐุง ุงุญุชุฌุช ูุฐูู!

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> sampling_rate = dataset.features["audio"].sampling_rate
>>> audio_file = dataset[0]["audio"]["path"]
```

ุฃุณูู ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงููุถุจูุท ูู ุฃุฌู ุงูุงุณุชุฏูุงู ูู ุงุณุชุฎุฏุงูู ุถูู [`pipeline`]. ูู ุจุฅูุดุงุก `pipeline` ุฎุงุต ุจุงูุชุนุฑูู ุงูุชููุงุฆู ุนูู ุงูููุงู ุจุงุณุชุฎุฏุงู ูููุฐุฌูุ ุซู ูุฑูุฑ ูู ููู ุงูุตูุช:

```py
>>> from transformers import pipeline

>>> transcriber = pipeline("automatic-speech-recognition", model="stevhliu/my_awesome_asr_minds_model")
>>> transcriber(audio_file)
{'text': 'I WOUD LIKE O SET UP JOINT ACOUNT WTH Y PARTNER'}
```

<Tip>

ุงููุงุชุฌ ุงููุตู ุฌูุฏุ ูููู ูุฏ ูููู ุฃูุถู! ุญุงูู ุฅุฌุฑุงุก ุถุจุท ุฏููู ููููุฐุฌู ุนูู ุนุฏุฏ ุฃูุจุฑ ูู ุงูุฃูุซูุฉ ูุชุญุตู ุนูู ูุชุงุฆุฌ ุฃูุถู.

</Tip>

ููููู ุฃูุถูุง ุฅุนุงุฏุฉ ุชูููุฐ ูุชุงุฆุฌ `pipeline` ูุฏูููุง ุฅุฐุง ุฑุบุจุช ุจุฐูู:

<frameworkcontent>
<pt>
ุญููู ูุนุงูุฌูุง (processor) ูุชููุฆุฉ ููู ุงูุตูุช ูุงููุต ูุฅุฑุฌุงุน `input` ุนูู ุดูู ููุชุฑุงุช PyTorch:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("stevhliu/my_awesome_asr_mind_model")
>>> inputs = processor(dataset[0]["audio"]["array"], sampling_rate=sampling_rate, return_tensors="pt")
```

ูุฑูุฑ ุงูููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ ูุงุณุชุฑุฌุน ุงูููู ุงูููุบุงุฑูุฉ (logits):

```py
>>> from transformers import AutoModelForCTC

>>> model = AutoModelForCTC.from_pretrained("stevhliu/my_awesome_asr_mind_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

ุงุญุตู ุนูู `input_ids` ุงููุชูุจุฃ ุจูุง ุฐุงุช ุงูุงุญุชูุงููุฉ ุงูุฃุนููุ ุซู ุงุณุชุฎุฏู ุงููุนุงูุฌ (processor) ููู ุชุดููุฑ `input_ids` ุงููุชูุจุฃ ุจูุง ุฅูู ูุต:

```py
>>> import torch

>>> predicted_ids = torch.argmax(logits, dim=-1)
>>> transcription = processor.batch_decode(predicted_ids)
>>> transcription
['I WOUD LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']
```
</pt>
</frameworkcontent>
