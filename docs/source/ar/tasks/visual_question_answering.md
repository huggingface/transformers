<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

โ๏ธ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ุงูุฅุฌุงุจุฉ ุนู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ (Visual Question Answering)

[[open-in-colab]]

ุงูุฅุฌุงุจุฉ ุนู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ (VQA) ูู ูููุฉ ุงูุฅุฌุงุจุฉ ุนู ุฃุณุฆูุฉ ููุชูุญุฉ ุงุณุชูุงุฏูุง ุฅูู ุตูุฑุฉ.
ุนุงุฏุฉู ูุง ูููู ููุฏุฎู ุงูููุงุฐุฌ ุงูุฏุงุนูุฉ ููุฐู ุงููููุฉ ุนุจุงุฑุฉ ุนู ูุฒูุฌ ูู ุตูุฑุฉ ูุณุคุงูุ ููููู ุงููุฎุฑุฌ ุฅุฌุงุจุฉ ููุนุจููุฑูุง ุนููุง ุจูุบุฉ ุทุจูุนูุฉ.

ุฃูุซูุฉ ุฌุฏูุฑุฉ ุจุงูุฐูุฑ ูุงุณุชุฎุฏุงูุงุช VQA:
- ุงูุฅุชุงุญุฉ: ุชุทุจููุงุช ููุณุงุนุฏุฉ ุฐูู ุงูุฅุนุงูุฉ ุงูุจุตุฑูุฉ.
- ุงูุชุนููู: ุทุฑุญ ุฃุณุฆูุฉ ุญูู ุงูููุงุฏ ุงููุฑุฆูุฉ ุงูููุฏูููุฉ ูู ุงููุญุงุถุฑุงุช ุฃู ุงููุชุจ. ูููู ุฃูุถูุง ุงุณุชุฎุฏุงู VQA ูู ุงููุนุงุฑุถ ุงููุชุญููุฉ ุงูุชูุงุนููุฉ ุฃู ุงูููุงูุน ุงูุชุงุฑูุฎูุฉ.
- ุฎุฏูุฉ ุงูุนููุงุก ูุงูุชุฌุงุฑุฉ ุงูุฅููุชุฑูููุฉ: ูููู ุฃู ูุนุฒููุฒ VQA ุชุฌุฑุจุฉ ุงููุณุชุฎุฏู ุจุงูุณูุงุญ ููู ุจุทุฑุญ ุฃุณุฆูุฉ ุญูู ุงูููุชุฌุงุช.
- ุงุณุชุฑุฌุงุน ุงูุตูุฑ: ูููู ุงุณุชุฎุฏุงู ููุงุฐุฌ VQA ูุงุณุชุฑุฌุงุน ุงูุตูุฑ ุฐุงุช ุงูุฎุตุงุฆุต ุงููุญุฏุฏุฉ. ุนูู ุณุจูู ุงููุซุงูุ ูุณุชุทูุน ุงููุณุชุฎุฏู ุฃู ูุณุฃู "ูู ููุฌุฏ ููุจุ" ููุนุซูุฑ ุนูู ุฌููุน ุงูุตูุฑ ุงูุชู ุชุญุชูู ุนูู ููุงุจ ูู ูุฌููุนุฉ ุตูุฑ.

ูู ูุฐุง ุงูุฏููู ุณุชุชุนูู ููู:

- ุชุถุจุท ูููุฐุฌ VQA ุชุตูููููุงุ ุชุญุฏูุฏูุง [ViLT](../model_doc/vilt)ุ ุนูู [ูุฌููุนุฉ ุจูุงูุงุช `Graphcore/vqa`](https://huggingface.co/datasets/Graphcore/vqa).
- ุชุณุชุฎุฏู ูููุฐุฌ ViLT ุงููุถุจูุท ููุงุณุชุฏูุงู.
- ุชุดุบูู ุงุณุชุฏูุงู VQA ุจุฏูู ุชุฏุฑูุจ ูุณุจู ุจุงุณุชุฎุฏุงู ูููุฐุฌ ุชูููุฏู ูุซู BLIP-2.

## ุถุจุท ViLT

ููุถูููู ูููุฐุฌ ViLT ุชุถูููุงุช ูุตูุฉ ุฏุงุฎู ูุญููู ุฑุคูุฉ (ViT)ุ ููุง ูุชูุญ ุชุตููููุง ุจุณูุทูุง ููุฑุญูุฉ ุงูุชุฏุฑูุจ ุงููุณุจู ููุฑุคูุฉ ูุงููุบุฉ (VLP).
ูููู ุงุณุชุฎุฏุงู ูุฐุง ุงููููุฐุฌ ูุนุฏุฉ ููุงู ูุงุญูุฉ. ููููุฉ VQAุ ูููุถูุน ุฑุฃุณ ุชุตูููู ูู ุงูุฃุนูู (ุทุจูุฉ ุฎุทูุฉ ููู ุงูุญุงูุฉ ุงููุฎููุฉ ุงูููุงุฆูุฉ ูุฑูุฒ `[CLS]`) ููููููุฃ ุนุดูุงุฆููุง.
ูููุฐุง ุชูุนุงููู ูููุฉ VQA ุนูู ุฃููุง "ูุดููุฉ ุชุตููู".

ุชุชุนุงูู ุงูููุงุฐุฌ ุงูุฃุญุฏุซุ ูุซู BLIP ูBLIP-2 ูInstructBLIPุ ูุน VQA ุจูุตููุง ูููุฉ ุชูููุฏูุฉ. ุณููุถูุญ ูุงุญููุง ูู ูุฐุง ุงูุฏููู ููููุฉ ุงุณุชุฎุฏุงููุง ููุงุณุชุฏูุงู ุจุฏูู ุชุฏุฑูุจ ูุณุจู.

ูุจู ุฃู ุชุจุฏุฃุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงููุงุฒูุฉ.

```bash
pip install -q transformers datasets
```

ููุตูู ุจูุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจู ุนูู Hugging Face ูุฑูุนู ุฅูู ๐ค Hub.
ุนูุฏ ุงููุทุงูุจุฉุ ุฃุฏุฎู ุฑูุฒู ูุชุณุฌูู ุงูุฏุฎูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

ููุนุฑูู ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ููุชุบูุฑ ุนุงู:

```py
>>> model_checkpoint = "dandelin/vilt-b32-mlm"
```

## ุชุญููู ุงูุจูุงูุงุช

ูุฃุบุฑุงุถ ุงูุดุฑุญุ ูุณุชุฎุฏู ูู ูุฐุง ุงูุฏููู ุนููุฉ ุตุบูุฑุฉ ุฌุฏูุง (200 ูุซุงู) ูู ุฌุฒุก ุงูุชุญูู ูู ูุฌููุนุฉ ุจูุงูุงุช `Graphcore/vqa` ุงูุฎุงุตุฉ ุจุงูุฅุฌุงุจุฉ ุนู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ.
ููููู ุงูุนุซูุฑ ุนูู ุงููุฌููุนุฉ ุงููุงููุฉ ุนูู [๐ค Hub](https://huggingface.co/datasets/Graphcore/vqa).

ูุจุฏูู ุนู [ูุฌููุนุฉ ุจูุงูุงุช `Graphcore/vqa`](https://huggingface.co/datasets/Graphcore/vqa)ุ ููููู ุชูุฒูู ููุณ ุงูุจูุงูุงุช ูุฏูููุง ูู [ุตูุญุฉ ูุฌููุนุฉ ุจูุงูุงุช VQA ุงูุฑุณููุฉ](https://visualqa.org/download.html).
ุฅุฐุง ูุถููุช ูุชุงุจุนุฉ ุงูุฏููู ุจุงุณุชุฎุฏุงู ุจูุงูุงุชู ุงููุฎุตูุตุฉุ ุฑุงุฌุน ููููุฉ [ุฅูุดุงุก ูุฌููุนุฉ ุจูุงูุงุช ุตูุฑ](https://huggingface.co/docs/datasets/image_dataset#loading-script) ูู ุชูุซูู ๐ค Datasets.

ููุญููู ุฃูู 200 ูุซุงู ูู ุฌุฒุก ุงูุชุญูู ููุณุชูุดู ููุฒุงุช ุงููุฌููุนุฉ:

```python
>>> from datasets import load_dataset

>>> dataset = load_dataset("Graphcore/vqa", split="validation[:200]")
>>> dataset
Dataset({
    features: ['question', 'question_type', 'question_id', 'image_id', 'answer_type', 'label'],
    num_rows: 200
})
```

ููููู ูุธุฑุฉ ุนูู ูุซุงู ูููู ููุฒุงุช ุงููุฌููุนุฉ:

```py
>>> dataset[0]
{'question': 'Where is he looking?',
 'question_type': 'none of the above',
 'question_id': 262148000,
 'image_id': '/root/.cache/huggingface/datasets/downloads/extracted/ca733e0e000fb2d7a09fbcc94dbfe7b5a30750681d0e965f8e0a23b1c2f98c75/val2014/COCO_val2014_000000262148.jpg',
 'answer_type': 'other',
 'label': {'ids': ['at table', 'down', 'skateboard', 'table'],
  'weights': [0.30000001192092896,
   1.0,
   0.30000001192092896,
   0.30000001192092896]}}
```

ุงูููุฒุงุช ุฐุงุช ุงูุตูุฉ ุจุงููููุฉ ุชุชุถูู:
- `question`: ุงูุณุคุงู ุงูููุฑุงุฏ ุงูุฅุฌุงุจุฉ ุนูู ูู ุงูุตูุฑุฉ
- `image_id`: ูุณุงุฑ ุงูุตูุฑุฉ ุงูุชู ููุดูุฑ ุฅูููุง ุงูุณุคุงู
- `label`: ุงูุชูุณููุงุช/ุงูุชุฑููุฒุงุช

ูููููุง ุฅุฒุงูุฉ ุจููุฉ ุงูููุฒุงุช ูุฃููุง ูู ุชููู ุถุฑูุฑูุฉ:

```py
>>> dataset = dataset.remove_columns(['question_type', 'question_id', 'answer_type'])
```

ููุง ุชุฑูุ ุชุญุชูู ููุฒุฉ `label` ุนูู ุนุฏุฉ ุฅุฌุงุจุงุช ููุณุคุงู ููุณู (ุชุณูู ููุง `ids`) ุฌูููุนุช ูู ููุนูููููู ุจุดุฑููู ูุฎุชูููู.
ุฐูู ูุฃู ุงูุฅุฌุงุจุฉ ุนู ุณุคุงู ูุง ูุฏ ุชููู ุฐุงุชูุฉ. ูู ูุฐุง ุงููุซุงูุ ุงูุณุคุงู ูู "ุฃูู ููุธุฑุ". ุจุนุถ ุงูุฃุดุฎุงุต ูุณููู ุจู"down"ุ ูุขุฎุฑูู ุจู"at table"ุ ูุขุฎุฑ ุจู"skateboard"ุ ุฅูุฎ.

ุงูุธุฑ ุฅูู ุงูุตูุฑุฉ ููููุฑ ุฃู ุฅุฌุงุจุฉ ุณุชุนุทู:

```python
>>> from PIL import Image

>>> image = Image.open(dataset[0]['image_id'])
>>> image
```

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/vqa-example.png" alt="VQA Image Example"/>
</div>

ูุธุฑูุง ูุบููุถ ุงูุฃุณุฆูุฉ ูุงูุฃุฌูุจุฉุ ุชูุนุงููู ูุฌููุนุงุช ููุฐู ููุดููุฉ ุชุตููู ูุชุนุฏุฏ ุงูููุตูุงุช (ุฅุฐ ูุฏ ุชููู ุนุฏุฉ ุฅุฌุงุจุงุช ุตุญูุญุฉ).
ูุนูุถูุง ุนู ุฅูุดุงุก ูุชุฌู ุชุฑููุฒ ุฃุญุงุฏู (one-hot) ููุทุ ูููุดุฆ ุชุฑููุฒูุง ููููุง (soft) ุงุนุชูุงุฏูุง ุนูู ุนุฏุฏ ูุฑุงุช ุธููุฑ ุฅุฌุงุจุฉ ูุนูููุฉ ูู ุงูุชุนูููุงุช.

ุนูู ุณุจูู ุงููุซุงู ุฃุนูุงูุ ูุฃู ุงูุฅุฌุงุจุฉ "down" ููุฎุชุงุฑุฉ ุฃูุซุฑ ุจูุซูุฑ ูู ุงูุฅุฌุงุจุงุช ุงูุฃุฎุฑูุ ุชุญุตู ุนูู ุฏุฑุฌุฉ (ุชูุณูู `weight` ูู ุงููุฌููุนุฉ) ูุฏุฑูุง 1.0ุ ุจูููุง ุจููุฉ ุงูุฅุฌุงุจุงุช ุฃูู ูู 1.0.

ูุงุญููุง ูุชููุฆุฉ ุฑุฃุณ ุชุตูููู ููุงุณุจ ูู ุงููููุฐุฌุ ูููุดุฆ ูุงููุณูู: ุฃุญุฏููุง ูุญููู ุงุณู ุงููุณู ุฅูู ุนุฏุฏ ุตุญูุญุ ูุงูุขุฎุฑ ูุนูุณู:

```py
>>> import itertools

>>> labels = [item['ids'] for item in dataset['label']]
>>> flattened_labels = list(itertools.chain(*labels))
>>> unique_labels = list(set(flattened_labels))

>>> label2id = {label: idx for idx, label in enumerate(unique_labels)}
>>> id2label = {idx: label for label, idx in label2id.items()}
```

ุงูุขู ุจุนุฏ ุฃู ุฃุตุจุญ ูุฏููุง ุงูุฎุฑุงุฆุทุ ูููููุง ุงุณุชุจุฏุงู ุงูุฅุฌุงุจุงุช ุงููุตูุฉ ุจูุนุฑููุงุชูุงุ ูุชุณุทูุญ ุงููุฌููุนุฉ ูุชููุฆุฉ ุงููุนุงูุฌุฉ ุงููุงุญูุฉ ุจุดูู ุฃุณูู:

```python
>>> def replace_ids(inputs):
...   inputs["label"]["ids"] = [label2id[x] for x in inputs["label"]["ids"]]
...   return inputs


>>> dataset = dataset.map(replace_ids)
>>> flat_dataset = dataset.flatten()
>>> flat_dataset.features
{'question': Value(dtype='string', id=None),
 'image_id': Value(dtype='string', id=None),
 'label.ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),
 'label.weights': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}
```

## ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุจูุงูุงุช

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ููุนุงูุฌ ViLT ูุชุญุถูุฑ ุจูุงูุงุช ุงูุตูุฑุฉ ูุงููุต ูููููุฐุฌ.
ูููู [`ViltProcessor`] ูููุณููู BERT ูููุนุงูุฌ ุตูุฑ ViLT ุถูู ููุนุงูุฌ ูุงุญุฏ ูุฑูุญ:

```py
>>> from transformers import ViltProcessor

>>> processor = ViltProcessor.from_pretrained(model_checkpoint)
```

ููุนุงูุฌุฉ ุงูุจูุงูุงุช ูุณุจููุง ูุญุชุงุฌ ุฅูู ุชุฑููุฒ ุงูุตูุฑ ูุงูุฃุณุฆูุฉ ุจุงุณุชุฎุฏุงู [`ViltProcessor`]. ุณูุณุชุฎุฏู ุงูููุนุงูุฌ [`BertTokenizerFast`] ูุชูุณูู ุงููุต ูุฅูุดุงุก
`input_ids` ู`attention_mask` ู`token_type_ids` ูุจูุงูุงุช ุงููุต. ูุจุงููุณุจุฉ ููุตูุฑุ ุณูุณุชููุฏ ุงูููุนุงูุฌ ูู [`ViltImageProcessor`] ูุชุบููุฑ ุงูุญุฌู ูุชุทุจูุน ุงูุตูุฑุฉุ ูุฅูุดุงุก `pixel_values` ู`pixel_mask`.

ุชุชู ุฌููุน ุฎุทูุงุช ุงููุนุงูุฌุฉ ูุฐู ุฎูู ุงูููุงููุณุ ููู ูุง ูุญุชุงุฌ ุฅููู ูู ุงุณุชุฏุนุงุก `processor`. ููููุง ูุง ุฒููุง ุจุญุงุฌุฉ ูุชุญุถูุฑ ุงูููุตูุงุช ุงููุฏู. ูู ูุฐุง ุงูุชูุซููุ ููุงุจู ูู ุนูุตุฑ ุฅุฌุงุจุฉู ูุญุชููุฉ (ูุณููุง). ููุฅุฌุงุจุงุช ุงูุตุญูุญุฉุ ูุญูู ุงูุนูุตุฑ ุฏุฑุฌุชูุง ุงูููุงุจูุฉ (ุงููุฒู)ุ ุจูููุง ุชูุถุจุท ุงูุนูุงุตุฑ ุงููุชุจููุฉ ุนูู ุงูุตูุฑ.

ุชูุทุจูู ุงูุฏุงูุฉ ุงูุชุงููุฉ `processor` ุนูู ุงูุตูุฑ ูุงูุฃุณุฆูุฉ ูุชูุณูู ุงูููุตูุงุช ููุง ูู ููุตูู ุฃุนูุงู:

```py
>>> import torch

>>> def preprocess_data(examples):
...     image_paths = examples['image_id']
...     images = [Image.open(image_path) for image_path in image_paths]
...     texts = examples['question']

...     encoding = processor(images, texts, padding="max_length", truncation=True, return_tensors="pt")

...     for k, v in encoding.items():
...           encoding[k] = v.squeeze()

...     targets = []

...     for labels, scores in zip(examples['label.ids'], examples['label.weights']):
...         target = torch.zeros(len(id2label))

...         for label, score in zip(labels, scores):
...             target[label] = score

...         targets.append(target)

...     encoding["labels"] = targets

...     return encoding
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุนูู ูุงูู ุงููุฌููุนุฉุ ุงุณุชุฎุฏู ุฏุงูุฉ ๐ค Datasets [`~datasets.map`]. ููููู ุชุณุฑูุน `map` ุนุจุฑ ุถุจุท `batched=True` ููุนุงูุฌุฉ ุนุฏุฉ ุนูุงุตุฑ ุฏูุนุฉู ูุงุญุฏุฉ. ูู ูุฐู ุงููุฑุญูุฉุ ูุง ุชุชุฑุฏุฏ ูู ุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุบูุฑ ุงููุงุฒูุฉ.

```py
>>> processed_dataset = flat_dataset.map(preprocess_data, batched=True, remove_columns=['question','question_type',  'question_id', 'image_id', 'answer_type', 'label.ids', 'label.weights'])
>>> processed_dataset
Dataset({
    features: ['input_ids', 'token_type_ids', 'attention_mask', 'pixel_values', 'pixel_mask', 'labels'],
    num_rows: 200
})
```

ูุฎุทูุฉ ุฃุฎูุฑุฉุ ุฃูุดุฆ ุฏูุนุฉ ุฃูุซูุฉ ุจุงุณุชุฎุฏุงู [`DefaultDataCollator`]:

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator()
```

## ุชุฏุฑูุจ ุงููููุฐุฌ

ุฃุตุจุญุช ุฌุงูุฒูุง ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู ุงูุขู! ุญููู ViLT ุจุงุณุชุฎุฏุงู [`ViltForQuestionAnswering`]. ุญุฏูุฏ ุนุฏุฏ ุงููุณูู ูุน ุฎุฑุงุฆุท ุงููุณูู:

```py
>>> from transformers import ViltForQuestionAnswering

>>> model = ViltForQuestionAnswering.from_pretrained(model_checkpoint, num_labels=len(id2label), id2label=id2label, label2id=label2id)
```

ูู ูุฐู ุงููุฑุญูุฉุ ุชุจูู ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุนุฑูู ูุฑุทููุงุช ุงูุชุฏุฑูุจ ูู [`TrainingArguments`]:

```py
>>> from transformers import TrainingArguments

>>> repo_id = "MariaK/vilt_finetuned_200"

>>> training_args = TrainingArguments(
...     output_dir=repo_id,
...     per_device_train_batch_size=4,
...     num_train_epochs=20,
...     save_steps=200,
...     logging_steps=50,
...     learning_rate=5e-5,
...     save_total_limit=2,
...     remove_unused_columns=False,
...     push_to_hub=True,
... )
```

2. ูุฑูุฑ ูุนุงููุงุช ุงูุชุฏุฑูุจ ุฅูู [`Trainer`] ูุน ุงููููุฐุฌ ูุงููุฌููุนุฉ ูุงูููุนุงูุฌ ููุฌููุน ุงูุจูุงูุงุช.

```py
>>> from transformers import Trainer

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     data_collator=data_collator,
...     train_dataset=processed_dataset,
...     processing_class=processor,
... )
```

3. ุงุณุชุฏุนู [`~Trainer.train`] ูุถุจุท ูููุฐุฌู.

```py
>>> trainer.train()
```

ุจุนุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ุนูู Hub ุจุงุณุชุฎุฏุงู ุงูุชุงุจุน [`~Trainer.push_to_hub`] ููุดุงุฑูุฉ ูููุฐุฌู ุงูููุงุฆู ุนูู ๐ค Hub:

```py
>>> trainer.push_to_hub()
```

## ุงูุงุณุชุฏูุงู

ุงูุขู ุจุนุฏ ุฃู ุถุจุทุช ูููุฐุฌ ViLT ูุฑูุนุชู ุฅูู ๐ค Hubุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชุฏูุงู. ุฃุจุณุท ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงููุถุจูุท ููุงุณุชุฏูุงู ูู ุงุณุชุฎุฏุงูู ุถูู [`Pipeline`].

```py
>>> from transformers import pipeline

>>> pipe = pipeline("visual-question-answering", model="MariaK/vilt_finetuned_200")
```

ูู ููุฏุฑููุจ ุงููููุฐุฌ ูู ูุฐุง ุงูุฏููู ุฅูุง ุนูู 200 ูุซุงูุ ูุฐุง ูุง ุชุชููุน ุงููุซูุฑ ููู. ููุฑู ุฅู ูุงู ูุฏ ุชุนููู ุดูุฆูุง ูุง ุนูู ุงูุฃููุ ูููุฃุฎุฐ ุงููุซุงู ุงูุฃูู ูู ุงููุฌููุนุฉ ูุดุฑุญ ุงูุงุณุชุฏูุงู:

```py
>>> example = dataset[0]
>>> image = Image.open(example['image_id'])
>>> question = example['question']
>>> print(question)
>>> pipe(image, question, top_k=1)
"Where is he looking?"
[{'score': 0.5498199462890625, 'answer': 'down'}]
```

ุนูู ุงูุฑุบู ูู ุฃู ุงูุซูุฉ ููุณุช ุนุงููุฉุ ูุจุฏู ุฃู ุงููููุฐุฌ ูุฏ ุชุนููู ุดูุฆูุง ุจุงููุนู. ูุน ูุฒูุฏ ูู ุงูุฃูุซูุฉ ูุชุฏุฑูุจ ุฃุทููุ ุณุชุญุตู ุนูู ูุชุงุฆุฌ ุฃูุถู ุจูุซูุฑ!

ููููู ุฃูุถูุง ุฅุนุงุฏุฉ ุฅูุชุงุฌ ูุชุงุฆุฌ ุงูุฃูุจูุจ ูุฏูููุง ุฅุฐุง ุฑุบุจุช:
1. ุฎูุฐ ุตูุฑุฉู ูุณุคุงููุงุ ูุญุถูุฑูููุง ูููููุฐุฌ ุจุงุณุชุฎุฏุงู ุงูููุนุงูุฌ ูู ูููุฐุฌู.
2. ูุฑูุฑ ูุชูุฌุฉ ุงููุนุงูุฌุฉ ุนุจุฑ ุงููููุฐุฌ.
3. ูู ุงูููุฌูุชุ ุงุญุตู ุนูู ูุนุฑูู ุงูุฅุฌุงุจุฉ ุงูุฃูุซุฑ ุงุญุชูุงููุงุ ูุงุนุซุฑ ุนูู ุงูุฅุฌุงุจุฉ ุงููุนููุฉ ูู `id2label`.

```py
>>> processor = ViltProcessor.from_pretrained("MariaK/vilt_finetuned_200")

>>> image = Image.open(example['image_id'])
>>> question = example['question']

>>> # prepare inputs
>>> inputs = processor(image, question, return_tensors="pt")

>>> model = ViltForQuestionAnswering.from_pretrained("MariaK/vilt_finetuned_200")

>>> # forward pass
>>> with torch.no_grad():
...     outputs = model(**inputs)

>>> logits = outputs.logits
>>> idx = logits.argmax(-1).item()
>>> print("Predicted answer:", model.config.id2label[idx])
Predicted answer: down
```

## VQA ุจุฏูู ุชุฏุฑูุจ ูุณุจู

ุนุงูุฌ ุงููููุฐุฌ ุงูุณุงุจู VQA ููููุฉ ุชุตููู. ุจุนุถ ุงูููุงุฐุฌ ุงูุญุฏูุซุฉ ูุซู BLIP ูBLIP-2 ูInstructBLIP ุชุชุนุงูู ูุน VQA ููููุฉ ุชูููุฏูุฉ.
ููุฃุฎุฐ [BLIP-2](../model_doc/blip-2) ูุซุงููุง. ูุฏูู BLIP-2 ููุฌ ุชุฏุฑูุจ ูุณุจู ููุฑุคูุฉ ูุงููุบุฉ ูุณูุญ ุจุงุณุชุฎุฏุงู ุฃู ุชููููุฉ ูู ููุฑููุฒ ุฑุคูุฉ ููููุฐุฌ ูุบุฉ ูุจูุฑ (ุชุนุฑู ุฃูุซุฑ ูู [ููุงู BLIP-2](https://huggingface.co/blog/blip-2)).
ูููููู ูุฐุง ูู ุชุญููู ุฃุญุฏุซ ุงููุชุงุฆุฌ ุงููููุฉ ูู ููุงู ุงูุฑุคูุฉ ูุงููุบุฉุ ุจูุง ูู ุฐูู ุงูุฅุฌุงุจุฉ ุนู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ.

ูููุถูุญ ููู ููููู ุงุณุชุฎุฏุงู ูุฐุง ุงููููุฐุฌ ูู VQA. ุฃูููุงุ ููุญููู ุงููููุฐุฌ. ุณูุฑุณู ุงููููุฐุฌ ุตุฑุงุญุฉู ุฅูู ูุนุงูุฌ ุฑุณููู GPU ุฅู ูุงู ูุชุงุญูุงุ ููู ูุง ูู ูุญุชุฌู ุณุงุจููุง ุฃุซูุงุก ุงูุชุฏุฑูุจุ ุฅุฐ ูุชูููู [`Trainer`] ุจุฐูู ุชููุงุฆููุง:

```py
>>> from transformers import AutoProcessor, Blip2ForConditionalGeneration
>>> import torch
>>> from accelerate.test_utils.testing import get_backend

>>> processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")
>>> model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b", torch_dtype=torch.float16)
>>> device, _, _ = get_backend() # ููุชุดู ุชููุงุฆููุง ููุน ุงูุฌูุงุฒ ุงูุฃุณุงุณู (CUDA ุฃู CPU ุฃู XPU ุฃู MPS ...)
>>> model.to(device)
```

ูุชููู ุงููููุฐุฌ ุตูุฑุฉ ููุตูุง ููุฏุฎูุ ูุฐุง ุณูุณุชุฎุฏู ููุณ ุฒูุฌ ุงูุตูุฑุฉ/ุงูุณุคุงู ูู ุงููุซุงู ุงูุฃูู ูู ูุฌููุนุฉ VQA:

```py
>>> example = dataset[0]
>>> image = Image.open(example['image_id'])
>>> question = example['question']
```

ูุงุณุชุฎุฏุงู BLIP-2 ูู ูููุฉ ุงูุฅุฌุงุจุฉ ุนู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉุ ูุฌุจ ุฃู ูุชุจุน ุงููููุฌููู ุงููุตู ุชูุณูููุง ูุญุฏุฏูุง: `Question: {} Answer:`.

```py
>>> prompt = f"Question: {question} Answer:"
```

ุงูุขู ูุญุชุงุฌ ููุนุงูุฌุฉ ุงูุตูุฑุฉ/ุงูููุฌููู ุจููุนุงูุฌ ุงููููุฐุฌุ ุซู ุชูุฑูุฑ ุงููุฏุฎูุงุช ุงููุนุงูุฌุฉ ุนุจุฑ ุงููููุฐุฌุ ููู ุชุฑููุฒ ุงููุฎุฑุฌุงุช:

```py
>>> inputs = processor(image, text=prompt, return_tensors="pt").to(device, torch.float16)

>>> generated_ids = model.generate(**inputs, max_new_tokens=10)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
>>> print(generated_text)
"He is looking at the crowd"
```

ููุง ุชุฑูุ ุชุนุฑูู ุงููููุฐุฌ ุนูู ุงูุญุดุฏ ูุงุชุฌุงู ุงููุฌู (ุงููุธุฑ ููุฃุณูู)ุ ูููู ูุจุฏู ุฃูู ูู ููุชูุท ุญูููุฉ ุฃู ุงูุญุดุฏ ุฎูู ุงููุชุฒููุฌ. ููุน ุฐููุ ูู ุงูุญุงูุงุช ุงูุชู ูุตุนุจ ูููุง ุงูุญุตูู ุนูู ูุฌููุนุงุช ุจูุงูุงุช ููุนูููุฉ ุจุดุฑููุงุ ูููู ุฃู ููุชุฌ ูุฐุง ุงูููุฌ ูุชุงุฆุฌ ูููุฏุฉ ุจุณุฑุนุฉ.
