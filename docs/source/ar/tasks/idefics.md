<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

โ๏ธ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ููุงู ุงูุตูุฑ ุจุงุณุชุฎุฏุงู IDEFICS

[[open-in-colab]]

ุจูููุง ูููู ุงูุชุนุงูู ูุน ุงูููุงู ุงููุฑุฏูุฉ ุนุจุฑ ุชุญุณูู (Fine-tuning) ููุงุฐุฌ ูุชุฎุตุตุฉุ ุธูุฑุช ููุงุฑุจุฉ ุจุฏููุฉ ูุคุฎุฑูุง ูุงูุชุณุจุช ุดุนุจูุฉุ ููู ุงุณุชุฎุฏุงู ููุงุฐุฌ ุถุฎูุฉ ููุฌููุนุฉ ูุชููุนุฉ ูู ุงูููุงู ุฏูู ุชุญุณูู. ุนูู ุณุจูู ุงููุซุงูุ ูููู ูููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงูุชุนุงูู ูุน ููุงู ุงููุนุงูุฌุฉ ุงููุบููุฉ ุงูุทุจูุนูุฉ ูุซู ุงูุชูุฎูุต ูุงูุชุฑุฌูุฉ ูุงูุชุตููู ูุงููุฒูุฏ. ูู ูุนุฏ ูุฐุง ุงูููุฌ ููุชุตุฑูุง ุนูู ุฃุณููุจ ูุงุญุฏ ูุซู ุงููุต ููุทุ ููู ูุฐุง ุงูุฏููู ุณููุถุญ ููู ููููู ุญู ููุงู ุงูุตูุฑุฉ-ูุต ุจุงุณุชุฎุฏุงู ูููุฐุฌ ูุชุนุฏุฏ ุงููุณุงุฆุท ูุจูุฑ ููุฏุนู IDEFICS.

[IDEFICS](../model_doc/idefics) ูู ูููุฐุฌ ุฑุคูุฉ ููุบุฉ ููุชูุญ ุงููุตูู ูุนุชูุฏ ุนูู [Flamingo](https://huggingface.co/papers/2204.14198)ุ ููู ูููุฐุฌ ุฑุงุฆุฏ ููุบุฉ ุงููุฑุฆูุฉ ุทูููุฑ ูุจุฏุฆููุง ุจูุงุณุทุฉ DeepMind. ููุจู ุงููููุฐุฌ ุชุณูุณูุงุช ุนุดูุงุฆูุฉ ูู ูุฏุฎูุงุช ุงูุตูุฑ ูุงููุตูุต ูููููุฏ ูุตูุง ูุชูุงุณููุง ููุฎุฑุฌ. ููููู ุงูุฅุฌุงุจุฉ ุนู ุฃุณุฆูุฉ ุญูู ุงูุตูุฑุ ููุตู ุงููุญุชูู ุงูุจุตุฑูุ ูุงุจุชูุงุฑ ูุตุต ูุณุชูุฏุฉ ุฅูู ุนุฏุฉ ุตูุฑุ ูุบูุฑ ุฐูู. ูุฃุชู IDEFICS ุจูุณุฎุชูู: [80 ูููุงุฑ ูุนููุฉ](https://huggingface.co/HuggingFaceM4/idefics-80b) ู[9 ูููุงุฑุงุช ูุนููุฉ](https://huggingface.co/HuggingFaceM4/idefics-9b)ุ ูููุงููุง ูุชุงุญ ุนูู ๐ค Hub. ูููู ูุณุฎุฉุ ุณุชุฌุฏ ุฃูุถูุง ุฅุตุฏุงุฑุงุช ูุญุณููุฉ ุจุงูุชุนูููุงุช ูููููุฉ ูุญุงูุงุช ุงูุงุณุชุฎุฏุงู ุงูุญูุงุฑูุฉ.

ูุฐุง ุงููููุฐุฌ ูุชุนุฏุฏ ุงูุงุณุชุฎุฏุงูุงุช ุจุดูู ุงุณุชุซูุงุฆู ููููู ุงุณุชุฎุฏุงูู ููุฌููุนุฉ ูุงุณุนุฉ ูู ููุงู ุงูุตูุฑ ูุงูููุงู ูุชุนุฏุฏุฉ ุงููุณุงุฆุท. ููู ูููู ูููุฐุฌูุง ูุจูุฑูุง ูุนูู ุฃูู ูุชุทูุจ ููุงุฑุฏ ุญูุณุจุฉ ูุจููุฉ ุชุญุชูุฉ ูุจูุฑุฉ. ูุนูุฏ ูู ุชุญุฏูุฏ ูุง ุฅุฐุง ูุงู ูุฐุง ุงูููุฌ ููุงุณุจูุง ูุญุงูุชู ุฃูุซุฑ ูู ุชุญุณูู ููุงุฐุฌ ูุชุฎุตุตุฉ ููู ูููุฉ ูุฑุฏูุฉ.

ูู ูุฐุง ุงูุฏูููุ ุณุชุชุนูู ููููุฉ:
- [ุชุญููู IDEFICS](#loading-the-model) ู[ุชุญููู ุงููุณุฎุฉ ุงููููููููุฉ ูู ุงููููุฐุฌ](#quantized-model)
- ุงุณุชุฎุฏุงู IDEFICS ูู: 
  - [ูุตู ุงูุตูุฑ (Image captioning)](#image-captioning)
  - [ูุตู ุงูุตูุฑ ูุน ุชุญููุฒ ูุตู (Prompted image captioning)](#prompted-image-captioning)
  - [ุงูุชุญููุฒ ุจุนุฏุฉ ุฃูุซูุฉ (Few-shot prompting)](#few-shot-prompting)
  - [ุงูุฅุฌุงุจุฉ ุงูุจุตุฑูุฉ ุนู ุงูุฃุณุฆูุฉ (VQA)](#visual-question-answering)
  - [ุชุตููู ุงูุตูุฑ](#image-classification)
  - [ุชูููุฏ ูุต ููุฌูู ุจุงูุตูุฑ](#image-guided-text-generation)
- [ุชุดุบูู ุงูุงุณุชุฏูุงู ุนูู ุฏูุนุงุช](#running-inference-in-batch-mode)
- [ุชุดุบูู IDEFICS instruct ููุงุณุชุฎุฏุงู ุงูุญูุงุฑู](#idefics-instruct-for-conversational-use)

ูุจู ุฃู ุชุจุฏุฃุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงููุงุฒูุฉ.

```bash
pip install -q bitsandbytes sentencepiece accelerate transformers
```

<Tip>
ูุชุดุบูู ุงูุฃูุซูุฉ ุงูุชุงููุฉ ุจุงุณุชุฎุฏุงู ูุณุฎุฉ ุบูุฑ ูููููููุฉ ูู ููุทุฉ ุชุญูู ุงููููุฐุฌุ ุณุชุญุชุงุฌ ุฅูู 20GB ุนูู ุงูุฃูู ูู ุฐุงูุฑุฉ GPU.
</Tip>

## Loading the model

ููุจุฏุฃ ุจุชุญููู ููุทุฉ ุชุญูู ุงููุณุฎุฉ ุฐุงุช 9 ูููุงุฑุงุช ูุนููุฉ:

```py
>>> checkpoint = "HuggingFaceM4/idefics-9b"
```

ููุง ูู ุงูุญุงู ูุน ููุงุฐุฌ Transformers ุงูุฃุฎุฑูุ ุชุญุชุงุฌ ุฅูู ุชุญููู "ูุนุงูุฌ" (processor) ูุงููููุฐุฌ ููุณู ูู ููุทุฉ ุงูุชุญูู.
ููู ูุนุงูุฌ IDEFICS ูููุง ูู [`LlamaTokenizer`] ููุนุงูุฌ ุงูุตูุฑ ุงูุฎุงุต ุจู IDEFICS ูู ูุนุงูุฌ ูุงุญุฏ ููุชููู ุชุฌููุฒ ูุฏุฎูุงุช ุงููุต ูุงูุตูุฑุฉ ูููููุฐุฌ.

```py
>>> import torch

>>> from transformers import IdeficsForVisionText2Text, AutoProcessor

>>> processor = AutoProcessor.from_pretrained(checkpoint)

>>> model = IdeficsForVisionText2Text.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, device_map="auto")
```

ุชุนููู `device_map` ุฅูู `"auto"` ุณูุญุฏุฏ ุชููุงุฆููุง ููููุฉ ุชุญููู ูุชุฎุฒูู ุฃูุฒุงู ุงููููุฐุฌ ุจุฃูุซุฑ ุงูุทุฑู ููุงุกูุฉู ููุฃุฌูุฒุฉ ุงููุชุงุญุฉ.

### Quantized model

ุฅุฐุง ูุงูุช ุฐุงูุฑุฉ GPU ุนุงููุฉ ุงูุณุนุฉ ุชูุซู ูุดููุฉุ ููููู ุชุญููู ูุณุฎุฉ ูููููููุฉ ูู ุงููููุฐุฌ. ูุชุญููู ุงููููุฐุฌ ูุงููุนุงูุฌ ุจุฏูุฉ 4-ุจุชุ ูุฑูุฑ `BitsAndBytesConfig` ุฅูู ุฏุงูุฉ `from_pretrained` ูุณูุชู ุถุบุท ุงููููุฐุฌ ุฃุซูุงุก ุงูุชุญููู.

```py
>>> import torch
>>> from transformers import IdeficsForVisionText2Text, AutoProcessor, BitsAndBytesConfig

>>> quantization_config = BitsAndBytesConfig(
...     load_in_4bit=True,
...     bnb_4bit_compute_dtype=torch.float16,
... )

>>> processor = AutoProcessor.from_pretrained(checkpoint)

>>> model = IdeficsForVisionText2Text.from_pretrained(
...     checkpoint,
...     quantization_config=quantization_config,
...     device_map="auto"
... )
```

ุจุนุฏ ุฃู ููุช ุจุชุญููู ุงููููุฐุฌ ุจุฅุญุฏู ุงูุทุฑู ุงูููุชุฑุญุฉุ ูููุชูู ูุงุณุชูุดุงู ุงูููุงู ุงูุชู ููููู ุงุณุชุฎุฏุงู IDEFICS ูููุง.

## Image captioning
ูุตู ุงูุตูุฑ ูู ูููุฉ ุชููุน ุชุณููุฉ ุชูุถูุญูุฉ ูุตูุฑุฉ ูุนููุฉ. ููุนุฏ ุฐูู ุชุทุจูููุง ุดุงุฆุนูุง ููุณุงุนุฏุฉ ุฐูู ุงูุฅุนุงูุฉ ุงูุจุตุฑูุฉ ุนูู ุงูุชููู ูู ููุงูู ูุฎุชููุฉุ ูุซู ุงุณุชูุดุงู ูุญุชูู ุงูุตูุฑ ุนุจุฑ ุงูุฅูุชุฑูุช.

ูุชูุถูุญ ุงููููุฉุ ุงุญุตู ุนูู ุตูุฑุฉ ููุตููุงุ ูุซููุง:

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-im-captioning.jpg" alt="Image of a puppy in a flower bed"/>
</div>

Photo by [Hendo Wang](https://unsplash.com/@hendoo).

ููุจู IDEFICS ูุญุซูุงุช ูุตูุฉ ูุตูุฑูุฉ. ูููู ูู ุฃุฌู ูุตู ุตูุฑุฉุ ูุณุช ูุถุทุฑูุง ูุชูุฏูู ูุญุซู ูุตู ูููููุฐุฌุ ูููู ููุท ุงูุตูุฑุฉ ุงูููุญุถูุฑุฉ. ุจุฏูู ูุญุซู ูุตูุ ุณูุจุฏุฃ ุงููููุฐุฌ ุชูููุฏ ุงููุต ูู ุฑูุฒ ุจุฏุงูุฉ ุงูุชุณูุณู (BOS) ูุชูููู ุงูุชุณููุฉ ุงูุชูุถูุญูุฉ.

ููุฏุฎู ุตูุฑุฉ ูููููุฐุฌุ ููููู ุงุณุชุฎุฏุงู ูุงุฆู ุตูุฑุฉ (`PIL.Image`) ุฃู ุฑุงุจุท URL ูููู ููู ุฌูุจ ุงูุตูุฑุฉ.

```py
>>> prompt = [
...     "https://images.unsplash.com/photo-1583160247711-2191776b4b91?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3542&q=80",
... ]

>>> inputs = processor(prompt, return_tensors="pt").to("cuda")
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, max_new_tokens=10, bad_words_ids=bad_words_ids)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> print(generated_text[0])
A puppy in a flower bed
```

<Tip>
ูู ุงูุฌูุฏ ุชุถููู `bad_words_ids` ูู ุงุณุชุฏุนุงุก `generate` ูุชุฌูุจ ุฃุฎุทุงุก ูุฏ ุชูุดุฃ ุนูุฏ ุฒูุงุฏุฉ `max_new_tokens`: ุณูุญุงูู ุงููููุฐุฌ ุชูููุฏ ุฑูุฒ `<image>` ุฃู `<fake_token_around_image>` ุฌุฏูุฏ ุนูุฏูุง ูุง ุชูุฌุฏ ุตูุฑุฉ ูุฌุฑู ุชูููุฏูุง. ููููู ุชุนูููู ุฃุซูุงุก ุงูุชุดุบูู ููุง ูู ูุฐุง ุงูุฏูููุ ุฃู ุชุฎุฒููู ูู `GenerationConfig` ููุง ูู ููุถุญ ูู ุฏููู [ุงุณุชุฑุงุชูุฌูุงุช ุชูููุฏ ุงููุต](../generation_strategies).
</Tip>

## Prompted image captioning

ููููู ุชูุณูุน ูุตู ุงูุตูุฑ ุนุจุฑ ุชูุฏูู ูุญุซู ูุตู ุณููููููู ุงููููุฐุฌ ุจุงููุธุฑ ุฅูู ุงูุตูุฑุฉ. ููุฃุฎุฐ ุตูุฑุฉ ุฃุฎุฑู ููุชูุถูุญ:

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-prompted-im-captioning.jpg" alt="Image of the Eiffel Tower at night"/>
</div>

Photo by [Denys Nevozhai](https://unsplash.com/@dnevozhai).

ูููู ุชูุฑูุฑ ุงููุญุซูุงุช ุงููุตูุฉ ูุงูุตูุฑูุฉ ุฅูู ูุนุงูุฌ ุงููููุฐุฌ ููุงุฆูุฉ ูุงุญุฏุฉ ูุฅูุดุงุก ุงููุฏุฎูุงุช ุงูููุงุณุจุฉ.

```py
>>> prompt = [
...     "https://images.unsplash.com/photo-1543349689-9a4d426bee8e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3501&q=80",
...     "This is an image of ",
... ]

>>> inputs = processor(prompt, return_tensors="pt").to("cuda")
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, max_new_tokens=10, bad_words_ids=bad_words_ids)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> print(generated_text[0])
This is an image of the Eiffel Tower in Paris, France.
```

## Few-shot prompting

ุนูู ุงูุฑุบู ูู ุฃู IDEFICS ููุฏูู ูุชุงุฆุฌ ุฌูุฏุฉ ุฏูู ุฃูุซูุฉ (zero-shot)ุ ุฅูุง ุฃู ูููุชู ูุฏ ุชุชุทูุจ ุตูุบุฉ ูุนููุฉ ููุชุณููุฉ ุงูุชูุถูุญูุฉุ ุฃู ุชุฃุชู ุจูููุฏ ุฃู ูุชุทูุจุงุช ุชุฒูุฏ ูู ุชุนููุฏ ุงููููุฉ. ูููู ุงุณุชุฎุฏุงู ุงูุชุญููุฒ ุจุนุฏุฉ ุฃูุซูุฉ (few-shot) ูุชูููู ุงูุชุนูู ุฏุงุฎู ุงูุณูุงู. ุนุจุฑ ุชูุฏูู ุฃูุซูุฉ ูู ุงููุญุซูุ ููููู ุชูุฌูู ุงููููุฐุฌ ูุชูููุฏ ูุชุงุฆุฌ ุชุญุงูู ุตูุบุฉ ุงูุฃูุซูุฉ ุงููุนุทุงุฉ.

ููุณุชุฎุฏู ุตูุฑุฉ ุจุฑุฌ ุฅููู ุงูุณุงุจูุฉ ููุซุงู ูููููุฐุฌ ููุจูู ูุญุซูุง ููุถุญ ูููููุฐุฌ ุฃููุงุ ุจุงูุฅุถุงูุฉ ุฅูู ุชุนุฑูู ุงููุงุฆู ูู ุงูุตูุฑุฉุ ูุฑูุฏ ุฃูุถูุง ุงูุญุตูู ุนูู ูุนูููุฉ ููุชุนุฉ ุนูู. ุซู ููุฑู ุฅู ูุงู ุจุฅููุงููุง ุงูุญุตูู ุนูู ููุณ ุตูุบุฉ ุงูุงุณุชุฌุงุจุฉ ูุตูุฑุฉ ุชูุซุงู ุงูุญุฑูุฉ:

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg" alt="Image of the Statue of Liberty"/>
</div>

Photo by [Juan Mayobre](https://unsplash.com/@jmayobres).

```py
>>> prompt = ["User:",
...            "https://images.unsplash.com/photo-1543349689-9a4d426bee8e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3501&q=80",
...            "Describe this image.\nAssistant: An image of the Eiffel Tower at night. Fun fact: the Eiffel Tower is the same height as an 81-storey building.\n",
...            "User:",
...            "https://images.unsplash.com/photo-1524099163253-32b7f0256868?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3387&q=80",
...            "Describe this image.\nAssistant:"
...            ]

>>> inputs = processor(prompt, return_tensors="pt").to("cuda")
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, max_new_tokens=30, bad_words_ids=bad_words_ids)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> print(generated_text[0])
User: Describe this image.
Assistant: An image of the Eiffel Tower at night. Fun fact: the Eiffel Tower is the same height as an 81-storey building. 
User: Describe this image.
Assistant: An image of the Statue of Liberty. Fun fact: the Statue of Liberty is 151 feet tall.
```

ูุงุญุธ ุฃูู ูู ูุฌุฑุฏ ูุซุงู ูุงุญุฏ (ุฃู 1-shot) ุชุนููู ุงููููุฐุฌ ููููุฉ ุฃุฏุงุก ุงููููุฉ. ููููุงู ุงูุฃูุซุฑ ุชุนููุฏูุงุ ูุง ุชุชุฑุฏุฏ ูู ุชุฌุฑุจุฉ ุนุฏุฏ ุฃูุจุฑ ูู ุงูุฃูุซูุฉ (3-shotุ 5-shotุ ุฅูุฎ).

## Visual question answering

ุงูุฅุฌุงุจุฉ ุงูุจุตุฑูุฉ ุนู ุงูุฃุณุฆูุฉ (VQA) ูู ูููุฉ ุงูุฅุฌุงุจุฉ ุนู ุฃุณุฆูุฉ ููุชูุญุฉ ุจุงูุงุนุชูุงุฏ ุนูู ุตูุฑุฉ. ูุจุดูู ููุงุซู ููุตู ุงูุตูุฑุ ูููู ุงุณุชุฎุฏุงููุง ูุชุทุจููุงุช ุฅููุงููุฉ ุงููุตููุ ูุฃูุถูุง ูู ุงูุชุนููู (ุงูุงุณุชุฏูุงู ุนูู ููุงุฏ ุจุตุฑูุฉ)ุ ูุฎุฏูุฉ ุงูุนููุงุก (ุฃุณุฆูุฉ ุญูู ุงูููุชุฌุงุช ุจูุงุกู ุนูู ุงูุตูุฑ)ุ ูุงุณุชุฑุฌุงุน ุงูุตูุฑ.

ููุญุตู ุนูู ุตูุฑุฉ ุฌุฏูุฏุฉ ููุฐู ุงููููุฉ:

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-vqa.jpg" alt="Image of a couple having a picnic"/>
</div>

Photo by [Jarritos Mexican Soda](https://unsplash.com/@jarritos).

ููููู ุชูุฌูู ุงููููุฐุฌ ูู ูุตู ุงูุตูุฑ ุฅูู ุงูุฅุฌุงุจุฉ ุงูุจุตุฑูุฉ ุนู ุงูุฃุณุฆูุฉ ุนุจุฑ ูุญุซูุงุช ููุงุณุจุฉ:

```py
>>> prompt = [
...     "Instruction: Provide an answer to the question. Use the image to answer.\n",
...     "https://images.unsplash.com/photo-1623944889288-cd147dbb517c?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80",
...     "Question: Where are these people and what's the weather like? Answer:"
... ]

>>> inputs = processor(prompt, return_tensors="pt").to("cuda")
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, max_new_tokens=20, bad_words_ids=bad_words_ids)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> print(generated_text[0])
Instruction: Provide an answer to the question. Use the image to answer.
 Question: Where are these people and what's the weather like? Answer: They're in a park in New York City, and it's a beautiful day.
```

## Image classification

ูุณุชุทูุน IDEFICS ุชุตููู ุงูุตูุฑ ุฅูู ูุฆุงุช ูุฎุชููุฉ ุฏูู ุฃู ูููู ูุฏ ุฏูุฑูุจ ุตุฑุงุญุฉู ุนูู ุจูุงูุงุช ุชุญุชูู ุฃูุซูุฉ ูุนูููุฉ ูู ุชูู ุงููุฆุงุช ุงููุญุฏุฏุฉ. ุจุงููุธุฑ ุฅูู ูุงุฆูุฉ ุจุงููุฆุงุช ููุนุชูุฏุงู ุนูู ูููู ููุตูุฑุฉ ูุงููุตุ ูููู ูููููุฐุฌ ุงุณุชูุชุงุฌ ุงููุฆุฉ ุงูุฃูุซุฑ ุงุญุชูุงููุง ูุงูุชูุงุก ุงูุตูุฑุฉ ุฅูููุง.

ูููุชุฑุถ ุฃู ูุฏููุง ูุฐู ุงูุตูุฑุฉ ููุดู ุฎุถุฑูุงุช:

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-classification.jpg" alt="Image of a vegetable stand"/>
</div>

Photo by [Peter Wendt](https://unsplash.com/@peterwendt).

ูููููุง ุชูุฌูู ุงููููุฐุฌ ูุชุตููู ุงูุตูุฑุฉ ุถูู ุฅุญุฏู ุงููุฆุงุช ุงูููุฌูุฏุฉ ูุฏููุง:

```py
>>> categories = ['animals','vegetables', 'city landscape', 'cars', 'office']
>>> prompt = [f"Instruction: Classify the following image into a single category from the following list: {categories}.\n",
...     "https://images.unsplash.com/photo-1471193945509-9ad0617afabf?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80",    
...     "Category: "
... ]

>>> inputs = processor(prompt, return_tensors="pt").to("cuda")
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, max_new_tokens=6, bad_words_ids=bad_words_ids)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> print(generated_text[0])
Instruction: Classify the following image into a single category from the following list: ['animals', 'vegetables', 'city landscape', 'cars', 'office'].
Category: Vegetables
```

ูู ุงููุซุงู ุฃุนูุงู ูุฌูููุง ุงููููุฐุฌ ูุชุตููู ุงูุตูุฑุฉ ุถูู ูุฆุฉ ูุงุญุฏุฉุ ููู ููููู ุฃูุถูุง ุชุญููุฒู ูุฅุฌุฑุงุก ุชุตููู ุชุฑุชูุจู (rank classification).

## Image-guided text generation

ููุชุทุจููุงุช ุงูุฃูุซุฑ ุฅุจุฏุงุนูุงุ ููููู ุงุณุชุฎุฏุงู ุชูููุฏ ุงููุต ุงูููุฌูู ุจุงูุตูุฑ ูุฅูุชุงุฌ ูุต ุจุงูุงุนุชูุงุฏ ุนูู ุตูุฑุฉ. ูููู ุฃู ูููู ุฐูู ูููุฏูุง ูุฅูุดุงุก ุฃูุตุงู ููููุชุฌุงุช ูุงูุฅุนูุงูุงุช ููุตู ูุดุงูุฏุ ููุง ุฅูู ุฐูู.

ููุญููุฒ IDEFICS ุนูู ูุชุงุจุฉ ูุตุฉ ุจูุงุกู ุนูู ุตูุฑุฉ ุจุณูุทุฉ ูุจุงุจ ุฃุญูุฑ:

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-story-generation.jpg" alt="Image of a red door with a pumpkin on the steps"/>
</div>

Photo by [Craig Tidball](https://unsplash.com/@devonshiremedia).

```py
>>> prompt = ["Instruction: Use the image to write a story. \n",
...     "https://images.unsplash.com/photo-1517086822157-2b0358e7684a?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2203&q=80",
...     "Story: \n"]

>>> inputs = processor(prompt, return_tensors="pt").to("cuda")
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, num_beams=2, max_new_tokens=200, bad_words_ids=bad_words_ids)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> print(generated_text[0]) 
Instruction: Use the image to write a story. 
 Story: 
Once upon a time, there was a little girl who lived in a house with a red door.  She loved her red door.  It was the prettiest door in the whole world.

One day, the little girl was playing in her yard when she noticed a man standing on her doorstep.  He was wearing a long black coat and a top hat.

The little girl ran inside and told her mother about the man.

Her mother said, โDonโt worry, honey.  Heโs just a friendly ghost.โ

The little girl wasnโt sure if she believed her mother, but she went outside anyway.

When she got to the door, the man was gone.

The next day, the little girl was playing in her yard again when she noticed the man standing on her doorstep.

He was wearing a long black coat and a top hat.

The little girl ran
```

ูุจุฏู ุฃู IDEFICS ูุงุญุธ ุงูููุทููุฉ ุนูู ุงูุนุชุจุฉ ูุฐูุจ ูุญู ูุตุฉ ูุงููููู ูุฎููุฉ ุนู ุดุจุญ.

<Tip>
ููููุงุชุฌ ุงูุฃุทูู ููุฐุง ุงููุซุงูุ ุณุชุณุชููุฏ ูุซูุฑูุง ูู ุถุจุท ุงุณุชุฑุงุชูุฌูุฉ ุชูููุฏ ุงููุต. ููุฐุง ูุณุงุนุฏ ุจุดูู ููุญูุธ ุนูู ุชุญุณูู ุฌูุฏุฉ ุงููุฎุฑุฌุงุช. ุงุทููุน ุนูู [ุงุณุชุฑุงุชูุฌูุงุช ุชูููุฏ ุงููุต](../generation_strategies) ููุนุฑูุฉ ุงููุฒูุฏ.
</Tip>

## Running inference in batch mode

ุนุฑุถุช ุงูุฃูุณุงู ุงูุณุงุจูุฉ IDEFICS ุนูู ูุซุงู ูุงุญุฏ. ูุจุทุฑููุฉ ูุดุงุจูุฉ ุฌุฏูุงุ ููููู ุชุดุบูู ุงูุงุณุชุฏูุงู ูุฏูุนุฉ ูู ุงูุฃูุซูุฉ ุนุจุฑ ุชูุฑูุฑ ูุงุฆูุฉ ูู ุงููุญุซูุงุช:

```py
>>> prompts = [
...     [   "https://images.unsplash.com/photo-1543349689-9a4d426bee8e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3501&q=80",
...         "This is an image of ",
...     ],
...     [   "https://images.unsplash.com/photo-1623944889288-cd147dbb517c?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80",
...         "This is an image of ",
...     ],
...     [   "https://images.unsplash.com/photo-1471193945509-9ad0617afabf?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=3540&q=80",
...         "This is an image of ",
...     ],
... ]

>>> inputs = processor(prompts, return_tensors="pt").to("cuda")
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, max_new_tokens=10, bad_words_ids=bad_words_ids)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> for i,t in enumerate(generated_text):
...     print(f"{i}:\n{t}\n") 
0:
This is an image of the Eiffel Tower in Paris, France.

1:
This is an image of a couple on a picnic blanket.

2:
This is an image of a vegetable stand.
```

## IDEFICS instruct for conversational use

ูุญุงูุงุช ุงูุงุณุชุฎุฏุงู ุงูุญูุงุฑูุฉุ ุณุชุฌุฏ ุฅุตุฏุงุฑุงุช ููุญุณููุฉ ุจุงูุชุนูููุงุช ูููููุฐุฌ ุนูู ๐ค Hub: 
`HuggingFaceM4/idefics-80b-instruct` ู`HuggingFaceM4/idefics-9b-instruct`.

ูุฐู ุงูููุงุท ูู ูุชูุฌุฉ ุชุญุณูู ุงูููุงุฐุฌ ุงูุฃุณุงุณูุฉ ุงูููุงุซูุฉ ุนูู ูุฒูุฌ ูู ูุฌููุนุงุช ุจูุงูุงุช ุงูุฅุดุฑุงู ูุงูุชุนูููุงุชุ ูุง ูุนุฒูุฒ ุงูุฃุฏุงุก ุนูู ุงูููุงู ุงููุงุญูุฉ ููุฌุนู ุงูููุงุฐุฌ ุฃูุซุฑ ูุงุจููุฉ ููุงุณุชุฎุฏุงู ูู ุงูุฅุนุฏุงุฏุงุช ุงูุญูุงุฑูุฉ.

ุงุณุชุฎุฏุงู ุงููููุฐุฌ ูุชูููุฏ ุงููุญุซูุงุช ูู ุงูุณููุงุฑูู ุงูุญูุงุฑู ูุดุงุจู ุฌุฏูุง ูุงุณุชุฎุฏุงู ุงูููุงุฐุฌ ุงูุฃุณุงุณูุฉ:

```py
>>> import torch
>>> from transformers import IdeficsForVisionText2Text, AutoProcessor
>>> from accelerate.test_utils.testing import get_backend

>>> device, _, _ = get_backend() # ููุชุดู ุชููุงุฆููุง ููุน ุงูุฌูุงุฒ ุงูุฃุณุงุณู (CUDA, CPU, XPU, MPS, etc.)
>>> checkpoint = "HuggingFaceM4/idefics-9b-instruct"
>>> model = IdeficsForVisionText2Text.from_pretrained(checkpoint, torch_dtype=torch.bfloat16).to(device)
>>> processor = AutoProcessor.from_pretrained(checkpoint)

>>> prompts = [
...     [
...         "User: What is in this image?",
...         "https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG",
...         "<end_of_utterance>",
...         "\nAssistant: This picture depicts Idefix, the dog of Obelix in Asterix and Obelix. Idefix is running on the ground.<end_of_utterance>",
...         "\nUser:",
...         "https://static.wikia.nocookie.net/asterix/images/2/25/R22b.gif/revision/latest?cb=20110815073052",
...         "And who is that?<end_of_utterance>",
...         "\nAssistant:",
...     ],
... ]

>>> # --batched mode
>>> inputs = processor(prompts, add_end_of_utterance_token=False, return_tensors="pt").to(device)
>>> # --single sample mode
>>> # inputs = processor(prompts[0], return_tensors="pt").to(device)

>>> # Generation args
>>> exit_condition = processor.tokenizer("<end_of_utterance>", add_special_tokens=False).input_ids
>>> bad_words_ids = processor.tokenizer(["<image>", "<fake_token_around_image>"], add_special_tokens=False).input_ids

>>> generated_ids = model.generate(**inputs, eos_token_id=exit_condition, bad_words_ids=bad_words_ids, max_length=100)
>>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)
>>> for i, t in enumerate(generated_text):
...     print(f"{i}:\n{t}\n")
```
