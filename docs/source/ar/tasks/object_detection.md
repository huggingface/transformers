<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

โ๏ธ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ุงูุชุดุงู ุงููุงุฆูุงุช (Object detection)

[[open-in-colab]]

ุงูุชุดุงู ุงููุงุฆูุงุช ูู ูููุฉ ูู ููุงู ุงูุฑุคูุฉ ุงูุญุงุณูุจูุฉ ุชูุฏู ุฅูู ุงูุชุดุงู ุงูููุงูุงุช (ูุซู ุงูุจุดุฑ ุฃู ุงููุจุงูู ุฃู ุงูุณูุงุฑุงุช) ุฏุงุฎู ุงูุตูุฑุฉ. ุชุณุชูุจู ููุงุฐุฌ ุงูุชุดุงู ุงููุงุฆูุงุช ุตูุฑุฉู ููุฏุฎูุ ูุชูุฎุฑุฌ ุฅุญุฏุงุซูุงุช ุงููุฑุจุนุงุช ุงููุญูุทุฉ (Bounding boxes) ูุงูุชุณููุงุช ุงููุฑุชุจุทุฉ ุจุงููุงุฆูุงุช ุงูููุชุดูุฉ. ูููู ุฃู ุชุญุชูู ุงูุตูุฑุฉ ุนูู ุนุฏุฉ ูุงุฆูุงุชุ ูููู ูููุง ูุฑุจุน ูุญูุท ูุชุณููุชู ุงูุฎุงุตุฉ (ุนูู ุณุจูู ุงููุซุงูุ ูุฏ ุชุญุชูู ุงูุตูุฑุฉ ุนูู ุณูุงุฑุฉ ููุจูู)ุ ููููู ุฃู ุชุชูุงุฌุฏ ุงููุงุฆูุงุช ูู ููุงุถุน ูุฎุชููุฉ ูู ุงูุตูุฑุฉ (ูุซู ูุฌูุฏ ุนุฏุฉ ุณูุงุฑุงุช).
ูุฐุง ุงูููุน ูู ุงูููุงู ุดุงุฆุน ูู ุงูููุงุฏุฉ ุงูุฐุงุชูุฉ ูุงูุชุดุงู ุงููุดุงุฉ ูุนูุงูุงุช ุงูุทุฑู ูุฅุดุงุฑุงุช ุงููุฑูุฑ. ุชุชุถูู ุชุทุจููุงุช ุฃุฎุฑู ุงูุนุฏู ูู ุงูุตูุฑุ ูุงูุจุญุซ ุจุงูุตูุฑุ ูุบูุฑูุง.

ูู ูุฐุง ุงูุฏูููุ ุณุชุชุนูู ููููุฉ:

 1. ุถุจุท ูููุฐุฌ [DETR](https://huggingface.co/docs/transformers/model_doc/detr) ุจุฏูุฉ (Fine-tuning) โ ููู ูููุฐุฌ ูุฌูุน ุจูู ุนููุฏ ููุฑู ุงูุชูุงููู (Convolutional backbone) ููุญููู Encoder-Decoder โ ุนูู ูุฌููุนุฉ ุจูุงูุงุช [CPPE-5](https://huggingface.co/datasets/cppe-5).
 2. ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุถุจูุท ููุงุณุชุฏูุงู (Inference).

<Tip>

ููุงุทูุงุน ุนูู ุฌููุน ุงููุนูุงุฑูุงุช ูููุงุท ุงูุชูุชูุด (Checkpoints) ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจูุฑุงุฌุนุฉ [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/object-detection)

</Tip>

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงููุงุฒูุฉ:

```bash
pip install -q datasets transformers accelerate timm
pip install -q -U albumentations>=1.4.5 torchmetrics pycocotools
```

ุณูุณุชุฎุฏู ๐ค Datasets ูุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ูู Hugging Face Hubุ ู๐ค Transformers ูุชุฏุฑูุจ ุงููููุฐุฌุ ูููุชุจุฉ `albumentations` ูุฒูุงุฏุฉ ุงูุจูุงูุงุช (Data augmentation).

ูุดุฌุนู ุนูู ูุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจู ูู Hugging Face ูุฑูุนู ุฅูู Hub. ุนูุฏ ุงููุทุงูุจุฉุ ุฃุฏุฎู ุฑูุฒ ุงููุตูู ูุชุณุฌูู ุงูุฏุฎูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

ููุจุฏุกุ ุณูุนุฑูู ุซูุงุจุช ุนุงูุฉุ ููู ุงุณู ุงููููุฐุฌ ูุญุฌู ุงูุตูุฑุฉ. ุณูุณุชุฎุฏู ูู ูุฐุง ุงูุฏููู ูููุฐุฌ DETR ุงูุดุฑุทู (Conditional DETR) ูุธุฑูุง ูุชูุงุฑุจู ุงูุฃุณุฑุน. ูุง ุชุชุฑุฏุฏ ูู ุงุฎุชูุงุฑ ุฃู ูููุฐุฌ ูุงูุชุดุงู ุงููุงุฆูุงุช ูุชุงุญ ูู ููุชุจุฉ `transformers`.

```py
>>> MODEL_NAME = "microsoft/conditional-detr-resnet-50"  # ุฃู "facebook/detr-resnet-50"
>>> IMAGE_SIZE = 480
```

## ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช CPPE-5

ุชุญุชูู [ูุฌููุนุฉ ุจูุงูุงุช CPPE-5](https://huggingface.co/datasets/cppe-5) ุนูู ุตูุฑ ูุน ุชุนูููุงุช (Annotations) ุชูุญุฏููุฏ ูุนุฏุงุช ุงูููุงูุฉ ุงูุดุฎุตูุฉ ุงูุทุจูุฉ (PPE) ูู ุณูุงู ุฌุงุฆุญุฉ ููููุฏ-19.

ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฅูุดุงุก ูุณู `validation` ูู `train`:

```py
>>> from datasets import load_dataset

>>> cppe5 = load_dataset("cppe-5")

>>> if "validation" not in cppe5:
...     split = cppe5["train"].train_test_split(0.15, seed=1337)
...     cppe5["train"] = split["train"]
...     cppe5["validation"] = split["test"]

>>> cppe5
DatasetDict({
    train: Dataset({
        features: ['image_id', 'image', 'width', 'height', 'objects'],
        num_rows: 850
    })
    test: Dataset({
        features: ['image_id', 'image', 'width', 'height', 'objects'],
        num_rows: 29
    })
    validation: Dataset({
        features: ['image_id', 'image', 'width', 'height', 'objects'],
        num_rows: 150
    })
})
```

ุณุชูุงุญุธ ุฃู ูุฐู ุงููุฌููุนุฉ ุชุญุชูู ุนูู 1000 ุตูุฑุฉ ููุฌููุนุชู ุงูุชุฏุฑูุจ ูุงูุชุญููุ ููุฌููุนุฉ ุงุฎุชุจุงุฑ ุชุถู 29 ุตูุฑุฉ.

ููุชุนุฑู ุฃูุซุฑ ุนูู ุงูุจูุงูุงุชุ ุงุณุชูุดู ุดูู ุงูุฃูุซูุฉ:

```py
>>> cppe5["train"][0]
{
  'image_id': 366,
  'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=500x290>,
  'width': 500,
  'height': 500,
  'objects': {
    'id': [1932, 1933, 1934],
    'area': [27063, 34200, 32431],
    'bbox': [[29.0, 11.0, 97.0, 279.0],
      [201.0, 1.0, 120.0, 285.0],
      [382.0, 0.0, 113.0, 287.0]],
    'category': [0, 0, 0]
  }
}
```

ุชุชุถูู ุฃูุซูุฉ ุงููุฌููุนุฉ ุงูุญููู ุงูุชุงููุฉ:
- `image_id`: ูุนุฑูู ุตูุฑุฉ ุงููุซุงู
- `image`: ูุงุฆู `PIL.Image.Image` ูุญุชูู ุนูู ุงูุตูุฑุฉ
- `width`: ุนุฑุถ ุงูุตูุฑุฉ
- `height`: ุงุฑุชูุงุน ุงูุตูุฑุฉ
- `objects`: ูุงููุณ ูุญุชูู ุจูุงูุงุช ุงููุฑุจุนุงุช ุงููุญูุทุฉ ูููุงุฆูุงุช ูู ุงูุตูุฑุฉ:
  - `id`: ูุนุฑูู ุงูุชุนููู (annotation)
  - `area`: ูุณุงุญุฉ ุงููุฑุจุน ุงููุญูุท
  - `bbox`: ุงููุฑุจุน ุงููุญูุท ูููุงุฆู (ุจุตูุบุฉ [COCO](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/#coco))
  - `category`: ูุฆุฉ ุงููุงุฆูุ ุจุงูููู ุงููุญุชููุฉ: `Coverall (0)`, `Face_Shield (1)`, `Gloves (2)`, `Goggles (3)`, `Mask (4)`

ูุฏ ุชูุงุญุธ ุฃู ุงูุญูู `bbox` ูุชุจุน ุตูุบุฉ COCOุ ููู ุงูุตูุบุฉ ุงูุชู ูุชููุนูุง ูููุฐุฌ DETR. ููุน ุฐููุ ูุฅู ุชุฌููุน ุงูุญููู ุฏุงุฎู `objects` ูุฎุชูู ุนู ุชูุณูู ุงูุชุนูููุงุช ุงูุฐู ูุชุทูุจู DETR. ุณุชุญุชุงุฌ ูุชุทุจูู ุจุนุถ ุชุญูููุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูุจู ุงุณุชุฎุฏุงู ูุฐู ุงูุจูุงูุงุช ูู ุงูุชุฏุฑูุจ.

ูุฒูุงุฏุฉ ุงููููุ ุงุนุฑุถ ูุซุงููุง ูู ุงููุฌููุนุฉ:

```py
>>> import numpy as np
>>> import os
>>> from PIL import Image, ImageDraw

>>> image = cppe5["train"][2]["image"]
>>> annotations = cppe5["train"][2]["objects"]
>>> draw = ImageDraw.Draw(image)

>>> categories = cppe5["train"].features["objects"]["category"].feature.names

>>> id2label = {index: x for index, x in enumerate(categories, start=0)}
>>> label2id = {v: k for k, v in id2label.items()}

>>> for i in range(len(annotations["id"])):
...     box = annotations["bbox"][i]
...     class_idx = annotations["category"][i]
...     x, y, w, h = tuple(box)
...     # ุชุญููู ููุง ุฅุฐุง ูุงูุช ุงูุฅุญุฏุงุซูุงุช ููุทุจููุนุฉ (Normalized) ุฃู ูุง
...     if max(box) > 1.0:
...         # ุงูุฅุญุฏุงุซูุงุช ุบูุฑ ููุทุจููุนุฉุ ูุง ุญุงุฌุฉ ูุฅุนุงุฏุฉ ุงูุชุญุฌูู
...         x1, y1 = int(x), int(y)
...         x2, y2 = int(x + w), int(y + h)
...     else:
...         # ุงูุฅุญุฏุงุซูุงุช ููุทุจููุนุฉุ ุฃุนุฏ ุชุญุฌูููุง ุฅูู ุฅุญุฏุงุซูุงุช ูุทููุฉ
...         x1 = int(x * width)
...         y1 = int(y * height)
...         x2 = int((x + w) * width)
...         y2 = int((y + h) * height)
...     draw.rectangle((x, y, x + w, y + h), outline="red", width=1)
...     draw.text((x, y), id2label[class_idx], fill="white")

>>> image
```
<div class="flex justify-center">
    <img src="https://i.imgur.com/oVQb9SF.png" alt="CPPE-5 Image Example"/>
</div>

ูุนุฑุถ ุงููุฑุจุนุงุช ุงููุญูุทุฉ ูุน ุงูุชุณููุงุช ุงููุฑุชุจุทุฉ ุจูุงุ ููููู ุงูุญุตูู ุนูู ุงูุชุณููุงุช ูู ุจูุงูุงุช ุชุนุฑูู (Metadata) ุงููุฌููุนุฉุ ูุชุญุฏูุฏูุง ุญูู `category`.
ุณุชุญุชุงุฌ ุฃูุถูุง ูุฅูุดุงุก ูุงููุณูู ููุญููููุงู ุจูู ูุนุฑูู ุงูุชุณููุฉ ูุงููุฆุฉ (`id2label`) ูุจุงูุนูุณ (`label2id`). ุณุชุณุชุฎุฏูููุง ูุงุญููุง ุนูุฏ ุชููุฆุฉ ุงููููุฐุฌ. ูุงุญุธ ุฃู ุฌุฒุก ุงูุฑุณู ุฃุนูุงู ููุชุฑุถ ุฃู ุงูุตูุบุฉ ูู `COCO` ุฃู `(x_min, y_min, width, height)`. ูุฌุจ ุชุนุฏูู ุฐูู ุฅุฐุง ููุช ุชุนูู ุจุตูุบ ุฃุฎุฑู ูุซู `(x_min, y_min, x_max, y_max)`.

ูุฎุทูุฉ ุฃุฎูุฑุฉ ููุชุนุฑูู ุนูู ุงูุจูุงูุงุชุ ุงูุญุตูุง ุจุญุซูุง ุนู ูุดุงูู ูุญุชููุฉ. ูู ุงููุดุงูู ุงูุดุงุฆุนุฉ ูู ูุฌููุนุงุช ุจูุงูุงุช ุงูุชุดุงู ุงููุงุฆูุงุช ูุฌูุฏ ูุฑุจุนุงุช ูุญูุทุฉ "ุชุชุฌุงูุฒ" ุญุงูุฉ ุงูุตูุฑุฉ. ูุซู ูุฐู ุงููุฑุจุนุงุช ูุฏ ุชูุณุจุจ ุฃุฎุทุงุก ุฃุซูุงุก ุงูุชุฏุฑูุจ ููุฌุจ ูุนุงูุฌุชูุง. ุชูุฌุฏ ุจุนุถ ุงูุฃูุซูุฉ ุนูู ุฐูู ูู ูุฐู ุงููุฌููุนุฉ. ูุชุจุณูุท ุงูุฃููุฑ ูู ูุฐุง ุงูุฏูููุ ุณูุถุจุท `clip=True` ูู `BboxParams` ุถูู ุงูุชุญูููุงุช ุฃุฏูุงู.

## ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุจูุงูุงุช (Preprocess)

ูุฅุฌุฑุงุก ุงูุถุจุท ุงูุฏููู (Fine-tuning) ููููุฐุฌุ ูุฌุจ ุฃู ุชูุฌูููุฒ ุงูุจูุงูุงุช ูุชุทุงุจู ุจุฏูุฉ ุงูุทุฑููุฉ ุงููุณุชุฎุฏูุฉ ุฃุซูุงุก ูุง ูุจู ุงูุชุฏุฑูุจ (Pretraining) ูููููุฐุฌ.
ูููู [`AutoImageProcessor`] ุจูุนุงูุฌุฉ ุจูุงูุงุช ุงูุตูุฑ ูุฅูุชุงุฌ `pixel_values` ู`pixel_mask` ู`labels` ุงูุชู ูููู ููููุฐุฌ DETR ุงูุชุฏุฑูุจ ุนูููุง. ูุญุชูู ุงููุนุงูุฌ ุงูุตูุฑู (Image processor) ุนูู ุจุนุถ ุงูุฎุตุงุฆุต ุงูุฌุงูุฒุฉ ุงูุชู ูุณุช ูุถุทุฑูุง ููููู ุจุดุฃููุง:

- `image_mean = [0.485, 0.456, 0.406 ]`
- `image_std = [0.229, 0.224, 0.225]`

ูุฐู ูู ููู ุงููุชูุณุท ูุงูุงูุญุฑุงู ุงููุนูุงุฑู ุงููุณุชุฎุฏูุฉ ูุชุทุจูุน ุงูุตูุฑ ุฃุซูุงุก ูุง ูุจู ุงูุชุฏุฑูุจ. ูู ุงูุถุฑูุฑู ุฅุนุงุฏุฉ ุงุณุชุฎุฏุงููุง ุฃุซูุงุก ุงูุงุณุชุฏูุงู ุฃู ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ุงูุตูุฑ.

ุฃูุดุฆ ูุงุฆู ุงููุนุงูุฌุฉ ุงูุตูุฑูุฉ ูู ููุณ ููุทุฉ ุงูุชูุชูุด (Checkpoint) ุงูุฎุงุตุฉ ุจุงููููุฐุฌ ุงูุฐู ุชุฑุบุจ ุจุถุจุทู:

```py
>>> from transformers import AutoImageProcessor

>>> MAX_SIZE = IMAGE_SIZE

>>> image_processor = AutoImageProcessor.from_pretrained(
...     MODEL_NAME,
...     do_resize=True,
...     size={"max_height": MAX_SIZE, "max_width": MAX_SIZE},
...     do_pad=True,
...     pad_size={"height": MAX_SIZE, "width": MAX_SIZE},
... )
```

ูุจู ุชูุฑูุฑ ุงูุตูุฑ ุฅูู `image_processor`ุ ุทุจูู ุชุญููููู ูุณุจููู ุนูู ุงููุฌููุนุฉ:
- ุฒูุงุฏุฉ ุงูุจูุงูุงุช (Augmentation) ููุตูุฑ
- ุฅุนุงุฏุฉ ุชูุณูู ุงูุชุนูููุงุช ูุชุชูุงูู ูุน ุชููุนุงุช DETR

ุฃูููุงุ ูุชูููู ูุฑุท ุงูุชูููู (Overfitting) ุนูู ุจูุงูุงุช ุงูุชุฏุฑูุจุ ููููู ุชุทุจูู ุฒูุงุฏุฉ ููุจูุงูุงุช ุจุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ููุงุณุจุฉ. ููุง ูุณุชุฎุฏู [Albumentations](https://albumentations.ai/docs/).
ุชุถูู ูุฐู ุงูููุชุจุฉ ุฃู ุงูุชุญูููุงุช ุชุคุซุฑ ุนูู ุงูุตูุฑุฉ ูุชุญุฏูุซ ุงููุฑุจุนุงุช ุงููุญูุทุฉ ููููุง ูุฐูู.
ุชุญุชูู ุชูุซููุงุช ููุชุจุฉ ๐ค Datasets ุนูู [ุฏููู ููุตูู ูุฒูุงุฏุฉ ุงูุตูุฑ ูุงูุชุดุงู ุงููุงุฆูุงุช](https://huggingface.co/docs/datasets/object_detection) ููุณุชุฎุฏู ููุณ ูุฌููุนุฉ ุงูุจูุงูุงุช ููุซุงู. ุทุจูู ุจุนุถ ุงูุชุญูููุงุช ุงูููุฏุณูุฉ ูุงูููููุฉ ุนูู ุงูุตูุฑุฉ. ูุงุณุชูุดุงู ุงููุฒูุฏ ูู ุฎูุงุฑุงุช ุงูุฒูุงุฏุฉุ ุฑุงุฌุน [Albumentations Demo Space](https://huggingface.co/spaces/qubvel-hf/albumentations-demo).

```py
>>> import albumentations as A

>>> train_augment_and_transform = A.Compose(
...     [
...         A.Perspective(p=0.1),
...         A.HorizontalFlip(p=0.5),
...         A.RandomBrightnessContrast(p=0.5),
...         A.HueSaturationValue(p=0.1),
...     ],
...     bbox_params=A.BboxParams(format="coco", label_fields=["category"], clip=True, min_area=25),
... )

>>> validation_transform = A.Compose(
...     [A.NoOp()],
...     bbox_params=A.BboxParams(format="coco", label_fields=["category"], clip=True),
... )
```

ูุชููุน `image_processor` ุฃู ุชููู ุงูุชุนูููุงุช ูู ุงูุตูุบุฉ ุงูุชุงููุฉ: `{'image_id': int, 'annotations': list[Dict]}` ุญูุซ ููุซู ูู ูุงููุณ ุชุนููู ูุงุฆู ุจุตูุบุฉ COCO. ูููุถูู ุฏุงูุฉ ูุฅุนุงุฏุฉ ุชูุณูู ุชุนูููุงุช ูุซุงู ูุงุญุฏ:

```py
>>> def format_image_annotations_as_coco(image_id, categories, areas, bboxes):
...     """ุชูุณูู ูุฌููุนุฉ ุชุนูููุงุช ูุตูุฑุฉ ูุงุญุฏุฉ ุฅูู ุตูุบุฉ COCO

...     ุงููุณุงุฆุท (Args):
...         image_id (str): ูุนุฑูู ุงูุตูุฑุฉ. ูุซููุง: "0001"
...         categories (list[int]): ูุงุฆูุฉ ุงููุฆุงุช/ุงูุชุณููุงุช ุงูููุงููุฉ ูููุฑุจุนุงุช ุงููุญูุทุฉ
...         areas (list[float]): ูุงุฆูุฉ ุงููุณุงุญุงุช ุงูููุงููุฉ ูููุฑุจุนุงุช ุงููุญูุทุฉ
...         bboxes (list[tuple[float]]): ูุงุฆูุฉ ุงููุฑุจุนุงุช ุงููุญูุทุฉ ุจุตูุบุฉ COCO
...             ([center_x, center_y, width, height] ุจุฅุญุฏุงุซูุงุช ูุทููุฉ)

...     ุงููููุฉ ุงููุนุงุฏุฉ (Returns):
...         dict: {
...             "image_id": ูุนุฑูู ุงูุตูุฑุฉ,
...             "annotations": ูุงุฆูุฉ ุงูุชุนูููุงุช ุงูููุณููุฉ
...         }
...     """
...     annotations = []
...     for category, area, bbox in zip(categories, areas, bboxes):
...         formatted_annotation = {
...             "image_id": image_id,
...             "category_id": category,
...             "iscrowd": 0,
...             "area": area,
...             "bbox": list(bbox),
...         }
...         annotations.append(formatted_annotation)

...     return {
...         "image_id": image_id,
...         "annotations": annotations,
...     }

```

ููููู ุงูุขู ุฏูุฌ ุชุญูููุงุช ุงูุตูุฑุฉ ูุงูุชุนูููุงุช ููุงุณุชุฎุฏุงู ุนูู ุฏูุนุฉ (Batch) ูู ุงูุฃูุซูุฉ:

```py
>>> def augment_and_transform_batch(examples, transform, image_processor, return_pixel_mask=False):
...     """ุชุทุจูู ุงูุฒูุงุฏุงุช ูุฅุฎุฑุงุฌ ุงูุชุนูููุงุช ุจุตูุบุฉ COCO ููููุฉ ุงูุชุดุงู ุงููุงุฆูุงุช"""

...     images = []
...     annotations = []
...     for image_id, image, objects in zip(examples["image_id"], examples["image"], examples["objects"]):
...         image = np.array(image.convert("RGB"))

...         # ุชุทุจูู ุฒูุงุฏุงุช ุงูุจูุงูุงุช
...         output = transform(image=image, bboxes=objects["bbox"], category=objects["category"])
...         images.append(output["image"])

...         # ุชูุณูู ุงูุชุนูููุงุช ุจุตูุบุฉ COCO
...         formatted_annotations = format_image_annotations_as_coco(
...             image_id, output["category"], objects["area"], output["bboxes"]
...         )
...         annotations.append(formatted_annotations)

...     # ุชุทุจูู ุชุญูููุงุช ุงููุนุงูุฌ ุงูุตูุฑู: ุชุบููุฑ ุงูุญุฌูุ ุฅุนุงุฏุฉ ุงูููุงุณุ ุงูุชุทุจูุน
...     result = image_processor(images=images, annotations=annotations, return_tensors="pt")

...     if not return_pixel_mask:
...         result.pop("pixel_mask", None)

...     return result
```

ุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูุฐู ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุฉู ุจุงุณุชุฎุฏุงู ุฃุณููุจ ๐ค Datasets [`~datasets.Dataset.with_transform`]. ูุทุจู ูุฐุง ุงูุฃุณููุจ ุงูุชุญูููุงุช ุฃุซูุงุก ุชุญููู ุนูุงุตุฑ ุงููุฌููุนุฉ ุนูุฏ ุงูุทูุจ.

ูู ูุฐู ุงููุฑุญูุฉุ ููููู ูุญุต ููู ูุจุฏู ุงููุซุงู ุจุนุฏ ุงูุชุญูููุงุช. ููุจุบู ุฃู ุชุฑู ููุชุฑูุง (Tensor) ูู`pixel_values`ุ ูููุชุฑูุง ูู`pixel_mask`ุ ูุญูู `labels`.

```py
>>> from functools import partial

>>> # ุฅูุดุงุก ุฏูุงู ุงูุชุญููู ุนูู ุฏูุนุงุช ูุชุทุจูููุง ุนูู ุงูุฃูุณุงู
>>> train_transform_batch = partial(
...     augment_and_transform_batch, transform=train_augment_and_transform, image_processor=image_processor
... )
>>> validation_transform_batch = partial(
...     augment_and_transform_batch, transform=validation_transform, image_processor=image_processor
... )

>>> cppe5["train"] = cppe5["train"].with_transform(train_transform_batch)
>>> cppe5["validation"] = cppe5["validation"].with_transform(validation_transform_batch)
>>> cppe5["test"] = cppe5["test"].with_transform(validation_transform_batch)

>>> cppe5["train"][15]
{'pixel_values': tensor([[[ 1.9235,  1.9407,  1.9749,  ..., -0.7822, -0.7479, -0.6965],
          [ 1.9578,  1.9749,  1.9920,  ..., -0.7993, -0.7650, -0.7308],
          [ 2.0092,  2.0092,  2.0263,  ..., -0.8507, -0.8164, -0.7822],
          ...,
          [ 0.0741,  0.0741,  0.0741,  ...,  0.0741,  0.0741,  0.0741],
          [ 0.0741,  0.0741,  0.0741,  ...,  0.0741,  0.0741,  0.0741],
          [ 0.0741,  0.0741,  0.0741,  ...,  0.0741,  0.0741,  0.0741]],

          [[ 1.6232,  1.6408,  1.6583,  ...,  0.8704,  1.0105,  1.1331],
          [ 1.6408,  1.6583,  1.6758,  ...,  0.8529,  0.9930,  1.0980],
          [ 1.6933,  1.6933,  1.7108,  ...,  0.8179,  0.9580,  1.0630],
          ...,
          [ 0.2052,  0.2052,  0.2052,  ...,  0.2052,  0.2052,  0.2052],
          [ 0.2052,  0.2052,  0.2052,  ...,  0.2052,  0.2052,  0.2052],
          [ 0.2052,  0.2052,  0.2052,  ...,  0.2052,  0.2052,  0.2052]],

          [[ 1.8905,  1.9080,  1.9428,  ..., -0.1487, -0.0964, -0.0615],
          [ 1.9254,  1.9428,  1.9603,  ..., -0.1661, -0.1138, -0.0790],
          [ 1.9777,  1.9777,  1.9951,  ..., -0.2010, -0.1138, -0.0790],
          ...,
          [ 0.4265,  0.4265,  0.4265,  ...,  0.4265,  0.4265,  0.4265],
          [ 0.4265,  0.4265,  0.4265,  ...,  0.4265,  0.4265,  0.4265],
          [ 0.4265,  0.4265,  0.4265,  ...,  0.4265,  0.4265,  0.4265]]]),
  'labels': {'image_id': tensor([688]), 'class_labels': tensor([3, 4, 2, 0, 0]), 'boxes': tensor([[0.4700, 0.1933, 0.1467, 0.0767],
          [0.4858, 0.2600, 0.1150, 0.1000],
          [0.4042, 0.4517, 0.1217, 0.1300],
          [0.4242, 0.3217, 0.3617, 0.5567],
          [0.6617, 0.4033, 0.5400, 0.4533]]), 'area': tensor([ 4048.,  4140.,  5694., 72478., 88128.]), 'iscrowd': tensor([0, 0, 0, 0, 0]), 'orig_size': tensor([480, 480])}}
```

ููุฏ ููุชู ุจุฒูุงุฏุฉ ุงูุตูุฑ ุงููุฑุฏูุฉ ูุฅุนุฏุงุฏ ุชุนูููุงุชูุง. ููู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูู ุชูุชูู ุจุนุฏ. ูู ุงูุฎุทูุฉ ุงูุฃุฎูุฑุฉุ ุฃูุดุฆ ุฏุงูุฉ `collate_fn` ูุฎุตูุตุฉ ูุชุฌููุน ุงูุตูุฑ ูู ุฏูุนุงุช.
ูู ุจููุก ุงูุตูุฑ (ุงูุชู ุฃุตุจุญุช ุงูุขู `pixel_values`) ุฅูู ุฃูุจุฑ ุญุฌู ูู ุงูุฏูุนุฉุ ูุฃูุดุฆ `pixel_mask` ูุทุงุจููุง ูุญุฏูุฏ ุฃู ุงูุจูุณูุงุช ุญููููุฉ (1) ูุฃููุง ุชุนุจุฆุฉ (0).

```py
>>> import torch

>>> def collate_fn(batch):
...     data = {}
...     data["pixel_values"] = torch.stack([x["pixel_values"] for x in batch])
...     data["labels"] = [x["labels"] for x in batch]
...     if "pixel_mask" in batch[0]:
...         data["pixel_mask"] = torch.stack([x["pixel_mask"] for x in batch])
...     return data

```

<!-- INSERT_MAP_SECTION -->

<!-- INSERT_TRAINING_SECTION -->

<!-- INSERT_EVAL_INFER_SECTION -->
