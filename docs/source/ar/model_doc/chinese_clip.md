# Chinese-CLIP

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©
ØªÙ… Ø§Ù‚ØªØ±Ø§Ø­ Ù†Ù…ÙˆØ°Ø¬ Chinese-CLIP ÙÙŠ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¨Ø­Ø«ÙŠØ© Ø¨Ø¹Ù†ÙˆØ§Ù† "Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese" Ø¨ÙˆØ§Ø³Ø·Ø© An Yang Ùˆ Junshu Pan Ùˆ Junyang Lin Ùˆ Rui Men Ùˆ Yichang Zhang Ùˆ Jingren Zhou Ùˆ Chang Zhou.

Ù†Ù…ÙˆØ°Ø¬ Chinese-CLIP Ù‡Ùˆ ØªØ·Ø¨ÙŠÙ‚ Ù„Ù†Ù…ÙˆØ°Ø¬ CLIP (Radford et al.ØŒ 2021) Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø®Ù…Ø© Ù…Ù† Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„ØµÙŠÙ†ÙŠØ©. ÙŠØªÙ…ÙŠØ² Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø¹Ø¨Ø± Ø§Ù„ÙˆØ³Ø§Ø¦Ø·ØŒ ÙƒÙ…Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙƒØ¹Ù…ÙˆØ¯ ÙÙ‚Ø±ÙŠ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¨ØµØ±ÙŠØ© Ù…Ø«Ù„ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¥Ø´Ø±Ø§Ù ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…ÙØªÙˆØ­ØŒ ÙˆÙ…Ø§ Ø¥Ù„Ù‰ Ø°Ù„Ùƒ. ØªÙ… Ø¥ØµØ¯Ø§Ø± Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ Ù„Ù†Ù…ÙˆØ°Ø¬ Chinese-CLIP [Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø±Ø§Ø¨Ø·](https://github.com/OFA-Sys/Chinese-CLIP).

ÙˆÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¨Ø­Ø«ÙŠØ©:

*Ø­Ù‚Ù‚ Ù†Ù…ÙˆØ°Ø¬ CLIP (Radford et al.ØŒ 2021) Ù†Ø¬Ø§Ø­Ù‹Ø§ Ù‡Ø§Ø¦Ù„Ø§Ù‹ØŒ Ù…Ù…Ø§ Ø¹Ø²Ø² Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ…ÙŠÙŠØ²ÙŠ Ù„Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ù„Ù„Ø±Ø¤ÙŠØ© ÙˆØ§Ù„Ù„ØºØ©. ÙˆÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…Ù„ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø¨Ù†Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø®Ù…Ø© Ù…Ù† Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„ØµÙŠÙ†ÙŠØ©ØŒ Ø­ÙŠØ« ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ø¹Ù…ÙˆÙ…ØŒ Ø«Ù… Ù†Ù‚ÙˆÙ… Ø¨ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Chinese CLIP Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©. Ù‚Ù…Ù†Ø§ Ø¨ØªØ·ÙˆÙŠØ± 5 Ù†Ù…Ø§Ø°Ø¬ Chinese CLIP Ø¨Ø£Ø­Ø¬Ø§Ù… Ù…ØªØ¹Ø¯Ø¯Ø©ØŒ ØªØªØ±Ø§ÙˆØ­ Ù…Ù† 77 Ø¥Ù„Ù‰ 958 Ù…Ù„ÙŠÙˆÙ† Ù…Ø¹Ø§Ù…Ù„. Ø¹Ù„Ø§ÙˆØ© Ø¹Ù„Ù‰ Ø°Ù„ÙƒØŒ Ù†Ù‚ØªØ±Ø­ Ø·Ø±ÙŠÙ‚Ø© ØªØ¯Ø±ÙŠØ¨ Ù…ÙƒÙˆÙ†Ø© Ù…Ù† Ù…Ø±Ø­Ù„ØªÙŠÙ†ØŒ Ø­ÙŠØ« ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ø¹ ØªØ«Ø¨ÙŠØª Ù…Ø´ÙØ± Ø§Ù„ØµÙˆØ±ØŒ Ø«Ù… ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§ØªØŒ ÙˆØ°Ù„Ùƒ Ù„ØªØ­Ù‚ÙŠÙ‚ Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬. ØªÙØ¸Ù‡Ø± ØªØ¬Ø§Ø±Ø¨Ù†Ø§ Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ø£Ù† Ù†Ù…ÙˆØ°Ø¬ Chinese CLIP ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ­Ù‚Ù‚ Ø£Ø¯Ø§Ø¡Ù‹ Ù…ØªÙ…ÙŠØ²Ù‹Ø§ Ø¹Ù„Ù‰ MUGE Ùˆ Flickr30K-CN Ùˆ COCO-CN ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø¯ÙˆÙ† Ø¥Ø´Ø±Ø§Ù ÙˆØªÙ†Ù‚ÙŠØ­ Ø§Ù„Ø¯Ù‚Ø©ØŒ ÙƒÙ…Ø§ Ø£Ù†Ù‡ Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ ØªØ­Ù‚ÙŠÙ‚ Ø£Ø¯Ø§Ø¡ ØªÙ†Ø§ÙØ³ÙŠ ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ø¨Ø¯ÙˆÙ† Ø¥Ø´Ø±Ø§Ù Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ù…Ø¹ÙŠØ§Ø± ELEVATER (Li et al.ØŒ 2022). ÙˆÙ‚Ø¯ ØªÙ… Ø¥ØµØ¯Ø§Ø± Ø£ÙƒÙˆØ§Ø¯Ù†Ø§ ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆØ§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©.*

ØªÙ…Øª Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ Ù†Ù…ÙˆØ°Ø¬ Chinese-CLIP Ø¨ÙˆØ§Ø³Ø·Ø© [OFA-Sys](https://huggingface.co/OFA-Sys).

## Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
ÙŠÙˆØ¶Ø­ Ù…Ù‚ØªØ·Ù Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠ ÙƒÙŠÙÙŠØ© Ø­Ø³Ø§Ø¨ Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ ÙˆÙ…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ†Ù‡Ø§:

```python
>>> from PIL import Image
>>> import requests
>>> from transformers import ChineseCLIPProcessor, ChineseCLIPModel

>>> model = ChineseCLIPModel.from_pretrained("OFA-Sys/chinese-clip-vit-base-patch16")
>>> processor = ChineseCLIPProcessor.from_pretrained("OFA-Sys/chinese-clip-vit-base-patch16")

>>> url = "https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/pokemon.jpeg"
>>> image = Image.open(requests.get(url, stream=True).raw)
>>> # Squirtle, Bulbasaur, Charmander, Pikachu in English
>>> texts = ["æ°å°¼é¾Ÿ", "å¦™è›™ç§å­", "å°ç«é¾™", "çš®å¡ä¸˜"]

>>> # compute image feature
>>> inputs = processor(images=image, return_tensors="pt")
>>> image_features = model.get_image_features(**inputs)
>>> image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)  # normalize

>>> # compute text features
>>> inputs = processor(text=texts, padding=True, return_tensors="pt")
>>> text_features = model.get_text_features(**inputs)
>>> text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True)  # normalize

>>> # compute image-text similarity scores
>>> inputs = processor(text=texts, images=image, return_tensors="pt", padding=True)
>>> outputs = model(**inputs)
>>> logits_per_image = outputs.logits_per_image  # this is the image-text similarity score
>>> probs = logits_per_image.softmax(dim=1)  # probs: [[1.2686e-03, 5.4499e-02, 6.7968e-04, 9.4355e-01]]
```

Ø­Ø§Ù„ÙŠÙ‹Ø§ØŒ ØªØªÙˆÙØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù†Ù…ÙˆØ°Ø¬ Chinese-CLIP Ø¹Ù„Ù‰ Ù…Ù†ØµØ© ğŸ¤— Hub Ø¨Ø§Ù„Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù…Ø®ØªÙ„ÙØ©:

- [OFA-Sys/chinese-clip-vit-base-patch16](https://huggingface.co/OFA-Sys/chinese-clip-vit-base-patch16)
- [OFA-Sys/chinese-clip-vit-large-patch14](https://huggingface.co/OFA-Sys/chinese-clip-vit-large-patch14)
- [OFA-Sys/chinese-clip-vit-large-patch14-336px](https://huggingface.co/OFA-Sys/chinese-clip-vit-large-patch14-336px)
- [OFA-Sys/chinese-clip-vit-huge-patch14](https://huggingface.co/OFA-Sys/chinese-clip-vit-huge-patch14)

## ChineseCLIPConfig

[[autodoc]] ChineseCLIPConfig

- from_text_vision_configs

## ChineseCLIPTextConfig

[[autodoc]] ChineseCLIPTextConfig

## ChineseCLIPVisionConfig

[[autodoc]] ChineseCLIPVisionConfig

## ChineseCLIPImageProcessor

[[autodoc]] ChineseCLIPImageProcessor

- preprocess

## ChineseCLIPFeatureExtractor

[[autodoc]] ChineseCLIPFeatureExtractor

## ChineseCLIPProcessor

[[autodoc]] ChineseCLIPProcessor

## ChineseCLIPModel

[[autodoc]] ChineseCLIPModel

- forward

- get_text_features

- get_image_features

## ChineseCLIPTextModel

[[autodoc]] ChineseCLIPTextModel

- forward

## ChineseCLIPVisionModel

[[autodoc]] ChineseCLIPVisionModel

- forward