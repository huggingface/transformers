# ุชุญุณูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูู ุญูุซ ุงูุณุฑุนุฉ ูุงูุฐุงูุฑุฉ


[[open-in-colab]]

ุชุญูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ (LLMs) ูุซู GPT3/4ุ [Falcon](https://huggingface.co/tiiuae/falcon-40b)ุ ู [Llama](https://huggingface.co/meta-llama/Llama-2-70b-hf) ุชูุฏููุง ุณุฑูุนูุง ูู ูุฏุฑุชูุง ุนูู ูุนุงูุฌุฉ ุงูููุงู ุงูุชู ุชุฑูุฒ ุนูู ุงูุฅูุณุงูุ ููุง ูุฌุนููุง ุฃุฏูุงุช ุฃุณุงุณูุฉ ูู ุงูุตูุงุนุงุช ุงููุงุฆูุฉ ุนูู ุงููุนุฑูุฉ ุงูุญุฏูุซุฉ.
ูุง ูุฒุงู ูุดุฑ ูุฐู ุงูููุงุฐุฌ ูู ุงูููุงู ุงููุงูุนูุฉ ููุซู ุชุญุฏููุงุ ููุน ุฐูู:

-   ููู ุชุธูุฑ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุฏุฑุงุช ููู ูุชูููุฏ ุงููุตูุต ูุฑูุจุฉ ูู ูุฏุฑุงุช ุงูุฅูุณุงูุ ูุฅููุง ุชุชุทูุจ ุญุงูููุง  ุฅูู ุชูููููุง ูู ูููุงุฑุงุช ุงููุนููุงุช (ุงูุธุฑ [ูุงุจูุงู ูุขุฎุฑูู](https://arxiv.org/abs/2001.08361)ุ [ูู ูุขุฎุฑูู](https://arxiv.org/abs/2206.07682)). ููุฐุง ุจุฏูุฑู ูุฒูุฏ ูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ููุงุณุชุฏูุงู.
-   ูู ุงูุนุฏูุฏ ูู ุงูููุงู ุงููุงูุนูุฉุ ุชุญุชุงุฌ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุฅูู ูุนูููุงุช ุณูุงููุฉ ุดุงููุฉ. ูุชุทูุจ ุฐูู ูุฏุฑุฉ ุงููููุฐุฌ ุนูู ุฅุฏุงุฑุฉ ุชุณูุณูุงุช ุฅุฏุฎุงู ุทูููุฉ ููุบุงูุฉ ุฃุซูุงุก ุงูุงุณุชุฏูุงู.

ูููู ุฌููุฑ ุตุนูุจุฉ ูุฐู ุงูุชุญุฏูุงุช ูู ุชุนุฒูุฒ ุงููุฏุฑุงุช ุงูุญุณุงุจูุฉ ูุงูุฐุงูุฑุฉ ูููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉุ ุฎุงุตุฉ ุนูุฏ ุงูุชุนุงูู ูุน ุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูุถุฎูุฉ.

ูู ูุฐุง ุงูุฏูููุ ุณูุณุชุนุฑุถ ุงูุชูููุงุช ุงููุนุงูุฉ ูุชูุญุณููู ูู ููุงุกุฉ ูุดุฑ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ:

1. ุณูุชูุงูู ุชูููุฉ "ุฏูุฉ ุฃูู" ุงูุชู ุฃุซุจุชุช ุงูุฃุจุญุงุซ ูุนุงููุชูุง ูู ุชุญููู ูุฒุงูุง ุญุณุงุจูุฉ ุฏูู ุงูุชุฃุซูุฑ ุจุดูู ููุญูุธ ุนูู ุฃุฏุงุก ุงููููุฐุฌ ุนู ุทุฑูู ุงูุนูู ุจุฏูุฉ ุฑูููุฉ ุฃูู [8 ุจุช ู4 ุจุช](/main_classes/quantization.md).

2.  **ุงFlash Attention:** ุฅู Flash Attention ููู ูุณุฎุฉ ููุนุฏูููุฉ ูู ุฎูุงุฑุฒููุฉ ุงูุงูุชุจุงู ุงูุชู ูุง ุชููุฑ ููุท ููุฌูุง ุฃูุซุฑ ููุงุกุฉ ูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉุ ูููููุง ุชุญูู ุฃูุถูุง ููุงุกุฉ ูุชุฒุงูุฏุฉ ุจุณุจุจ ุงูุงุณุชุฎุฏุงู ุงูุฃูุซู ูุฐุงูุฑุฉ GPU.

3.  **ุงูุงุจุชูุงุฑุงุช ุงููุนูุงุฑูุฉ:** ุญูุซ ุชู ุงูุชุฑุงุญ ููุงูู ูุชุฎุตุตุฉ ุชุณูุญ ุจุงุณุชุฏูุงู ุฃูุซุฑ ูุนุงููุฉ ูุธุฑูุง ูุฃู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุชู ูุดุฑูุง ุฏุงุฆููุง ุจููุณ ุงูุทุฑููุฉ ุฃุซูุงุก ุนูููุฉ ุงูุงุณุชุฏูุงูุ ุฃู ุชูููุฏ ุงููุต ุงูุชูุจุคู ุงูุชููุงุฆู ูุน ุณูุงู ุงูุฅุฏุฎุงู ุงูุทูููุ ููุฏ ุชู ุงูุชุฑุงุญ ุจููุงุช ูููุฐุฌ ูุชุฎุตุตุฉ ุชุณูุญ ุจุงูุงุณุชุฏูุงู ุงูุฃูุซุฑ ููุงุกุฉ. ุฃูู ุชูุฏู ูู ุจููุงุช ุงูููุงุฐุฌ ููุง ูู [ุนุฐุฑ](https://arxiv.org/abs/2108.12409)ุ [ุงูุชุฑููุฒ ุงูุฏูุงุฑ](https://arxiv.org/abs/2104.09864)ุ [ุงูุงูุชูุงู ูุชุนุฏุฏ ุงูุงุณุชุนูุงูุงุช (MQA)](https://arxiv.org/abs/1911.02150) ู [ูุฌููุนุฉ ุงูุงูุชุจุงู ุจุงูุงุณุชุนูุงู (GQA)]((https://arxiv.org/abs/2305.13245)).

ุนูู ูุฏุงุฑ ูุฐุง ุงูุฏูููุ ุณููุฏู ุชุญููููุง ููุชูููุฏ ุงูุชูุจุคู ุงูุชููุงุฆู ูู ููุธูุฑ ุงููููุชููุฑุงุช. ูุชุนูู ูู ูุฒุงูุง ูุนููุจ ุงุณุชุฎุฏุงู ุฏูุฉ ุฃููุ ูููุฏู ุงุณุชูุดุงููุง ุดุงููุงู ูุฎูุงุฑุฒููุงุช ุงูุงูุชุจุงู ุงูุฃุญุฏุซุ ูููุงูุด ุจููุงุช ููุงุฐุฌ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงููุญุณูุฉ. ุณูุฏุนู ุงูุดุฑุญ ุจุฃูุซูุฉ ุนูููุฉ ุชูุจุฑูุฒ ูู ุชุญุณูู ุนูู ุญุฏุฉ.

## 1. ุฏูุฉ ุฃูู

ูููู ููู ูุชุทูุจุงุช ุฐุงูุฑุฉ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจุดูู ุฃูุถู ูู ุฎูุงู ุงููุธุฑ ุฅูู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุนูู ุฃููุง ูุฌููุนุฉ ูู ุงููุตูููุงุช ูุงููุชุฌูุงุช ุงููุฒููุฉุ ููุฏุฎูุงุช ุงููุต ุนูู ุฃููุง ุชุณูุณู ูู ุงููุชุฌูุงุช. ูููุง ูููุ ุณูุชู ุงุณุชุฎุฏุงู ุชุนุฑูู "ุงูุฃูุฒุงู" ููุฅุดุงุฑุฉ ุฅูู ุฌููุน ูุตูููุงุช ุงูุฃูุฒุงู ูุงููุชุฌูุงุช ูู ุงููููุฐุฌ.
ูู ููุช ูุชุงุจุฉ ูุฐุง ุงูุฏูููุ ุชุชููู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูู ูููุงุฑุงุช ุงููุนููุงุช ุนูู ุงูุฃูู.ูู ูุนููุฉ ูุชู ุชูุซูููุง ุจุฑูู ุนุดุฑู ูุซู 4.5689 `` ูุงูุฐู ูุชู ุชุฎุฒููู ุนุงุฏุฉู ุจุชูุณูู [float32](https://en.wikipedia.org/wiki/Single-precision_floating-point_format)ุ [bfloat16](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format)ุ ุฃู [float16](https://en.wikipedia.org/wiki/Half-precision_floating-point_format) . ูุณูุญ ููุง ูุฐุง ุจุญุณุงุจ ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุญููู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูู ุงูุฐุงูุฑุฉ ุจุณูููุฉ:

> *ูุชุทูุจ ุชุญููู ุฃูุฒุงู ูููุฐุฌ ุจู X ูููุงุฑ ูุนููุฉ ุญูุงูู 4 * X ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM) ุจุฏูุฉ float32*

ููุน ุฐููุ ูุงุฏุฑูุง ูุง ูุชู ุชุฏุฑูุจ ุงูููุงุฐุฌ ูู ุงูููุช ุงูุญุงูู ุจุฏูุฉ float32 ุงููุงููุฉุ ูููู ุนุงุฏุฉู ูุง ุชููู ุจุฏูุฉ bfloat16 ุฃู ุจุดูู ุฃูู ูู ุชูุณูู float16. ูุฐููุ ุชุตุจุญ ุงููุงุนุฏุฉ ุงูุฅุฑุดุงุฏูุฉ ููุง ููู:

> *ูุชุทูุจ ุชุญููู ุฃูุฒุงู ูููุฐุฌ ุจู X ูููุงุฑ ูุนููุฉ ุญูุงูู 2 * X ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM) ุจุฏูุฉ bfloat16/float16*

ุจุงููุณุจุฉ ููุฏุฎูุงุช  ุงููุตูุต ุงููุตูุฑุฉ (ุฃูู ูู 1024 ุฑูุฒูุง)ุ ูุฅู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ููุงุณุชุฏูุงู ุชูููู ุนูููุง ุฅูู ุญุฏ ูุจูุฑ ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุญููู ุงูุฃูุฒุงู. ูุฐููุ ุฏุนูุง ููุชุฑุถุ ูู ุงูููุช ุงูุญุงููุ ุฃู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ููุงุณุชุฏูุงู ุชุณุงูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุญููู ุงููููุฐุฌ ูู ุฐุงูุฑุฉ VRAM ููุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช GPU..

ููุฅุนุทุงุก ุจุนุถ ุงูุฃูุซูุฉ ุนูู ููุฏุงุฑ ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM) ุงูุชู ูุชุทูุจูุง ุชุญููู ูููุฐุฌ ุจุชูุณูู bfloat16 ุชูุฑูุจูุง:

-   **GPT3** ูุชุทูุจ 2 \* 175 ุฌูุฌุง ุจุงูุช = **350 ุฌูุฌุง ุจุงูุช** VRAM
-   [**ุจููู**](https://huggingface.co/bigscience/bloom) ูุชุทูุจ 2 \* 176 ุฌูุฌุง ุจุงูุช = **352 ุฌูุฌุง ุจุงูุช** VRAM
-   [**Llama-2-70b**](https://huggingface.co/meta-llama/Llama-2-70b-hf) ูุชุทูุจ 2 \* 70 ุฌูุฌุง ุจุงูุช = **140 ุฌูุฌุง ุจุงูุช** VRAM
-   [**Falcon-40b**](https://huggingface.co/tiiuae/falcon-40b) ูุชุทูุจ 2 \* 40 ุฌูุฌุง ุจุงูุช = **80 ุฌูุฌุง ุจุงูุช** VRAM
-   [**MPT-30b**](https://huggingface.co/mosaicml/mpt-30b) ูุชุทูุจ 2 \* 30 ุฌูุฌุง ุจุงูุช = **60 ุฌูุฌุง ุจุงูุช** VRAM
-   [**bigcode/starcoder**](https://huggingface.co/bigcode/starcoder) ูุชุทูุจ 2 \* 15.5 = **31 ุฌูุฌุง ุจุงูุช** VRAM

ุนูุฏ ูุชุงุจุฉ ูุฐุง ุงูุฏูููุ ุฃูุจุฑ ุดุฑูุญุฉ ููุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช  ุงููุชูููุฑุฉ  ูู  A100 ู  H100  ุงูุชู ุชููุฑ 80 ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM). ุชุชุทูุจ ูุนุธู ุงูููุงุฐุฌ ุงููุฏุฑุฌุฉ ุฃุนูุงู ุฃูุซุฑ ูู 80 ุฌูุฌุงุจุงูุช ููุท ูุชุญููููุงุ ูุจุงูุชุงูู ููู ุชุชุทูุจ ุจุงูุถุฑูุฑุฉ [ุงูุชูุงุฒู ููููุชูุฑุงุช](https://huggingface.co/docs/transformers/perf_train_gpu_many#tensor-parallelism) ู/ุฃู [ูุชูุงุฒู  ุงูุฎุทู](https://huggingface.co/docs/transformers/perf_train_gpu_many#naive-model-parallelism-vertical-and-pipeline-parallelism).

๐ค ูุง ูุฏุนู Transformers ููุงุฒุงุฉ ุงูุชูุณูุฑ ุฎุงุฑุฌ ุงูุตูุฏูู ูุฃูู ูุชุทูุจ ูุชุงุจุฉ ููููุฉ ุงููููุฐุฌ ุจุทุฑููุฉ ูุญุฏุฏุฉ. ุฅุฐุง ููุช ููุชููุง ุจูุชุงุจุฉ ููุงุฐุฌ ุจุทุฑููุฉ ุตุฏููุฉ ูููุงุฒุงุฉ ุงูุชูุณูุฑุ ููุง ุชุชุฑุฏุฏ ูู ุฅููุงุก ูุธุฑุฉ ุนูู [ููุชุจุฉ ุงูุงุณุชุฏูุงู ุจุชูููุฏ ุงููุต](https://github.com/huggingface/text-generation-inference/tree/main/server/text_generation_server/models/custom_modeling).

ุจุฏุนู ููุงุฒุงุฉ ูููุงุช ุงููุนุงูุฌุฉ ุงูุจุณูุทุฉ ุฎุงุฑุฌ ุงูุตูุฏูู. ููููุงู ุจุฐููุ ูู ุจุชุญููู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู `device="auto"` ูุงูุฐู ุณูููู ุชููุงุฆููุง ุจูุถุน ุงูุทุจูุงุช ุงููุฎุชููุฉ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุงููุชุงุญุฉ ููุง ูู ููุถุญ [ููุง](https://huggingface.co/docs/accelerate/v0.22.0/en/concept_guides/big_model_inference).
ูุงุญุธุ ูุน ุฐููุ ุฃูู ูู ุญูู ุฃู ููุงุฒุงุฉ ูููุงุช ุงููุนุงูุฌุฉ ุงูุจุณูุทุฉ ูุนุงูุฉ ููุบุงูุฉุ ุฅูุง ุฃููุง ูุง ุชุนุงูุฌ ูุดููุงุช ุนุฏู ูุดุงุท ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU). ููุฐุงุ ุชููู ููุงุฒุงุฉ ูููุงุช ุงููุนุงูุฌุฉ ุงููุชูุฏูุฉ ูุทููุจุฉ ููุง ูู ููุถุญ [ููุง](https://huggingface.co/docs/transformers/en/perf_train_gpu_many#naive-model-parallelism-vertical-and-pipeline-parallelism).

ุฅุฐุง ูุงู ูุฏูู ุญู ุงููุตูู ุฅูู ุนูุฏุฉ 8 x 80 ุฌูุฌุงุจุงูุช A100ุ ูููููู ุชุญููู BLOOM ููุง ููู

```bash
!pip install transformers accelerate bitsandbytes optimum
```
```python
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained("bigscience/bloom", device_map="auto", pad_token_id=0)
```

ูู ุฎูุงู ุงุณุชุฎุฏุงู `device_map="auto"` ุณูุชู ุชูุฒูุน ุทุจูุงุช ุงูุงูุชูุงู ุจุงูุชุณุงูู ุนุจุฑ ุฌููุน ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุงููุชุงุญุฉ.

ูู ูุฐุง ุงูุฏูููุ ุณูุณุชุฎุฏู [bigcode/octocoder](https://huggingface.co/bigcode/octocoder) ูุฃูู ูููู ุชุดุบููู ุนูู ุดุฑูุญุฉ ุฌูุงุฒ GPU A100 ุฐุงุช 40 ุฌูุฌุง ุจุงูุช. ูุงุญุธ ุฃู ุฌููุน ุชุญุณููุงุช ุงูุฐุงูุฑุฉ ูุงูุณุฑุนุฉ ุงูุชู ุณูุทุจููุง ูู ุงูุขู ูุตุงุนุฏูุง ุชูุทุจู ุจุงูุชุณุงูู ุนูู ุงูููุงุฐุฌ ุงูุชู ุชุชุทูุจ ููุงุฒุงุฉ ุงูููุงุฐุฌ ุฃู ุงููุตูููุงุช.

ูุธุฑูุง ูุฃู ุงููููุฐุฌ ููุญูููู ุจุฏูุฉ bfloat16ุ ูุจุงุณุชุฎุฏุงู ูุงุนุฏุชูุง ุงูุฅุฑุดุงุฏูุฉ ุฃุนูุงูุ ูุชููุน ุฃู ุชููู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุดุบูู ุงูุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู `bigcode/octocoder` ุญูุงูู 31 ุฌูุฌุง ุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM). ุฏุนูุง ูุฌุฑุจ.

ูููู ุฃููุงู ุจุชุญููู ุงููููุฐุฌ ูุงููุฌุฒูุก ุงููุบูู ุซู ูููู ุจุชูุฑูุฑ ููุงููุง ุฅูู ูุงุฆู [ูููุงุช ุงููุนุงูุฌุฉ](https://huggingface.co/docs/transformers/main_classes/pipelines) ูู Transformers.

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch

model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", torch_dtype=torch.bfloat16, device_map="auto", pad_token_id=0)
tokenizer = AutoTokenizer.from_pretrained("bigcode/octocoder")

pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)
```

```python
prompt = "Question: Please write a function in Python that transforms bytes to Giga bytes.\n\nAnswer:"

result = pipe(prompt, max_new_tokens=60)[0]["generated_text"][len(prompt):]
result
```

**ุงูุฅุฎุฑุงุฌ**:
```
Here is a Python function that transforms bytes to Giga bytes:\n\n```python\ndef bytes_to_giga_bytes(bytes):\n    return bytes / 1024 / 1024 / 1024\n```\n\nThis function takes a single
```

ุฑุงุฆุนุ ูููููุง ุงูุขู ุงุณุชุฎุฏุงู ุงููุชูุฌุฉ ูุจุงุดุฑุฉ ูุชุญููู ุงูุจุงูุช ุฅูู ุฌูุฌุง ุจุงูุช.

```python
def bytes_to_giga_bytes(bytes):
  return bytes / 1024 / 1024 / 1024
```

ุฏุนููุง ูุณุชุฏุนู [`torch.cuda.max_memory_allocated`](https://pytorch.org/docs/stable/generated/torch.cuda.max_memory_allocated.html) ูููุงุณ ุฐุฑูุฉ ุชุฎุตูุต ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU).

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:
```bash
29.0260648727417
```

ูุฑูุจ ุจูุง ูููู ูู ุญุณุงุจูุง ุงูุชูุฑูุจู! ูููููุง ุฃู ูุฑู ุฃู ุงูุฑูู ุบูุฑ ุตุญูุญ ุชูุงููุง ูุฃู ุงูุงูุชูุงู ูู ุงูุจุงูุช ุฅูู ุงูููููุจุงูุช ูุชุทูุจ ุงูุถุฑุจ ูู 1024 ุจุฏูุงู ูู 1000. ูุฐูู ูููู ุฃูุถูุง ููู ุตูุบุฉ ุงูุชูุฑูุจ ุนูู ุฃููุง ุญุณุงุจ "ุจุญุฏ ุฃูุตู X ุฌูุฌุง ุจุงูุช".
ูุงุญุธ ุฃูู ุฅุฐุง ุญุงูููุง ุชุดุบูู ุงููููุฐุฌ ุจุฏูุฉ float32 ุงููุงููุฉุ ูุณุชููู ููุงู ุญุงุฌุฉ ุฅูู 64 ุฌูุฌุง ุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM).

> ูุชู ุชุฏุฑูุจ ุฌููุน ุงูููุงุฐุฌ ุชูุฑูุจูุง ุจุชูุณูู bfloat16 ูู ุงูููุช ุงูุญุงููุ ููุง ููุฌุฏ ุณุจุจ ูุชุดุบูู ุงููููุฐุฌ ุจุฏูุฉ float32 ุงููุงููุฉ ุฅุฐุง [ูุงูุช ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุงูุฎุงุตุฉ ุจู ุชุฏุนู bfloat16](https://discuss.pytorch.org/t/bfloat16-native-support/117155/5). ูู ุชููุฑ ุฏูุฉ float32 ูุชุงุฆุฌ ุงุณุชุฏูุงู ุฃูุถู ูู ุงูุฏูุฉ ุงูุชู ุชู ุงุณุชุฎุฏุงููุง ูุชุฏุฑูุจ ุงููููุฐุฌ.

ุฅุฐุง ูู ุชูู ูุชุฃูุฏูุง ูู ุชูุณูู ุชุฎุฒูู ุฃูุฒุงู ุงููููุฐุฌ ุนูู Hubุ ูููููู ุฏุงุฆููุง ุงูุงุทูุงุน ุนูู ุชููุฆุฉ ููุทุฉ ุงูุชูุชูุด ูู `"torch_dtype"`ุ ุนูู ุณุจูู ุงููุซุงู [ููุง](https://huggingface.co/meta-llama/Llama-2-7b-hf/blob/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/config.json#L21). ููุตู ุจุชุนููู ุงููููุฐุฌ ุฅูู ููุณ ููุน ุงูุฏูุฉ ููุง ูู ููุชูุจ ูู ุงูุชููุฆุฉ ุนูุฏ ุงูุชุญููู ุจุงุณุชุฎุฏุงู `from_pretrained(..., torch_dtype=...)` ุฅูุง ุฅุฐุง ูุงู ุงูููุน ุงูุฃุตูู ูู float32ุ ููู ูุฐู ุงูุญุงูุฉ ูููู ุงุณุชุฎุฏุงู `float16` ุฃู `bfloat16` ููุงุณุชุฏูุงู.


ุฏุนููุง ูุญุฏุฏ ูุธููุฉ `flush(...)` ูุชุญุฑูุฑ ุฌููุน ุงูุฐุงูุฑุฉ ุงููุฎุตุตุฉ ุจุญูุซ ูููููุง ููุงุณ ุฐุฑูุฉ ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุงููุฎุตุตุฉ ุจุฏูุฉ.

```python
del pipe
del model

import gc
import torch

def flush():
  gc.collect()
  torch.cuda.empty_cache()
  torch.cuda.reset_peak_memory_stats()
```

ุฏุนููุง ูุณุชุฏุนูู ุงูุขู ููุชุฌุฑุจุฉ ุงูุชุงููุฉ.

```python
flush()
```
ูู ุงูุฅุตุฏุงุฑ ุงูุฃุฎูุฑ ูู ููุชุจุฉ Accelerateุ ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู ุทุฑููุฉ ูุณุงุนุฏุฉ ุชุณูู `release_memory()`

```python
from accelerate.utils import release_memory
# ...

release_memory(model)
```
```python
from accelerate.utils import release_memory
# ...

release_memory(model)
```

ูุงูุขู ูุงุฐุง ูู ูู ููู ูุฏู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูุฏูู 32 ุฌูุฌุง ุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM)ุ ููุฏ ูุฌุฏ ุฃู ุฃูุฒุงู ุงูููุงุฐุฌ ูููู ุชุญููููุง ุฅูู 8 ุจุชุงุช ุฃู 4 ุจุชุงุช ุฏูู ุฎุณุงุฑุฉ ูุจูุฑุฉ ูู ุงูุฃุฏุงุก (ุงูุธุฑ [Dettmers et al.](https://arxiv.org/abs/2208.07339)).
ูููู ุชุญููู ุงููููุฐุฌ ุฅูู 3 ุจุชุงุช ุฃู 2 ุจุชุงุช ูุน ููุฏุงู ููุจูู ูู ุงูุฃุฏุงุก ููุง ูู ููุถุญ ูู ูุฑูุฉ [GPTQ](https://arxiv.org/abs/2210.17323) ๐คฏ.

ุฏูู ุงูุฏุฎูู ูู ุงููุซูุฑ ูู ุงูุชูุงุตููุ ุชูุฏู ูุฎุทุทุงุช ุงูุชูููู ุฅูู ุชุฎููุถ ุฏูุฉ ุงูุฃูุฒุงู ูุน ูุญุงููุฉ ุงูุญูุงุธ ุนูู ุฏูุฉ ูุชุงุฆุฌ ุงููููุฐุฌ ููุง ูู (*ุฃู* ุฃูุฑุจ ูุง ูููู ุฅูู bfloat16).
ูุงุญุธ ุฃู ุงูุชูููู ูุนูู ุจุดูู ุฎุงุต ุฌูุฏูุง ูุชูููุฏ ุงููุต ุญูุซ ูู ูุง ููุชู ุจู ูู ุงุฎุชูุงุฑ *ูุฌููุนุฉ ุงูุฑููุฒ ุงูุฃูุซุฑ ุงุญุชูุงููุง ุงูุชุงููุฉ* ููุง ููุชู ุญููุง ุจุงูููู ุงูุฏูููุฉ ูุชูุฒูุน ุงูุฑูุฒ ุงูุชุงูู *logit*.
ูู ูุง ููู ูู ุฃู ุชูุฒูุน ุงูุฑูุฒ ุงูุชุงูู *logit* ูุธู ููุง ูู ุชูุฑูุจูุง ุจุญูุซ ุชุนุทู ุนูููุฉ `argmax` ุฃู `topk` ููุณ ุงููุชุงุฆุฌ.

ููุงู ุนุฏุฉ ุชูููุงุช ููุชููููุ ูุงูุชู ูู ููุงูุดูุง ุจุงูุชูุตูู ููุงุ ูููู ุจุดูู ุนุงูุ ุชุนูู ุฌููุน ุชูููุงุช ุงูุชูููู ููุง ููู:

-   1.  ุชูููู ุฌููุน ุงูุฃูุฒุงู ุฅูู ุงูุฏูุฉ ุงููุณุชูุฏูุฉ
-   2.  ุชุญููู ุงูุฃูุฒุงู ุงููุญููุฉุ ููุฑุฑ ุชุณูุณู ุงููุฏุฎูุงุช ูู ุงููุชุฌูุงุช ุจุชูุณูู bfloat16
-   3.  ูู ุจุชุญููู ุงูุฃูุฒุงู ุฏููุงูููููุง ุฅูู bfloat1  ูุฅุฌุฑุงุก ุงูุญุณุงุจุงุช ูุน ูุชุฌูุงุช ุงููุฏุฎูุงุช ุจุฏูุฉ `bfloat16`

ุจุงุฎุชุตุงุฑุ ูุฐุง ูุนูู ุฃู ูุถุฑูุจุงุช *ูุตูููุฉ ุงููุฏุฎูุงุช-ุงููุฒู*ุ ุญูุซ \\( X \\) ูู ุงููุฏุฎูุงุชุ \\( W \\) ูู ูุตูููุฉ ูุฒู ู \\( Y \\) ูู ุงููุงุชุฌ:

$$ Y = X * W $$

ุชุชุบูุฑ ุฅูู

$$ Y = X * \text{dequantize}(W) $$

ููู ุนูููุฉ ุถุฑุจ ุงููุตูููุงุช. ูุชู ุชูููุฐ ุฅูุบุงุก ุงูุชูููู ูุฅุนุงุฏุฉ ุงูุชูููู ุจุดูู ูุชุณูุณู ูุฌููุน ูุตูููุงุช ุงูุฃูุฒุงู ุฃุซูุงุก ูุฑูุฑ ุงููุฏุฎูุงุช ุนุจุฑ ุฑุณู ุงูุดุจูุฉ.

ูุฐููุ ุบุงูุจูุง ูุง ูุง ูุชู ุชูููู ููุช ุงูุงุณุชุฏูุงู ุนูุฏ ุงุณุชุฎุฏุงู ุงูุฃูุฒุงู ุงูููููุฉุ ูููู ุจุฏูุงู ูู ุฐูู ูุฒูุฏ.

ููู ูุธุฑูุฉุ ุฏุนูุง ูุฌุฑุจ! ูุชูููู ุงูุฃูุฒุงู ุจุงุณุชุฎุฏุงู ุงููุญููุงุชุ ุชุญุชุงุฌ ุฅูู ุงูุชุฃูุฏ ูู ุชุซุจูุช ููุชุจุฉ [`bitsandbytes`](https://github.com/TimDettmers/bitsandbytes).

```bash
!pip install bitsandbytes
```

ูููููุง ุจุนุฏ ุฐูู ุชุญููู ุงูููุงุฐุฌ ูู ุชูููู 8 ุจุช ุจุจุณุงุทุฉ ุนู ุทุฑูู ุฅุถุงูุฉ ุนูุงูุฉ `load_in_8bit=True` ุฅูู `from_pretrained`.

```python
model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", load_in_8bit=True, pad_token_id=0)
```

ุงูุขูุ ุฏุนูุง ูุนูุฏ ุชุดุบูู ูุซุงููุง ููููุณ ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ.

```python
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

result = pipe(prompt, max_new_tokens=60)[0]["generated_text"][len(prompt):]
result
```

**ุงูุฅุฎุฑุงุฌ**:
```
Here is a Python function that transforms bytes to Giga bytes:\n\n```python\ndef bytes_to_giga_bytes(bytes):\n    return bytes / 1024 / 1024 / 1024\n```\n\nThis function takes a single
```

ุฌูููุ ูุญุตู ุนูู ููุณ ุงููุชูุฌุฉ ููุง ูู ุงูุณุงุจูุ ูุฐูู ูุง ููุฌุฏ ููุฏุงู ูู ุงูุฏูุฉ! ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ููุฏุงุฑ ุงูุฐุงูุฑุฉ ุงููุณุชุฎุฏูุฉ ูุฐู ุงููุฑุฉ.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:
```
15.219234466552734
```

ุฃูู ุจูุซูุฑ! ููุฏ ุงูุฎูุถูุง ุฅูู ูุง ูุฒูุฏ ููููุงู ุนู 15 ุฌูุฌุงุจุงูุชุ ูุจุงูุชุงูู ูููููุง ุชุดุบูู ูุฐุง ุงููููุฐุฌ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ูููุณุชููู ูุซู 4090.

ูุฑู ููุณุจูุง ูุทูููุง ุฌุฏูุง ูู ููุงุกุฉ ุงูุฐุงูุฑุฉ ููุง ููุฌุฏ ุชูุฑูุจูุง ุฃู ุชุฏููุฑ ูู ูุงุชุฌ ุงููููุฐุฌ. ููุน ุฐููุ ูููููุง ุฃูุถูุง ููุงุญุธุฉ ุชุจุงุทุค ุทููู ุฃุซูุงุก ุงูุงุณุชุฏูุงู.

ูุญุฐู ุงูููุงุฐุฌ ูููุฑุบ ุงูุฐุงูุฑุฉ ูุฑุฉ ุฃุฎุฑู.
```python
del model
del pipe
```

```python
flush()
```

ุฏุนูุง ูุฑู ูุง ูู ุงุณุชููุงู ุฐุงูุฑุฉ GPU ุงูุฐุฑูุฉ ุงูุฐู ูููุฑู ุชูููู 4 ุจุช. ูููู ุชูููู ุงููููุฐุฌ ุฅูู 4 ุจุช ุจุงุณุชุฎุฏุงู ููุณ ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ููุง ูู ุงูุณุงุจู - ูุฐู ุงููุฑุฉ ุนู ุทุฑูู ุชูุฑูุฑ `load_in_4bit=True` ุจุฏูุงู ูู `load_in_8bit=True`.

```python
model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", load_in_4bit=True, low_cpu_mem_usage=True, pad_token_id=0)

pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

result = pipe(prompt, max_new_tokens=60)[0]["generated_text"][len(prompt):]
result
```

**ุงูุฅุฎุฑุงุฌ**:
```
Here is a Python function that transforms bytes to Giga bytes:\n\n```\ndef bytes_to_gigabytes(bytes):\n    return bytes / 1024 / 1024 / 1024\n```\n\nThis function takes a single argument
```

ูุญู ูุฑู ุชูุฑูุจูุง ููุณ ูุต ุงูุฅุฎุฑุงุฌ ููุง ูู ุงูุณุงุจู - ููุท `python` ููููุฏ ูุจู ููุทุน ุงูููุฏ. ุฏุนูุง ูุฑู ููุฏุงุฑ ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:
```
9.543574333190918
```

ููุท 9.5 ุฌูุฌุงุจุงูุช! ูุฐุง ููุณ ูุซูุฑูุง ุจุงููุนู ููููุฐุฌ ูุฒูุฏ ุนุฏุฏ ูุนุงููุงุชู ุนู 15 ูููุงุฑ.

ุนูู ุงูุฑุบู ูู ุฃููุง ูุฑู ุชุฏููุฑูุง ุจุณูุทูุง ุฌุฏูุง ูู ุงูุฏูุฉ ููููุฐุฌูุง ููุงุ ุฅูุง ุฃู ุชูููู 4 ุจุช ูููู ุฃู ูุคุฏู ูู ุงูููุงุฑุณุฉ ุงูุนูููุฉ ุบุงูุจูุง ุฅูู ูุชุงุฆุฌ ูุฎุชููุฉ ููุงุฑูุฉ ุจุชูููู 8 ุจุช ุฃู ุงูุงุณุชุฏูุงู ุงููุงูู `bfloat16`. ุงูุฃูุฑ ูุชุฑูู ูููุณุชุฎุฏู ูุชุฌุฑุจุชู.

ูุงุญุธ ุฃูุถูุง ุฃู ุงูุงุณุชุฏูุงู ููุง ูุงู ุฃุจุทุฃ ููููุงู ููุงุฑูุฉ ุจุชูููู 8 ุจุช ูุงูุฐู ูุฑุฌุน ุฅูู ุทุฑููุฉ ุงูุชูููู ุงูุฃูุซุฑ ุนุฏูุงููุฉ ุงููุณุชุฎุฏูุฉ ูุชูููู 4 ุจุช ููุง ูุคุฏู ุฅูู \\( \text{quantize} \\) ู \\( \text{dequantize} \\) ูุณุชุบุฑู ููุชูุง ุฃุทูู ุฃุซูุงุก ุงูุงุณุชุฏูุงู.

```python
del model
del pipe
```
```python
flush()
```

ุจุดูู ุนุงูุ ุฑุฃููุง ุฃู ุชุดุบูู OctoCoder ุจุฏูุฉ 8 ุจุช ููู ูู ุฐุงูุฑุฉ GPU VRAM ุงููุทููุจุฉ ูู 32G GPU VRAM ุฅูู 15 ุฌูุฌุงุจุงูุช ููุทุ ูุชุดุบูู ุงููููุฐุฌ ุจุฏูุฉ 4 ุจุช ูููู ูู ุฐุงูุฑุฉ GPU VRAM ุงููุทููุจุฉ ุฅูู ูุง ูุฒูุฏ ููููุงู ุนู 9 ุฌูุฌุงุจุงูุช.

ูุณูุญ ุชูููู 4 ุจุช ุจุชุดุบูู ุงููููุฐุฌ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ูุซู RTX3090 ู V100 ู T4 ูุงูุชู ูููู ุงููุตูู ุฅูููุง ุจุณูููุฉ ููุนุธู ุงูุฃุดุฎุงุต.

ููุฒูุฏ ูู ุงููุนูููุงุช ุญูู ุงูุชูููู ูููุนุฑูุฉ ููู ูููู ุชูููู ุงูููุงุฐุฌ ูุทูุจ ุฐุงูุฑุฉ GPU VRAM ุฃูู ุญุชู ูู 4 ุจุชุ ููุตู ุจุงูุงุทูุงุน ุนูู ุชูููุฐ [`AutoGPTQ`](https://huggingface.co/docs/transformers/main/en/main_classes/quantization#autogptq-integration%60).

> ูุงุณุชูุชุงุฌุ ูู ุงูููู ุชุฐูุฑ ุฃู ุชูููู ุงููููุฐุฌ ูุชุฏุงูู ููุงุกุฉ ุงูุฐุงูุฑุฉ ุงููุญุณูุฉ ููุงุจู ุงูุฏูุฉ ููู ุจุนุถ ุงูุญุงูุงุช ููุช ุงูุงุณุชุฏูุงู.

ุฅุฐุง ูู ุชูู ุฐุงูุฑุฉ GPU ููุฏูุง ูุญุงูุชู ุงูุงุณุชุฎุฏุงูุ ูุบุงูุจูุง ูุง ุชูุฌุฏ ุญุงุฌุฉ ูููุธุฑ ูู ุงูุชูููู. ููุน ุฐููุ ูุง ูููู ููุนุฏูุฏ ูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุจุจุณุงุทุฉ ุชุดุบูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจุฏูู ุทุฑู ุงูุชูููู ููู ูุฐู ุงูุญุงูุฉุ ุชุนุฏ ูุฎุทุทุงุช ุงูุชูููู 4 ุจุช ู 8 ุจุช ุฃุฏูุงุช ูููุฏุฉ ููุบุงูุฉ.

ููุฒูุฏ ูู ุงููุนูููุงุช ุญูู ุงูุงุณุชุฎุฏุงู ุงูุชูุตูููุ ููุตู ุจุดุฏุฉ ุจุฅููุงุก ูุธุฑุฉ ุนูู [ูุซุงุฆู ุชูููู ุงููุญููุงุช](https://huggingface.co/docs/transformers/main_classes/quantization#general-usage).

ุจุนุฏ ุฐููุ ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ููููุฉ ุชุญุณูู ุงูููุงุกุฉ ุงูุญุณุงุจูุฉ ูููุงุกุฉ ุงูุฐุงูุฑุฉ ุจุงุณุชุฎุฏุงู ุฎูุงุฑุฒููุงุช ุฃูุถู ูุจููุฉ ูููุฐุฌ ูุญุณูุฉ.

## 2. ุงูุงูุชุจุงู ุงูุณุฑูุน

ุชุชุดุงุฑู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ (LLMs) ุงูุฃุนูู ุฃุฏุงุกู ุงูููู ุชูุฑูุจูุง ููุณ ุงูุจููุฉ ุงูุฃุณุงุณูุฉ ุงูุชู ุชุชููู ูู ุทุจูุงุช ุงูุชุบุฐูุฉ ุงูุฃูุงููุฉุ ูุทุจูุงุช ุงูุชูุดูุทุ ูุทุจูุงุช ุงูุชุทุจูุน ุงูุทุจููุ ูุงูุฃูู ูู ุฐููุ ุทุจูุงุช ุงูุงูุชุจุงู ุงูุฐุงุชู.

ุชุนุฏ ุทุจูุงุช ุงูุงูุชุจุงู ุงูุฐุงุชู ูุฑูุฒูุฉ ูููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ (LLMs) ุญูุซ ุชููู ุงููููุฐุฌ ูู ููู ุงูุนูุงูุงุช ุงูุณูุงููุฉ ุจูู ุฑููุฒ ุงููุฏุฎูุงุช.
ููุน ุฐููุ ูุฅู ุงุณุชููุงู ุฐุงูุฑุฉ GPU ุงูุฐุฑูุฉ ูุทุจูุงุช ุงูุงูุชุจุงู ุงูุฐุงุชู ูููู ุจุดูู *ุฑุจุงุนู* ูู ูู ูู ุงูุชุนููุฏ ุงูุญุณุงุจู ูุชุนููุฏ ุงูุฐุงูุฑุฉ ูุน ุนุฏุฏ ุฑููุฒ ุงููุฏุฎูุงุช (ูุงูุฐู ููุทูู ุนููู ุฃูุถูุง *ุทูู ุงูุชุณูุณู*) ุงูุฐู ูุณููู ูู ูุง ููู ุจู \\( N \\) .
ุนูู ุงูุฑุบู ูู ุฃู ูุฐุง ุบูุฑ ููุญูุธ ุญููุง ููุชุณูุณูุงุช ุงูุฃูุตุฑ (ุญุชู 1000 ุฑูุฒ ุฅุฏุฎุงู)ุ ุฅูุง ุฃูู ูุตุจุญ ูุดููุฉ ุฎุทูุฑุฉ ููุชุณูุณูุงุช ุงูุฃุทูู (ุญูุงูู 16000 ุฑูุฒ ุฅุฏุฎุงู).

ุฏุนูุง ูููู ูุธุฑุฉ ุฃูุฑุจ. ุงูุตูุบุฉ ูุญุณุงุจ ุงููุงุชุฌ \\( \mathbf{O} \\) ูุทุจูุฉ ุงูุงูุชุจุงู ุงูุฐุงุชู ูุฅุฏุฎุงู \\( \mathbf{X} \\) ุจุทูู \\( N \\) ูู:

$$ \textbf{O} = \text{Attn}(\mathbf{X}) = \mathbf{V} \times \text{Softmax}(\mathbf{QK}^T) \text{ with } \mathbf{Q} = \mathbf{W}_q \mathbf{X}, \mathbf{V} = \mathbf{W}_v \mathbf{X}, \mathbf{K} = \mathbf{W}_k \mathbf{X} $$

ูุนุฏ \\( \mathbf{X} = (\mathbf{x}_1, ... \mathbf{x}_{N}) \\) ุจุงูุชุงูู ุชุณูุณู ุงูุฅุฏุฎุงู ุฅูู ุทุจูุฉ ุงูุงูุชูุงู. ูุณุชุชููู ูู ูู ุงูุฅุณูุงุทุงุช \\( \mathbf{Q} \\) ู \\( \mathbf{K} \\) ูู \\( N \\) ูู ุงููุชุฌูุงุช ููุง ูุคุฏู ุฅูู ุฃู ูููู ุญุฌู \\( \mathbf{QK}^T \\) ูู \\( N^2 \\).

ุนุงุฏุฉ ูุง ูููู ูุฏู LLMs ุงูุนุฏูุฏ ูู ุฑุคูุณ ุงูุงูุชูุงูุ ูุจุงูุชุงูู ูุชู ุฅุฌุฑุงุก ุงูุนุฏูุฏ ูู ุญุณุงุจุงุช ุงูุงูุชูุงู ุงูุฐุงุชู ุจุงูุชูุงุฒู.
ูุจุงูุชุฑุงุถ ุฃู LLM ูุฏููุง 40 ุฑุฃุณ ุงูุชูุงู ูุชุนูู ุจุฏูุฉ bfloat16ุ ูููููุง ุญุณุงุจ ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุฎุฒูู ูุตูููุงุช \\( \mathbf{QK^T} \\) ูุชููู \\( 40 * 2 * N^2 \\) ุจุงูุช. ุจุงููุณุจุฉ ูู \\( N=1000 \\)ุ ูุง ููุฒู ุณูู ุญูุงูู 50 ููุฌุงุจุงูุช ูู VRAMุ ูููู ุจุงููุณุจุฉ ูู \\( N=16000 \\) ุณูุญุชุงุฌ ุฅูู 19 ุฌูุฌุงุจุงูุช ูู VRAMุ ูุจุงููุณุจุฉ ูู \\( N=100,000 \\) ุณูุญุชุงุฌ ุฅูู ูุง ููุฑุจ ูู 1 ุชูุฑุงุจุงูุช ููุท ูุชุฎุฒูู ูุตูููุงุช \\( \mathbf{QK}^T \\).

ุจุงุฎุชุตุงุฑุ ุณุฑุนุงู ูุง ูุตุจุญ ุฎูุงุฑุฒููุฉ ุงูุงูุชุจุงู ุงูุฐุงุชู ุงูุงูุชุฑุงุถูุฉ ููููุฉ ููุบุงูุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉ ุจุงููุณุจุฉ ูุณูุงูุงุช ุงูุฅุฏุฎุงู ุงููุจูุฑุฉ.

ูุน ุชุญุณู LLMs ูู ููู ุงููุต ูุชูููุฏ ุงููุตุ ูุชู ุชุทุจูููุง ุนูู ููุงู ูุชุฒุงูุฏุฉ ุงูุชุนููุฏ. ูู ุญูู ุฃู ุงูููุงุฐุฌ ูุงูุช ุชุชุนุงูู ุณุงุจููุง ูุน ุชุฑุฌูุฉ ุฃู ุชูุฎูุต ุจุถุน ุฌููุ ูุฅููุง ุงูุขู ุชุฏูุฑ ุตูุญุงุช ูุงููุฉุ ููุง ูุชุทูุจ ุงููุฏุฑุฉ ุนูู ูุนุงูุฌุฉ ุฃุทูุงู ุฅุฏุฎุงู ูุงุณุนุฉ.

ููู ูููููุง ุงูุชุฎูุต ูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ุงูุจุงูุธุฉ ููุชุทูููุงุช ุงููุฏุฎูุฉ ุงููุจูุฑุฉุ ูุญู ุจุญุงุฌุฉ ุฅูู ุทุฑููุฉ ุฌุฏูุฏุฉ ูุญุณุงุจ ุขููุฉ ุงูุงูุชูุงู ุงูุฐุงุชู ุงูุชู ุชุชุฎูุต ูู ูุตูููุฉ \\( QK^T \\). [ุทุฑููู ุฏุงู ูุขุฎุฑูู.](Https://arxiv.org/abs/2205.14135) ุทูุฑูุง ุจุงูุถุจุท ูุซู ูุฐุง ุงูุฎูุงุฑุฒููุฉ ุงูุฌุฏูุฏุฉ ูุฃุทูููุง ุนูููุง ุงุณู **Flash Attention**.

ุจุงุฎุชุตุงุฑุ ููุณุฑ ุงูุงูุชูุงู ุงูููุงุดู ุญุณุงุจ \\( \mathbf{V} \times \operatorname{Softmax}(\mathbf{QK}^T\\)) ููุญุณุจ ุจุฏูุงู ูู ุฐูู ูุทุนูุง ุฃุตุบุฑ ูู ุงูุฅุฎุฑุงุฌ ุนู ุทุฑูู ุงูุชูุฑุงุฑ ุนุจุฑ ุงูุนุฏูุฏ ูู ุฎุทูุงุช ุญุณุงุจ Softmax:

$$ \textbf{O}_i \leftarrow s^a_{ij} * \textbf{O}_i + s^b_{ij} * \mathbf{V}_{j} \times \operatorname{Softmax}(\mathbf{QK}^T_{i,j}) \text{ for multiple } i, j \text{ iterations } $$

ูุน \\( s^a_{ij} \\) ู \\( s^b_{ij} \\) ููููุง ุจุนุถ ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน softmax ุงูุชู ูุฌุจ ุฅุนุงุฏุฉ ุญุณุงุจูุง ููู \\( i \\) ู \\( j \\).

ูุฑุฌู ููุงุญุธุฉ ุฃู Flash Attention ุจุงููุงูู ุฃูุซุฑ ุชุนููุฏูุง ุฅูู ุญุฏ ูุง ููุชู ุชุจุณูุทู ุจุดูู ูุจูุฑ ููุง ุญูุซ ุฃู ุงูุชุนูู ูุซูุฑูุง ูุฎุฑุฌ ุนู ูุทุงู ูุฐุง ุงูุฏููู. ุงููุงุฑุฆ ูุฏุนู ูุฅููุงุก ูุธุฑุฉ ุนูู ูุฑูุฉ Flash Attention ุงูููุชูุจุฉ ุฌูุฏูุง [1] ููุฒูุฏ ูู ุงูุชูุงุตูู.

ุงูููุฑุฉ ุงูุฑุฆูุณูุฉ ููุง ูู:

> ูู ุฎูุงู ุชุชุจุน ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน softmax ูุงุณุชุฎุฏุงู ุจุนุถ ุงูุฑูุงุถูุงุช ุงูุฐููุฉุ ูุนุทู Flash Attention **ูุฎุฑุฌุงุช ูุชุทุงุจูุฉ ุฑููููุง** ููุงุฑูุฉ ุจุทุจูุฉ ุงูุงูุชูุงู ุงูุฐุงุชู ุงูุงูุชุฑุงุถูุฉ ุจุชูููุฉ ุฐุงูุฑุฉ ูุง ุชุฒูุฏ ุฎุทููุง ูุน \\( N \\).

ุนูุฏ ุงููุธุฑ ุฅูู ุงูุตูุบุฉุ ูุฏ ูููู ุงููุฑุก ุจุฏููููุง ุฃู ุงูุงูุชูุงู ุงูููุงุดู ูุฌุจ ุฃู ูููู ุฃุจุทุฃ ุจูุซูุฑ ููุงุฑูุฉ ุจุตูุบุฉ ุงูุงูุชูุงู ุงูุงูุชุฑุงุถูุฉ ุญูุซ ููุฒู ุฅุฌุฑุงุก ุงููุฒูุฏ ูู ุงูุญุณุงุจุงุช. ูู ุงููุงูุนุ ูุชุทูุจ Flash Attention ุงููุฒูุฏ ูู ุนูููุงุช ุงููุงุตูุฉ ุงูุนุงุฆูุฉ ููุงุฑูุฉ ุจุงูุงูุชูุงู ุงูุนุงุฏู ุญูุซ ูุฌุจ ุฅุนุงุฏุฉ ุญุณุงุจ ุฅุญุตุงุฆูุงุช ุงูุชุทุจูุน softmax ุจุงุณุชูุฑุงุฑ (ุฑุงุฌุน [ุงููุฑูุฉ](https://arxiv.org/abs/2205.14135) ููุฒูุฏ ูู ุงูุชูุงุตูู ุฅุฐุง ููุช ููุชููุง)

> ููุน ุฐููุ ูุฅู ุงูุงูุชูุงู ุงูููุงุดู ุฃุณุฑุน ุจูุซูุฑ ูู ุงูุงุณุชุฏูุงู ููุงุฑูุฉ ุจุงูุงูุชูุงู ุงูุงูุชุฑุงุถู ุงูุฐู ูุฃุชู ูู ูุฏุฑุชู ุนูู ุชูููู ุงูุทูุจุงุช ุนูู ุฐุงูุฑุฉ GPU ุงูุฃุจุทุฃ ุฐุงุช ุงููุทุงู ุงูุชุฑุฏุฏู ุงูุนุงูู (VRAM)ุ ูุงูุชุฑููุฒ ุจุฏูุงู ูู ุฐูู ุนูู ุฐุงูุฑุฉ SRAM ุงูุฃุณุฑุน ุงูููุฌูุฏุฉ ุนูู ุงูุดุฑูุญุฉ.

ูู ุงููุงุญูุฉ ุงูุฃุณุงุณูุฉุ ูุชุฃูุฏ Flash Attention ูู ุฅููุงููุฉ ุฅุฌุฑุงุก ุฌููุน ุนูููุงุช ุงููุชุงุจุฉ ูุงููุฑุงุกุฉ ุงููุณูุทุฉ ุจุงุณุชุฎุฏุงู ุฐุงูุฑุฉ SRAM ุงูุณุฑูุนุฉ ุงูููุฌูุฏุฉ ุนูู ุงูุดุฑูุญุฉ ุจุฏูุงู ูู ุงูุงุถุทุฑุงุฑ ุฅูู ุงููุตูู ุฅูู ุฐุงูุฑุฉ VRAM ุงูุฃุจุทุฃ ูุญุณุงุจ ูุชุฌู ุงูุฅุฎุฑุงุฌ \\( \mathbf{O} \\).

ูู ุงููุงุญูุฉ ุงูุนูููุฉุ ูุง ููุฌุฏ ุญุงูููุง ุฃู ุณุจุจ **ุนุฏู** ุงุณุชุฎุฏุงู ุงูุงูุชูุงู ุงูููุงุดู ุฅุฐุง ูุงู ูุชุงุญูุง. ุงูุฎูุงุฑุฒููุฉ ุชุนุทู ููุณ ุงููุฎุฑุฌุงุช ุฑูุงุถูุงุ ูุฃุณุฑุน ูุฃูุซุฑ ููุงุกุฉ ูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ.

ููููู ูุธุฑุฉ ุนูู ูุซุงู ุนููู.


ูุญุตู ูููุฐุฌ OctoCoder ุงูุฎุงุต ุจูุง ุงูุขู ุนูู ููุฌู ุฅุฏุฎุงู ุฃุทูู ุจุดูู ูุจูุฑ ูุชุถูู ูุง ูุณูู *ููุฌู ุงููุธุงู*. ุชูุณุชุฎุฏู ููุฌูุงุช ุงููุธุงู ูุชูุฌูู LLM ุฅูู ูุณุงุนุฏ ุฃูุถู ูุตูู ูููุงู ุงููุณุชุฎุฏููู.
ูููุง ูููุ ูุณุชุฎุฏู ููุฌู ุงููุธุงู ุงูุฐู ุณูุฌุนู OctoCoder ูุณุงุนุฏ ุชุฑููุฒ ุฃูุถู.

```python
system_prompt = """Below are a series of dialogues between various people and an AI technical assistant.
The assistant tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble but knowledgeable.
The assistant is happy to help with code questions and will do their best to understand exactly what is needed.
It also tries to avoid giving false or misleading information, and it caveats when it isn't entirely sure about the right answer.
That said, the assistant is practical really does its best, and doesn't let caution get too much in the way of being useful.

The Starcoder models are a series of 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2) (excluding opt-out requests).
The model uses Multi Query Attention, was trained using the Fill-in-the-Middle objective, and with 8,192 tokens context window for a trillion tokens of heavily deduplicated data.
-----

Question: Write a function that takes two lists and returns a list that has alternating elements from each input list.

Answer: Sure. Here is a function that does that.

def alternating(list1, list2):
   results = []
   for i in range(len(list1)):
       results.append(list1[i])
       results.append(list2[i])
   return results

Question: Can you write some test cases for this function?

Answer: Sure, here are some tests.

assert alternating([10, 20, 30], [1, 2, 3]) == [10, 1, 20, 2, 30, 3]
assert alternating([True, False], [4, 5]) == [True, 4, False, 5]
assert alternating([], []) == []

Question: Modify the function so that it returns all input elements when the lists have uneven length. The elements from the longer list should be at the end.

Answer: Here is the modified function.

def alternating(list1, list2):
   results = []
   for i in range(min(len(list1), len(list2))):
       results.append(list1[i])
       results.append(list2[i])
   if len(list1) > len(list2):
       results.extend(list1[i+1:])
   else:
       results.extend(list2[i+1:])
   return results
-----
"""
```
ูุฃุบุฑุงุถ ุงูุชูุถูุญุ ุณููุฑุฑ ููุฌู ุงููุธุงู ุนุดุฑ ูุฑุงุช ุจุญูุซ ูููู ุทูู ุงูุฅุฏุฎุงู ุทูููุงู ุจูุง ูููู ูููุงุญุธุฉ ูููุฑุงุช ุฐุงูุฑุฉ Flash Attention.
ูุถูู ููุฌู ุงููุต ุงูุฃุตูู "ุณุคุงู: ูุฑุฌู ูุชุงุจุฉ ูุธููุฉ ูู Python ุชููู ุจุชุญููู ุงูุจุงูุชุงุช ุฅูู ุฌูุฌุง ุจุงูุช.

```python
long_prompt = 10 * system_prompt + prompt
```

ูููู ุจุชูููุฐ ูููุฐุฌูุง ูุฑุฉ ุฃุฎุฑู ุจุฏูุฉ bfloat16.

```python
model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", torch_dtype=torch.bfloat16, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained("bigcode/octocoder")

pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)
```

ุฏุนูุง ุงูุขู ูููู ุจุชุดุบูู ุงููููุฐุฌ ุชูุงููุง ูุซููุง ูุงู ูู ูุจู *ุจุฏูู ุงูุชูุงู ููุงุดู* ูููุงุณ ูุชุทูุจุงุช ุฐุงูุฑุฉ GPU ููุช ุงูุฐุฑูุฉ ูููุช ุงูุงุณุชุฏูุงู.

```python
import time

start_time = time.time()
result = pipe(long_prompt, max_new_tokens=60)[0]["generated_text"][len(long_prompt):]

print(f"Generated in {time.time() - start_time} seconds.")
result
```

**ุงูุฅุฎุฑุงุฌ**:
```
ุชู ุงูุชูููุฏ ูู 10.96854019165039 ุซุงููุฉ.
ุจุงูุชุฃููุฏ. ุฅููู ูุธููุฉ ููููุงู ุจุฐูู.

def bytes_to_giga(bytes):
return bytes / 1024 / 1024 / 1024

ุงูุฅุฌุงุจุฉ: ุจุงูุชุฃููุฏ. ุฅููู ูุธููุฉ ููููุงู ุจุฐูู.

ุฏูู
```

ูุญุตู ุนูู ููุณ ุงูุฅุฎุฑุงุฌ ููุง ูุงู ูู ูุจูุ ูููู ูุฐู ุงููุฑุฉุ ูููู ุงููููุฐุฌ ุจุชูุฑุงุฑ ุงูุฅุฌุงุจุฉ ุนุฏุฉ ูุฑุงุช ุญุชู ูุชู ูุทุนูุง ุนูุฏ 60 ุฑูุฒูุง. ููุณ ูู ุงููุณุชุบุฑุจ ุฃููุง ูุฑุฑูุง ููุฌู ุงููุธุงู ุนุดุฑ ูุฑุงุช ูุฃุบุฑุงุถ ุงูุชูุถูุญ ูุจุงูุชุงูู ูููุง ุจุชุดุบูู ุงููููุฐุฌ ูุชูุฑุงุฑ ููุณู.

**ููุงุญุธุฉ** ูุง ููุจุบู ุชูุฑุงุฑ ููุฌู ุงููุธุงู ุนุดุฑ ูุฑุงุช ูู ุงูุชุทุจููุงุช ุงููุงูุนูุฉ - ูุฑุฉ ูุงุญุฏุฉ ูุงููุฉ!

ุฏุนูุง ูููุณ ูุชุทูุจุงุช ุฐุงูุฑุฉ GPU ููุช ุงูุฐุฑูุฉ.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:
```
37.668193340301514
```

ููุง ูุฑูุ ูุฅู ูุชุทูุจุงุช ุฐุงูุฑุฉ GPU ููุช ุงูุฐุฑูุฉ ุฃุนูู ุจูุซูุฑ ููุง ูุงูุช ุนููู ูู ุงูุจุฏุงูุฉุ ููู ูุง ูุฑุฌุน ุฅูู ุญุฏ ูุจูุฑ ุฅูู ุชุณูุณู ุงูุฅุฏุฎุงู ุงูุฃุทูู. ุฃูุถูุงุ ูุณุชุบุฑู ุงูุชูููุฏ ุฃูุซุฑ ูู ุฏูููุฉ ุจูููู ุงูุขู.

ูุณุชุฏุนู `flush()` ูุชุญุฑูุฑ ุฐุงูุฑุฉ GPU ูุชุฌุฑุจุชูุง ุงูุชุงููุฉ.

```python
flush()
```

ูููุงุฑูุฉุ ุฏุนููุง ูููู ุจุชุดุบูู ููุณ ุงูุฏุงูุฉุ ูููู ุชูููู ุงูุงูุชูุงู ููุงุด ุจุฏูุง ูู ุฐูู.
ููููุงู ุจุฐููุ ูููู ุจุชุญููู ุงููููุฐุฌ ุฅูู [BetterTransformer](Https://huggingface.co/docs/optimum/bettertransformer/overview) ููู ุฎูุงู ุงูููุงู ุจุฐูู ุชูููู PyTorch's [SDPA self-attention](Https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention) ูุงูุชู ุจุฏูุฑูุง ูุงุฏุฑุฉ ุนูู ุงุณุชุฎุฏุงู ุงูุงูุชูุงู ููุงุด.

```python
model.to_bettertransformer()
```

ุงูุขู ูููู ุจุชุดุบูู ููุณ ููุชุทู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุจุงูุถุจุท ููุง ูุงู ูู ูุจู ูุชุญุช ุงูุบุทุงุก ุณูู ุชุณุชุฎุฏู ุงููุญููุงุช ุงูุงูุชูุงู ููุงุด.

```py
start_time = time.time()
with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=False):
    result = pipe(long_prompt, max_new_tokens=60)[0]["generated_text"][len(long_prompt):]

print(f"Generated in {time.time() - start_time} seconds.")
result
```

**ุงูุฅุฎุฑุงุฌ**:
```
ุชู ุงูุชูููุฏ ูู 3.0211617946624756 ุซุงููุฉ.
ุจุงูุชุฃููุฏ. ุฅููู ูุธููุฉ ููููุงู ุจุฐูู.

def bytes_to_giga(bytes):
return bytes / 1024 / 1024 / 1024

ุงูุฅุฌุงุจุฉ: ุจุงูุชุฃููุฏ. ุฅููู ูุธููุฉ ููููุงู ุจุฐูู.

ุฏูู
```

ูุญุตู ุนูู ููุณ ุงููุชูุฌุฉ ุจุงูุถุจุท ููุง ูุงู ูู ูุจูุ ูููู ูููููุง ููุงุญุธุฉ ุชุณุฑูุน ูุจูุฑ ุจูุถู ุงูุงูุชูุงู ููุงุด.

ุฏุนูุง ูููุณ ุงุณุชููุงู ุงูุฐุงูุฑุฉ ูุขุฎุฑ ูุฑุฉ.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:
```
32.617331981658936
```

ููุญู ุชูุฑูุจุง ูุฑุฉ ุฃุฎุฑู ุฅูู ุฐุงูุฑุฉ GPU ุงูุฐุฑูุฉ ุงูุฃุตููุฉ ูุฏููุง 29GB.

ูููููุง ุฃู ููุงุญุธ ุฃููุง ูุณุชุฎุฏู ููุท ุญูุงูู 100 ููุฌุงุจุงูุช ุฅุถุงููุฉ ูู ุฐุงูุฑุฉ GPU ุนูุฏ ุชูุฑูุฑ ุชุณูุณู ุฅุฏุฎุงู ุทููู ุฌุฏูุง ูุน ุงูุงูุชูุงู ููุงุด ููุงุฑูุฉ ุจุชูุฑูุฑ ุชุณูุณู ุฅุฏุฎุงู ูุตูุฑ ููุง ูุนููุง ูู ุงูุจุฏุงูุฉ.

```py
flush()
```

ููุฒูุฏ ูู ุงููุนูููุงุช ุญูู ููููุฉ ุงุณุชุฎุฏุงู Flash Attentionุ ูุฑุฌู ุงูุงุทูุงุน ุนูู [ุตูุญุฉ doc ูุฐู](Https://huggingface.co/docs/transformers/en/perf_infer_gpu_one#flashattention-2).

## 3. ุงูุงุจุชูุงุฑุงุช ุงููุนูุงุฑูุฉ

ุญุชู ุงูุขูุ ูุธุฑูุง ูู ุชุญุณูู ุงูููุงุกุฉ ุงูุญุณุงุจูุฉ ูุงูุฐุงูุฑุฉ ูู ุฎูุงู:

-   ุตุจ ุงูุฃูุฒุงู ูู ุชูุณูู ุฏูุฉ ุฃูู
-   ุงุณุชุจุฏุงู ุฎูุงุฑุฒููุฉ ุงูุงูุชูุงู ุงูุฐุงุชู ุจุฅุตุฏุงุฑ ุฃูุซุฑ ููุงุกุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉ ูุงูุญุณุงุจ

ุฏุนููุง ุงูุขู ูููู ูุธุฑุฉ ุนูู ููููุฉ ุชุบููุฑ ุจููุฉ LLM ุจุญูุซ ุชููู ุฃูุซุฑ ูุนุงููุฉ ูููุงุกุฉ ููููุงู ุงูุชู ุชุชุทูุจ ูุฏุฎูุงุช ูุตูุฉ ุทูููุฉุ ุนูู ุณุจูู ุงููุซุงู:
-   ุงุณุชุฑุฌุงุน ุงูุฃุณุฆูุฉ ุงููุนุฒุฒุฉุ
-   ุชูุฎูุตุ
-   ุงูุฏุฑุฏุดุฉ

ูุงุญุธ ุฃู "ุงูุฏุฑุฏุดุฉ" ูุง ุชุชุทูุจ ูู LLM ุงูุชุนุงูู ูุน ูุฏุฎูุงุช ูุตูุฉ ุทูููุฉ ูุญุณุจุ ุจู ุชุชุทูุจ ุฃูุถูุง ุฃู ูููู LLM ูุงุฏุฑูุง ุนูู ุงูุชุนุงูู ุจููุงุกุฉ ูุน ุงูุญูุงุฑ ุฐูุงุจูุง ูุฅูุงุจูุง ุจูู ุงููุณุชุฎุฏู ูุงููุณุงุนุฏ (ูุซู ChatGPT).

ุจูุฌุฑุฏ ุชุฏุฑูุจูุงุ ูุตุจุญ ูู ุงูุตุนุจ ุชุบููุฑ ุจููุฉ LLM ุงูุฃุณุงุณูุฉุ ูุฐูู ูู ุงูููู ูุฑุงุนุงุฉ ููุงู LLM ูุณุจููุง ูุชุญุณูู ุจููุฉ ุงููููุฐุฌ ููููุง ูุฐูู.
ููุงู ููููุงู ูููุงู ูุจููุฉ ุงููููุฐุฌ ูุตุจุญุงู ุจุณุฑุนุฉ ุนูู ุฒุฌุงุฌุฉ ููุฐุงูุฑุฉ ู/ุฃู ุงูุฃุฏุงุก ูุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงููุจูุฑุฉ.

-   ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉ
-   ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ูููููุฉ ุงูุฑุฆูุณูุฉ

ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ูู ูููู ุจูุฒูุฏ ูู ุงูุชูุงุตูู

### 3.1 ุชุญุณูู ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉ ูู LLMs

ูุถุน ุงูุงูุชูุงู ุงูุฐุงุชู ูู ุฑูุฒ ูู ุนูุงูุฉ ูุน ุฑููุฒ ุฃุฎุฑู.
ููุซุงูุ ูููู ุฃู ุชุจุฏู ูุตูููุฉ \\( \operatorname{Softmax}(\mathbf{QK}^T) \\) ูุชุณูุณู ุงูุฅุฏุฎุงู ุงููุตู *"ูุฑุญุจูุง"ุ "ุฃูุง"ุ "ุฃุญุจ"ุ "ุฃูุช"* ููุง ููู:

![](/blog/assets/163_optimize_llm/self_attn_tokens.png)

ูุชู ููุญ ูู ุฑูุฒ ูููุฉ ูุชูุฉ ุงุญุชูุงู ูุชู ูู ุฎูุงููุง ุงูุงูุชูุงู ุจุฌููุน ุฑููุฒ ุงููููุงุช ุงูุฃุฎุฑูุ ูุจุงูุชุงูู ูุชู ูุถุนูุง ูู ุนูุงูุฉ ูุน ุฌููุน ุฑููุฒ ุงููููุงุช ุงูุฃุฎุฑู. ุนูู ุณุจูู ุงููุซุงูุ ุชุญุถุฑ ูููุฉ *"ุงูุญุจ"* ูููุฉ *"ูุฑุญุจูุง"* ุจูุณุจุฉ 5%ุ ู *"ุฃูุง"* ุจูุณุจุฉ 30%ุ ูููุณูุง ุจูุณุจุฉ 65%.

ุณููุงุฌู LLM ุงููุงุฆู ุนูู ุงูุงูุชูุงู ุงูุฐุงุชูุ ูููู ุจุฏูู ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉุ ุตุนูุจุงุช ูุจูุฑุฉ ูู ููู ููุงุถุน ูุตูุต ุงูุฅุฏุฎุงู ุจุงููุณุจุฉ ูุจุนุถูุง ุงูุจุนุถ.
ููุฑุฌุน ุฐูู ุฅูู ุฃู ุฏุฑุฌุฉ ุงูุงุญุชูุงู ุงูุชู ูุญุณุจูุง \\( \mathbf{QK}^T \\) ุชุฑุจุท ูู ุฑูุฒ ูููุฉ ุจูู ุฑูุฒ ูููุฉ ุฃุฎุฑู ูู ุญุณุงุจุงุช \\( O (1) \\) ุจุบุถ ุงููุธุฑ ุนู ูุณุงูุฉ ุงูููุถุน ุงููุณุจู ุจููููุง.
ูุฐููุ ุจุงููุณุจุฉ ุฅูู LLM ุจุฏูู ุชุฑููุฒุงุช ููุถุนูุฉุ ูุจุฏู ุฃู ูู ุฑูุฒ ูู ููุณ ุงููุณุงูุฉ ุฅูู ุฌููุน ุงูุฑููุฒ ุงูุฃุฎุฑูุ ุนูู ุณุจูู ุงููุซุงูุ ุณูููู ูู ุงูุตุนุจ ุงูุชูููุฒ ุจูู *"ูุฑุญุจูุง ุฃูุง ุฃุญุจู"* ู *"ุฃูุช ุชุญุจูู ูุฑุญุจูุง"*.

ููู ูููู LLM ุชุฑุชูุจ ุงูุฌููุฉุ ููุฒู ูุฌูุฏ *ุฅุดุงุฑุฉ* ุฅุถุงููุฉ ููุชู ุชุทุจูููุง ุนุงุฏุฉู ูู ุดูู *ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉ* (ุฃู ูุง ููุทูู ุนููู ุฃูุถูุง *ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉ*).
ูู ูุชู ุชุฑุฌูุฉ ุงููุต ุงูุฎุงุต ูุงูุฑูุงุจุท ูุฃููุงุฏ HTML ูCSS ุจูุงุกู ุนูู ุทูุจู.

ูุฏู ูุคููู ุงููุฑูุฉ ุงูุจุญุซูุฉ [*Attention Is All You Need*](https://arxiv.org/abs/1706.03762) ุชุถูููุงุช ููุถุนูุฉ ุฌูุจูุฉ ูุซูุซูุฉ \\( \mathbf{P} = \mathbf{p}_1, \ldots, \mathbf{p}_N \\) ุญูุซ ูุชู ุญุณุงุจ ูู ูุชุฌู \\( \mathbf{p}_i \\) ูุฏุงูุฉ ุฌูุจูุฉ ูููุถุนู \\( i \\) .
ุจุนุฏ ุฐูู ูุชู ุจุจุณุงุทุฉ ุฅุถุงูุฉ ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุฅูู ูุชุฌูุงุช ุชุณูุณู ุงูุฅุฏุฎุงู \\( \mathbf{\hat{X}} = \mathbf{\hat{x}}_1, \ldots, \mathbf{\hat{x}}_N \\) = \\( \mathbf{x}_1 + \mathbf{p}_1, \ldots, \mathbf{x}_N + \mathbf{p}_N \\) ูุจุงูุชุงูู ุชูุฌูู ุงููููุฐุฌ ูุชุนูู ุชุฑุชูุจ ุงูุฌููุฉ ุจุดูู ุฃูุถู.

ุจุฏูุงู ูู ุงุณุชุฎุฏุงู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูุซุงุจุชุฉุ ุงุณุชุฎุฏู ุขุฎุฑูู (ูุซู [Devlin et al.](https://arxiv.org/abs/1810.04805)) ุชุถูููุงุช ููุถุนูุฉ ููุชุณุจุฉ ูุชู ูู ุฎูุงููุง ุชุนูู ุงูุชุถูููุงุช ุงูููุถุนูุฉ \\( \mathbf{P} \\) ุฃุซูุงุก ุงูุชุฏุฑูุจ.

ูุงูุช ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูุฌูุจูุฉ ูุงูููุชุณุจุฉ ูู ุงูุทุฑู ุงูุณุงุฆุฏุฉ ูุชุฑููุฒ ุชุฑุชูุจ ุงูุฌููุฉ ูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉุ ูููู ุชู ุงูุนุซูุฑ ุนูู ุจุนุถ ุงููุดููุงุช ุงููุชุนููุฉ ุจูุฐู ุงูุชุถูููุงุช ุงูููุถุนูุฉ:

1. ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูุฌูุจูุฉ ูุงูููุชุณุจุฉ ูู ุชุถูููุงุช ููุถุนูุฉ ูุทููุฉุ ุฃู ุชุฑููุฒ ุชุถููู ูุฑูุฏ ููู ูุนุฑู ููุถุนู: \\( 0, \ldots, N \\) . ููุง ุฃุธูุฑ [Huang et al.](https://arxiv.org/abs/2009.13658) ู [Su et al.](https://arxiv.org/abs/2104.09864)ุ ุชุคุฏู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงููุทููุฉ ุฅูู ุฃุฏุงุก ุถุนูู ูููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูููุฏุฎูุงุช ุงููุตูุฉ ุงูุทูููุฉ. ุจุงููุณุจุฉ ูููุฏุฎูุงุช ุงููุตูุฉ ุงูุทูููุฉุ ูููู ูู ุงููููุฏ ุฅุฐุง ุชุนูู ุงููููุฐุฌ ุงููุณุงูุฉ ุงูููุถุนูุฉ ุงููุณุจูุฉ ุงูุชู ุชูุชูููุง ุฑููุฒ ุงููุฏุฎูุงุช ุฅูู ุจุนุถูุง ุงูุจุนุถ ุจุฏูุงู ูู ููุถุนูุง ุงููุทูู.
2. ุนูุฏ ุงุณุชุฎุฏุงู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูููุชุณุจุฉุ ูุฌุจ ุชุฏุฑูุจ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุนูู ุทูู ุฅุฏุฎุงู ุซุงุจุช \\( N \\)ุ ููุง ูุฌุนู ูู ุงูุตุนุจ ุงูุงุณุชูุฑุงุก ุฅูู ุทูู ุฅุฏุฎุงู ุฃุทูู ููุง ุชู ุชุฏุฑูุจู ุนููู.

ูู ุงูุขููุฉ ุงูุฃุฎูุฑุฉุ ุฃุตุจุญุช ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงููุณุจูุฉ ุงูุชู ูููููุง ูุนุงูุฌุฉ ุงููุดููุงุช ุงููุฐููุฑุฉ ุฃุนูุงู ุฃูุซุฑ ุดุนุจูุฉุ ูุฃุจุฑุฒูุง:

-   [ุชุถููู ุงูููุถุน ุงูุฏูุฑุงูู (RoPE)](https://arxiv.org/abs/2104.09864)
-   [ALiBi](https://arxiv.org/abs/2108.12409)

ูุคูุฏ ูู ูู *RoPE* ู *ALiBi* ุฃูู ูู ุงูุฃูุถู ุชูุฌูู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุญูู ุชุฑุชูุจ ุงูุฌููุฉ ูุจุงุดุฑุฉ ูู ุฎูุงุฑุฒููุฉ ุงูุงูุชุจุงู ุงูุฐุงุชู ุญูุซ ูุชู ูุถุน ุฑููุฒ ุงููููุงุช ูู ุนูุงูุฉ ูุน ุจุนุถูุง ุงูุจุนุถ. ุนูู ูุฌู ุงูุชุญุฏูุฏุ ูุฌุจ ุชูุฌูู ุชุฑุชูุจ ุงูุฌููุฉ ุนู ุทุฑูู ุชุนุฏูู ุนูููุฉ \\( \mathbf{QK}^T \\) .

ุฏูู ุงูุฏุฎูู ูู ุงููุซูุฑ ูู ุงูุชูุงุตููุ ูุดูุฑ *RoPE* ุฅูู ุฃูู ูููู ุชุฑููุฒ ุงููุนูููุงุช ุงูููุถุนูุฉ ูู ุฃุฒูุงุฌ ุงูุงุณุชุนูุงู-ุงูููุชุงุญุ ุนูู ุณุจูู ุงููุซุงู \\( \mathbf{q}_i \\) ู \\( \mathbf{x}_j \\) ุนู ุทุฑูู ุชุฏููุฑ ูู ูุชุฌู ุจุฒุงููุฉ \\( \theta * i \\) ู \\( \theta * j \\) ุนูู ุงูุชูุงูู ูุน \\( i, j \\) ุชุตู ููุถุน ุงูุฌููุฉ ููู ูุชุฌู:

$$ \mathbf{\hat{q}}_i^T \mathbf{\hat{x}}_j = \mathbf{{q}}_i^T \mathbf{R}_{\theta, i -j} \mathbf{{x}}_j. $$

ููุซู \\( \mathbf{R}_{\theta, i - j} \\) ูุตูููุฉ ุฏูุฑุงููุฉ. \\( \theta \\) *ูุง* ูุชู ุชุนููู ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูููู ุจุฏูุงู ูู ุฐูู ูุชู ุชุนูููู ุฅูู ูููุฉ ูุญุฏุฏุฉ ูุณุจููุง ุชุนุชูุฏ ุนูู ุทูู ุชุณูุณู ุงูุฅุฏุฎุงู ุงูุฃูุตู ุฃุซูุงุก ุงูุชุฏุฑูุจ.

> ูู ุฎูุงู ุงูููุงู ุจุฐููุ ูุชู ุงูุชุฃุซูุฑ ุนูู ุฏุฑุฌุฉ ุงูุงุญุชูุงู ุจูู \\( \mathbf{q}_i \\) ู \\( \mathbf{q}_j \\) ููุท ุฅุฐุง \\( i \ne j \\) ููุนุชูุฏ ููุท ุนูู ุงููุณุงูุฉ ุงููุณุจูุฉ \\( i - j \\) ุจุบุถ ุงููุธุฑ ุนู ุงูููุงุถุน ุงููุญุฏุฏุฉ ููู ูุชุฌู \\( i \\) ู \\( j \\) .

ูุณุชุฎุฏู *RoPE* ูู ุงูุนุฏูุฏ ูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงูุฃูุซุฑ ุฃูููุฉ ุงููููุ ูุซู:

-   [**Falcon**](https://huggingface.co/tiiuae/falcon-40b)
-   [**Llama**](https://arxiv.org/abs/2302.13971)
-   [**PaLM**](https://arxiv.org/abs/2204.02311)

ูุจุฏููุ ููุชุฑุญ *ALiBi* ูุฎุทุท ุชุฑููุฒ ููุถุนู ูุณุจู ุฃุจุณุท ุจูุซูุฑ. ูุชู ุฅุถุงูุฉ ุงููุณุงูุฉ ุงููุณุจูุฉ ุงูุชู ุชูุชูููุง ุฑููุฒ ุงููุฏุฎูุงุช ุฅูู ุจุนุถูุง ุงูุจุนุถ ูุนุฏุฏ ุตุญูุญ ุณูุจู ูููุงุณ ุจูููุฉ ูุญุฏุฏุฉ ูุณุจููุง `m` ุฅูู ูู ุฅุฏุฎุงู ุงุณุชุนูุงู-ููุชุงุญ ููุตูููุฉ \\( \mathbf{QK}^T \\) ูุจุงุดุฑุฉ ูุจู ุญุณุงุจ softmax.

![](/blog/assets/163_optimize_llm/alibi.png)

ููุง ูู ููุถุญ ูู ูุฑูุฉ [ALiBi](https://arxiv.org/abs/2108.12409)ุ ูุณูุญ ูุฐุง ุงูุชุฑููุฒ ุงูููุถุนู ุงููุณุจู ุงูุจุณูุท ูููููุฐุฌ ุจุงูุญูุงุธ ุนูู ุฃุฏุงุก ุนุงูู ุญุชู ูู ุชุณูุณูุงุช ุงููุฏุฎูุงุช ุงููุตูุฉ ุงูุทูููุฉ ุฌุฏูุง.

ููุณุชุฎุฏู *ALiBi* ูู ุงูุนุฏูุฏ ูู ุฃูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงููุณุชุฎุฏูุฉ ุงููููุ ูุซู:

-   [**MPT**](https://huggingface.co/mosaicml/mpt-30b)
-   [**BLOOM**](https://huggingface.co/bigscience/bloom)

ูููู ููู ูู ุชุฑููุฒุงุช ุงูููุถุน *RoPE* ู *ALiBi* ุงูุงุณุชูุฑุงุก ุฅูู ุฃุทูุงู ุฅุฏุฎุงู ูู ูุชู ููุงุญุธุชูุง ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูู ุญูู ุซุจุช ุฃู ุงูุงุณุชูุฑุงุก ูุนูู ุจุดูู ุฃูุถู ุจูุซูุฑ ุฎุงุฑุฌ ุงูุตูุฏูู ูู *ALiBi* ููุงุฑูุฉ ุจู *RoPE*.
ุจุงููุณุจุฉ ูู ALiBiุ ูุง ุนููู ุณูู ุฒูุงุฏุฉ ููู ูุตูููุฉ ุงูููุถุน ุงููุซูุซ ุงูุณููู ููุทุงุจูุฉ ุทูู ุชุณูุณู ุงูุฅุฏุฎุงู.
ุจุงููุณุจุฉ ูู *RoPE*ุ ูุคุฏู ุงูุญูุงุธ ุนูู ููุณ \\( \theta \\) ุงูุฐู ุชู ุงุณุชุฎุฏุงูู ุฃุซูุงุก ุงูุชุฏุฑูุจ ุฅูู ูุชุงุฆุฌ ุณูุฆุฉ ุนูุฏ ุชูุฑูุฑ ุฅุฏุฎุงูุงุช ูุตูุฉ ุฃุทูู ุจูุซูุฑ ูู ุชูู ุงูุชู ุดููุฏุช ุฃุซูุงุก ุงูุชุฏุฑูุจุ ุฑุงุฌุน [Press et al.](https://arxiv.org/abs/2108.12409). ููุน ุฐููุ ูุฌุฏ ุงููุฌุชูุน ุจุนุถ ุงูุญูู ุงููุนุงูุฉ ุงูุชู ุชููู ุจุชุนุฏูู \\( \theta \\)ุ ููุง ูุณูุญ ูุชุฑููุฒุงุช ุงูููุถุน *RoPE* ุจุงูุนูู ุจุดูู ุฌูุฏ ูุชุณูุณูุงุช ุฅุฏุฎุงู ุงููุต ุงููุณุชูุฑุฆุฉ (ุฑุงุฌุน [ููุง](https://github.com/huggingface/transformers/pull/24653)).

> ูู ูู RoPE ู ALiBi ุนุจุงุฑุฉ ุนู ุชุฑููุฒุงุช ููุถุน ูุณุจู *ูุง* ูุชู ุชุนูููุง ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูููู ุจุฏูุงู ูู ุฐูู ุชุณุชูุฏ ุฅูู ุงูุญุฏุณ ุงูุชุงูู:
 -   ูุฌุจ ุฅุนุทุงุก ุงูุฅุดุงุฑุงุช ุงูููุถุนูุฉ ุญูู ุฅุฏุฎุงูุงุช ุงููุต ูุจุงุดุฑุฉ ุฅูู ูุตูููุฉ \\( QK^T \\) ูุทุจูุฉ ุงูุงูุชูุงู ุงูุฐุงุชู
 -   ูุฌุจ ุชุญููุฒ LLM ูุชุนูู ุชุฑููุฒุงุช ููุถุนูุฉ ุซุงุจุชุฉ *ูุณุจูุฉ* ุงููุณุงูุฉ ูุจุนุถูุง ุงูุจุนุถ
 -   ูููุง ุงุจุชุนุฏุช ุฑููุฒ ุฅุฏุฎุงู ุงููุต ุนู ุจุนุถูุง ุงูุจุนุถุ ุงูุฎูุถ ุงุญุชูุงู ุงูุงุณุชุนูุงู ูุงููููุฉ. ูู ูู RoPE ู ALiBi ููููุงู ูู ุงุญุชูุงู ุงูุงุณุชุนูุงู ูุงูููุชุงุญ ููุฑููุฒ ุงูุจุนูุฏุฉ ุนู ุจุนุถูุง ุงูุจุนุถ. ูููู RoPE ุจุฐูู ุนู ุทุฑูู ุชูููู ููุชุฌ ุงููุชุฌู ูู ุฎูุงู ุฒูุงุฏุฉ ุงูุฒุงููุฉ ุจูู ูุชุฌูุงุช ุงูุงุณุชุนูุงู ูุงูููุชุงุญ. ุชุถูู ALiBi ุฃุฑูุงููุง ูุจูุฑุฉ ุณุงูุจุฉ ุฅูู ุงูููุชุฌ ุงูุงุชุฌุงูู

ูู ุงูุฎุชุงูุ ูู ุงูุฃูุถู ุชุฏุฑูุจ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงููุฑุงุฏ ูุดุฑูุง ูู ููุงู ุชุชุทูุจ ุงูุชุนุงูู ูุน ุฅุฏุฎุงูุงุช ูุตูุฉ ูุจูุฑุฉ ุจุงุณุชุฎุฏุงู ุชุฑููุฒุงุช ููุถุนูุฉ ูุณุจูุฉุ ูุซู RoPE ู ALiBi. ูุงุญุธ ุฃูุถูุง ุฃูู ุญุชู ุฅุฐุง ุชู ุชุฏุฑูุจ ูููุฐุฌ ูุบุฉ ูุจูุฑุฉ ุจุงุณุชุฎุฏุงู RoPE ู ALiBi ุนูู ุทูู ุซุงุจุช ูุจูุบุ ุนูู ุณุจูู ุงููุซุงูุ \\( N_1 = 2048 \\)ุ ููููู ุงุณุชุฎุฏุงูู ุนููููุง ุจุฅุฏุฎุงูุงุช ูุตูุฉ ุฃูุจุฑ ุจูุซูุฑ ูู \\( N_1 \\)ุ ูุซู \\( N_2 = 8192> N_1 \\) ุนู ุทุฑูู ุงุณุชูุฑุงุก ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉ.

### 3.2 ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ ูุงููููุฉ

ุชุนูู ุนูููุฉ ุชูููุฏ ุงููุต ุฐุงุชู ุงูุชุฑุงุฌุน ุจุงุณุชุฎุฏุงู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุนู ุทุฑูู ุฅุฏุฎุงู ุชุณูุณู ุฅุฏุฎุงู ุจุดูู ุชูุฑุงุฑูุ ูุฃุฎุฐ ุนููุงุช ูู ุงูุฑูุฒ ุงูุชุงููุ ูุฅูุญุงู ุงูุฑูุฒ ุงูุชุงูู ุจุชุณูุณู ุงูุฅุฏุฎุงูุ ูุงูุงุณุชูุฑุงุฑ ูู ุฐูู ุญุชู ููุชุฌ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุฑูุฒูุง ูุดูุฑ ุฅูู ุงูุชูุงุก ุงูุชูููุฏ.

ูุฑุฌู ุงูุงุทูุงุน ุนูู [ุฏููู ุฅูุดุงุก ุงููุต ุงูุฎุงุต ุจู Transformer](https://huggingface.co/docs/transformers/llm_tutorial#generate-text) ููุญุตูู ุนูู ุดุฑุญ ูุฑุฆู ุฃูุถู ูููููุฉ ุนูู ุงูุชูููุฏ ุฐุงุชู ุงูุชุฑุงุฌุน.

ุฏุนูุง ูููุฐ ููุชุทููุง ูุตูุฑูุง ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูุฅุธูุงุฑ ููููุฉ ุนูู ุงูุชูููุฏ ุฐุงุชู ุงูุชุฑุงุฌุน ูู ุงูููุงุฑุณุฉ. ุจุจุณุงุทุฉุ ุณูุฃุฎุฐ ุงูุฑูุฒ ุงูุฃูุซุฑ ุงุญุชูุงููุง ุนุจุฑ `torch.argmax`.

```python
input_ids = tokenizer(prompt, return_tensors="pt")["input_ids"].to("cuda")

for _ in range(5):
  next_logits = model(input_ids)["logits"][:, -1:]
  next_token_id = torch.argmax(next_logits,dim=-1)

  input_ids = torch.cat([input_ids, next_token_id], dim=-1)
  print("shape of input_ids", input_ids.shape)

generated_text = tokenizer.batch_decode(input_ids[:, -5:])
generated_text
```

**ุงูุฅุฎุฑุงุฌ**:
```
shape of input_ids torch.Size([1, 21])
shape of input_ids torch.Size([1, 22])
shape of input_ids torch.Size([1, 23])
shape of input_ids torch.Size([1, 24])
shape of input_ids torch.Size([1, 25])
[' Here is a Python function']
```

ููุง ูุฑูุ ูู ูู ูุฑุฉ ูุฒูุฏ ูู ุฑููุฒ ุฅุฏุฎุงู ุงููุต ุจุงูุฑูุฒ ุงูุฐู ุชู ุฃุฎุฐ ุนููุงุช ููู ููุชู.

ุจุงุณุชุซูุงุกุงุช ููููุฉ ุฌุฏูุงุ ูุชู ุชุฏุฑูุจ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจุงุณุชุฎุฏุงู [ูุฏู ููุฐุฌุฉ ุงููุบุฉ ุงูุณุจุจูุฉ](https://huggingface.co/docs/transformers/tasks/language_modeling#causal-language-modeling) ูุจุงูุชุงูู ูุชู ููุงุน ุงููุซูุซ ุงูุนููู ููุตูููุฉ ูุชูุฌุฉ ุงูุงูุชูุงู - ููุฐุง ูู ุงูุณุจุจ ูู ุชุฑู ูุชุงุฆุฌ ุงูุงูุชูุงู ูุงุฑุบุฉ (*ุฃู ููุง ุงุญุชูุงู 0*) ูู ุงููุฎุทุทูู ุฃุนูุงู. ููุญุตูู ุนูู ููุฎุต ุณุฑูุน ุญูู ููุฐุฌุฉ ุงููุบุฉ ุงูุณุจุจูุฉุ ููููู ุงูุฑุฌูุน ุฅูู ูุฏููุฉ [*Illustrated Self Attention*](https://jalammar.github.io/illustrated-gpt2/#part-2-illustrated-self-attention).

ููุชูุฌุฉ ูุฐููุ *ูุง* ุชุนุชูุฏ ุงูุฑููุฒ *ุฃุจุฏูุง* ุนูู ุงูุฑููุฒ ุงูุณุงุจูุฉุ ูุจุดูู ุฃูุซุฑ ุชุญุฏูุฏูุงุ ูุง ูุชู ุฃุจุฏูุง ูุถุน ุงููุชุฌู \\( \mathbf{q}_i \\) ูู ุนูุงูุฉ ูุน ุฃู ูุชุฌูุงุช ุงูููุงุชูุญ ูุงูููู \\( \mathbf{k}_jุ \mathbf{v}_j \\) ุฅุฐุง \\( j> i \\). ุจุฏูุงู ูู ุฐููุ ูุญุถุฑ \\( \mathbf{q}_i \\) ููุท ุฅูู ูุชุฌูุงุช ุงูููุงุชูุญ ูุงูููู ุงูุณุงุจูุฉ \\( \mathbf{k}_{m < i}ุ \mathbf{v}_{m < i} \text{ , for } m \in \{0ุ \ ldots i - 1\} \\). ูุชูููู ุงูุญุณุงุจุงุช ุบูุฑ ุงูุถุฑูุฑูุฉุ ูููู ุชุฎุฒูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููู ุทุจูุฉ ููููุงุชูุญ ููุชุฌูุงุช ุงูููู ูุฌููุน ุงูุฎุทูุงุช ุงูุฒูููุฉ ุงูุณุงุจูุฉ.

ูููุง ูููุ ุณูุทูุจ ูู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ุนู ุทุฑูู ุงุณุชุฑุฏุงุฏูุง ูุฅุฑุณุงููุง ููู ุนูููุฉ ุชูุฌูู.
ูู Transformersุ ูููููุง ุงุณุชุฑุฏุงุฏ ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ุนู ุทุฑูู ุชูุฑูุฑ ุนูู `use_cache` ุฅูู ููุงููุฉ `forward` ููููููุง ุจุนุฏ ุฐูู ุชูุฑูุฑู ูุน ุงูุฑูุฒ ุงูุญุงูู.

```python
past_key_values = None # past_key_values is the key-value cache
generated_tokens = []
next_token_id = tokenizer(prompt, return_tensors="pt")["input_ids"].to("cuda")

for _ in range(5):
  next_logits, past_key_values = model(next_token_id, past_key_values=past_key_values, use_cache=True).to_tuple()
  next_logits = next_logits[:, -1:]
  next_token_id = torch.argmax(next_logits, dim=-1)

  print("shape of input_ids", next_token_id.shape)
  print("length of key-value cache", len(past_key_values[0][0]))  # past_key_values are of shape [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]
  generated_tokens.append(next_token_id.item())

generated_text = tokenizer.batch_decode(generated_tokens)
generated_text
```

**ุงูุฅุฎุฑุงุฌ**:
```
shape of input_ids torch.Size([1, 1])
length of key-value cache 20
shape of input_ids torch.Size([1, 1])
length of key-value cache 21
shape of input_ids torch.Size([1, 1])
length of key-value cache 22
shape of input_ids torch.Size([1, 1])
length of key-value cache 23
shape of input_ids torch.Size([1, 1])
length of key-value cache 24
[' Here', ' is', ' a', ' Python', ' function']
```

ููุง ูู ููุถุญุ ุนูุฏ ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงููููุ ูุง ูุชู ุฒูุงุฏุฉ ุฑููุฒ ุฅุฏุฎุงู ุงููุต ูู ุงูุทููุ ูููููุง ุชุธู ูุชุฌู ุฅุฏุฎุงู ูุงุญุฏูุง. ูู ูุงุญูุฉ ุฃุฎุฑูุ ูุชู ุฒูุงุฏุฉ ุทูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ุจูุงุญุฏ ูู ูู ุฎุทูุฉ ูู ุงูุชุดููุฑ.

> ูุนูู ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ุฃู \\( \mathbf{QK}^T \\) ูุชู ุชููููู ุจุดูู ุฃุณุงุณู ุฅูู \\( \mathbf{q}_c\mathbf{K}^T \\) ูุน \\( \mathbf{q}_c \\) ููููุง ุฅุณูุงุท ุงูุงุณุชุนูุงู ููุฑูุฒ ุงููุฏุฎู ุงูุญุงูู ุงูุฐู ูููู *ุฏุงุฆููุง* ูุฌุฑุฏ ูุชุฌู ูุงุญุฏ.

ูุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ููุฒุชุงู:
-   ุฒูุงุฏุฉ ูุจูุฑุฉ ูู ุงูููุงุกุฉ ุงูุญุณุงุจูุฉ ุญูุซ ูุชู ุฅุฌุฑุงุก ุญุณุงุจุงุช ุฃูู ููุงุฑูุฉ ุจุญุณุงุจ ูุตูููุฉ \\( \mathbf{QK}^T \\) ุงููุงููุฉ. ูุคุฏู ุฐูู ุฅูู ุฒูุงุฏุฉ ุณุฑุนุฉ ุงูุงุณุชุฏูุงู
-   ูุง ุชุฒุฏุงุฏ ุงูุฐุงูุฑุฉ ุงููุตูู ุงููุทููุจุฉ ุจุดูู ุชุฑุจูุนู ูุน ุนุฏุฏ ุงูุฑููุฒ ุงููููุฏุฉุ ูููููุง ุชุฒุฏุงุฏ ุจุดูู ุฎุทู ููุท.

> ูุฌุจ *ุฏุงุฆููุง* ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ุญูุซ ูุคุฏู ุฐูู ุฅูู ูุชุงุฆุฌ ูุชุทุงุจูุฉ ูุฒูุงุฏุฉ ูุจูุฑุฉ ูู ุงูุณุฑุนุฉ ูุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูุฃุทูู. ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ูููููุฉ ุจุดูู ุงูุชุฑุงุถู ูู Transformers ุนูุฏ ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ ุงููุต ุฃู ุทุฑููุฉ [`generate`](https://huggingface.co/docs/transformers/main_classes/text_generation).


<Tip warning={true}>

ูุงุญุธ ุฃูู ุนูู ุงูุฑุบู ูู ูุตูุญุชูุง ุจุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงููููุ ููุฏ ูููู ุฅุฎุฑุงุฌ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุฎุชูููุง ููููุงู ุนูุฏ ุงุณุชุฎุฏุงููุง. ูุฐู ุฎุงุตูุฉ ููู ุถุฑุจ ุงููุตูููุฉ ููุณูุง - ููููู ูุฑุงุกุฉ ุงููุฒูุฏ ุนููุง [ููุง](https://github.com/huggingface/transformers/issues/25420#issuecomment-1775317535).

</Tip>

#### 3.2.1 ูุญุงุฏุซุฉ ูุชุนุฏุฏุฉ ุงูุฌููุงุช

ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุงุชูุญ ูุงูููู ูููุฏุฉ ุจุดูู ุฎุงุต ููุชุทุจููุงุช ูุซู ุงูุฏุฑุฏุดุฉ ุญูุซ ุชููู ููุงู ุญุงุฌุฉ ุฅูู ุนุฏุฉ ุชูุฑูุฑุงุช ูู ูู ุงูุชุดููุฑ ุฐุงุชู ุงูุชุฑุงุฌุน. ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ูุซุงู.

```
ุงููุณุชุฎุฏู: ูู ุนุฏุฏ ุงูุฃุดุฎุงุต ุงูุฐูู ูุนูุดูู ูู ูุฑูุณุงุ
ุงููุณุงุนุฏ: ูุนูุด ุญูุงูู 75 ููููู ุดุฎุต ูู ูุฑูุณุง
ุงููุณุชุฎุฏู: ููู ุนุฏุฏ ุงูุฃุดุฎุงุต ูู ุฃููุงููุงุ
ุงููุณุงุนุฏ: ููุฌุฏ ูู ุฃููุงููุง ุญูุงูู 81 ููููู ูุณูุฉ

User: How many people live in France?
Assistant: Roughly 75 million people live in France
User: And how many are in Germany?
Assistant: Germany has ca. 81 million inhabitants
```

In this chatุ ูููู LLM ุจุชุดุบูู ูู ุงูุชุดููุฑ ุงูุชููุงุฆู ูุฑุชูู:
  1. ุงููุฑุฉ ุงูุฃูููุ ุชููู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ูุงุฑุบุฉุ ููููู ููุฌู ุงูุฅุฏุฎุงู ูู "User: How many people live in Franceุ" ููููู ุงููููุฐุฌ ุจุฅูุดุงุก ุงููุต "Roughly 75 million people live in France" ุจุดูู ุชููุงุฆู ุฃุซูุงุก ุฒูุงุฏุฉ ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ูู ูู ุฎุทูุฉ ูู ุชุดููุฑ.
  2. ูู ุงููุฑุฉ ุงูุซุงููุฉุ ูููู ููุฌู ุงูุฅุฏุฎุงู ูู "User: How many people live in Franceุ \n Assistant: Roughly 75 million people live in France \n User: And how many in Germanyุ". ุจูุถู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุชุ ูุชู ุจุงููุนู ุญุณุงุจ ุฌููุน ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ูุฌุงุฑูุชูู ุงูุฃููู. ูุฐูู ูุชููู ููุฌู ุงูุฅุฏุฎุงู ููุท ูู "User: And how many in Germanyุ". ุฃุซูุงุก ูุนุงูุฌุฉ ููุฌู ุงูุฅุฏุฎุงู ุงููุฎุชุตุฑุ ูุชู ุฑุจุท ูุชุฌูุงุช ุงููููุฉ ุงููุญุณูุจุฉ ุจุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ุงูุฎุงุตุฉ ุจูู ุงูุชุดููุฑ ุงูุฃูู. ูุชู ุจุนุฏ ุฐูู ุฅูุดุงุก ุฅุฌุงุจุฉ ุงููุณุงุนุฏ ุงูุซุงููุฉ "Germany has ca. 81 million inhabitants" ุจุดูู ุชููุงุฆู ุจุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ุงูููููุฉ ูู ูุชุฌูุงุช ุงููููุฉ ุงููุดูุฑุฉ ูู "User: How many people live in Franceุ \n Assistant: Roughly 75 million people live in France \n User: And how many are in Germanyุ".

ูุฌุจ ููุงุญุธุฉ ุฃูุฑูู ููุง:
  1. ุงูุญูุงุธ ุนูู ูู ุงูุณูุงู ุฃูุฑ ุจุงูุบ ุงูุฃูููุฉ ููููุงุฐุฌ ุงููุบููุฉ ุงููุจูุฑุฉ (LLMs) ุงูุชู ูุชู ูุดุฑูุง ูู ุงูุฏุฑุฏุดุฉ ุจุญูุซ ูููู LLM ูู ุณูุงู ุงููุญุงุฏุซุฉ ุงูุณุงุจู. ุนูู ุณุจูู ุงููุซุงูุ ุจุงููุณุจุฉ ูููุซุงู ุฃุนูุงูุ ูุญุชุงุฌ LLM ุฅูู ููู ุฃู ุงููุณุชุฎุฏู ูุดูุฑ ุฅูู ุงูุณูุงู ุนูุฏ ุงูุณุคุงู "And how many are in Germanyุ".
  2. ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ูููุฏุฉ ููุบุงูุฉ ููุฏุฑุฏุดุฉ ุญูุซ ุชุชูุญ ููุง ุงูููู ุงููุณุชูุฑ ูุชุงุฑูุฎ ุงูุฏุฑุฏุดุฉ ุงููุดูุฑุฉ ุจุฏูุงู ูู ุงูุงุถุทุฑุงุฑ ุฅูู ุฅุนุงุฏุฉ ุชุดููุฑ ุชุงุฑูุฎ ุงูุฏุฑุฏุดุฉ ูู ุงูุจุฏุงูุฉ (ููุง ูู ุงูุญุงูุ ุนูู ุณุจูู ุงููุซุงูุ ุนูุฏ ุงุณุชุฎุฏุงู ุจููุฉ ุชุฑููุฒ ูู ุงูุชุดููุฑ).

ูู `transformers`ุ ุณุชุนูุฏ ููุงููุฉ `generate` `past_key_values` ุนูุฏูุง ูุชู ุชูุฑูุฑ `return_dict_in_generate=True`ุ ุจุงูุฅุถุงูุฉ ุฅูู `use_cache=True` ุงูุงูุชุฑุงุถู. ูุงุญุธ ุฃูู ุบูุฑ ูุชููุฑ ุจุนุฏ ูู ุฎูุงู ูุงุฌูุฉ `pipeline`.

```python
# Generation as usual
prompt = system_prompt + "Question: Please write a function in Python that transforms bytes to Giga bytes.\n\nAnswer: Here"
model_inputs = tokenizer(promptุ return_tensors='pt')
generation_output = model.generate(**model_inputsุ max_new_tokens=60ุ return_dict_in_generate=True)
decoded_output = tokenizer.batch_decode(generation_output.sequences)[0]

# Piping the returned `past_key_values` to speed up the next conversation round
prompt = decoded_output + "\nQuestion: How can I modify the function above to return Mega bytes instead?\n\nAnswer: Here"
model_inputs = tokenizer(promptุ return_tensors='pt')
generation_output = model.generate(
  **model_inputsุ
  past_key_values=generation_output.past_key_valuesุ
  max_new_tokens=60ุ
  return_dict_in_generate=True
)
tokenizer.batch_decode(generation_output.sequences)[0][len(prompt):]
```

**ุงูุฅุฎุฑุงุฌ**:
```
 ูู ูุณุฎุฉ ูุนุฏูุฉ ูู ุงูุฏุงูุฉ ุงูุชู ุชุนูุฏ ููุฌุง ุจุงูุช ุจุฏูุงู ูู ุฐูู.

def bytes_to_megabytes(bytes):
   return bytes / 1024 / 1024

Answer: The function takes a number of bytes as input and returns the number of
```

ุฑุงุฆุนุ ูุง ูุชู ุฅููุงู ููุช ุฅุถุงูู ุนูู ุฅุนุงุฏุฉ ุญุณุงุจ ููุณ ุงูููุชุงุญ ูุงูููู ูุทุจูุฉ ุงูุงูุชูุงู! ููุน ุฐููุ ููุงู ุดูุก ูุงุญุฏ ูุฌุจ ููุงุญุธุชู. ูู ุญูู ุฃู ุฐุฑูุฉ ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ ููุตูููุฉ \\( \mathbf{QK}^T \\) ูุชู ุชูููููุง ุจุดูู ูุจูุฑุ ูุฅู ุงูุงุญุชูุงุธ ุจุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ูู ุงูุฐุงูุฑุฉ ูููู ุฃู ูุตุจุญ ูููููุง ุฌุฏูุง ูู ุญูุซ ุงูุฐุงูุฑุฉ ูุณูุงุณู ุงูุฅุฏุฎุงู ุงูุทูููุฉ ุฃู ุงูุฏุฑุฏุดุฉ ูุชุนุฏุฏุฉ ุงูุฌููุงุช. ุชุฐูุฑ ุฃู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ุจุญุงุฌุฉ ุฅูู ุชุฎุฒูู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ูุฌููุน ูุชุฌูุงุช ุงูุฅุฏุฎุงู ุงูุณุงุจูุฉ \\( \mathbf{x}_i \text{ุ ูู } i \in \{1ุ \ ldotsุ c - 1\} \\) ูุฌููุน ุทุจูุงุช ุงูุงูุชูุงู ุงูุฐุงุชู ููู ุฑุคูุณ ุงูุงูุชูุงู.

ุฏุนูุง ูุญุณุจ ุนุฏุฏ ุงูููู ุงูุนุงุฆูุฉ ุงูุชู ูุฌุจ ุชุฎุฒูููุง ูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ููููุฐุฌ LLM `bigcode/octocoder` ุงูุฐู ุงุณุชุฎุฏููุงู ูู ูุจู.
ูุจูุบ ุนุฏุฏ ุงูููู ุงูุนุงุฆูุฉ ุถุนู ุทูู ุงูุชุณูุณู ูุถุฑูุจูุง ูู ุนุฏุฏ ุฑุคูุณ ุงูุงูุชูุงู ูุถุฑูุจูุง ูู ุจุนุฏ ุฑุฃุณ ุงูุงูุชูุงู ููุถุฑูุจูุง ูู ุนุฏุฏ ุงูุทุจูุงุช.
ุญุณุงุจ ูุฐุง ููููุฐุฌ LLM ูุฏููุง ุนูุฏ ุทูู ุชุณูุณู ุงูุชุฑุงุถู ูุจูุบ 16000 ูุนุทู:

```python
config = model.config
2 * 16_000 * config.n_layer * config.n_head * config.n_embd // config.n_head
```

**ุงูุฅุฎุฑุงุฌ**:
```
7864320000
```

Roughly 8 ูููุงุฑ ูููุฉ ุนุงุฆูุฉ! ูุชุทูุจ ุชุฎุฒูู 8 ูููุงุฑุงุช ูููุฉ ุนุงุฆูุฉ ูู ุฏูุฉ `float16` ุญูุงูู 15 ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ ุงููุตูู ุงูุนุดูุงุฆู (RAM) ููู ูุง ููุฑุจ ูู ูุตู ุญุฌู ุฃูุฒุงู ุงููููุฐุฌ ููุณูุง!
ุงูุชุฑุญ ุงูุจุงุญุซูู ุทุฑููุชูู ุชุณูุญุงู ุจุชูููู ุชูููุฉ ุงูุฐุงูุฑุฉ ูุชุฎุฒูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value ุจุดูู ูุจูุฑุ ูุงูุชู ูุชู ุงุณุชูุดุงููุง ูู ุงูุฃูุณุงู ุงููุฑุนูุฉ ุงูุชุงููุฉ.

#### 3.2.2 Multi-Query-Attention (MQA)

[Multi-Query-Attention](https://arxiv.org/abs/1911.02150) ุงูุชุฑุญูุง Noam Shazeer ูู ูุฑูุชู *Fast Transformer Decoding: One Write-Head is All You Need*. ููุง ูููู ุงูุนููุงูุ ุงูุชุดู Noam ุฃูู ุจุฏูุงู ูู ุงุณุชุฎุฏุงู `n_head` ูู ุฃูุฒุงู ุฅุณูุงุท ุงููููุฉ ุงูุฑุฆูุณูุฉุ ูููู ุงุณุชุฎุฏุงู ุฒูุฌ ูุงุญุฏ ูู ุฃูุฒุงู ุฅุณูุงุท ุฑุฃุณ ุงููููุฉ ุงูุชู ูุชู ูุดุงุฑูุชูุง ุนุจุฑ ุฌููุน ุฑุคูุณ ุงูุงูุชูุงู ุฏูู ุฃู ูุชุฏููุฑ ุฃุฏุงุก ุงููููุฐุฌ ุจุดูู ูุจูุฑ.

> ุจุงุณุชุฎุฏุงู ุฒูุฌ ูุงุญุฏ ูู ุฃูุฒุงู ุฅุณูุงุท ุฑุฃุณ ุงููููุฉุ ูุฌุจ ุฃู ุชููู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ \\( \mathbf{k}_iุ \mathbf{v}_i \\) ูุชุทุงุจูุฉ ุนุจุฑ ุฌููุน ุฑุคูุณ ุงูุงูุชูุงู ูุงูุชู ุจุฏูุฑูุง ุชุนูู ุฃููุง ุจุญุงุฌุฉ ููุท ุฅูู ุชุฎุฒูู ุฒูุฌ ุฅุณูุงุท ูููุฉ ุฑุฆูุณู ูุงุญุฏ ูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ุจุฏูุงู ูู `n_head` ูููุง.

ูุธุฑูุง ูุฃู ูุนุธู LLMs ุชุณุชุฎุฏู ูุง ุจูู 20 ู100 ุฑุฃุณ ุงูุชูุงูุ ูุฅู MQA ูููู ุจุดูู ูุจูุฑ ูู ุงุณุชููุงู ุงูุฐุงูุฑุฉ ูุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช key-value. ุจุงููุณุจุฉ ุฅูู LLM ุงููุณุชุฎุฏู ูู ูุฐุง ุงูุฏูุชุฑุ ูููููุง ุชูููู ุงุณุชููุงู ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ ูู 15 ุฌูุฌุงุจุงูุช ุฅูู ุฃูู ูู 400 ููุฌุงุจุงูุช ุนูุฏ ุทูู ุชุณูุณู ุงูุฅุฏุฎุงู 16000.

ุจุงูุฅุถุงูุฉ ุฅูู ุชูููุฑ ุงูุฐุงูุฑุฉุ ูุคุฏู MQA ุฃูุถูุง ุฅูู ุชุญุณูู ุงูููุงุกุฉ ุงูุญุณุงุจูุฉ ููุง ูู ููุถุญ ูู ูุง ููู.
ูู ูู ุงูุชุดููุฑ ุงูุชููุงุฆูุ ูุฌุจ ุฅุนุงุฏุฉ ุชุญููู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ุงููุจูุฑุฉุ ูุฏูุฌูุง ูุน ุฒูุฌ ูุชุฌู ุงููููุฉ ุงูุญุงููุ ุซู ุฅุฏุฎุงููุง ูู \\( \mathbf{q}_c\mathbf{K}^T \\) ุงูุญุณุงุจ ูู ูู ุฎุทูุฉ. ุจุงููุณุจุฉ ููู ุงูุชุดููุฑ ุงูุชููุงุฆูุ ูููู ุฃู ุชุตุจุญ ุนุฑุถ ุงููุทุงู ุงูุชุฑุฏุฏู ููุฐุงูุฑุฉ ุงููุทููุจุฉ ูุฅุนุงุฏุฉ ุงูุชุญููู ุงููุณุชูุฑ ุนูู ุฒุฌุงุฌุฉ ุฒููููุง ุฎุทูุฑูุง. ูู ุฎูุงู ุชูููู ุญุฌู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉุ ูุฌุจ ุงููุตูู ุฅูู ุฐุงูุฑุฉ ุฃููุ ูุจุงูุชุงูู ุชูููู ุนูู ุงูุฒุฌุงุฌุฉ ูู ุนุฑุถ ุงููุทุงู ุงูุชุฑุฏุฏู ููุฐุงูุฑุฉ. ููุฒูุฏ ูู ุงูุชูุงุตููุ ูุฑุฌู ุฅููุงุก ูุธุฑุฉ ุนูู [ูุฑูุฉ Noam](https://arxiv.org/abs/1911.02150).

ุงูุฌุฒุก ุงูููู ุงูุฐู ูุฌุจ ูููู ููุง ูู ุฃู ุชูููู ุนุฏุฏ ุฑุคูุณ ุงูุงูุชูุงู ุจุงููููุฉ ุงูุฑุฆูุณูุฉ ุฅูู 1 ูุง ูุนูู ูู ุฅูุง ุฅุฐุง ุชู ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ูููููุฉ ุงูุฑุฆูุณูุฉ. ูุธู ุงูุงุณุชููุงู ุงูุฐุฑูู ูุฐุงูุฑุฉ ุงููููุฐุฌ ููุฑูุฑ ูุงุญุฏ ููุฃูุงู ุจุฏูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ูููููุฉ ุงูุฑุฆูุณูุฉ ุฏูู ุชุบููุฑ ูุฃู ูู ุฑุฃุณ ุงูุชูุงู ูุง ูุฒุงู ูุฏูู ูุชุฌู ุงุณุชุนูุงู ูุฑูุฏ ุจุญูุซ ูููู ููู ุฑุฃุณ ุงูุชูุงู ูุตูููุฉ \\( \mathbf{QK}^T \\) ูุฎุชููุฉ.

ุดูุฏุช MQA ุงุนุชูุงุฏูุง ูุงุณุน ุงููุทุงู ูู ูุจู ุงููุฌุชูุน ููุชู ุงุณุชุฎุฏุงููุง ุงูุขู ุจูุงุณุทุฉ ุงูุนุฏูุฏ ูู LLMs ุงูุฃูุซุฑ ุดูุฑุฉ:

-   [**Falcon**](https://huggingface.co/tiiuae/falcon-40b)
-   [**PaLM**](https://arxiv.org/abs/2204.02311)
-   [**MPT**](https://huggingface.co/mosaicml/mpt-30b)
-   [**BLOOM**](https://huggingface.co/bigscience/bloom)

ููุง ูุณุชุฎุฏู ููุทุฉ ุงูุชุญูู ุงููุณุชุฎุฏูุฉ ูู ูุฐุง ุงูุฏูุชุฑ - `bigcode/octocoder` - MQA.

#### 3.2.3 ูุฌููุนุฉ ุงูุงุณุชุนูุงู ุงูุงูุชูุงู (GQA)

[ูุฌููุนุฉ ุงูุงุณุชุนูุงู ุงูุงูุชูุงู](https://arxiv.org/abs/2305.13245)ุ ููุง ุงูุชุฑุญ Ainslie et al. ูู Googleุ ูุฌุฏ ุฃู ุงุณุชุฎุฏุงู MQA ูููู ุฃู ูุคุฏู ุบุงูุจูุง ุฅูู ุชุฏููุฑ ุงูุฌูุฏุฉ ููุงุฑูุฉ ุจุงุณุชุฎุฏุงู ุฅุณูุงุทุงุช ุฑุฃุณ ุงููููุฉ ุงูุฑุฆูุณูุฉ ุงููุชุนุฏุฏุฉ. ุชุฌุงุฏู ุงููุฑูุฉ ุจุฃูู ูููู ุงูุญูุงุธ ุนูู ุฃุฏุงุก ุงููููุฐุฌ ุจุดูู ุฃูุจุฑ ุนู ุทุฑูู ุชูููู ุนุฏุฏ ุฃูุฒุงู ุฅุณูุงุท ุฑุฃุณ ุงูุงุณุชุนูุงู ุจุดูู ุฃูู ุญุฏุฉ. ุจุฏูุงู ูู ุงุณุชุฎุฏุงู ูุฒู ุฅุณูุงุท ูููุฉ ุฑุฆูุณูุฉ ูุงุญุฏุฉ ููุทุ ูุฌุจ ุงุณุชุฎุฏุงู `n <n_head` ุฃูุฒุงู ุฅุณูุงุท ูููุฉ ุฑุฆูุณูุฉ. ูู ุฎูุงู ุงุฎุชูุงุฑ `n` ุฅูู ูููุฉ ุฃูู ุจูุซูุฑ ูู `n_head`ุ ูุซู 2 ุฃู 4 ุฃู 8ุ ูููู ุงูุงุญุชูุงุธ ุจูุนุธู ููุงุณุจ ุงูุฐุงูุฑุฉ ูุงูุณุฑุนุฉ ูู MQA ูุน ุงูุชุถุญูุฉ ุจูุฏุฑ ุฃูู ูู ุณุนุฉ ุงููููุฐุฌ ูุจุงูุชุงููุ ูู ุงูููุชุฑุถุ ุฃูู ุฃุฏุงุก.

ุนูุงูุฉ ุนูู ุฐููุ ุงูุชุดู ูุคููู GQA ุฃูู ูููู *ุชุฏุฑูุจ* ููุงุท ุชูุชูุด ุงููููุฐุฌ ุงูููุฌูุฏุฉ ููููู ููุง ุจููุฉ GQA ุจุงุณุชุฎุฏุงู 5% ููุท ูู ุงูุญูุณุจุฉ ุงูุฃุตููุฉ ููุชุนููู ุงููุณุจู. ูู ุญูู ุฃู 5% ูู ุงูุญูุณุจุฉ ุงูุฃุตููุฉ ููุชุนููู ุงููุณุจู ูููู ุฃู ุชููู ูููุฉ ูุงุฆูุฉุ ูุณูุญ GQA *uptraining* ุจููุงุท ุชูุชูุด ููุฌูุฏุฉ ููุงุณุชูุงุฏุฉ ูู ุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูุฃุทูู.

ุชู ุงูุชุฑุงุญ GQA ูุคุฎุฑูุง ููุทุ ูููุฐุง ุงูุณุจุจ ููุงู ุงุนุชูุงุฏ ุฃูู ููุช ูุชุงุจุฉ ูุฐุง ุงูุฏูุชุฑ.
ุฃุจุฑุฒ ุชุทุจูู ูู GQA ูู [Llama-v2](https://huggingface.co/meta-llama/Llama-2-70b-hf).

> ูุฎุงุชูุฉุ ูู ุงููุณุชุญุณู ุจุดุฏุฉ ุงุณุชุฎุฏุงู GQA ุฃู MQA ุฅุฐุง ุชู ูุดุฑ LLM ุจุงุณุชุฎุฏุงู ูู ุงูุชุดููุฑ ุงูุชููุงุฆู ููุชุทูุจ ุงูุชุนุงูู ูุน ุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงููุจูุฑุฉ ููุง ูู ุงูุญุงู ุนูู ุณุจูู ุงููุซุงู ููุฏุฑุฏุดุฉ.


## ุงูุฎุงุชูุฉ

ูุฌุชูุน ุงูุจุญุซ ูุฃุชู ุจุงุณุชูุฑุงุฑ ุจุทุฑู ุฌุฏูุฏุฉ ููุจุชูุฑุฉ ูุชุณุฑูุน ููุช ุงูุงุณุชุฏูุงู ููููุงุฐุฌ ุงููุบููุฉ ุงููุจูุฑุฉ ุนูู ุงูุฅุทูุงู. ููุซุงูุ ุฃุญุฏ ุงุชุฌุงูุงุช ุงูุจุญุซ ุงููุงุนุฏุฉ ูู [ูู ุงูุชุดููุฑ ุงูุชุฎูููู](https://arxiv.org/abs/2211.17192) ุญูุซ ุชููู "ุงูุฑููุฒ ุงูุณููุฉ" ุจุฅูุดุงุฆูุง ููุงุฐุฌ ุงููุบุฉ ุงูุฃุตุบุฑ ูุงูุฃุณุฑุน ููุชู ุฅูุดุงุก "ุงูุฑููุฒ ุงูุตุนุจุฉ" ููุท ุจูุงุณุทุฉ LLM ููุณู. ุฅู ุงูุชุนูู ูู ุงูุชูุงุตูู ูุชุฌุงูุฒ ูุทุงู ูุฐุง ุงูุฏูุชุฑุ ูููู ูููู ูุฑุงุกุชู ูู ูุฐู [ุชุฏูููุฉ ุงููุฏููุฉ ุงููุทููุฉ](https://huggingface.co/blog/assisted-generation).

ุงูุณุจุจ ูู ุฃู LLMs ุงูุถุฎูุฉ ูุซู GPT3/4ุ ูLlama-2-70bุ ูClaudeุ ูPaLM ูููู ุฃู ุชุนูู ุจุณุฑุนุฉ ูุจูุฑุฉ ูู ูุงุฌูุงุช ุงูุฏุฑุฏุดุฉ ูุซู [Hugging Face Chat](https://huggingface.co/chat/) ุฃู ChatGPT ูุฑุฌุน ุฅูู ุญุฏ ูุจูุฑ ุฅูู ุงูุชุญุณููุงุช ุงููุฐููุฑุฉ ุฃุนูุงู ูู ุงูุฏูุฉ ูุงูุฎูุงุฑุฒููุงุช ูุงูููุฏุณุฉ ุงููุนูุงุฑูุฉ.
ูู ุงููุณุชูุจูุ ุณุชููู ุฃุฌูุฒุฉ ุงูุชุณุฑูุน ูุซู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPUs) ููุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (TPUs)ุ ููุง ุฅูู ุฐูู... ุณุชููู ุฃุณุฑุน ููุท ูุณุชุณูุญ ุจูุฒูุฏ ูู ุงูุฐุงูุฑุฉุ ูููู ูุฌุจ ุฏุงุฆููุง ุงูุชุฃูุฏ ูู ุงุณุชุฎุฏุงู ุฃูุถู ุงูุฎูุงุฑุฒููุงุช ูุงูููุฏุณุฉ ุงููุนูุงุฑูุฉ ุงููุชุงุญุฉ ููุญุตูู ุนูู ุฃูุจุฑ ูุฏุฑ ูู ุงููุงู
