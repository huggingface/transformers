# ุงููุนุงูุฌุฉ ุงููุณุจูุฉ Preprocessing

[[open-in-colab]]

ูุจู ุชุฏุฑูุจ ูููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุชุ ูุฌุจ ูุนุงูุฌุชูุง ูุณุจููุง ููููุง ุชูุณูู  ุงููุชููุน ููุฏุฎูุงุช ุงููููุฐุฌ. ุณูุงุก ูุงูุช ุจูุงูุงุชู ูุตูุฉ ุฃู ุตูุฑูุง ุฃู ุตูุชูุงุ ููุฌุจ ุชุญููููุง ูุชุฌููุนูุง ูู ุฏูุนุงุช ูู ุงูููุชุฑุงุช. ูููุฑ ๐ค Transformers ูุฌููุนุฉ ูู ูุฆุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูููุณุงุนุฏุฉ ูู ุฅุนุฏุงุฏ ุจูุงูุงุชู ูููููุฐุฌ. ูู ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณุชุชุนูู ุฃูู ุจุงููุณุจุฉ ูู:

* ูููุตุ ุงุณุชุฎุฏู [ููุฌุฒูุฆ ุงูุฑููุฒ](./main_classes/tokenizer) ูุชุญููู ุงููุต ุฅูู ุชุณูุณู ูู ุงูุฑููุฒุ ูุฅูุดุงุก ุชูุซูู ุฑููู ููุฑููุฒุ ูุชุฌููุนูุง ูู ููุชุฑุงุช(tensors).
* ููููุงู ูุงูุตูุชุ ุงุณุชุฎุฏู [ูุณุชุฎุฑุฌ ุงูููุฒุงุช](./main_classes/feature_extractor) ูุงุณุชุฎุฑุงุฌ ููุฒุงุช ูุชุณูุณูุฉ ูู ุฃุดูุงู ููุฌุงุช ุงูุตูุช ูุชุญููููุง ุฅูู ููุชุฑุงุช.
* ุชุณุชุฎุฏู ูุฏุฎูุงุช ุงูุตูุฑุฉ [ImageProcessor](./main_classes/image_processor) ูุชุญููู ุงูุตูุฑ ุฅูู ููุชุฑุงุช.
* ุชุณุชุฎุฏู ูุฏุฎูุงุช ูุชุนุฏุฏุฉ ุงููุณุงุฆุท [ูุนุงูุฌูุง](./main_classes/processors) ูุฏูุฌ ููุฌุฒูุฆ ุงูุฑููุฒ ููุณุชุฎุฑุฌ ุงูููุฒุงุช ุฃู ูุนุงูุฌ ุงูุตูุฑ.

<Tip>

`AutoProcessor` **ูุนูู ุฏุงุฆููุง** ููุฎุชุงุฑ ุชููุงุฆููุง ุงููุฆุฉ ุงูุตุญูุญุฉ ูููููุฐุฌ ุงูุฐู ุชุณุชุฎุฏููุ ุณูุงุก ููุช ุชุณุชุฎุฏู ููุฌุฒูุฆ ุฑููุฒ ุฃู ูุนุงูุฌ ุตูุฑ ุฃู ูุณุชุฎุฑุฌ ููุฒุงุช ุฃู ูุนุงูุฌูุง.

</Tip>

ูุจู ุงูุจุฏุกุ ูู ุจุชุซุจูุช ๐ค Datasets ุญุชู ุชุชููู ูู ุชุญููู ุจุนุถ ูุฌููุนุงุช ุงูุจูุงูุงุช ูุชุฌุฑุจุชูุง:

```bash
pip install datasets
```

## ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ (Natural Language Processing (NLP

<Youtube id="Yffk5aydLzg"/>

ุฃุฏุงุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุงูุฑุฆูุณูุฉ ููุจูุงูุงุช ุงููุตูุฉ ูู [ููุฌุฒูุฆ ุงููุบูู](main_classes/tokenizer). ูููู ููุฌุฒูุฆ ุงููุบูู ุจุชูุณูู ุงููุต ุฅูู  "ุฃุฌุฒุงุก ูุบููุฉ" (tokens) ููููุง ููุฌููุนุฉ ูู ุงูููุงุนุฏ. ูุชู ุชุญููู ุงูุฃุฌุฒุงุก ุงููุบููุฉ ุฅูู ุฃุฑูุงู ุซู ุฅูู ููุณูุฌุงุชุ ูุงูุชู ุชุตุจุญ ูุฏุฎูุงุช ูููููุฐุฌ. ูููู ุงููุฌุฒุฆ ุงููุบูู ุจุฅุถุงูุฉ ุฃู ูุฏุฎูุงุช ุฅุถุงููุฉ ูุญุชุงุฌูุง ุงููููุฐุฌ.

<Tip>

ุฅุฐุง ููุช ุชุฎุทุท ูุงุณุชุฎุฏุงู ูููุฐุฌ ููุฏุฑุจ ูุณุจููุงุ ููู ุงูููู ุงุณุชุฎุฏุงูุงููุฌุฒุฆ ุงููุบูู ุงูููุชุฑู ุจููุณ ุฐูู ุงููููุฐุฌ. ูุถูู ุฐูู ุชูุณูู ุงููุต ุจููุณ ุงูุทุฑููุฉ ุงูุชู ุชู ุจูุง ุชูุณูู ุงููุตูุต ูุง ูุจู ุงูุชุฏุฑูุจุ ูุงุณุชุฎุฏุงู ููุณ  ุงููุงููุณ ุงูุฐู ูุฑุจุท ุจูู ุงูุฃุฌุฒุงุก ุงููุบููุฉ ูุฃุฑูุงููุง ( ููุดุงุฑ ุฅูููุง ุนุงุฏุฉู ุจุงุณู ุงูููุฑุฏุงุช *vocab*) ุฃุซูุงุก ุงูุชุฏุฑูุจ ุงููุณุจู.

</Tip>

ุงุจุฏุฃ ุจุชุญููู  ุงูููุฌุฒูุฆ ุงููุบูู ููุฏุฑุจ ูุณุจููุง ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`AutoTokenizer.from_pretrained`]. ูููู ูุฐุง ุจุชูุฒูู ุงูููุฑุฏุงุช *vocab* ุงูุฐู ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุนููู:

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-cased")
```

ุซู ูุฑุฑ ูุตู ุฅูู ุงูููุฌุฒูุฆ ุงููุบูู:

```py
>>> encoded_input = tokenizer("Do not meddle in the affairs of wizards, for they are subtle and quick to anger.")
>>> print(encoded_input)
{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102],
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

ูุนูุฏ ุงูููุฌุฒูุฆ ุงููุบูู ูุงููุณูุง ูุญุชูู ุนูู ุซูุงุซุฉ ุนูุงุตุฑ ูููุฉ:

* [input_ids](glossary#input-ids) ูู ุงูููุงุฑุณ ุงูููุงุจูุฉ ููู ุฑูุฒ ูู ุงูุฌููุฉ.
* [attention_mask](glossary#attention-mask) ูุดูุฑ ุฅูู ูุง ุฅุฐุง ูุงู ูุฌุจ ุงูุงูุชุจุงู ุจุงูุฑูุฒ ุฃู ูุง.
* [token_type_ids](glossary#token-type-ids) ูุญุฏุฏ ุงูุชุณูุณู ุงูุฐู ููุชูู ุฅููู ุงูุฑูุฒ ุนูุฏูุง ูููู ููุงู ุฃูุซุฑ ูู ุชุณูุณู ูุงุญุฏ.

ุฃุนุฏ ุฅุฏุฎุงูู ุงูุฃุตูู ุนู ุทุฑูู ูู ุชุฑููุฒ `input_ids`:

```py
>>> tokenizer.decode(encoded_input["input_ids"])
'[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'
```

ููุง ุชุฑูุ ุฃุถุงู ุงูููุฌุฒูุฆ ุงููุบูู ุฑูุฒูู ุฎุงุตูู - `CLS` ู`SEP` (ูุตูู ููุงุตู) - ุฅูู ุงูุฌููุฉ. ูุง ุชุญุชุงุฌ ุฌููุน ุงูููุงุฐุฌ ุฅูู
ุฑููุฒ ุฎุงุตุฉุ ูููู ุฅุฐุง ูุนููุง ุฐููุ ูุฅู ุงูููุฌุฒูุฆ ุงููุบูู ูุถูููุง ุชููุงุฆููุง ูู.

ุฅุฐุง ูุงู ููุงู ุนุฏุฉ ุฌูู ุชุฑูุฏ ูุนุงูุฌุชูุง ูุณุจููุงุ ููู ุจุชูุฑูุฑูุง ููุงุฆูุฉ ุฅูู ููุฌุฒูุฆ ุงููุบูู:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_inputs = tokenizer(batch_sentences)
>>> print(encoded_inputs)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0]],
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1]]}
```

### ุงูุญุดู Padding

ูุง ุชููู ุงูุฌูู ุฏุงุฆููุง ุจููุณ ุงูุทููุ  ููุฐุง ูููู ุฃู ููุซู ูุดููุฉ ูุฃู ุงูููุชุฑุงุชุููู ูุฏุฎูุงุช ุงููููุฐุฌุ ุชุญุชุงุฌ ุฅูู ุดูู ููุญุฏ. ุงูุญุดู ูู ุงุณุชุฑุงุชูุฌูุฉ ูุถูุงู ุฃู ุชููู ุงูููุชุฑุงุช ูุณุชุทููุฉ ุนู ุทุฑูู ุฅุถุงูุฉ ุฑูุฒ ุญุดู *padding* ุฎุงุต ุฅูู ุงูุฌูู ุงูุฃูุตุฑ.

ูู ุจุชุนููู ูุนููุฉ ุงูุญุดู `padding` ุฅูู `True` ูุญุดู ุงูุชุณูุณูุงุช ุงูุฃูุตุฑ ูู ุงูุฏูุนุฉ ูุชุทุงุจู ุฃุทูู ุชุณูุณู:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1, 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0]]}
```

ุชู ุงูุขู ุญุดู ุงูุฌููุชูู ุงูุฃููู ูุงูุซุงูุซุฉ ุจู `0` ูุฃูููุง ุฃูุตุฑ.

### ุงูุจุชุฑ Truncation

ูุนูู ุตุนูุฏ ุฃุฎุฑุ ูุฏ ูููู ุงูุชุณูุณู ุทููููุง ุฌุฏูุง ุจุงููุณุจุฉ ูููููุฐุฌ ููุชุนุงูู ูุนู. ูู ูุฐู ุงูุญุงูุฉุ ุณุชุญุชุงุฌ ุฅูู ุจุชุฑ ุงูุชุณูุณู ุฅูู ุทูู ุฃูุตุฑ.

ูู ุจุชุนููู ูุนููุฉ `truncation` ุฅูู `True` ูุชูููู ุชุณูุณู ุฅูู ุงูุทูู ุงูุฃูุตู ุงูุฐู ููุจูู ุงููููุฐุฌ:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0ุ 0ุ 0ุ 0ุ 0]]ุ
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0ุ 0ุ 0ุ 0],
                    [1, 1, 1, 1, 1, 1, 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1],
                    [1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0]]}
```

<Tip>

ุชุญูู ูู ุฏููู ุงูููุงููู [Padding and truncation](./pad_truncation) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ูุนุงู๏ปปุช ุงูุญุดู ู ุงูุจุชุฑ ุงููุฎุชููุฉ.

</Tip>

### ุจูุงุก ุงูููุชุฑุงุช Build tensors

ุฃุฎูุฑูุงุ ุชุฑูุฏ ุฃู ูููู  ุงููุฌุฒุฆ ุงููุบูู ุจุฅุฑุฌุงุน ููุชุฑุงุช (tensors) ุงููุนููุฉ ุงูุชู ุณุชูุบุฐู ุงููููุฐุฌ.

ูู ุจุชุนููู ูุนููุฉ `return_tensors` ุฅูู ุฅูุง `pt` ูู PyTorchุ ุฃู `tf` ูู TensorFlow:


```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors="pt")
>>> print(encoded_input)
{'input_ids': tensor([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
                      [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
                      [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]]),
 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),
 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                           [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}
```

<Tip>

ุชุฏุนู ุฎุทูุท ุงูุฃูุงุจูุจ ุงููุฎุชููุฉ ูุนุงูู ููุฌุฒููุฆ ุงูุฑููุฒ(tokenizer) ุจุดูู ูุฎุชูู ูู ุทุฑููุฉ `()__call__` ุงูุฎุงุตุฉ ุจูุง.
ู ุฎุทูุท ุงูุฃูุงุจูุจ `text-2-text-generation` ุชุฏุนู ููุท `truncation`.
ู ุฎุทูุท ุงูุฃูุงุจูุจ `text-generation` ุชุฏุนู `max_length` ู`truncation` ู`padding` ู`add_special_tokens`.
ุฃูุง ูู ุฎุทูุท ุงูุฃูุงุจูุจ `fill-mask`ุ ูููู ุชูุฑูุฑ ูุนุงูู ููุฌุฒููุฆ ุงูุฑููุฒ (tokenizer) ูู ุงููุชุบูุฑ `tokenizer_kwargs` (ูุงููุณ).

</Tip>

## ุงูุตูุช Audio

ุจุงููุณุจุฉ ููููุงู ุงูุตูุชูุฉุ ุณุชุญุชุงุฌ ุฅูู [ูุณุชุฎุฑุฌ ุงูููุฒุงุช](main_classes/feature_extractor) ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ููููุงุฐุฌ. ุชู ุชุตููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูุงุณุชุฎุฑุงุฌ ุงูููุฒุงุช ูู ุจูุงูุงุช ุงูุตูุช ุงูุฎุงูุ ูุชุญููููุง ุฅูู ููุชูุฑุงุช.

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) (ุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ูู ๐ค [Datasets](https://huggingface.co/docs/datasets/load_hub) ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููููุฉ ุงุณุชุฎุฏุงู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูุน ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุตูุชูุฉ:

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")
```

ุงููุตูู ุฅูู ุงูุนูุตุฑ ุงูุฃูู ูู ุนููุฏ `audio` ููุนุฑูุฉ ุงููุฏุฎูุงุช. ูุคุฏู ุงุณุชุฏุนุงุก ุนููุฏ `audio` ุฅูู ุชุญููู ููู ุงูุตูุช ูุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ุชููุงุฆููุง:

```py
>>> dataset[0]["audio"]
{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,
         0.        ,  0.        ], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 8000}
```

ูุนูุฏ ูุฐุง ุซูุงุซุฉ ุนูุงุตุฑ:

* `array` ูู ุฅุดุงุฑุฉ ุงูููุงู ุงููุญููุฉ - ูุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ุงููุญุชููุฉ - ูุตููู 1D.
* `path` ูุดูุฑ ุฅูู ูููุน ููู ุงูุตูุช.
* `sampling_rate` ูุดูุฑ ุฅูู ุนุฏุฏ ููุงุท ุงูุจูุงูุงุช ูู ุฅุดุงุฑุฉ ุงูููุงู ุงูููุงุณุฉ ูู ุงูุซุงููุฉ.

ุจุงููุณุจุฉ ููุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณุชุณุชุฎุฏู ูููุฐุฌ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base). ุงูู ูุธุฑุฉ ุนูู ุจุทุงูุฉ ุงููููุฐุฌุ ูุณุชุชุนูู ุฃู Wav2Vec2 ููุฏุฑุจ ูุณุจููุง ุนูู ุตูุช ุงูููุงู ุงูุฐู ุชู ุฃุฎุฐ ุนููุงุช ููู ุจูุนุฏู 16 ูููู ูุฑุชุฒ. ูู ุงูููู ุฃู ูุชุทุงุจู ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูุจูุงูุงุช ุงูุตูุช ูุน ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ููุฌููุนุฉ ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ูุชุฏุฑูุจ ุงููููุฐุฌ ูุณุจููุง. ุฅุฐุง ูู ููู ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูุจูุงูุงุชู ูู ููุณูุ ููุฌุจ ุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ูู ุจูุงูุงุชู.

1. ุงุณุชุฎุฏู ุทุฑููุฉ [`~datasets.Dataset.cast_column`] ูู ๐ค Datasets ูุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ุจูุนุฏู ุฃุฎุฐ ุงูุนููุงุช 16 ูููู ูุฑุชุฒ:

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16_000))
```

2. ุงุณุชุฏุนุงุก ุนููุฏ `audio` ูุฑุฉ ุฃุฎุฑู ูุฃุฎุฐ ุนููุงุช ูู ููู ุงูุตูุช:

```py
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 16000}
```

ุจุนุฏ ุฐููุ ูู ุจุชุญููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูุชุทุจูุน ูุญุดู ุงููุฏุฎูุงุช. ุนูุฏ ุฅุถุงูุฉ ุญุดู ููุจูุงูุงุช ุงููุตูุฉุ ุชุชู ุฅุถุงูุฉ "0" ููุชุณูุณูุงุช ุงูุฃูุตุฑ. ุชูุทุจู ููุณ ุงูููุฑุฉ ุนูู ุจูุงูุงุช ุงูุตูุช. ูุถูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช "0" - ุงูุฐู ูุชู ุชูุณูุฑู ุนูู ุฃูู ุตูุช - ุฅูู "array".

ูู ุจุชุญููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ุจุงุณุชุฎุฏุงู [`AutoFeatureExtractor.from_pretrained`]:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

ูุฑุฑ ุตููู ุงูุตูุช ุฅูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช. ููุง ููุตู ุจุฅุถุงูุฉ ูุนุงูู `sampling_rate` ูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูู ุฃุฌู ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงูุตุงูุชุฉ ุงูุชู ูุฏ ุชุญุฏุซ ุจุดูู ุฃูุถู.

```py
>>> audio_input = [dataset[0]["audio"]["array"]]
>>> feature_extractor(audio_input, sampling_rate=16000)
{'input_values': [array([ 3.8106556e-04,  2.7506407e-03,  2.8015103e-03, ...,
        5.6335266e-04,  4.6588284e-06, -1.7142107e-04], dtype=float32)]}
```

ุชูุงููุง ูุซู ููุฌุฒููุฆ ุงูุฑููุฒุ ููููู ุชุทุจูู ุงูุญุดู ุฃู ุงูุจุชุฑ ููุชุนุงูู ูุน ุงูุชุณูุณูุงุช ุงููุชุบูุฑุฉ ูู ุฏูุนุฉ. ุงูู ูุธุฑุฉ ุนูู ุทูู ุงูุชุณูุณู ููุงุชูู ุงูุนููุชูู ุงูุตูุชูุชูู:

```py
>>> dataset[0]["audio"]["array"].shape
(173398,)

>>> dataset[1]["audio"]["array"].shape
(106496,)
```

ูู ุจุฅูุดุงุก ุฏุงูุฉ ููุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุญูุซ ูููู ููููุงุฐุฌ ุงูุตูุชูุฉ ููุณ ุงูุฃุทูุงู. ุญุฏุฏ ุฃูุตู ุทูู ููุนููุฉ ุ ูุณูููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ุฅูุง ุจุฅุถุงูุฉ ุญุดู ุฃู ุจุชุฑ ุงูุชุณูุณูุงุช ููุทุงุจูุชูุง:

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays,
...         sampling_rate=16000,
...         padding=True,
...         max_length=100000,
...         truncation=True,
...     )
...     return inputs
```

ูู ุจุชุทุจูู `preprocess_function` ุนูู ุฃูู ุจุถุน ุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> processed_dataset = preprocess_function(dataset[:5])
```

ุฃุทูุงู ุงูุนููุงุช ุงูุขู ูุชุณุงููุฉ ูุชุทุงุจู ุงูุทูู ุงูุฃูุตู ุงููุญุฏุฏ. ููููู ุงูุขู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ!

```py
>>> processed_dataset["input_values"][0].shape
(100000,)

>>> processed_dataset["input_values"][1].shape
(100000,)
```

## ุฑุคูุฉ ุงูููุจููุชุฑ Computer vision

ุจุงููุณุจุฉ ูููุงู ุฑุคูุฉ ุงูุญุงุณูุจูุฉุ ุณุชุญุชุงุฌ ุฅูู ูุนุงูุฌ ุตูุฑ [image processor](main_classes/image_processor) ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ูุชูุงุณุจ ุงููููุฐุฌ. ุชุชููู ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ูู ุนุฏุฉ ุฎุทูุงุช ูุชุญููู ุงูุตูุฑ ุฅูู ุงูุดูู ุงูุฐู ูุชููุนู ุงููููุฐุฌ. ูุชุดูู ูุฐู ุงูุฎุทูุงุชุ ุนูู ุณุจูู ุงููุซุงู ูุง ุงูุญุตุฑุ ุชุบููุฑ ุงูุญุฌู ูุงูุชุทุจูุน ูุชุตุญูุญ ููุงุฉ ุงูุฃููุงู ูุชุญููู ุงูุตูุฑ ุฅูู ููุชุฑุงุช(tensors).

<Tip>

ุนุงุฏุฉ ูุง ุชุชุจุน ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ุดููุงู ูู ุฃุดูุงู ุฒูุงุฏุฉ ุงูุจูุงูุงุช (ุงูุชุถุฎูู). ููุง ุงูุนูููุชููุ  ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ูุฒูุงุฏุฉ ุงูุตูุฑ ุชุบูุฑุงู ุจูุงูุงุช ุงูุตูุฑุฉุ ูููููุง ุชุฎุฏู ุฃุบุฑุงุถูุง ูุฎุชููุฉ:

*ุฒูุงุฏุฉ ุงูุจูุงูุงุช: ุชุบููุฑ ุงูุตูุฑ ุนู ุทุฑูู ุฒูุงุฏุฉ ุงูุตูุฑ ุจุทุฑููุฉ ูููู ุฃู ุชุณุงุนุฏ ูู ููุน ุงูุฅูุฑุงุท ูู ุงูุชุนููู ูุฒูุงุฏุฉ ูุชุงูุฉ ุงููููุฐุฌ. ููููู ุฃู ุชููู ูุจุฏุนูุง ูู ููููุฉ ุฒูุงุฏุฉ ุจูุงูุงุชู - ุถุจุท ุงูุณุทูุน ูุงูุฃููุงูุ ูุงุงููุตุ ูุงูุฏูุฑุงูุ ุชุบููุฑ ุงูุญุฌูุ ุงูุชูุจูุฑุ ุฅูุฎ. ููุน ุฐููุ ูู ุญุฐุฑูุง ูู ุนุฏู ุชุบููุฑ ูุนูู ุงูุตูุฑ ุจุฒูุงุฏุงุชู.
*ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ: ุชุถูู ูุนุงูุฌุฉ ุงูุตูุฑ ุงุชุชุทุงุจู ุงูุตูุฑ ูุน ุชูุณูู ุงูุฅุฏุฎุงู ุงููุชููุน ูููููุฐุฌ. ุนูุฏ ุถุจุท ูููุฐุฌ ุฑุคูุฉ ุญุงุณูุจูุฉ ุจุฏูุฉุ ูุฌุจ ูุนุงูุฌุฉ ุงูุตูุฑ ุจุงูุถุจุท ููุง ูุงูุช ุนูุฏ ุชุฏุฑูุจ ุงููููุฐุฌ ูู ุงูุจุฏุงูุฉ.

ููููู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุชุฑูุฏูุง ูุฒูุงุฏุฉ ุจูุงูุงุช ุงูุตูุฑ. ููุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉุ ุงุณุชุฎุฏู `ImageProcessor` ุงููุฑุชุจุท ุจุงููููุฐุฌ.

</Tip>

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [food101](https://huggingface.co/datasets/food101) (ุฑุงุฌุน ุฏููู ๐ค [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููู ููููู ุงุณุชุฎุฏุงู ูุนุงูุฌ ุงูุตูุฑ ูุน ูุฌููุนุงุช ุจูุงูุงุช ุฑุคูุฉ ุงูุญุงุณุจ:

<Tip>

ุงุณุชุฎุฏู ูุนุงูู `split` ูู ๐ค Datasets ูุชุญููู ุนููุฉ ุตุบูุฑุฉ ููุท ูู ูุฌููุนุฉ ุงูุชุฏุฑูุจ ูุธุฑูุง ูุญุฌู ุงูุจูุงูุงุช ูุจูุฑุฉ ุฌุฏูุง!

</Tip>

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("food101", split="train[:100]")
```

ุจุนุฏ ุฐููุ ุงูู ูุธุฑุฉ ุนูู ุงูุตูุฑุฉ ูุน ููุฒุฉ ๐ค Datasets [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image):

```py
>>> dataset[0]["image"]
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png"/>
</div>

ูู ุจุชุญููู ูุนุงูุฌ ุงูุตูุฑ ุจุงุณุชุฎุฏุงู [`AutoImageProcessor.from_pretrained`]:

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
```

ุฃููุงูุ ุฏุนูุง ูุถูู ุจุนุถ ุงูุฒูุงุฏุงุช ุฅูู ุงูุตูุฑ. ููููู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุชูุถููุงุ ูููู ูู ูุฐุง ุงูุฏูููุ ุณูุณุชุฎุฏู ูุญุฏุฉ [`transforms`](https://pytorch.org/vision/stable/transforms.html) ูู torchvision. ุฅุฐุง ููุช ููุชููุง ุจุงุณุชุฎุฏุงู ููุชุจุฉ ุฒูุงุฏุฉ ุจูุงูุงุช ุฃุฎุฑูุ ูุชุนุฑู ุนูู ููููุฉ ุงูููุงู ุจุฐูู ูู [ุฏูุงุชุฑ Albumentations](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb) ุฃู [ุฏูุงุชุฑ Kornia](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb).

1. ููุง ูุณุชุฎุฏู [`Compose`](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html) ูุฑุจุท ุจุนุถ ุงูุชุญููุงุช ูุนูุง - [`RandomResizedCrop`](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html) ู [`ColorJitter`](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html).
ูุงุญุธ ุจุงููุณุจุฉ ูุชุบููุฑ ุงูุญุฌูุ ูููููุง ุงูุญุตูู ุนูู ูุชุทูุจุงุช ุญุฌู ุงูุตูุฑุฉ ูู `image_processor`. ุจุงููุณุจุฉ ูุจุนุถ ุงูููุงุฐุฌุ ููุชููุน ุงุฑุชูุงุน ูุนุฑุถ ุฏูููููุ ุจูููุง ุจุงููุณุจุฉ ููููุงุฐุฌ ุงูุฃุฎุฑูุ ูุชู ุชุญุฏูุฏ  ุงูุญุงูุฉ ุงูุฃูุตุฑ`shortest_edge` ููุท.

```py
>>> from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose

>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )

>>> _transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])
```

2. ููุจู ุงููููุฐุฌ [`pixel_values`](model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel.forward.pixel_values)
ูุฅุฏุฎุงู ูู. ูููู ูู `ImageProcessor` ุงูุชุนุงูู ูุน ุชุทุจูุน ุงูุตูุฑุ ูุชูููุฏ ููุชุฑุงุช(tensors) ููุงุณุจุฉ.
ูู ุจุฅูุดุงุก ุฏุงูุฉ ุชุฌูุน ุจูู ุชุถุฎูู ุจูุงูุงุช ุงูุตูุฑ ููุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ููุฌููุนุฉ ูู ุงูุตูุฑ ูุชูููุฏ `pixel_values`:

```py
>>> def transforms(examples):
...     images = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     examples["pixel_values"] = image_processor(images, do_resize=False, return_tensors="pt")["pixel_values"]
...     return examples
```

<Tip>

ูู ุงููุซุงู ุฃุนูุงูุ ูููุง ุจุชุนููู `do_resize=False` ูุฃููุง ูููุง ุจุงููุนู ุจุชุบููุฑ ุญุฌู ุงูุตูุฑ ูู ุชุญููู ุฒูุงุฏุฉ ุงูุตูุฑุ
ูุงุณุชูุฏูุง ูู ุฎุงุตูุฉ `size` ูู `image_processor` ุงูููุงุณุจ. ุฅุฐุง ูู ุชูู ุจุชุบููุฑ ุญุฌู ุงูุตูุฑ ุฃุซูุงุก ุฒูุงุฏุฉ ุงูุตูุฑุ
ูุงุชุฑู ูุฐุง ุงููุนููุฉ. ุจุดูู ุงูุชุฑุงุถูุ ุณุชุชุนุงูู `ImageProcessor` ูุน ุชุบููุฑ ุงูุญุฌู.

ุฅุฐุง ููุช ุชุฑุบุจ ูู ุชุทุจูุน ุงูุตูุฑ ูุฌุฒุก ูู ุชุญููู ุฒูุงุฏุฉ ุงูุตูุฑุ ูุงุณุชุฎุฏู ููู `image_processor.image_mean`ุ
ู `image_processor.image_std`.
</Tip>

3. ุซู ุงุณุชุฎุฏู ๐ค Datasets[`~datasets.Dataset.set_transform`] ูุชุทุจูู ุงูุชุญููุงุช ุฃุซูุงุก ุงูุชููู:
```py
>>> dataset.set_transform(transforms)
```

4. ุงูุขู ุนูุฏ ุงููุตูู ุฅูู ุงูุตูุฑุฉุ ุณุชูุงุญุธ ุฃู ูุนุงูุฌ ุงูุตูุฑ ูุฏ ุฃุถุงู `pixel_values`. ููููู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ ุงูุขู!

```py
>>> dataset[0].keys()
```

ููุฐุง ุชุจุฏู ุงูุตูุฑุฉ ุจุนุฏ ุชุทุจูู ุงูุชุญููุงุช. ุชู ุงูุชุตุงุต ุงูุตูุฑุฉ ุจุดูู ุนุดูุงุฆู ูุชุฎุชูู ุฎุตุงุฆุต ุงูุฃููุงู ุจูุง.

```py
>>> import numpy as np
>>> import matplotlib.pyplot as plt

>>> img = dataset[0]["pixel_values"]
>>> plt.imshow(img.permute(1, 2, 0))
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png"/>
</div>

<Tip>

ุจุงููุณุจุฉ ููููุงู ูุซู ุงููุดู ุนู ุงูุฃุดูุงุกุ ูุงูุชุฌุฒุฆุฉ ุงูุฏูุงููุฉุ ูุงูุชุฌุฒุฆุฉ ุงููุซุงููุฉุ ูุงูุชุฌุฒุฆุฉ ุงูุดุงููุฉุ ูููุฑ `ImageProcessor`
ุชููู ูุฐู ุงูุทุฑู ุจุชุญููู ุงูููุงุชุฌ ุงูุฃูููุฉ ูููููุฐุฌ ุฅูู ุชูุจุคุงุช ุฐุงุช ูุนูู ูุซู ูุฑุจุนุงุช ุงูุญุฏูุฏุ
ุฃู ุฎุฑุงุฆุท ุงูุชุฌุฒุฆุฉ.

</Tip>

### ุงูุญุดู Pad

ูู ุจุนุถ ุงูุญุงูุงุชุ ุนูู ุณุจูู ุงููุซุงูุ ุนูุฏ ุถุจุท ูููุฐุฌ [DETR](./model_doc/detr) ุจุฏูุฉุ ูููู ุงููููุฐุฌ ุจุชุทุจูู ุฒูุงุฏุฉ ุงููููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ. ูุฏ ูุชุณุจุจ ุฐูู ูู ุงุฎุชูุงู ุฃุญุฌุงู ุงูุตูุฑ ูู ุฏูุนุฉ ูุงุญุฏุฉ. ููููู ุงุณุชุฎุฏุงู [`DetrImageProcessor.pad`]
ูู [`DetrImageProcessor`] ูุชุญุฏูุฏ ุฏุงูุฉ `collate_fn` ูุฎุตุตุฉ ูุชุฌููุน ุงูุตูุฑ ูุนูุง.

```py
>>> def collate_fn(batch):
...     pixel_values = [item["pixel_values"] for item in batch]
...     encoding = image_processor.pad(pixel_values, return_tensors="pt")
...     labels = [item["labels"] for item in batch]
...     batch = {}
...     batch["pixel_values"] = encoding["pixel_values"]
...     batch["pixel_mask"] = encoding["pixel_mask"]
...     batch["labels"] = labels
...     return batch
```

## ูุชุนุฏุฏ ุงููุณุงุฆุท Mulimodal

ุจุงููุณุจุฉ ููููุงู ุงูุชู ุชุชุทูุจ ูุฏุฎูุงุช ูุชุนุฏุฏุฉ ุงููุณุงุฆุทุ ุณุชุญุชุงุฌ ุฅูู ูุนุงูุฌ [processor](main_classes/processors) ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ูุชูุงุณุจ ุงููููุฐุฌ. ููุชุฑู ุงููุนุงูุฌ ุจูู  ุจูุนุงูุฌูู ุขุฎุฑูู ูุซู ูุญูู ุงููุต ุฅูู ุฑูุฒ ููุณุชุฎุฑุฌ ุงูููุฒุงุช.

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [LJ Speech](https://huggingface.co/datasets/lj_speech) (ุฑุงุฌุน ุฏููู ๐ค [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููู ููููู ุงุณุชุฎุฏุงู ูุนุงูุฌ ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR):

```py
>>> from datasets import load_dataset

>>> lj_speech = load_dataset("lj_speech", split="train")
```

ุจุงููุณุจุฉ ูู ASRุ ูุฃูุช ุชุฑูุฒ ุจุดูู ุฃุณุงุณู ุนูู `audio` ู `text` ูุฐุง ููููู ุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู:

```py
>>> lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])
```

ุงูุขู ุงูู ูุธุฑุฉ ุนูู ุฃุนูุฏุฉ `audio` ู `text`:
```py
>>> lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])
```

ุงูุขู ุงูู ูุธุฑุฉ ุนูู ุฃุนูุฏุฉ `audio` ู `text`:

```py
>>> lj_speech[0]["audio"]
{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,
         7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',
 'sampling_rate': 22050}

>>> lj_speech[0]["text"]
'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'
```

ุชุฐูุฑ ุฃูู ูุฌุจ ุนููู ุฏุงุฆููุง [ุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช](preprocessing#audio) ููุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุตูุชูุฉ ุงูุฎุงุตุฉ ุจู ููุทุงุจูุฉ ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ูุชุฏุฑูุจ ุงููููุฐุฌ ูุณุจููุง!

```py
>>> lj_speech = lj_speech.cast_column("audio", Audio(sampling_rate=16_000))
```

ูู ุจุชุญููู ูุนุงูุฌ ุจุงุณุชุฎุฏุงู [`AutoProcessor.from_pretrained`]:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")
```

1. ูู ุจุฅูุดุงุก ุฏุงูุฉ ููุนุงูุฌุฉ ุจูุงูุงุช ุงูุตูุช ุงูููุฌูุฏุฉ ูู `array` ุฅูู `input_values`ุ ูุฑููุฒ `text` ุฅูู `labels`. ูุฐู ูู ุงููุฏุฎูุงุช ูููููุฐุฌ:

```py
>>> def prepare_dataset(example):
...     audio = example["audio"]

...     example.update(processor(audio=audio["array"], text=example["text"], sampling_rate=16000))

...     return example
```

2. ูู ุจุชุทุจูู ุฏุงูุฉ `prepare_dataset` ุนูู ุนููุฉ:

```py
>>> prepare_dataset(lj_speech[0])
```

ููุฏ ุฃุถุงู ุงููุนุงูุฌ ุงูุขู `input_values` ู `labels`ุ ูุชู ุฃูุถูุง ุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ููุนุฏู ุฃุฎุฐ ุงูุนููุงุช ุจุดูู ุตุญูุญ ุฅูู 16 ูููู ูุฑุชุฒ. ููููู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ ุงูุขู!
