<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

‚ö†Ô∏è Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ‡∞∂‡±Ä‡∞ò‡±ç‡∞∞ ‡∞™‡∞∞‡±ç‡∞Ø‡∞ü‡∞®

[[‡∞ì‡∞™‡±Ü‡∞®‡±ç-‡∞á‡∞®‡±ç-‡∞ï‡±ã‡∞≤‡∞æ‡∞¨‡±ç]]

ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‚Äå‡∞≤‡∞§‡±ã ‡∞≤‡±á‡∞ö‡∞ø ‡∞™‡∞∞‡±Å‡∞ó‡±Ü‡∞§‡±ç‡∞§‡∞Ç‡∞°‡∞ø! ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞°‡±Ü‡∞µ‡∞≤‡∞™‡∞∞‡±ç ‡∞Ö‡∞Ø‡∞ø‡∞®‡∞æ ‡∞≤‡±á‡∞¶‡∞æ ‡∞∞‡±ã‡∞ú‡±Å‡∞µ‡∞æ‡∞∞‡±Ä ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞¶‡∞æ‡∞∞‡±Å ‡∞Ö‡∞Ø‡∞ø‡∞®‡∞æ, ‡∞à ‡∞∂‡±Ä‡∞ò‡±ç‡∞∞ ‡∞™‡∞∞‡±ç‡∞Ø‡∞ü‡∞® ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å [`pipeline`] ‡∞Ö‡∞®‡±Å‡∞Æ‡∞ø‡∞§‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞é‡∞≤‡∞æ ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡±ã ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞ö‡±Ç‡∞™‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø, [AutoClass](./model_doc/auto) ‡∞§‡±ã ‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±à‡∞®‡±ç‡∞°‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ç‡∞∞‡∞ø‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞∞‡±ç/ ‡∞Ü‡∞ü‡±ã, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å PyTorch ‡∞≤‡±á‡∞¶‡∞æ TensorFlow‡∞§‡±ã ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡±Å ‡∞§‡±ç‡∞µ‡∞∞‡∞ó‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï ‡∞Ö‡∞®‡±Å‡∞≠‡∞µ‡∞∂‡±Ç‡∞®‡±ç‡∞Ø‡±Å‡∞°‡±Å ‡∞Ö‡∞Ø‡∞ø‡∞§‡±á, ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞™‡∞∞‡∞ø‡∞ö‡∞Ø‡∞Ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® ‡∞≠‡∞æ‡∞µ‡∞®‡∞≤ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞≤‡±ã‡∞§‡±à‡∞® ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡∞æ ‡∞ü‡±ç‡∞Ø‡±Å‡∞ü‡±ã‡∞∞‡∞ø‡∞Ø‡∞≤‡±ç‡∞∏‡±ç ‡∞≤‡±á‡∞¶‡∞æ [course](https://huggingface.co/course/chapter1/1)‡∞®‡∞ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Æ‡∞®‡∞ø ‡∞Æ‡±á‡∞Æ‡±Å ‡∞∏‡∞ø‡∞´‡∞æ‡∞∞‡±ç‡∞∏‡±Å ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å.

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Æ‡±à‡∞® ‡∞Ö‡∞®‡±ç‡∞®‡∞ø ‡∞≤‡±à‡∞¨‡±ç‡∞∞‡∞∞‡±Ä‡∞≤‡∞®‡±Å ‡∞á‡∞®‡±ç‚Äå‡∞∏‡±ç‡∞ü‡∞æ‡∞≤‡±ç ‡∞ö‡±á‡∞∂‡∞æ‡∞∞‡∞®‡∞ø ‡∞®‡∞ø‡∞∞‡±ç‡∞ß‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø:

```bash
!pip install transformers datasets evaluate accelerate
```

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞æ‡∞ß‡∞æ‡∞®‡±ç‡∞Ø ‡∞Ø‡∞Ç‡∞§‡±ç‡∞∞ ‡∞Ö‡∞≠‡±ç‡∞Ø‡∞æ‡∞∏ ‡∞´‡±ç‡∞∞‡±á‡∞Æ‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç‚Äå‡∞®‡±Å ‡∞ï‡±Ç‡∞°‡∞æ ‡∞á‡∞®‡±ç‚Äå‡∞∏‡±ç‡∞ü‡∞æ‡∞≤‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø:

<frameworkcontent>
<pt>

```bash
pip install torch
```
</pt>
<tf>

```bash
pip install tensorflow
```
</tf>
</frameworkcontent>

## ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç

<Youtube id="tiZFewofSLM"/>

[`pipeline`] ‡∞Ö‡∞®‡±Å‡∞Æ‡∞ø‡∞§‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞® ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡±Å‡∞≤‡∞≠‡∞Æ‡±à‡∞® ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡±á‡∞ó‡∞µ‡∞Ç‡∞§‡∞Æ‡±à‡∞® ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞Ç. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞µ‡∞ø‡∞µ‡∞ø‡∞ß ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡±Å‡∞≤‡∞≤‡±ã ‡∞Ö‡∞®‡±á‡∞ï ‡∞™‡∞®‡±Å‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç [`pipeline`] ‡∞µ‡±Ü‡∞≤‡±Å‡∞™‡∞≤ ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å, ‡∞µ‡∞æ‡∞ü‡∞ø‡∞≤‡±ã ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞ï‡±ç‡∞∞‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞ï‡∞≤‡±ã ‡∞ö‡±Ç‡∞™‡∞¨‡∞°‡±ç‡∞°‡∞æ‡∞Ø‡∞ø:


<Tip>

‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞™‡∞®‡±Å‡∞≤ ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ ‡∞ï‡±ã‡∞∏‡∞Ç, [‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç API ‡∞∏‡±Ç‡∞ö‡∞®](./main_classes/pipelines)‡∞®‡∞ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.

</Tip>

Here is the translation in Telugu:

| **‡∞™‡∞®‡∞ø**                      | **‡∞µ‡∞ø‡∞µ‡∞∞‡∞£**                                                                                              | **‡∞Æ‡±ã‡∞°‡∞æ‡∞≤‡∞ø‡∞ü‡±Ä**    | **‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±Ü‡±ñ‡∞®‡±ç ‡∞ê‡∞°‡±Ü‡∞Ç‡∞ü‡∞ø‡∞´‡±à‡∞Ø‡∞∞‡±ç**          |
|------------------------------|--------------------------------------------------------------------------------------------------------|-----------------|------------------------------------------|
| ‡∞µ‡∞ö‡∞® ‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞£‡±Å               | ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞µ‡∞ö‡∞®‡∞æ‡∞≤ ‡∞Ö‡∞Ç‡∞§‡∞æ ‡∞í‡∞ï ‡∞≤‡±á‡∞¨‡±Å‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ï‡±ä‡∞°‡∞ø                                                                   | NLP             | pipeline(task=‚Äúsentiment-analysis‚Äù)     |
| ‡∞µ‡∞ö‡∞® ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø                   | ‡∞™‡±ç‡∞∞‡∞Æ‡±ç‡∞™‡±Å‡∞ü‡∞Ç ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø‡∞®‡∞Ç‡∞§ ‡∞µ‡∞ö‡∞®‡∞Ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø                                                                 | NLP             | pipeline(task=‚Äútext-generation‚Äù)        |
| ‡∞∏‡∞Ç‡∞ï‡±ç‡∞∑‡±á‡∞™‡∞£                     | ‡∞µ‡∞ö‡∞®‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞™‡∞§‡±ç‡∞∞‡∞Ç ‡∞ï‡±ä‡∞∞‡∞ï‡±Å ‡∞∏‡∞Ç‡∞ï‡±ç‡∞∑‡±á‡∞™‡∞£ ‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡∞Ç‡∞°‡∞ø                                        | NLP             | pipeline(task=‚Äúsummarization‚Äù)          |
| ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞£‡±Å                | ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç‡∞≤‡±ã ‡∞í‡∞ï ‡∞≤‡±á‡∞¨‡±Å‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ï‡±ä‡∞°‡∞ø                                                           | ‡∞ï‡∞Ç‡∞™‡±ç‡∞Ø‡±Ç‡∞ü‡∞∞‡±ç ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç | pipeline(task=‚Äúimage-classification‚Äù) |
| ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞µ‡∞ø‡∞≠‡∞ú‡∞®                           | ‡∞í‡∞ï ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç‡∞≤‡±ã ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞µ‡±ç‡∞Ø‡∞ï‡±ç‡∞§‡∞ø‡∞ó‡∞§ ‡∞™‡∞ø‡∞ï‡±ç‡∞∏‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞í‡∞ï ‡∞≤‡±á‡∞¨‡±Å‡∞≤‡±ç‚Äå‡∞ó‡∞æ ‡∞®‡∞Æ‡±ã‡∞¶‡±Å ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø (‡∞∏‡±Ü‡∞Æ‡∞æ‡∞Ç‡∞ü‡∞ø‡∞ï‡±ç, ‡∞™‡∞æ‡∞®‡±ä‡∞™‡±ç‡∞ü‡∞ø‡∞ï‡±ç, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞á‡∞®‡±ç‡∞∏‡±ç‡∞ü‡∞®‡±ç‡∞∏‡±ç ‡∞µ‡∞ø‡∞≠‡∞ú‡∞®‡∞≤‡∞®‡±Å ‡∞Æ‡∞¶‡±ç‡∞¶‡∞§‡±Å ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø)         | ‡∞ï‡∞Ç‡∞™‡±ç‡∞Ø‡±Ç‡∞ü‡∞∞‡±ç ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç | pipeline(task=‚Äúimage-segmentation‚Äù)   |
| ‡∞µ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡±Å‡∞µ‡±Å                    | ‡∞í‡∞ï ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç‡∞≤‡±ã ‡∞™‡∞¶‡∞æ‡∞≤ ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞¨‡±å‡∞Ç‡∞°‡∞ø‡∞Ç‡∞ó‡±ç ‡∞¨‡∞æ‡∞ï‡±ç‡∞∏‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞æ‡∞≤ ‡∞µ‡∞∞‡±ç‡∞ó‡∞æ‡∞≤‡∞®‡±Å ‡∞Ö‡∞Ç‡∞ö‡∞®‡∞æ ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø      | ‡∞ï‡∞Ç‡∞™‡±ç‡∞Ø‡±Ç‡∞ü‡∞∞‡±ç ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç | pipeline(task=‚Äúobject-detection‚Äù)     |
| ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡±Å‡∞µ‡±Å                  | ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞°‡±á‡∞ü‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞í‡∞ï ‡∞≤‡±á‡∞¨‡±Å‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ï‡±ä‡∞°‡∞ø                                         | ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã           | pipeline(task=‚Äúaudio-classification‚Äù) |
| ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞≤‡∞® ‡∞™‡±ç‡∞∞‡∞∏‡∞Ç‡∞ó ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡±Å‡∞µ‡±Å   | ‡∞™‡±ç‡∞∞‡∞∏‡∞Ç‡∞ó‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞µ‡∞ö‡∞®‡∞Ç‡∞ó‡∞æ ‡∞µ‡∞∞‡±ç‡∞£‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø                                                                         | ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã           | pipeline(task=‚Äúautomatic-speech-recognition‚Äù) |
| ‡∞¶‡±É‡∞∂‡±ç‡∞Ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞∏‡∞Ç‡∞µ‡∞æ‡∞¶‡∞Ç          | ‡∞µ‡∞ö‡∞®‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞®‡∞Æ‡±ã‡∞¶‡±Å ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç‡∞§‡±ã ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞ï‡±Å ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø                     | ‡∞¨‡∞π‡±Å‡∞Æ‡±Ç‡∞≤‡∞ø‡∞ï          | pipeline(task=‚Äúvqa‚Äù)                   |
| ‡∞™‡∞§‡±ç‡∞∞‡∞Ç ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞∏‡∞Ç‡∞µ‡∞æ‡∞¶‡∞Ç         | ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞™‡∞§‡±ç‡∞∞‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞°‡∞æ‡∞ï‡±ç‡∞Ø‡±Å‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç‚Äå‡∞§‡±ã ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø                               | ‡∞¨‡∞π‡±Å‡∞Æ‡±Ç‡∞≤‡∞ø‡∞ï          | pipeline(task="document-question-answering") |
| ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞µ‡±ç‡∞∞‡∞æ‡∞∏‡∞æ‡∞Ø‡∞ø‡∞Ç‡∞ó‡±ç            | ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞™‡∞ø‡∞ü‡∞ø‡∞Ø‡∞æ‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø                                                         | ‡∞¨‡∞π‡±Å‡∞Æ‡±Ç‡∞≤‡∞ø‡∞ï          | pipeline(task="image-to-text")          |


[`pipeline`] ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞® ‡∞™‡∞®‡∞ø‡∞®‡∞ø ‡∞™‡±á‡∞∞‡±ç‡∞ï‡±ä‡∞®‡∞°‡∞Ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø. ‡∞à ‡∞ó‡±à‡∞°‡±ç‚Äå‡∞≤‡±ã, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞∏‡±Ü‡∞Ç‡∞ü‡∞ø‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞µ‡∞ø‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£ ‡∞ï‡±ã‡∞∏‡∞Ç [`pipeline`]‡∞®‡∞ø ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞ó‡∞æ ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å:

```py
>>> from transformers import pipeline

>>> classifier = pipeline("sentiment-analysis")
```

‡∞∏‡±Ü‡∞Ç‡∞ü‡∞ø‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞µ‡∞ø‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£ ‡∞ï‡±ã‡∞∏‡∞Ç [`pipeline`] ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç [‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±à‡∞®‡±ç‡∞°‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞®‡∞ø ‡∞°‡±å‡∞®‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ï‡∞æ‡∞∑‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞≤‡∞ï‡±ç‡∞∑‡±ç‡∞Ø ‡∞µ‡∞ö‡∞®‡∞Ç‡∞≤‡±ã `classifier`‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å:

```py
>>> classifier("We are very happy to show you the ü§ó Transformers library.")
[{'label': 'POSITIVE', 'score': 0.9998}]
```

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï‡∞ü‡∞ø ‡∞ï‡∞Ç‡∞ü‡±á ‡∞é‡∞ï‡±ç‡∞ï‡±Å‡∞µ ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞Ç‡∞ü‡±á, ‡∞®‡∞ø‡∞ò‡∞Ç‡∞ü‡±Å‡∞µ‡±Å‡∞≤ ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ‡∞®‡±Å ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ‡∞ó‡∞æ [`pipeline`]‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡∞Ç‡∞°‡∞ø:

```py
>>> results = classifier(["We are very happy to show you the ü§ó Transformers library.", "We hope you don't hate it."])
>>> for result in results:
...     print(f"label: {result['label']}, with score: {round(result['score'], 4)}")
label: POSITIVE, with score: 0.9998
label: NEGATIVE, with score: 0.5309
```

[`pipeline`] ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞®‡∞ö‡±ç‡∞ö‡∞ø‡∞® ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞™‡∞®‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞ï‡±Ç‡∞°‡∞æ ‡∞™‡±Å‡∞®‡∞∞‡∞æ‡∞µ‡±É‡∞§‡∞Ç ‡∞ö‡±á‡∞Ø‡∞ó‡∞≤‡∞¶‡±Å. ‡∞à ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£ ‡∞ï‡±ã‡∞∏‡∞Ç, ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ï ‡∞™‡±ç‡∞∞‡∞∏‡∞Ç‡∞ó ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡±Å‡∞®‡±Å ‡∞Æ‡∞® ‡∞™‡∞®‡∞ø‡∞ó‡∞æ ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±Å‡∞Ç‡∞¶‡∞æ‡∞Ç:

```py
>>> import torch
>>> from transformers import pipeline

>>> speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")
```

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞® ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø (‡∞Æ‡∞∞‡∞ø‡∞®‡±ç‡∞®‡∞ø ‡∞µ‡∞ø‡∞µ‡∞∞‡∞æ‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç ü§ó ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞≤‡±Å [‡∞§‡±ç‡∞µ‡∞∞‡∞ø‡∞§ ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞Ç](https://huggingface.co/docs/datasets/quickstart#audio) ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø. ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞ï‡±Å, [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")  # doctest: +IGNORE_RESULT
```

‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ ‡∞∞‡±á‡∞ü‡±Å ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ‡∞§‡±ã ‡∞∏‡∞∞‡∞ø‡∞™‡±ã‡∞≤‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞®‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞®‡∞ø‡∞∞‡±ç‡∞ß‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞ø
‡∞∞‡±á‡∞ü‡±Å [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h) ‡∞¶‡±Ä‡∞®‡∞ø‡∞™‡±à ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞¶‡∞ø:

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))
```

`"‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã"` ‡∞ï‡∞æ‡∞≤‡∞Æ‡±ç‚Äå‡∞ï‡∞ø ‡∞ï‡∞æ‡∞≤‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞´‡±à‡∞≤‡±ç‚Äå‡∞≤‡±Å ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞§‡∞æ‡∞Ø‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞§‡∞æ‡∞Ø‡∞ø.
‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø 4 ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ‡∞≤ ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞Æ‡±Å‡∞°‡∞ø ‡∞µ‡±á‡∞µ‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡±ç ‡∞∂‡±ç‡∞∞‡±á‡∞£‡±Å‡∞≤‡∞®‡±Å ‡∞∏‡∞Ç‡∞ó‡±ç‡∞∞‡∞π‡∞ø‡∞Ç‡∞ö‡∞ø, ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç‚Äå‡∞ï‡±Å ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ‡∞ó‡∞æ ‡∞™‡∞æ‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

```py
>>> result = speech_recognizer(dataset[:4]["audio"])
>>> print([d["text"] for d in result])
['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', "FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE", "I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS", 'HOW DO I FURN A JOINA COUT']
```

‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡±Å ‡∞™‡±Ü‡∞¶‡±ç‡∞¶‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞® ‡∞™‡±Ü‡∞¶‡±ç‡∞¶ ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç (‡∞∏‡±ç‡∞™‡±Ä‡∞ö‡±ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞µ‡∞ø‡∞ú‡∞®‡±ç ‡∞µ‡∞Ç‡∞ü‡∞ø‡∞µ‡∞ø), ‡∞Æ‡±Ü‡∞Æ‡∞∞‡±Ä‡∞≤‡±ã‡∞®‡∞ø ‡∞Ö‡∞®‡±ç‡∞®‡∞ø ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ‡∞ï‡±Å ‡∞¨‡∞¶‡±Å‡∞≤‡±Å‡∞ó‡∞æ ‡∞ú‡±Ü‡∞®‡∞∞‡±á‡∞ü‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞™‡∞æ‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å. ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞ï‡±ã‡∞∏‡∞Ç [‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç API ‡∞∏‡±Ç‡∞ö‡∞®](./main_classes/pipelines)‡∞®‡∞ø ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø.

### ‡∞™‡±à‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç‚Äå‡∞≤‡±ã ‡∞Æ‡∞∞‡±ä‡∞ï ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø

[`pipeline`] [Hub](https://huggingface.co/models) ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø, ‡∞¶‡±Ä‡∞®‡∞ø ‡∞µ‡∞≤‡∞® ‡∞á‡∞§‡∞∞ ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó-‡∞ï‡±á‡∞∏‡±Å‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç [`pipeline`]‡∞®‡∞ø ‡∞∏‡±Å‡∞≤‡∞≠‡∞Ç‡∞ó‡∞æ ‡∞∏‡±ç‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞ï‡±Å, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞´‡±ç‡∞∞‡±Ü‡∞Ç‡∞ö‡±ç ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞π‡±ç‡∞Ø‡∞æ‡∞Ç‡∞°‡∞ø‡∞≤‡±ç ‡∞ö‡±á‡∞Ø‡∞ó‡∞≤ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±á, ‡∞§‡∞ó‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞´‡∞ø‡∞≤‡±ç‡∞ü‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞π‡∞¨‡±ç‚Äå‡∞≤‡±ã‡∞®‡∞ø ‡∞ü‡±ç‡∞Ø‡∞æ‡∞ó‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø. ‡∞Ö‡∞ó‡±ç‡∞∞ ‡∞´‡∞ø‡∞≤‡±ç‡∞ü‡∞∞‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞´‡∞≤‡∞ø‡∞§‡∞Ç ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞´‡±ç‡∞∞‡±Ü‡∞Ç‡∞ö‡±ç ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ó‡∞≤ ‡∞∏‡±Ü‡∞Ç‡∞ü‡∞ø‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞µ‡∞ø‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞´‡±à‡∞®‡±ç‚Äå‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® ‡∞¨‡∞π‡±Å‡∞≠‡∞æ‡∞∑‡∞æ [BERT ‡∞Æ‡±ã‡∞°‡∞≤‡±ç](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø:

```py
>>> model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
```

<frameworkcontent>
<pt>
‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø [`AutoModelForSequenceClassification`] ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å [`AutoTokenizer`]‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø ‡∞Ö‡∞®‡±Å‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç (‡∞§‡∞¶‡±Å‡∞™‡∞∞‡∞ø ‡∞µ‡∞ø‡∞≠‡∞æ‡∞ó‡∞Ç‡∞≤‡±ã `AutoClass`‡∞™‡±à ‡∞Æ‡∞∞‡∞ø‡∞®‡±ç‡∞®‡∞ø):

```py
>>> from transformers import AutoTokenizer, AutoModelForSequenceClassification

>>> model = AutoModelForSequenceClassification.from_pretrained(model_name)
>>> tokenizer = AutoTokenizer.from_pretrained(model_name)
```
</pt>
<tf>
‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø [`TFAutoModelForSequenceClassification`] ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å [`AutoTokenizer`]‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø ‡∞Ö‡∞®‡±Å‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç (‡∞§‡∞¶‡±Å‡∞™‡∞∞‡∞ø ‡∞µ‡∞ø‡∞≠‡∞æ‡∞ó‡∞Ç‡∞≤‡±ã `TFAutoClass`‡∞™‡±à ‡∞Æ‡∞∞‡∞ø‡∞®‡±ç‡∞®‡∞ø):

```py
>>> from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

>>> model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
>>> tokenizer = AutoTokenizer.from_pretrained(model_name)
```
</tf>
</frameworkcontent>

[`pipeline`]‡∞≤‡±ã ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞™‡±á‡∞∞‡±ç‡∞ï‡±ä‡∞®‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞´‡±ç‡∞∞‡±Ü‡∞Ç‡∞ö‡±ç ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞™‡±à `‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡∞ø‡∞´‡±à‡∞Ø‡∞∞‡±ç`‡∞®‡∞ø ‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡∞ú‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å:

```py
>>> classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
>>> classifier("Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers.")
[{'label': '5 stars', 'score': 0.7273}]
```

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó-‡∞ï‡±á‡∞∏‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ï‡∞®‡±Å‡∞ó‡±ä‡∞®‡∞≤‡±á‡∞ï‡∞™‡±ã‡∞§‡±á, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞°‡±á‡∞ü‡∞æ‡∞™‡±à ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ö‡∞ï‡±ç‡∞ï‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞æ‡∞≤‡∞ø. ‡∞é‡∞≤‡∞æ‡∞ó‡±ã ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡∞æ [‡∞´‡±à‡∞®‡±ç‚Äå‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ü‡±ç‡∞Ø‡±Å‡∞ü‡±ã‡∞∞‡∞ø‡∞Ø‡∞≤‡±ç](./training)‡∞®‡∞ø ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø. ‡∞ö‡∞ø‡∞µ‡∞∞‡∞ó‡∞æ, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±à‡∞®‡±ç‡∞°‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡∞ø ‡∞´‡±à‡∞®‡±ç‚Äå‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§, ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞∞‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡±Ü‡∞∑‡∞ø‡∞®‡±ç ‡∞≤‡±Ü‡∞∞‡±ç‡∞®‡∞ø‡∞Ç‡∞ó‡±ç‚Äå‡∞®‡∞ø ‡∞°‡±Ü‡∞Æ‡±ã‡∞ï‡±ç‡∞∞‡∞ü‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞π‡∞¨‡±ç‚Äå‡∞≤‡±ã‡∞®‡∞ø ‡∞∏‡∞Ç‡∞ò‡∞Ç‡∞§‡±ã ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å [‡∞∑‡±á‡∞∞‡∞ø‡∞Ç‡∞ó‡±ç](./model_sharing) ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø! ü§ó

## AutoClass

<Youtube id="AhChOFRegn4"/>

‡∞π‡±Å‡∞°‡±ç ‡∞ï‡∞ø‡∞Ç‡∞¶, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞™‡±à‡∞® ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® [`pipeline`]‡∞ï‡∞ø ‡∞∂‡∞ï‡±ç‡∞§‡∞ø‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø [`AutoModelForSequenceClassification`] ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å [`AutoTokenizer`] ‡∞§‡∞∞‡∞ó‡∞§‡±Å‡∞≤‡±Å ‡∞ï‡∞≤‡∞ø‡∞∏‡∞ø ‡∞™‡∞®‡∞ø ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø. ‡∞í‡∞ï [AutoClass](./model_doc/auto) ‡∞Ö‡∞®‡±á‡∞¶‡∞ø ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞Ü‡∞∞‡±ç‡∞ï‡∞ø‡∞ü‡±Ü‡∞ï‡±ç‡∞ö‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞¶‡∞æ‡∞®‡∞ø ‡∞™‡±á‡∞∞‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞Ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞™‡±ä‡∞Ç‡∞¶‡±á ‡∞∏‡∞§‡±ç‡∞µ‡∞∞‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞Ç. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞§‡∞ó‡∞ø‡∞® `‡∞Ü‡∞ü‡±ã‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç`‡∞®‡∞ø ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞á‡∞¶‡∞ø ‡∞Ö‡∞®‡±Å‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç.

‡∞Æ‡±Å‡∞®‡±Å‡∞™‡∞ü‡∞ø ‡∞µ‡∞ø‡∞≠‡∞æ‡∞ó‡∞Ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞ï‡∞ø ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞ø, [`pipeline`] ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞¨‡∞ø‡∞Ç‡∞¨‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å `‡∞Ü‡∞ü‡±ã‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç`‡∞®‡∞ø ‡∞é‡∞≤‡∞æ ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±ã ‡∞ö‡±Ç‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç.

### AutoTokenizer

‡∞í‡∞ï ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡±Å ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡±Å‡∞ó‡∞æ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø‡∞≤ ‡∞∂‡±ç‡∞∞‡±á‡∞£‡∞ø‡∞≤‡±ã ‡∞µ‡∞ö‡∞®‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç ‡∞¨‡∞æ‡∞ß‡±ç‡∞Ø‡∞§ ‡∞µ‡∞π‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞™‡∞¶‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞é‡∞≤‡∞æ ‡∞µ‡∞ø‡∞≠‡∞ú‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞è ‡∞∏‡±ç‡∞•‡∞æ‡∞Ø‡∞ø‡∞≤‡±ã ‡∞™‡∞¶‡∞æ‡∞≤‡∞®‡±Å ‡∞µ‡∞ø‡∞≠‡∞ú‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø ([tokenizer ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç](./tokenizer_summary)‡∞≤‡±ã ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±á‡∞∑‡∞®‡±ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø) ‡∞∏‡∞π‡∞æ ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±á‡∞∑‡∞®‡±ç ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø‡∞®‡±Å ‡∞®‡∞ø‡∞Ø‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞Ç‡∞ö‡±á ‡∞Ö‡∞®‡±á‡∞ï ‡∞®‡∞ø‡∞Ø‡∞Æ‡∞æ‡∞≤‡±Å ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø. ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡±Å‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞≤‡∞∏‡∞ø‡∞® ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç ‡∞è‡∞Æ‡∞ø‡∞ü‡∞Ç‡∞ü‡±á, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡±Å ‡∞Æ‡±Å‡∞Ç‡∞¶‡±á ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞® ‡∞Ö‡∞¶‡±á ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±á‡∞∑‡∞®‡±ç ‡∞®‡∞ø‡∞Ø‡∞Æ‡∞æ‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞®‡∞ø ‡∞®‡∞ø‡∞∞‡±ç‡∞ß‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Ö‡∞¶‡±á ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞™‡±á‡∞∞‡±Å‡∞§‡±ã ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞§‡∞ï‡±ç‡∞∑‡∞£‡∞Ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø.

[`AutoTokenizer`]‡∞§‡±ã ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

```py
>>> from transformers import AutoTokenizer

>>> model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
>>> tokenizer = AutoTokenizer.from_pretrained(model_name)
```

‡∞Æ‡±Ä ‡∞µ‡∞ö‡∞®‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞ï‡±Å ‡∞™‡∞Ç‡∞™‡∞Ç‡∞°‡∞ø:

```py
>>> encoding = tokenizer("We are very happy to show you the ü§ó Transformers library.")
>>> print(encoding)
{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102],
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç ‡∞µ‡±Ä‡∞ü‡∞ø‡∞®‡∞ø ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞®‡±ç‡∞® ‡∞®‡∞ø‡∞ò‡∞Ç‡∞ü‡±Å‡∞µ‡±Å‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø:

* [input_ids](./glossary#input-ids): ‡∞Æ‡±Ä ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±ç‚Äå‡∞≤ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø‡∞æ‡∞™‡∞∞‡∞Æ‡±à‡∞® ‡∞™‡±ç‡∞∞‡∞æ‡∞§‡∞ø‡∞®‡∞ø‡∞ß‡±ç‡∞Ø‡∞Ç.
* [‡∞Ö‡∞ü‡±Ü‡∞®‡±ç‡∞∑‡∞®‡±ç_‡∞Æ‡∞æ‡∞∏‡±ç‡∞ï‡±ç](./glossary#attention-mask): ‡∞è ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±ç‚Äå‡∞≤‡∞ï‡±Å ‡∞π‡∞æ‡∞ú‡∞∞‡±Å ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡±ã ‡∞∏‡±Ç‡∞ö‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.

‡∞í‡∞ï ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤ ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ‡∞®‡±Å ‡∞ï‡±Ç‡∞°‡∞æ ‡∞Ü‡∞Æ‡±ã‡∞¶‡∞ø‡∞Ç‡∞ö‡∞ó‡∞≤‡∞¶‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞è‡∞ï‡∞∞‡±Ä‡∞§‡∞ø ‡∞™‡±ä‡∞°‡∞µ‡±Å‡∞§‡±ã ‡∞¨‡±ç‡∞Ø‡∞æ‡∞ö‡±ç‚Äå‡∞®‡±Å ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞á‡∞µ‡±ç‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ç‡∞Ø‡∞æ‡∞°‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞ï‡∞§‡±ç‡∞§‡∞ø‡∞∞‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å:

<frameworkcontent>
<pt>

```py
>>> pt_batch = tokenizer(
...     ["We are very happy to show you the ü§ó Transformers library.", "We hope you don't hate it."],
...     padding=True,
...     truncation=True,
...     max_length=512,
...     return_tensors="pt",
... )
```
</pt>
<tf>

```py
>>> tf_batch = tokenizer(
...     ["We are very happy to show you the ü§ó Transformers library.", "We hope you don't hate it."],
...     padding=True,
...     truncation=True,
...     max_length=512,
...     return_tensors="tf",
... )
```
</tf>
</frameworkcontent>

<Tip>

‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±á‡∞∑‡∞®‡±ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞®‡±ç‡∞®‡∞ø ‡∞µ‡∞ø‡∞µ‡∞∞‡∞æ‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç [‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç](./preprocessing) ‡∞ü‡±ç‡∞Ø‡±Å‡∞ü‡±ã‡∞∞‡∞ø‡∞Ø‡∞≤‡±ç‚Äå‡∞®‡∞ø ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞á‡∞Æ‡±á‡∞ú‡±ç, ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Æ‡∞≤‡±ç‡∞ü‡±Ä‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø [`AutoImageProcessor`], [`AutoFeatureExtractor`] ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å [`AutoProcessor`] ‡∞é‡∞≤‡∞æ ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø.

</Tip>

### AutoModel

<frameworkcontent>
<pt>
ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞≤‡±Å ‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±à‡∞®‡±ç‡∞°‡±ç ‡∞á‡∞®‡±ç‚Äå‡∞∏‡±ç‡∞ü‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡±Å‡∞≤‡∞≠‡∞Æ‡±à‡∞® ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞è‡∞ï‡±Ä‡∞ï‡±É‡∞§ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø. ‡∞¶‡±Ä‡∞®‡∞ø ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç ‡∞Æ‡±Ä‡∞∞‡±Å [`AutoTokenizer`]‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å‡∞ó‡∞æ [`AutoModel`]‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞∏‡∞∞‡±à‡∞® [`AutoModel`]‡∞®‡∞ø ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞§‡±á‡∞°‡∞æ. ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç (‡∞≤‡±á‡∞¶‡∞æ ‡∞∏‡±Ä‡∞ï‡±ç‡∞µ‡±Ü‡∞®‡±ç‡∞∏‡±ç) ‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞£ ‡∞ï‡±ã‡∞∏‡∞Ç, ‡∞Æ‡±Ä‡∞∞‡±Å [`AutoModelForSequenceClassification`]‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø:


```py
>>> from transformers import AutoModelForSequenceClassification

>>> model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
>>> pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)
```

<Tip>

[`AutoModel`] ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞∏‡∞™‡±ã‡∞∞‡±ç‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±á ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç‚Äå‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç [‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç](./task_summary)‡∞®‡∞ø ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø.

</Tip>

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® ‡∞¨‡±ç‡∞Ø‡∞æ‡∞ö‡±ç ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞®‡±á‡∞∞‡±Å‡∞ó‡∞æ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡∞Ç‡∞°‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å `**`‡∞®‡∞ø ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞®‡∞ø‡∞ò‡∞Ç‡∞ü‡±Å‡∞µ‡±Å‡∞®‡∞ø ‡∞Ö‡∞®‡±ç‚Äå‡∞™‡±ç‡∞Ø‡∞æ‡∞ï‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø:

```py
>>> pt_outputs = pt_model(**pt_batch)
```

‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞§‡±Å‡∞¶‡∞ø ‡∞Ø‡∞æ‡∞ï‡±ç‡∞ü‡∞ø‡∞µ‡±á‡∞∑‡∞®‡±ç‚Äå‡∞≤‡∞®‡±Å `logits` ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞Ç‡∞≤‡±ã ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞µ‡±ç‡∞Ø‡∞§‡∞≤‡∞®‡±Å ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞™‡±ä‡∞Ç‡∞¶‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞æ‡∞´‡±ç‡∞ü‡±ç‚Äå‡∞Æ‡∞æ‡∞ï‡±ç‡∞∏‡±ç ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å `logits` ‡∞ï‡±Å ‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡∞ú‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:


```py
>>> from torch import nn

>>> pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
>>> print(pt_predictions)
tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],
        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)
```

</pt>
<tf>
ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞≤‡±Å ‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±à‡∞®‡±ç‡∞°‡±ç ‡∞á‡∞®‡±ç‚Äå‡∞∏‡±ç‡∞ü‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡±Å‡∞≤‡∞≠‡∞Æ‡±à‡∞® ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞è‡∞ï‡±Ä‡∞ï‡±É‡∞§ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å [`AutoTokenizer`]‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å‡∞ó‡∞æ ‡∞Æ‡±Ä‡∞∞‡±Å [`TFAutoModel`]‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡∞®‡∞ø ‡∞¶‡±Ä‡∞®‡∞ø ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç. ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞∏‡∞∞‡±à‡∞® [`TFAutoModel`]‡∞®‡∞ø ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞§‡±á‡∞°‡∞æ. ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç (‡∞≤‡±á‡∞¶‡∞æ ‡∞∏‡±Ä‡∞ï‡±ç‡∞µ‡±Ü‡∞®‡±ç‡∞∏‡±ç) ‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞£ ‡∞ï‡±ã‡∞∏‡∞Ç, ‡∞Æ‡±Ä‡∞∞‡±Å [`TFAutoModelForSequenceClassification`]‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø:

```py
>>> from transformers import TFAutoModelForSequenceClassification

>>> model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
```

<Tip>

[`AutoModel`] ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞∏‡∞™‡±ã‡∞∞‡±ç‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±á ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç‚Äå‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç [‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç](./task_summary)‡∞®‡∞ø ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø.

</Tip>

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® ‡∞¨‡±ç‡∞Ø‡∞æ‡∞ö‡±ç ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞®‡±á‡∞∞‡±Å‡∞ó‡∞æ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡∞Ç‡∞°‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ü‡±Ü‡∞®‡±ç‡∞∏‡∞∞‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞á‡∞≤‡∞æ ‡∞™‡∞æ‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å:

```py
>>> tf_outputs = tf_model(tf_batch)
```

‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞§‡±Å‡∞¶‡∞ø ‡∞Ø‡∞æ‡∞ï‡±ç‡∞ü‡∞ø‡∞µ‡±á‡∞∑‡∞®‡±ç‚Äå‡∞≤‡∞®‡±Å `logits` ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞Ç‡∞≤‡±ã ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞µ‡±ç‡∞Ø‡∞§‡∞≤‡∞®‡±Å ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞™‡±ä‡∞Ç‡∞¶‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞æ‡∞´‡±ç‡∞ü‡±ç‚Äå‡∞Æ‡∞æ‡∞ï‡±ç‡∞∏‡±ç ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å `logits`‡∞ï‡±Å ‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡∞ú‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

```py
>>> import tensorflow as tf

>>> tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
>>> tf_predictions  # doctest: +IGNORE_RESULT
```
</tf>
</frameworkcontent>

<Tip>

‡∞Ö‡∞®‡±ç‡∞®‡∞ø ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞∏‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞≤‡±Å (PyTorch ‡∞≤‡±á‡∞¶‡∞æ TensorFlow) ‡∞§‡±Å‡∞¶‡∞ø ‡∞Ø‡∞æ‡∞ï‡±ç‡∞ü‡∞ø‡∞µ‡±á‡∞∑‡∞®‡±ç‚Äå‡∞ï‡±Å *‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å* ‡∞ü‡±Ü‡∞®‡±ç‡∞∏‡∞∞‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø
‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç (softmax ‡∞µ‡∞Ç‡∞ü‡∞ø‡∞¶‡∞ø) ‡∞é‡∞Ç‡∞¶‡±Å‡∞ï‡∞Ç‡∞ü‡±á ‡∞ö‡∞ø‡∞µ‡∞∞‡∞ø ‡∞Ø‡∞æ‡∞ï‡±ç‡∞ü‡∞ø‡∞µ‡±á‡∞∑‡∞®‡±ç ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞§‡∞∞‡∞ö‡±Å‡∞ó‡∞æ ‡∞®‡∞∑‡±ç‡∞ü‡∞Ç‡∞§‡±ã ‡∞ï‡∞≤‡∞ø‡∞∏‡∞ø‡∞™‡±ã‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡±Å ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï ‡∞°‡±á‡∞ü‡∞æ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç‚Äå‡∞≤‡±Å ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞µ‡∞æ‡∞ü‡∞ø ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡±Å IDE‡∞≤‡±ã ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞§‡∞æ‡∞Ø‡∞ø. ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞≤‡±Å ‡∞ü‡±Å‡∞™‡±Å‡∞≤‡±ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞°‡∞ø‡∞ï‡±ç‡∞∑‡∞®‡∞∞‡±Ä ‡∞≤‡∞æ‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø (‡∞Æ‡±Ä‡∞∞‡±Å ‡∞™‡±Ç‡∞∞‡±ç‡∞£‡∞æ‡∞Ç‡∞ï‡∞Ç, ‡∞∏‡±ç‡∞≤‡±à‡∞∏‡±ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞∏‡±ç‡∞ü‡±ç‡∞∞‡∞ø‡∞Ç‡∞ó‡±ç‚Äå‡∞§‡±ã ‡∞á‡∞Ç‡∞°‡±Ü‡∞ï‡±ç‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å) ‡∞à ‡∞∏‡∞Ç‡∞¶‡∞∞‡±ç‡∞≠‡∞Ç‡∞≤‡±ã, ‡∞è‡∞¶‡±Ä ‡∞≤‡±á‡∞®‡∞ø ‡∞ó‡±Å‡∞£‡∞æ‡∞≤‡±Å ‡∞µ‡∞ø‡∞∏‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞§‡∞æ‡∞Ø‡∞ø.

</Tip>

### ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±á‡∞µ‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø

<frameworkcontent>
<pt>
‡∞Æ‡±Ä ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞ö‡∞ï‡±ç‡∞ï‡∞ó‡∞æ ‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø [`PreTrainedModel.save_pretrained`]‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞¶‡∞æ‡∞®‡∞ø ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞§‡±ã ‡∞∏‡±á‡∞µ‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å:

```py
>>> pt_save_directory = "./pt_save_pretrained"
>>> tokenizer.save_pretrained(pt_save_directory)  # doctest: +IGNORE_RESULT
>>> pt_model.save_pretrained(pt_save_directory)
```

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å, ‡∞¶‡∞æ‡∞®‡±ç‡∞®‡∞ø [`PreTrainedModel.from_pretrained`]‡∞§‡±ã ‡∞∞‡±Ä‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

```py
>>> pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")
```
</pt>
<tf>
‡∞Æ‡±Ä ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞ö‡∞ï‡±ç‡∞ï‡∞ó‡∞æ ‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø [`TFPreTrainedModel.save_pretrained`]‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞¶‡∞æ‡∞®‡∞ø ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞§‡±ã ‡∞∏‡±á‡∞µ‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å:

```py
>>> tf_save_directory = "./tf_save_pretrained"
>>> tokenizer.save_pretrained(tf_save_directory)  # doctest: +IGNORE_RESULT
>>> tf_model.save_pretrained(tf_save_directory)
```
‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å, ‡∞¶‡∞æ‡∞®‡±ç‡∞®‡∞ø [`TFPreTrainedModel.from_pretrained`]‡∞§‡±ã ‡∞∞‡±Ä‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

```py
>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")
```
</tf>
</frameworkcontent>

‡∞í‡∞ï ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ö‡∞¶‡±ç‡∞≠‡±Å‡∞§‡∞Æ‡±à‡∞® ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞∏‡±ç ‡∞´‡±Ä‡∞ö‡∞∞‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±á‡∞µ‡±ç ‡∞ö‡±á‡∞Ø‡∞ó‡∞≤ ‡∞∏‡∞æ‡∞Æ‡∞∞‡±ç‡∞•‡±ç‡∞Ø‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø PyTorch ‡∞≤‡±á‡∞¶‡∞æ TensorFlow ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ó‡∞æ ‡∞∞‡±Ä‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞ó‡∞≤‡∞¶‡±Å. `from_pt` ‡∞≤‡±á‡∞¶‡∞æ `from_tf` ‡∞™‡∞∞‡∞æ‡∞Æ‡∞ø‡∞§‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞í‡∞ï ‡∞´‡±ç‡∞∞‡±á‡∞Æ‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡±ä‡∞ï ‡∞´‡±ç‡∞∞‡±á‡∞Æ‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç‚Äå‡∞ï‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞ó‡∞≤‡∞¶‡±Å:

<frameworkcontent>
<pt>

```py
>>> from transformers import AutoModel

>>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
>>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)
```
</pt>
<tf>

```py
>>> from transformers import TFAutoModel

>>> tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)
```
</tf>
</frameworkcontent>

## ‡∞ï‡∞∏‡±ç‡∞ü‡∞Æ‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞¨‡∞ø‡∞≤‡±ç‡∞°‡±ç‡∞∏‡±ç
‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞é‡∞≤‡∞æ ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡±ã ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç‚Äå‡∞®‡∞ø ‡∞∏‡∞µ‡∞∞‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞¶‡∞æ‡∞ö‡∞ø‡∞® ‡∞≤‡±á‡∞Ø‡∞∞‡±ç‚Äå‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞Ö‡∞ü‡±Ü‡∞®‡±ç‡∞∑‡∞®‡±ç ‡∞π‡±Ü‡∞°‡±ç‚Äå‡∞≤ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡∞®‡±Å ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞¶‡±á‡∞∂‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ï‡∞∏‡±ç‡∞ü‡∞Æ‡±ç ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å. ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞Ö‡∞ü‡±ç‡∞∞‡∞ø‡∞¨‡±ç‡∞Ø‡±Ç‡∞ü‡±ç‚Äå‡∞≤‡±Å ‡∞Ø‡∞æ‡∞¶‡±É‡∞ö‡±ç‡∞õ‡∞ø‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡±ç‡∞°‡∞æ‡∞Ø‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ö‡∞∞‡±ç‡∞•‡∞µ‡∞Ç‡∞§‡∞Æ‡±à‡∞® ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤‡∞®‡±Å ‡∞™‡±ä‡∞Ç‡∞¶‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡±á ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞á‡∞µ‡±ç‡∞µ‡∞æ‡∞≤‡∞ø.

[`AutoConfig`]‡∞®‡∞ø ‡∞¶‡∞ø‡∞ó‡±Å‡∞Æ‡∞§‡∞ø ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞Ü‡∞™‡±à ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞∏‡∞µ‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞® ‡∞™‡±ç‡∞∞‡±Ä‡∞ü‡±ç‡∞∞‡±à‡∞®‡±ç‡∞°‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø. [`AutoConfig.from_pretrained`]‡∞≤‡±ã, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Ö‡∞ü‡±Ü‡∞®‡±ç‡∞∑‡∞®‡±ç ‡∞π‡±Ü‡∞°‡±ç‚Äå‡∞≤ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞® ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞™‡±á‡∞∞‡±ç‡∞ï‡±ä‡∞®‡∞µ‡∞ö‡±ç‡∞ö‡±Å:

```py
>>> from transformers import AutoConfig

>>> my_config = AutoConfig.from_pretrained("distilbert/distilbert-base-uncased", n_heads=12)
```

<frameworkcontent>
<pt>
[`AutoModel.from_config`]‡∞§‡±ã ‡∞Æ‡±Ä ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤ ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:

```py
>>> from transformers import AutoModel

>>> my_model = AutoModel.from_config(my_config)
```
</pt>
<tf>
[`TFAutoModel.from_config`]‡∞§‡±ã ‡∞Æ‡±Ä ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤ ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:

```py
>>> from transformers import TFAutoModel

>>> my_model = TFAutoModel.from_config(my_config)
```
</tf>
</frameworkcontent>

‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤ ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞ï‡±ã‡∞∏‡∞Ç [‡∞ï‡∞∏‡±ç‡∞ü‡∞Æ‡±ç ‡∞Ü‡∞∞‡±ç‡∞ï‡∞ø‡∞ü‡±Ü‡∞ï‡±ç‡∞ö‡∞∞‡±ç‚Äå‡∞®‡∞ø ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø](./create_a_model) ‡∞ó‡±à‡∞°‡±ç‚Äå‡∞®‡±Å ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø.

## ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞ï‡±Å‡∞°‡±Å - ‡∞™‡±à‡∞ü‡∞æ‡∞∞‡±ç‡∞ö‡±ç ‡∞Ü‡∞™‡±ç‡∞ü‡∞ø‡∞Æ‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç

‡∞Ö‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞≤‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞Æ‡∞æ‡∞£‡∞ø‡∞ï‡∞Æ‡±à‡∞® [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç‚Äå‡∞≤‡±ã ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞∏‡±ç‡∞µ‡∞Ç‡∞§ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç‚Äå‡∞®‡±Å ‡∞µ‡±ç‡∞∞‡∞æ‡∞Ø‡∞ó‡∞≤‡∞ø‡∞ó‡∞ø‡∞®‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±Ä, ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞≤‡±Å PyTorch ‡∞ï‡±ã‡∞∏‡∞Ç [`‡∞ü‡±ç‡∞∞‡±à‡∞®‡∞∞‡±ç`] ‡∞§‡∞∞‡∞ó‡∞§‡∞ø‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ú‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø, ‡∞á‡∞Ç‡∞¶‡±Å‡∞≤‡±ã ‡∞™‡±ç‡∞∞‡∞æ‡∞•‡∞Æ‡∞ø‡∞ï ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡∞Ç‡∞™‡∞ø‡∞£‡±Ä ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞® ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£, ‡∞Æ‡∞ø‡∞∂‡±ç‡∞∞‡∞Æ ‡∞ñ‡∞ö‡±ç‡∞ö‡∞ø‡∞§‡∞§‡±ç‡∞µ‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Æ‡∞∞‡∞ø‡∞®‡±ç‡∞®‡∞ø ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞´‡±Ä‡∞ö‡∞∞‡±ç‚Äå‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Ö‡∞¶‡∞®‡∞™‡±Å ‡∞ï‡∞æ‡∞∞‡±ç‡∞Ø‡∞æ‡∞ö‡∞∞‡∞£‡∞®‡±Å ‡∞ú‡±ã‡∞°‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.

‡∞Æ‡±Ä ‡∞µ‡∞ø‡∞ß‡∞ø‡∞®‡∞ø ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£‡∞Ç‡∞ó‡∞æ ‡∞ï‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞™‡∞æ‡∞∞‡∞æ‡∞Æ‡∞ø‡∞§‡±Å‡∞≤‡∞®‡±Å [`‡∞ü‡±ç‡∞∞‡±à‡∞®‡∞∞‡±ç`]‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡±Å‡∞§‡∞æ‡∞∞‡±Å:

1. ‡∞Æ‡±Ä‡∞∞‡±Å [`PreTrainedModel`] ‡∞≤‡±á‡∞¶‡∞æ [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)‡∞§‡±ã ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å:
   ```py
   >>> from transformers import AutoModelForSequenceClassification

   >>> model = AutoModelForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased")
   ```

2. [`TrainingArguments`] ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞®‡±á‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±á ‡∞∞‡±á‡∞ü‡±Å, ‡∞¨‡±ç‡∞Ø‡∞æ‡∞ö‡±ç ‡∞™‡∞∞‡∞ø‡∞Æ‡∞æ‡∞£‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞µ‡∞≤‡∞∏‡∞ø‡∞® ‡∞Ø‡±Å‡∞ó‡∞æ‡∞≤ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞ó‡∞≤ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç ‡∞π‡±à‡∞™‡∞∞‡±ç‚Äå‡∞™‡∞æ‡∞∞‡∞æ‡∞Æ‡±Ä‡∞ü‡∞∞‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞≤‡∞æ‡∞Ç‡∞ü‡∞ø ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£‡∞æ ‡∞µ‡∞æ‡∞¶‡∞®‡∞≤‡∞®‡±Å ‡∞™‡±á‡∞∞‡±ç‡∞ï‡±ä‡∞®‡∞ï‡±Å‡∞Ç‡∞ü‡±á ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç ‡∞µ‡∞ø‡∞≤‡±Å‡∞µ‡∞≤‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞§‡∞æ‡∞Ø‡∞ø:

   ```py
   >>> from transformers import TrainingArguments

   >>> training_args = TrainingArguments(
   ...     output_dir="path/to/save/folder/",
   ...     learning_rate=2e-5,
   ...     per_device_train_batch_size=8,
   ...     per_device_eval_batch_size=8,
   ...     num_train_epochs=2,
   ... )
   ```

3. ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç, ‡∞á‡∞Æ‡±á‡∞ú‡±ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞∞‡±ç, ‡∞´‡±Ä‡∞ö‡∞∞‡±ç ‡∞é‡∞ï‡±ç‡∞∏‡±ç‚Äå‡∞ü‡±ç‡∞∞‡∞æ‡∞ï‡±ç‡∞ü‡∞∞‡±ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞∞‡±ç ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç‚Äå‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:
   ```py
   >>> from transformers import AutoTokenizer

   >>> tokenizer = AutoTokenizer.from_pretrained("distilbert/distilbert-base-uncased")
   ```

4. ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

   ```py
   >>> from datasets import load_dataset

   >>> dataset = load_dataset("rotten_tomatoes")  # doctest: +IGNORE_RESULT
   ```

5. ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞í‡∞ï ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:

   ```py
   >>> def tokenize_dataset(dataset):
   ...     return tokenizer(dataset["text"])
   ```

   ‡∞Ü‡∞™‡±à ‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø [`~datasets.Dataset.map`]‡∞§‡±ã ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞≤‡±ã ‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡∞ú‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

   ```py
   >>> dataset = dataset.map(tokenize_dataset, batched=True)
   ```

6. ‡∞Æ‡±Ä ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£‡∞≤ ‡∞∏‡∞Æ‡±Ç‡∞π‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø [`DataCollatorWithPadding`]:

   ```py
   >>> from transformers import DataCollatorWithPadding

   >>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
   ```

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞à ‡∞§‡∞∞‡∞ó‡∞§‡±Å‡∞≤‡∞®‡±ç‡∞®‡∞ø‡∞Ç‡∞ü‡∞ø‡∞®‡±Ä [`Trainer`]‡∞≤‡±ã ‡∞∏‡±á‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:

```py
>>> from transformers import Trainer

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=dataset["train"],
...     eval_dataset=dataset["test"],
...     processing_class=tokenizer,
...     data_collator=data_collator,
... )  # doctest: +SKIP
```

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å, ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø [`~Trainer.train`]‡∞ï‡∞ø ‡∞ï‡∞æ‡∞≤‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

```py
>>> trainer.train()  # doctest: +SKIP
```

<Tip>

‡∞∏‡±Ä‡∞ï‡±ç‡∞µ‡±Ü‡∞®‡±ç‡∞∏‡±ç-‡∞ü‡±Å-‡∞∏‡±Ä‡∞ï‡±ç‡∞µ‡±Ü‡∞®‡±ç‡∞∏‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡±á - ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞™‡∞®‡±Å‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç, ‡∞¨‡∞¶‡±Å‡∞≤‡±Å‡∞ó‡∞æ [`Seq2SeqTrainer`] ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å [`Seq2SeqTrainingArguments`] ‡∞§‡∞∞‡∞ó‡∞§‡±Å‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.

</Tip>

‡∞Æ‡±Ä‡∞∞‡±Å [`Trainer`] ‡∞≤‡±ã‡∞™‡∞≤ ‡∞â‡∞®‡±ç‡∞® ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡±Å‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç ‡∞™‡±ç‡∞∞‡∞µ‡∞∞‡±ç‡∞§‡∞®‡∞®‡±Å ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞á‡∞¶‡∞ø ‡∞≤‡∞æ‡∞∏‡±ç ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç, ‡∞Ü‡∞™‡±ç‡∞ü‡∞ø‡∞Æ‡±à‡∞ú‡∞∞‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∑‡±Ü‡∞°‡±ç‡∞Ø‡±Ç‡∞≤‡∞∞‡±ç ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡∞®‡±Å ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡∞ø‡∞Æ‡±ç‡∞Æ‡∞≤‡±ç‡∞®‡∞ø ‡∞Ö‡∞®‡±Å‡∞Æ‡∞§‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞â‡∞™‡∞µ‡∞∞‡±ç‡∞ó‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡±á ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡±Å‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç [`Trainer`] ‡∞∏‡±Ç‡∞ö‡∞®‡∞®‡±Å ‡∞™‡∞∞‡∞ø‡∞∂‡±Ä‡∞≤‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.

‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç‚Äå‡∞®‡±Å ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡∞∞‡±ä‡∞ï ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞Ç [‡∞ï‡∞æ‡∞≤‡±ç‚Äå‡∞¨‡±ç‡∞Ø‡∞æ‡∞ï‡±ç‚Äå‡∞≤‡±Å](./main_classes/callback). ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞á‡∞§‡∞∞ ‡∞≤‡±à‡∞¨‡±ç‡∞∞‡∞∞‡±Ä‡∞≤‡∞§‡±ã ‡∞Ö‡∞®‡±Å‡∞∏‡∞Ç‡∞ß‡∞æ‡∞®‡∞Ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ï‡∞æ‡∞≤‡±ç‚Äå‡∞¨‡±ç‡∞Ø‡∞æ‡∞ï‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±Å‡∞∞‡±ã‡∞ó‡∞§‡∞ø‡∞™‡±à ‡∞®‡∞ø‡∞µ‡±á‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç‚Äå‡∞®‡±Å ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£‡∞®‡±Å ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ‡∞®‡±á ‡∞Ü‡∞™‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞≤‡±Ç‡∞™‡±ç‚Äå‡∞≤‡±ã‡∞®‡±á ‡∞ï‡∞æ‡∞≤‡±ç‚Äå‡∞¨‡±ç‡∞Ø‡∞æ‡∞ï‡±ç‚Äå‡∞≤‡±Å ‡∞¶‡±á‡∞®‡∞ø‡∞®‡±Ä ‡∞∏‡∞µ‡∞∞‡∞ø‡∞Ç‡∞ö‡∞µ‡±Å. ‡∞≤‡∞æ‡∞∏‡±ç ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞µ‡∞Ç‡∞ü‡∞ø‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞¨‡∞¶‡±Å‡∞≤‡±Å‡∞ó‡∞æ [`Trainer`]‡∞®‡∞ø ‡∞â‡∞™‡∞µ‡∞∞‡±ç‡∞ó‡∞Ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø.

## TensorFlow‡∞§‡±ã ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø

‡∞Ö‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞≤‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞Æ‡∞æ‡∞£‡∞ø‡∞ï‡∞Æ‡±à‡∞® [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø [Keras]‡∞§‡±ã TensorFlow‡∞≤‡±ã ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞™‡±ä‡∞Ç‡∞¶‡∞µ‡∞ö‡±ç‡∞ö‡±Å(https: //keras.io/) API. ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‚Äå‡∞≤‡±Å ‡∞Æ‡±Ä ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡∞ø ‡∞∏‡±Å‡∞≤‡∞≠‡∞Ç‡∞ó‡∞æ `tf.data.Dataset`‡∞ó‡∞æ ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø [`~TFPreTrainedModel.prepare_tf_dataset`] ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡∞ø‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ú‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞µ‡±Ü‡∞Ç‡∞ü‡∞®‡±á Keras' [`compile`](https://keras.io/api/models/model_training_apis/#compile-method) ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å [`fit`](https://keras.io/api/models/model_training_apis/#fit-method) ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡±Å‡∞≤‡±Å.

1. ‡∞Æ‡±Ä‡∞∞‡±Å [`TFPreTrainedModel`] ‡∞≤‡±á‡∞¶‡∞æ [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)‡∞§‡±ã ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å:
   ```py
   >>> from transformers import TFAutoModelForSequenceClassification

   >>> model = TFAutoModelForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased")
   ```

2. ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç, ‡∞á‡∞Æ‡±á‡∞ú‡±ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞∞‡±ç, ‡∞´‡±Ä‡∞ö‡∞∞‡±ç ‡∞é‡∞ï‡±ç‡∞∏‡±ç‚Äå‡∞ü‡±ç‡∞∞‡∞æ‡∞ï‡±ç‡∞ü‡∞∞‡±ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞∞‡±ç ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞™‡±ç‡∞∞‡±Ä‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç‚Äå‡∞®‡∞ø ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:

   ```py
   >>> from transformers import AutoTokenizer

   >>> tokenizer = AutoTokenizer.from_pretrained("distilbert/distilbert-base-uncased")
   ```

3. ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞ü‡±ã‡∞ï‡∞®‡±à‡∞ú‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞í‡∞ï ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:

   ```py
   >>> def tokenize_dataset(dataset):
   ...     return tokenizer(dataset["text"])  # doctest: +SKIP
   ```

4. [`~datasets.Dataset.map`]‡∞§‡±ã ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞™‡±à ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞®‡∞ø ‡∞µ‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡∞ú‡±á‡∞Ø‡∞ø, ‡∞Ü‡∞™‡±à ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±à‡∞ú‡∞∞‡±ç‚Äå‡∞®‡±Å [`~TFPreTrainedModel.prepare_tf_dataset`]‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡∞Ç‡∞°‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±á ‡∞¨‡±ç‡∞Ø‡∞æ‡∞ö‡±ç ‡∞™‡∞∞‡∞ø‡∞Æ‡∞æ‡∞£‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ï‡±Ç‡∞°‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞µ‡∞ö‡±ç‡∞ö‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞°‡±á‡∞ü‡∞æ‡∞∏‡±Ü‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞∑‡∞´‡±Å‡∞≤‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å:
   ```py
   >>> dataset = dataset.map(tokenize_dataset)  # doctest: +SKIP
   >>> tf_dataset = model.prepare_tf_dataset(
   ...     dataset["train"], batch_size=16, shuffle=True, tokenizer=tokenizer
   ... )  # doctest: +SKIP
   ```

5. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å, ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å `‡∞ï‡∞Ç‡∞™‡±à‡∞≤‡±ç` ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å `‡∞´‡∞ø‡∞ü‡±ç`‡∞ï‡∞ø ‡∞ï‡∞æ‡∞≤‡±ç ‡∞ö‡±á‡∞Ø‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞∏‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‡∞∏‡±ç ‡∞Ö‡∞®‡±ç‡∞®‡±Ä ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç-‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞≤‡∞æ‡∞∏‡±ç ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç‚Äå‡∞®‡∞ø ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞®‡∞ø ‡∞ó‡±Å‡∞∞‡±ç‡∞§‡±Å‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø, ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ï‡±ã‡∞∞‡±Å‡∞ï‡±Å‡∞®‡±á ‡∞µ‡∞∞‡∞ï‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø ‡∞™‡±á‡∞∞‡±ç‡∞ï‡±ä‡∞®‡∞µ‡∞≤‡∞∏‡∞ø‡∞® ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞≤‡±á‡∞¶‡±Å:

   ```py
   >>> from tensorflow.keras.optimizers import Adam

   >>> model.compile(optimizer=Adam(3e-5))  # No loss argument!
   >>> model.fit(tf_dataset)  # doctest: +SKIP
   ```

## ‡∞§‡∞∞‡∞µ‡∞æ‡∞§ ‡∞è‡∞Ç‡∞ü‡∞ø?

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞∏‡±ç ‡∞§‡±ç‡∞µ‡∞∞‡∞ø‡∞§ ‡∞™‡∞∞‡±ç‡∞Ø‡∞ü‡∞®‡∞®‡±Å ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø ‡∞ö‡±á‡∞∏‡∞æ‡∞∞‡±Å, ‡∞Æ‡∞æ ‡∞ó‡±à‡∞°‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞µ‡±ç‡∞∞‡∞æ‡∞Ø‡∞°‡∞Ç, ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ö‡∞ï‡±ç‡∞ï‡∞ó‡∞æ ‡∞§‡±Ä‡∞∞‡±ç‡∞ö‡∞ø‡∞¶‡∞ø‡∞¶‡±ç‡∞¶‡∞°‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡±ç‡∞ï‡±ç‡∞∞‡∞ø‡∞™‡±ç‡∞ü‡±ç‚Äå‡∞§‡±ã ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡±Å ‡∞∂‡∞ø‡∞ï‡±ç‡∞∑‡∞£ ‡∞á‡∞µ‡±ç‡∞µ‡∞°‡∞Ç ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞®‡∞ø‡∞∞‡±ç‡∞¶‡∞ø‡∞∑‡±ç‡∞ü‡∞Æ‡±à‡∞® ‡∞™‡∞®‡±Å‡∞≤‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡±ã ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø. ü§ó ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞∞‡±ç‡∞∏‡±ç ‡∞ï‡±ã‡∞∞‡±ç ‡∞ï‡∞æ‡∞®‡±ç‡∞∏‡±Ü‡∞™‡±ç‡∞ü‡±ç‚Äå‡∞≤ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§ ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞Ü‡∞∏‡∞ï‡±ç‡∞§‡∞ø ‡∞â‡∞Ç‡∞ü‡±á, ‡∞í‡∞ï ‡∞ï‡∞™‡±ç‡∞™‡±Å ‡∞ï‡∞æ‡∞´‡±Ä ‡∞§‡∞æ‡∞ó‡∞ø, ‡∞Æ‡∞æ ‡∞ï‡∞æ‡∞®‡±ç‡∞∏‡±Ü‡∞™‡±ç‡∞ü‡±Å‡∞µ‡∞≤‡±ç ‡∞ó‡±à‡∞°‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞ö‡±Ç‡∞°‡∞Ç‡∞°‡∞ø!
