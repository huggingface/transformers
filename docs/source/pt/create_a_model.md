<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Criar uma arquitetura customizada

Uma [`AutoClass`](model_doc/auto) automaticamente infere a arquitetura do modelo e baixa configuraÃ§Ãµes e pesos prÃ©-treinados. Geralmente, nÃ³s recomendamos usar uma `AutoClass` para produzir um cÃ³digo independente de checkpoints. Mas usuÃ¡rios que querem mais contole sobre parÃ¢metros especÃ­ficos do modelo pode criar um modelo customizado ğŸ¤— Transformers a partir de algumas classes bases. Isso pode ser particulamente Ãºtil para alguÃ©m que estÃ¡ interessado em estudar, treinar ou fazer experimentos com um modelo ğŸ¤— Transformers. Nesse tutorial, serÃ¡ explicado como criar um modelo customizado sem uma `AutoClass`. Aprenda como:

- Carregar e customizar a configuraÃ§Ã£o de um modelo.
- Criar a arquitetura de um modelo.
- Criar um tokenizer rÃ¡pido e devagar para textos.
- Criar extrator de features para tarefas envolvendo audio e imagem.
- Criar um processador para tarefas multimodais.

## configuration

A [configuration](main_classes/configuration) refere-se a atributos especÃ­ficos de um modelo. Cada configuraÃ§Ã£o de modelo tem atributos diferentes; por exemplo, todos modelo de PLN possuem os atributos `hidden_size`, `num_attention_heads`, `num_hidden_layers` e `vocab_size` em comum. Esse atributos especificam o numero de 'attention heads' ou 'hidden layers' para construir um modelo.

DÃª uma olhada a mais em [DistilBERT](model_doc/distilbert) acessando [`DistilBertConfig`] para observar esses atributos:

```py
>>> from transformers import DistilBertConfig

>>> config = DistilBertConfig()
>>> print(config)
DistilBertConfig {
  "activation": "gelu",
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "transformers_version": "4.16.2",
  "vocab_size": 30522
}
```

[`DistilBertConfig`] mostra todos os atributos padrÃµes usados para construir um [`DistilBertModel`] base. Todos atributos sÃ£o customizÃ¡veis, o que cria espaÃ§o para experimentos. Por exemplo, vocÃª pode customizar um modelo padrÃ£o para:

- Tentar uma funÃ§Ã£o de ativaÃ§Ã£o diferente com o parÃ¢metro `activation`.
- Usar uma taxa de desistÃªncia maior para as probabilidades de 'attention' com o parÃ¢metro `attention_dropout`.

```py
>>> my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
>>> print(my_config)
DistilBertConfig {
  "activation": "relu",
  "attention_dropout": 0.4,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "transformers_version": "4.16.2",
  "vocab_size": 30522
}
```

Atributos de um modelo prÃ©-treinado podem ser modificados na funÃ§Ã£o [`~PretrainedConfig.from_pretrained`]:

```py
>>> my_config = DistilBertConfig.from_pretrained("distilbert/distilbert-base-uncased", activation="relu", attention_dropout=0.4)
```

Uma vez que vocÃª estÃ¡ satisfeito com as configuraÃ§Ãµes do seu modelo, vocÃª consegue salvar elas com [`~PretrainedConfig.save_pretrained`]. Seu arquivo de configuraÃ§Ãµes estÃ¡ salvo como um arquivo JSON no diretÃ³rio especificado:

```py
>>> my_config.save_pretrained(save_directory="./your_model_save_path")
```

Para reusar o arquivo de configuraÃ§Ãµes, carregue com [`~PretrainedConfig.from_pretrained`]:

```py
>>> my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
```

> [!TIP]
> VocÃª pode tambÃ©m salvar seu arquivo de configuraÃ§Ãµes como um dicionÃ¡rio ou atÃ© mesmo com a diferenÃ§a entre as seus atributos de configuraÃ§Ã£o customizados e os atributos de configuraÃ§Ã£o padrÃµes! Olhe a documentaÃ§Ã£o [configuration](main_classes/configuration) para mais detalhes.

## Modelo

O prÃ³ximo passo Ã© criar um [model](main_classes/models). O modelo - tambÃ©m vagamente referido como arquitetura - define o que cada camada estÃ¡ fazendo e quais operaÃ§Ãµes estÃ£o acontecendo. Atributos como `num_hidden_layers` das configuraÃ§Ãµes sÃ£o utilizados para definir a arquitetura. Todo modelo compartilha a classe base [`PreTrainedModel`] e alguns mÃ©todos em comum como redimensionar o tamanho dos embeddings de entrada e podar as 'self-attention heads'. AlÃ©m disso, todos os modelos tambÃ©m sÃ£o subclasses de [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) ou [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html). Isso significa que os modelos sÃ£o compatÃ­veis com cada respectivo uso de framework.

Carregar seus atributos de configuraÃ§Ã£o customizados em um modelo:

```py
>>> from transformers import DistilBertModel

>>> my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
>>> model = DistilBertModel(my_config)
```

Isso cria um modelo com valores aleatÃ³rios ao invÃ©s de prÃ©-treinar os pesos. VocÃª nÃ£o irÃ¡ conseguir usar usar esse modelo para nada Ãºtil ainda, atÃ© vocÃª treinar ele. Treino Ã© um processo caro e demorado. Geralmente Ã© melhor utilizar um modelo prÃ©-treinado para obter melhores resultados mais rÃ¡pido, enquanto usa apenas uma fraÃ§Ã£o dos recursos necessÃ¡rios para treinar.

Criar um modelo prÃ©-treinado com [`~PreTrainedModel.from_pretrained`]:

```py
>>> model = DistilBertModel.from_pretrained("distilbert/distilbert-base-uncased")
```

Quando vocÃª carregar os pesos prÃ©-treinados, a configuraÃ§Ã£o padrÃ£o do modelo Ã© automaticamente carregada se o modelo Ã© provido pelo ğŸ¤— Transformers. No entanto, vocÃª ainda consegue mudar - alguns ou todos - os atributos padrÃµes de configuraÃ§Ã£o do modelo com os seus prÃ³prio atributos, se vocÃª preferir: 

```py
>>> model = DistilBertModel.from_pretrained("distilbert/distilbert-base-uncased", config=my_config)
```

### Heads do modelo

Neste ponto, vocÃª tem um modelo bÃ¡sico do DistilBERT que gera os *estados ocultos*. Os estados ocultos sÃ£o passados como entrada para a head do moelo para produzir a saÃ­da final. ğŸ¤— Transformers fornece uma head de modelo diferente para cada tarefa desde que o modelo suporte essa tarefa (por exemplo, vocÃª nÃ£o consegue utilizar o modelo DistilBERT para uma tarefa de 'sequence-to-sequence' como traduÃ§Ã£o).

Por exemplo, [`DistilBertForSequenceClassification`] Ã© um modelo DistilBERT base com uma head de classificaÃ§Ã£o de sequÃªncia. A head de calssificaÃ§Ã£o de sequÃªncia Ã© uma camada linear no topo das saÃ­das agrupadas.

```py
>>> from transformers import DistilBertForSequenceClassification

>>> model = DistilBertForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased")
```

Reutilize facilmente esse ponto de parada para outra tarefe mudando para uma head de modelo diferente. Para uma tarefe de responder questÃµes, vocÃª usaria a head do modelo [`DistilBertForQuestionAnswering`]. A head de responder questÃµes Ã© similar com a de classificaÃ§Ã£o de sequÃªncias exceto o fato de que ela Ã© uma camada no topo dos estados das saÃ­das ocultas.

```py
>>> from transformers import DistilBertForQuestionAnswering

>>> model = DistilBertForQuestionAnswering.from_pretrained("distilbert/distilbert-base-uncased")
```

## Tokenizer

A Ãºtlima classe base que vocÃª precisa antes de usar um modelo para dados textuais Ã© a [tokenizer](main_classes/tokenizer) para converter textos originais para tensores. Existem dois tipos de tokenizers que vocÃª pode usar com ğŸ¤— Transformers:

- [`PreTrainedTokenizer`]: uma implementaÃ§Ã£o em Python de um tokenizer.
- [`PreTrainedTokenizerFast`]: um tokenizer da nossa biblioteca [ğŸ¤— Tokenizer](https://huggingface.co/docs/tokenizers/python/latest/) baseada em Rust. Esse tipo de tokenizer Ã© significantemente mais rapido - especialmente durante tokenization de codificaÃ§Ã£o - devido a implementaÃ§Ã£o em Rust. O tokenizer rÃ¡pido tambem oferece mÃ©todos adicionais como *offset mapping* que mapeia tokens para suar palavras ou caracteres originais.

Os dois tokenizers suporta mÃ©todos comuns como os de codificar e decodificar, adicionar novos tokens, e gerenciar tokens especiais.

> [!WARNING]
> Nem todo modelo suporta um 'fast tokenizer'. De uma olhada aqui [table](index#supported-frameworks) pra checar se um modelo suporta 'fast tokenizer'.

Se vocÃª treinou seu prÃ³rpio tokenizer, vocÃª pode criar um a partir do seu arquivo *vocabulary*:

```py
>>> from transformers import DistilBertTokenizer

>>> my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")
```

Ã‰ importante lembrar que o vocabulÃ¡rio de um tokenizer customizado serÃ¡ diferente de um vocabulÃ¡rio gerado pelo tokenizer de um modelo prÃ© treinado. VocÃª precisa usar o vocabulÃ¡rio de um modelo prÃ© treinado se vocÃª estiver usando um modelo prÃ© treinado, caso contrÃ¡rio as entradas nÃ£o farÃ£o sentido. Criando um tokenizer com um vocabulÃ¡rio de um modelo prÃ© treinado com a classe [`DistilBertTokenizer`]:

```py
>>> from transformers import DistilBertTokenizer

>>> slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert/distilbert-base-uncased")
```

Criando um 'fast tokenizer' com a classe [`DistilBertTokenizerFast`]:

```py
>>> from transformers import DistilBertTokenizerFast

>>> fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert/distilbert-base-uncased")
```

> [!TIP]
> Pos padrÃ£o, [`AutoTokenizer`] tentarÃ¡ carregar um 'fast tokenizer'. VocÃª pode disabilitar esse comportamento colocando `use_fast=False` no `from_pretrained`.

## Extrator de features

Um extrator de features processa entradas de imagem ou Ã¡udio. Ele herda da classe base [`~feature_extraction_utils.FeatureExtractionMixin`], e pode tambÃ©m herdar da classe [`ImageFeatureExtractionMixin`] para processamento de features de imagem ou da classe [`SequenceFeatureExtractor`] para processamento de entradas de Ã¡udio.

Dependendo do que vocÃª estÃ¡ trabalhando em um audio ou uma tarefa de visÃ£o, crie um estrator de features associado com o modelo que vocÃª estÃ¡ usando. Por exemplo, crie um [`ViTFeatureExtractor`] padrÃ£o se vocÃª estiver usando [ViT](model_doc/vit) para classificaÃ§Ã£o de imagens:

```py
>>> from transformers import ViTFeatureExtractor

>>> vit_extractor = ViTFeatureExtractor()
>>> print(vit_extractor)
ViTFeatureExtractor {
  "do_normalize": true,
  "do_resize": true,
  "feature_extractor_type": "ViTFeatureExtractor",
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "resample": 2,
  "size": 224
}
```

> [!TIP]
> Se vocÃª nÃ£o estiver procurando por nenhuma customizaÃ§Ã£o, apenas use o mÃ©todo `from_pretrained` para carregar parÃ¢metros do modelo de extrator de features padrÃ£o.

Modifique qualquer parÃ¢metro dentre os [`ViTFeatureExtractor`] para criar seu extrator de features customizado.

```py
>>> from transformers import ViTFeatureExtractor

>>> my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
>>> print(my_vit_extractor)
ViTFeatureExtractor {
  "do_normalize": false,
  "do_resize": true,
  "feature_extractor_type": "ViTFeatureExtractor",
  "image_mean": [
    0.3,
    0.3,
    0.3
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "resample": "PIL.Image.BOX",
  "size": 224
}
```

Para entradas de Ã¡utio, vocÃª pode criar um [`Wav2Vec2FeatureExtractor`] e customizar os parÃ¢metros de uma forma similar:

```py
>>> from transformers import Wav2Vec2FeatureExtractor

>>> w2v2_extractor = Wav2Vec2FeatureExtractor()
>>> print(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}
```

## Processor

Para modelos que suportam tarefas multimodais, ğŸ¤— Transformers oferece uma classe processadora que convenientemente cobre um extrator de features e tokenizer dentro de um Ãºnico objeto. Por exemplo, vamos usar o [`Wav2Vec2Processor`] para uma tarefa de reconhecimento de fala automÃ¡tica (ASR). ASR transcreve Ã¡udio para texto, entÃ£o vocÃª irÃ¡ precisar de um extrator de um features e um tokenizer.

Crie um extrator de features para lidar com as entradas de Ã¡udio.

```py
>>> from transformers import Wav2Vec2FeatureExtractor

>>> feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)
```

Crie um tokenizer para lidar com a entrada de textos:

```py
>>> from transformers import Wav2Vec2CTCTokenizer

>>> tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")
```

Combine o extrator de features e o tokenizer no [`Wav2Vec2Processor`]:

```py
>>> from transformers import Wav2Vec2Processor

>>> processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)
```

Com duas classes bÃ¡sicas - configuraÃ§Ã£o e modelo - e um preprocessamento de classe adicional (tokenizer, extrator de features, ou processador), vocÃª pode criar qualquer modelo que suportado por ğŸ¤— Transformers. Qualquer uma dessas classes base sÃ£o configurÃ¡veis, te permitindo usar os atributos especÃ­ficos que vocÃª queira. VocÃª pode facilmente preparar um modelo para treinamento ou modificar um modelo prÃ©-treinado com poucas mudanÃ§as.
