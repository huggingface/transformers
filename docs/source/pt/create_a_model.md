<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

‚ö†Ô∏è Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Criar uma arquitetura customizada

Uma [`AutoClass`](model_doc/auto) automaticamente infere a arquitetura do modelo e baixa configura√ß√µes e pesos pr√©-treinados. Geralmente, n√≥s recomendamos usar uma `AutoClass` para produzir um c√≥digo independente de checkpoints. Mas usu√°rios que querem mais contole sobre par√¢metros espec√≠ficos do modelo pode criar um modelo customizado ü§ó Transformers a partir de algumas classes bases. Isso pode ser particulamente √∫til para algu√©m que est√° interessado em estudar, treinar ou fazer experimentos com um modelo ü§ó Transformers. Nesse tutorial, ser√° explicado como criar um modelo customizado sem uma `AutoClass`. Aprenda como:

- Carregar e customizar a configura√ß√£o de um modelo.
- Criar a arquitetura de um modelo.
- Criar um tokenizer r√°pido e devagar para textos.
- Criar extrator de features para tarefas envolvendo audio e imagem.
- Criar um processador para tarefas multimodais.

## configuration

A [configuration](main_classes/configuration) refere-se a atributos espec√≠ficos de um modelo. Cada configura√ß√£o de modelo tem atributos diferentes; por exemplo, todos modelo de PLN possuem os atributos `hidden_size`, `num_attention_heads`, `num_hidden_layers` e `vocab_size` em comum. Esse atributos especificam o numero de 'attention heads' ou 'hidden layers' para construir um modelo.

D√™ uma olhada a mais em [DistilBERT](model_doc/distilbert) acessando [`DistilBertConfig`] para observar esses atributos:

```py
>>> from transformers import DistilBertConfig

>>> config = DistilBertConfig()
>>> print(config)
DistilBertConfig {
  "activation": "gelu",
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "transformers_version": "4.16.2",
  "vocab_size": 30522
}
```

[`DistilBertConfig`] mostra todos os atributos padr√µes usados para construir um [`DistilBertModel`] base. Todos atributos s√£o customiz√°veis, o que cria espa√ßo para experimentos. Por exemplo, voc√™ pode customizar um modelo padr√£o para:

- Tentar uma fun√ß√£o de ativa√ß√£o diferente com o par√¢metro `activation`.
- Usar uma taxa de desist√™ncia maior para as probabilidades de 'attention' com o par√¢metro `attention_dropout`.

```py
>>> my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
>>> print(my_config)
DistilBertConfig {
  "activation": "relu",
  "attention_dropout": 0.4,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "transformers_version": "4.16.2",
  "vocab_size": 30522
}
```

Atributos de um modelo pr√©-treinado podem ser modificados na fun√ß√£o [`~PretrainedConfig.from_pretrained`]:

```py
>>> my_config = DistilBertConfig.from_pretrained("distilbert/distilbert-base-uncased", activation="relu", attention_dropout=0.4)
```

Uma vez que voc√™ est√° satisfeito com as configura√ß√µes do seu modelo, voc√™ consegue salvar elas com [`~PretrainedConfig.save_pretrained`]. Seu arquivo de configura√ß√µes est√° salvo como um arquivo JSON no diret√≥rio especificado:

```py
>>> my_config.save_pretrained(save_directory="./your_model_save_path")
```

Para reusar o arquivo de configura√ß√µes, carregue com [`~PretrainedConfig.from_pretrained`]:

```py
>>> my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
```

<Tip>

Voc√™ pode tamb√©m salvar seu arquivo de configura√ß√µes como um dicion√°rio ou at√© mesmo com a diferen√ßa entre as seus atributos de configura√ß√£o customizados e os atributos de configura√ß√£o padr√µes! Olhe a documenta√ß√£o [configuration](main_classes/configuration) para mais detalhes.

</Tip>

## Modelo

O pr√≥ximo passo √© criar um [model](main_classes/models). O modelo - tamb√©m vagamente referido como arquitetura - define o que cada camada est√° fazendo e quais opera√ß√µes est√£o acontecendo. Atributos como `num_hidden_layers` das configura√ß√µes s√£o utilizados para definir a arquitetura. Todo modelo compartilha a classe base [`PreTrainedModel`] e alguns m√©todos em comum como redimensionar o tamanho dos embeddings de entrada e podar as 'self-attention heads'. Al√©m disso, todos os modelos tamb√©m s√£o subclasses de [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) ou [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html). Isso significa que os modelos s√£o compat√≠veis com cada respectivo uso de framework.

Carregar seus atributos de configura√ß√£o customizados em um modelo:

```py
>>> from transformers import DistilBertModel

>>> my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
>>> model = DistilBertModel(my_config)
```

Isso cria um modelo com valores aleat√≥rios ao inv√©s de pr√©-treinar os pesos. Voc√™ n√£o ir√° conseguir usar usar esse modelo para nada √∫til ainda, at√© voc√™ treinar ele. Treino √© um processo caro e demorado. Geralmente √© melhor utilizar um modelo pr√©-treinado para obter melhores resultados mais r√°pido, enquanto usa apenas uma fra√ß√£o dos recursos necess√°rios para treinar.

Criar um modelo pr√©-treinado com [`~PreTrainedModel.from_pretrained`]:

```py
>>> model = DistilBertModel.from_pretrained("distilbert/distilbert-base-uncased")
```

Quando voc√™ carregar os pesos pr√©-treinados, a configura√ß√£o padr√£o do modelo √© automaticamente carregada se o modelo √© provido pelo ü§ó Transformers. No entanto, voc√™ ainda consegue mudar - alguns ou todos - os atributos padr√µes de configura√ß√£o do modelo com os seus pr√≥prio atributos, se voc√™ preferir: 

```py
>>> model = DistilBertModel.from_pretrained("distilbert/distilbert-base-uncased", config=my_config)
```

### Heads do modelo

Neste ponto, voc√™ tem um modelo b√°sico do DistilBERT que gera os *estados ocultos*. Os estados ocultos s√£o passados como entrada para a head do moelo para produzir a sa√≠da final. ü§ó Transformers fornece uma head de modelo diferente para cada tarefa desde que o modelo suporte essa tarefa (por exemplo, voc√™ n√£o consegue utilizar o modelo DistilBERT para uma tarefa de 'sequence-to-sequence' como tradu√ß√£o).

Por exemplo, [`DistilBertForSequenceClassification`] √© um modelo DistilBERT base com uma head de classifica√ß√£o de sequ√™ncia. A head de calssifica√ß√£o de sequ√™ncia √© uma camada linear no topo das sa√≠das agrupadas.

```py
>>> from transformers import DistilBertForSequenceClassification

>>> model = DistilBertForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased")
```

Reutilize facilmente esse ponto de parada para outra tarefe mudando para uma head de modelo diferente. Para uma tarefe de responder quest√µes, voc√™ usaria a head do modelo [`DistilBertForQuestionAnswering`]. A head de responder quest√µes √© similar com a de classifica√ß√£o de sequ√™ncias exceto o fato de que ela √© uma camada no topo dos estados das sa√≠das ocultas.

```py
>>> from transformers import DistilBertForQuestionAnswering

>>> model = DistilBertForQuestionAnswering.from_pretrained("distilbert/distilbert-base-uncased")
```

## Tokenizer

A √∫tlima classe base que voc√™ precisa antes de usar um modelo para dados textuais √© a [tokenizer](main_classes/tokenizer) para converter textos originais para tensores. Existem dois tipos de tokenizers que voc√™ pode usar com ü§ó Transformers:

- [`PreTrainedTokenizer`]: uma implementa√ß√£o em Python de um tokenizer.
- [`PreTrainedTokenizerFast`]: um tokenizer da nossa biblioteca [ü§ó Tokenizer](https://huggingface.co/docs/tokenizers/python/latest/) baseada em Rust. Esse tipo de tokenizer √© significantemente mais rapido - especialmente durante tokenization de codifica√ß√£o - devido a implementa√ß√£o em Rust. O tokenizer r√°pido tambem oferece m√©todos adicionais como *offset mapping* que mapeia tokens para suar palavras ou caracteres originais.

Os dois tokenizers suporta m√©todos comuns como os de codificar e decodificar, adicionar novos tokens, e gerenciar tokens especiais.

<Tip warning={true}>

Nem todo modelo suporta um 'fast tokenizer'. De uma olhada aqui [table](index#supported-frameworks) pra checar se um modelo suporta 'fast tokenizer'.

</Tip>

Se voc√™ treinou seu pr√≥rpio tokenizer, voc√™ pode criar um a partir do seu arquivo *vocabulary*:

```py
>>> from transformers import DistilBertTokenizer

>>> my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")
```

√â importante lembrar que o vocabul√°rio de um tokenizer customizado ser√° diferente de um vocabul√°rio gerado pelo tokenizer de um modelo pr√© treinado. Voc√™ precisa usar o vocabul√°rio de um modelo pr√© treinado se voc√™ estiver usando um modelo pr√© treinado, caso contr√°rio as entradas n√£o far√£o sentido. Criando um tokenizer com um vocabul√°rio de um modelo pr√© treinado com a classe [`DistilBertTokenizer`]:

```py
>>> from transformers import DistilBertTokenizer

>>> slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert/distilbert-base-uncased")
```

Criando um 'fast tokenizer' com a classe [`DistilBertTokenizerFast`]:

```py
>>> from transformers import DistilBertTokenizerFast

>>> fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert/distilbert-base-uncased")
```

<Tip>

Pos padr√£o, [`AutoTokenizer`] tentar√° carregar um 'fast tokenizer'. Voc√™ pode disabilitar esse comportamento colocando `use_fast=False` no `from_pretrained`.

</Tip>

## Extrator de features

Um extrator de features processa entradas de imagem ou √°udio. Ele herda da classe base [`~feature_extraction_utils.FeatureExtractionMixin`], e pode tamb√©m herdar da classe [`ImageFeatureExtractionMixin`] para processamento de features de imagem ou da classe [`SequenceFeatureExtractor`] para processamento de entradas de √°udio.

Dependendo do que voc√™ est√° trabalhando em um audio ou uma tarefa de vis√£o, crie um estrator de features associado com o modelo que voc√™ est√° usando. Por exemplo, crie um [`ViTFeatureExtractor`] padr√£o se voc√™ estiver usando [ViT](model_doc/vit) para classifica√ß√£o de imagens:

```py
>>> from transformers import ViTFeatureExtractor

>>> vit_extractor = ViTFeatureExtractor()
>>> print(vit_extractor)
ViTFeatureExtractor {
  "do_normalize": true,
  "do_resize": true,
  "feature_extractor_type": "ViTFeatureExtractor",
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "resample": 2,
  "size": 224
}
```

<Tip>

Se voc√™ n√£o estiver procurando por nenhuma customiza√ß√£o, apenas use o m√©todo `from_pretrained` para carregar par√¢metros do modelo de extrator de features padr√£o.

</Tip>

Modifique qualquer par√¢metro dentre os [`ViTFeatureExtractor`] para criar seu extrator de features customizado.

```py
>>> from transformers import ViTFeatureExtractor

>>> my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
>>> print(my_vit_extractor)
ViTFeatureExtractor {
  "do_normalize": false,
  "do_resize": true,
  "feature_extractor_type": "ViTFeatureExtractor",
  "image_mean": [
    0.3,
    0.3,
    0.3
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "resample": "PIL.Image.BOX",
  "size": 224
}
```

Para entradas de √°utio, voc√™ pode criar um [`Wav2Vec2FeatureExtractor`] e customizar os par√¢metros de uma forma similar:

```py
>>> from transformers import Wav2Vec2FeatureExtractor

>>> w2v2_extractor = Wav2Vec2FeatureExtractor()
>>> print(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}
```

## Processor

Para modelos que suportam tarefas multimodais, ü§ó Transformers oferece uma classe processadora que convenientemente cobre um extrator de features e tokenizer dentro de um √∫nico objeto. Por exemplo, vamos usar o [`Wav2Vec2Processor`] para uma tarefa de reconhecimento de fala autom√°tica (ASR). ASR transcreve √°udio para texto, ent√£o voc√™ ir√° precisar de um extrator de um features e um tokenizer.

Crie um extrator de features para lidar com as entradas de √°udio.

```py
>>> from transformers import Wav2Vec2FeatureExtractor

>>> feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)
```

Crie um tokenizer para lidar com a entrada de textos:

```py
>>> from transformers import Wav2Vec2CTCTokenizer

>>> tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")
```

Combine o extrator de features e o tokenizer no [`Wav2Vec2Processor`]:

```py
>>> from transformers import Wav2Vec2Processor

>>> processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)
```

Com duas classes b√°sicas - configura√ß√£o e modelo - e um preprocessamento de classe adicional (tokenizer, extrator de features, ou processador), voc√™ pode criar qualquer modelo que suportado por ü§ó Transformers. Qualquer uma dessas classes base s√£o configur√°veis, te permitindo usar os atributos espec√≠ficos que voc√™ queira. Voc√™ pode facilmente preparar um modelo para treinamento ou modificar um modelo pr√©-treinado com poucas mudan√ßas.
