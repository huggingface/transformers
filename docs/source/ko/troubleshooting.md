<!---
Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ë¬¸ì œ í•´ê²°[[troubleshoot]]

ë•Œë•Œë¡œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆì§€ë§Œ, ì €í¬ê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ì´ ê°€ì´ë“œëŠ” í˜„ì¬ê¹Œì§€ í™•ì¸ëœ ê°€ì¥ ì¼ë°˜ì ì¸ ë¬¸ì œ ëª‡ ê°€ì§€ì™€ ê·¸ê²ƒë“¤ì„ í•´ê²°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ê°€ì´ë“œëŠ” ëª¨ë“  ğŸ¤— Transformers ë¬¸ì œë¥¼ í¬ê´„ì ìœ¼ë¡œ ë‹¤ë£¨ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë¬¸ì œ í•´ê²°ì— ë” ë§ì€ ë„ì›€ì„ ë°›ìœ¼ë ¤ë©´ ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:

<Youtube id="S2EEG3JIt2A"/>

1. [í¬ëŸ¼](https://discuss.huggingface.co/)ì—ì„œ ë„ì›€ì„ ìš”ì²­í•˜ì„¸ìš”. [Beginners](https://discuss.huggingface.co/c/beginners/5) ë˜ëŠ” [ğŸ¤— Transformers](https://discuss.huggingface.co/c/transformers/9)ì™€ ê°™ì€ íŠ¹ì • ì¹´í…Œê³ ë¦¬ì— ì§ˆë¬¸ì„ ê²Œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¬í˜„ ê°€ëŠ¥í•œ ì½”ë“œì™€ í•¨ê»˜ ì˜ ì„œìˆ ëœ í¬ëŸ¼ ê²Œì‹œë¬¼ì„ ì‘ì„±í•˜ì—¬ ì—¬ëŸ¬ë¶„ì˜ ë¬¸ì œê°€ í•´ê²°ë  ê°€ëŠ¥ì„±ì„ ê·¹ëŒ€í™”í•˜ì„¸ìš”!

<Youtube id="_PAli-V4wj0"/>

2. ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ê´€ë ¨ëœ ë²„ê·¸ì´ë©´ ğŸ¤— Transformers ì €ì¥ì†Œì—ì„œ [ì´ìŠˆ](https://github.com/huggingface/transformers/issues/new/choose)ë¥¼ ìƒì„±í•˜ì„¸ìš”. ë²„ê·¸ì— ëŒ€í•´ ì„¤ëª…í•˜ëŠ” ì •ë³´ë¥¼ ê°€ëŠ¥í•œ ë§ì´ í¬í•¨í•˜ë ¤ê³  ë…¸ë ¥í•˜ì—¬, ë¬´ì—‡ì´ ì˜ëª» ë˜ì—ˆëŠ”ì§€ì™€ ì–´ë–»ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ”ì§€ ë” ì˜ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

3. ì´ì „ ë²„ì „ì˜ ğŸ¤— Transformersì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì¤‘ìš”í•œ ë³€ê²½ ì‚¬í•­ì´ ë²„ì „ ì‚¬ì´ì— ë„ì…ë˜ì—ˆê¸° ë•Œë¬¸ì— [ë§ˆì´ê·¸ë ˆì´ì…˜](migration) ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.

ë¬¸ì œ í•´ê²° ë° ë„ì›€ ë§¤ë‰´ì–¼ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ Hugging Face ê°•ì¢Œì˜ [8ì¥](https://huggingface.co/course/chapter8/1?fw=pt)ì„ ì°¸ì¡°í•˜ì„¸ìš”.


## ë°©í™”ë²½ í™˜ê²½[[firewalled-environments]]

í´ë¼ìš°ë“œ ë° ë‚´ë¶€ë§(intranet) ì„¤ì •ì˜ ì¼ë¶€ GPU ì¸ìŠ¤í„´ìŠ¤ëŠ” ì™¸ë¶€ ì—°ê²°ì— ëŒ€í•œ ë°©í™”ë²½ìœ¼ë¡œ ì°¨ë‹¨ë˜ì–´ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ê°€ ëª¨ë¸ ê°€ì¤‘ì¹˜ë‚˜ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ë ¤ê³  í•  ë•Œ, ë‹¤ìš´ë¡œë“œê°€ ì¤‘ë‹¨ë˜ê³  ë‹¤ìŒ ë©”ì‹œì§€ì™€ í•¨ê»˜ ì‹œê°„ ì´ˆê³¼ë©ë‹ˆë‹¤: 

```
ValueError: Connection error, and we cannot find the requested files in the cached path.
Please try again or make sure your Internet connection is on.
```

ì´ ê²½ìš°ì—ëŠ” ì—°ê²° ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ğŸ¤— Transformersë¥¼ [ì˜¤í”„ë¼ì¸ ëª¨ë“œ](installation#offline-mode)ë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

## CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±(CUDA out of memory)[[cuda-out-of-memory]]

ìˆ˜ë°±ë§Œ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ëŒ€ê·œëª¨ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ê²ƒì€ ì ì ˆí•œ í•˜ë“œì›¨ì–´ ì—†ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ì˜¤ë¥˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```
CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)
```

ë‹¤ìŒì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ì‹œë„í•´ ë³¼ ìˆ˜ ìˆëŠ” ëª‡ ê°€ì§€ ì ì¬ì ì¸ í•´ê²°ì±…ì…ë‹ˆë‹¤:

- [`TrainingArguments`]ì˜ [`per_device_train_batch_size`](main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size) ê°’ì„ ì¤„ì´ì„¸ìš”.
- [`TrainingArguments`]ì˜ [`gradient_accumulation_steps`](main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps)ì€ ì „ì²´ ë°°ì¹˜ í¬ê¸°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ëŠ˜ë¦¬ì„¸ìš”.

> [!TIP]
> ë©”ëª¨ë¦¬ ì ˆì•½ ê¸°ìˆ ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ì„±ëŠ¥ [ê°€ì´ë“œ](performance)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ì €ì¥ëœ TensorFlow ëª¨ë¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤(Unable to load a saved TensorFlow model)[[unable-to-load-a-saved-uensorFlow-model]]

TensorFlowì˜ [model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) ë©”ì†Œë“œëŠ” ì•„í‚¤í…ì²˜, ê°€ì¤‘ì¹˜, í›ˆë ¨ êµ¬ì„± ë“± ì „ì²´ ëª¨ë¸ì„ ë‹¨ì¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ì‹œ ê°€ì ¸ì˜¬ ë•Œ ğŸ¤— TransformersëŠ” ëª¨ë¸ íŒŒì¼ì— ìˆëŠ” ëª¨ë“  TensorFlow ê´€ë ¨ ê°ì²´ë¥¼ ê°€ì ¸ì˜¤ì§€ ì•Šì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. TensorFlow ëª¨ë¸ ì €ì¥ ë° ê°€ì ¸ì˜¤ê¸° ë¬¸ì œë¥¼ í”¼í•˜ë ¤ë©´ ë‹¤ìŒì„ ê¶Œì¥í•©ë‹ˆë‹¤:

- ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ `h5` íŒŒì¼ í™•ì¥ìë¡œ [`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)ë¡œ ì €ì¥í•œ ë‹¤ìŒ [`~TFPreTrainedModel.from_pretrained`]ë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ ê°€ì ¸ì˜µë‹ˆë‹¤:

```py
>>> from transformers import TFPreTrainedModel
>>> from tensorflow import keras

>>> model.save_weights("some_folder/tf_model.h5")
>>> model = TFPreTrainedModel.from_pretrained("some_folder")
```

- ëª¨ë¸ì„ [`~TFPretrainedModel.save_pretrained`]ë¡œ ì €ì¥í•˜ê³  [`~TFPreTrainedModel.from_pretrained`]ë¡œ ë‹¤ì‹œ ê°€ì ¸ì˜µë‹ˆë‹¤:

```py
>>> from transformers import TFPreTrainedModel

>>> model.save_pretrained("path_to/model")
>>> model = TFPreTrainedModel.from_pretrained("path_to/model")
```

## ImportError[[importerror]]

íŠ¹íˆ ìµœì‹  ëª¨ë¸ì¸ ê²½ìš° ë§Œë‚  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ì¼ë°˜ì ì¸ ì˜¤ë¥˜ëŠ” `ImportError`ì…ë‹ˆë‹¤:

```
ImportError: cannot import name 'ImageGPTImageProcessor' from 'transformers' (unknown location)
```

ì´ëŸ¬í•œ ì˜¤ë¥˜ ìœ í˜•ì˜ ê²½ìš° ìµœì‹  ëª¨ë¸ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ ìµœì‹  ë²„ì „ì˜ ğŸ¤— Transformersê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

```bash
pip install transformers --upgrade
```

## CUDA error: device-side assert triggered[[cuda-error-deviceside-assert-triggered]]

ë•Œë•Œë¡œ ì¥ì¹˜ ì½”ë“œ ì˜¤ë¥˜ì— ëŒ€í•œ ì¼ë°˜ì ì¸ CUDA ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
RuntimeError: CUDA error: device-side assert triggered
```

ë” ìì„¸í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì–»ìœ¼ë ¤ë©´ ìš°ì„  ì½”ë“œë¥¼ CPUì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤. ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì½”ë“œì˜ ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€í•˜ì—¬ CPUë¡œ ì „í™˜í•˜ì„¸ìš”:

```py
>>> import os

>>> os.environ["CUDA_VISIBLE_DEVICES"] = ""
```

ë˜ ë‹¤ë¥¸ ì˜µì…˜ì€ GPUì—ì„œ ë” ë‚˜ì€ ì—­ì¶”ì (traceback)ì„ ì–»ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì½”ë“œì˜ ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€í•˜ì—¬ ì—­ì¶”ì ì´ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ì†ŒìŠ¤ë¥¼ ê°€ë¦¬í‚¤ë„ë¡ í•˜ì„¸ìš”:

```py
>>> import os

>>> os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
```

## íŒ¨ë”© í† í°ì´ ë§ˆìŠ¤í‚¹ë˜ì§€ ì•Šì€ ê²½ìš° ì˜ëª»ëœ ì¶œë ¥(Incorrect output when padding tokens aren't masked)[[incorrect-output-when-padding-tokens-arent-masked]]

ê²½ìš°ì— ë”°ë¼ `input_ids`ì— íŒ¨ë”© í† í°ì´ í¬í•¨ëœ ê²½ìš° `hidden_state` ì¶œë ¥ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ëª¨ë¥¼ ìœ„í•´ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”. ëª¨ë¸ì˜ `pad_token_id`ì— ì•¡ì„¸ìŠ¤í•˜ì—¬ í•´ë‹¹ ê°’ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë¶€ ëª¨ë¸ì˜ ê²½ìš° `pad_token_id`ê°€ `None`ì¼ ìˆ˜ ìˆì§€ë§Œ ì–¸ì œë“ ì§€ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
>>> from transformers import AutoModelForSequenceClassification
>>> import torch

>>> model = AutoModelForSequenceClassification.from_pretrained("google-bert/bert-base-uncased")
>>> model.config.pad_token_id
0
```

ë‹¤ìŒ ì˜ˆì œëŠ” íŒ¨ë”© í† í°ì„ ë§ˆìŠ¤í‚¹í•˜ì§€ ì•Šì€ ì¶œë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

```py
>>> input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [ 0.1317, -0.1683]], grad_fn=<AddmmBackward0>)
```

ë‹¤ìŒì€ ë‘ ë²ˆì§¸ ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ì¶œë ¥ì…ë‹ˆë‹¤:

```py
>>> input_ids = torch.tensor([[7592]])
>>> output = model(input_ids)
>>> print(output.logits)
tensor([[-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ëª¨ë¸ì— `attention_mask`ë¥¼ ì œê³µí•˜ì—¬ íŒ¨ë”© í† í°ì„ ë¬´ì‹œí•´ì•¼ ì´ëŸ¬í•œ ì¡°ìš©í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì œ ë‘ ë²ˆì§¸ ì‹œí€€ìŠ¤ì˜ ì¶œë ¥ì´ ì‹¤ì œ ì¶œë ¥ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤:

> [!TIP]
> ì¼ë°˜ì ìœ¼ë¡œ í† í¬ë‚˜ì´ì €ëŠ” íŠ¹ì • í† í¬ë‚˜ì´ì €ì˜ ê¸°ë³¸ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ìì— ëŒ€í•œ 'attention_mask'ë¥¼ ë§Œë“­ë‹ˆë‹¤.

```py
>>> attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])
>>> output = model(input_ids, attention_mask=attention_mask)
>>> print(output.logits)
tensor([[ 0.0082, -0.2307],
        [-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)
```

ğŸ¤— TransformersëŠ” íŒ¨ë”© í† í°ì´ ì œê³µëœ ê²½ìš° íŒ¨ë”© í† í°ì„ ë§ˆìŠ¤í‚¹í•˜ê¸° ìœ„í•œ `attention_mask`ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- ì¼ë¶€ ëª¨ë¸ì—ëŠ” íŒ¨ë”© í† í°ì´ ì—†ìŠµë‹ˆë‹¤.
- ì¼ë¶€ ì‚¬ìš© ì‚¬ë¡€ì˜ ê²½ìš° ì‚¬ìš©ìê°€ ëª¨ë¸ì´ íŒ¨ë”© í† í°ì„ ê´€ë¦¬í•˜ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤.

## ValueError: ì´ ìœ í˜•ì˜ AutoModelì— ëŒ€í•´ ì¸ì‹í•  ìˆ˜ ì—†ëŠ” XYZ êµ¬ì„± í´ë˜ìŠ¤(ValueError: Unrecognized configuration class XYZ for this kind of AutoModel)[[valueerror-unrecognized-configuration-class-xyz-for-this-kind-of-automodel]]

ì¼ë°˜ì ìœ¼ë¡œ, ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ [`AutoModel`] í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
ì´ í´ë˜ìŠ¤ëŠ” êµ¬ì„±ì— ë”°ë¼ ì£¼ì–´ì§„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì˜¬ë°”ë¥¸ ì•„í‚¤í…ì²˜ë¥¼ ìë™ìœ¼ë¡œ ì¶”ë¡ í•˜ê³  ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ëª¨ë¸ì„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°€ì ¸ì˜¬ ë•Œ ì´ `ValueError`ê°€ ë°œìƒí•˜ë©´, ì´ëŠ” Auto í´ë˜ìŠ¤ê°€ ì£¼ì–´ì§„ ì²´í¬í¬ì¸íŠ¸ì˜ êµ¬ì„±ì—ì„œ 
ê°€ì ¸ì˜¤ë ¤ëŠ” ëª¨ë¸ ìœ í˜•ê³¼ ë§¤í•‘ì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê°€ì¥ í”í•˜ê²Œ ë°œìƒí•˜ëŠ” ê²½ìš°ëŠ” 
ì²´í¬í¬ì¸íŠ¸ê°€ ì£¼ì–´ì§„ íƒœìŠ¤í¬ë¥¼ ì§€ì›í•˜ì§€ ì•Šì„ ë•Œì…ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒ ì˜ˆì œì—ì„œ ì§ˆì˜ì‘ë‹µì— ëŒ€í•œ GPT2ê°€ ì—†ê¸° ë•Œë¬¸ì— ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤:

```py
>>> from transformers import AutoProcessor, AutoModelForQuestionAnswering

>>> processor = AutoProcessor.from_pretrained("openai-community/gpt2-medium")
>>> model = AutoModelForQuestionAnswering.from_pretrained("openai-community/gpt2-medium")
ValueError: Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForQuestionAnswering.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BloomConfig, ...
```
