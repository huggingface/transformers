<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ë¬¸ì„œ ì§ˆì˜ ì‘ë‹µ(Document Question Answering) [[document_question_answering]]

[[open-in-colab]]

ë¬¸ì„œ ì‹œê°ì  ì§ˆì˜ ì‘ë‹µ(Document Visual Question Answering)ì´ë¼ê³ ë„ í•˜ëŠ”
ë¬¸ì„œ ì§ˆì˜ ì‘ë‹µ(Document Question Answering)ì€ ë¬¸ì„œ ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€ì„ ì£¼ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤.
ì´ íƒœìŠ¤í¬ë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ì˜ ì…ë ¥ì€ ì¼ë°˜ì ìœ¼ë¡œ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì˜ ì¡°í•©ì´ê³ , ì¶œë ¥ì€ ìì—°ì–´ë¡œ ëœ ë‹µë³€ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ í…ìŠ¤íŠ¸, ë‹¨ì–´ì˜ ìœ„ì¹˜(ë°”ìš´ë”© ë°•ìŠ¤), ì´ë¯¸ì§€ ë“± ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í™œìš©í•©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œëŠ” ë‹¤ìŒ ë‚´ìš©ì„ ì„¤ëª…í•©ë‹ˆë‹¤:

- [DocVQA dataset](https://huggingface.co/datasets/nielsr/docvqa_1200_examples_donut)ì„ ì‚¬ìš©í•´ [LayoutLMv2](../model_doc/layoutlmv2) ë¯¸ì„¸ ì¡°ì •í•˜ê¸°
- ì¶”ë¡ ì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸°

<Tip>

ì´ ì‘ì—…ê³¼ í˜¸í™˜ë˜ëŠ” ëª¨ë“  ì•„í‚¤í…ì²˜ì™€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë³´ë ¤ë©´ [ì‘ì—… í˜ì´ì§€](https://huggingface.co/tasks/image-to-text)ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

</Tip>

LayoutLMv2ëŠ” í† í°ì˜ ë§ˆì§€ë§‰ ì€ë‹‰ì¸µ ìœ„ì— ì§ˆì˜ ì‘ë‹µ í—¤ë“œë¥¼ ì¶”ê°€í•´ ë‹µë³€ì˜ ì‹œì‘ í† í°ê³¼ ë í† í°ì˜ ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•¨ìœ¼ë¡œì¨ ë¬¸ì„œ ì§ˆì˜ ì‘ë‹µ íƒœìŠ¤í¬ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì¦‰, ë¬¸ë§¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¶”ì¶œí˜• ì§ˆì˜ ì‘ë‹µ(Extractive question answering)ìœ¼ë¡œ ë¬¸ì œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
ë¬¸ë§¥ì€ OCR ì—”ì§„ì˜ ì¶œë ¥ì—ì„œ ê°€ì ¸ì˜¤ë©°, ì—¬ê¸°ì„œëŠ” Googleì˜ Tesseractë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. LayoutLMv2ëŠ” detectron2, torchvision ë° í…Œì„œë™íŠ¸ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.

```bash
pip install -q transformers datasets
```

```bash
pip install 'git+https://github.com/facebookresearch/detectron2.git'
pip install torchvision
```

```bash
sudo apt install tesseract-ocr
pip install -q pytesseract
```

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ëª¨ë‘ ì„¤ì¹˜í•œ í›„ ëŸ°íƒ€ì„ì„ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.

ì»¤ë®¤ë‹ˆí‹°ì— ë‹¹ì‹ ì˜ ëª¨ë¸ì„ ê³µìœ í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•´ì„œ ëª¨ë¸ì„ ğŸ¤— Hubì— ì—…ë¡œë“œí•˜ì„¸ìš”.
í”„ë¡¬í”„íŠ¸ê°€ ì‹¤í–‰ë˜ë©´, ë¡œê·¸ì¸ì„ ìœ„í•´ í† í°ì„ ì…ë ¥í•˜ì„¸ìš”:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

ëª‡ ê°€ì§€ ì „ì—­ ë³€ìˆ˜ë¥¼ ì •ì˜í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```py
>>> model_checkpoint = "microsoft/layoutlmv2-base-uncased"
>>> batch_size = 4
```

## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° [[load-the-data]]

ì´ ê°€ì´ë“œì—ì„œëŠ” ğŸ¤— Hubì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì „ì²˜ë¦¬ëœ DocVQAì˜ ì‘ì€ ìƒ˜í”Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
DocVQAì˜ ì „ì²´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´, [DocVQA homepage](https://rrc.cvc.uab.es/?ch=17)ì— ê°€ì… í›„ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì²´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ í–ˆë‹¤ë©´, ì´ ê°€ì´ë“œë¥¼ ê³„ì† ì§„í–‰í•˜ê¸° ìœ„í•´ [ğŸ¤— datasetì— íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•](https://huggingface.co/docs/datasets/loading#local-and-remote-files)ì„ í™•ì¸í•˜ì„¸ìš”.

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("nielsr/docvqa_1200_examples")
>>> dataset
DatasetDict({
    train: Dataset({
        features: ['id', 'image', 'query', 'answers', 'words', 'bounding_boxes', 'answer'],
        num_rows: 1000
    })
    test: Dataset({
        features: ['id', 'image', 'query', 'answers', 'words', 'bounding_boxes', 'answer'],
        num_rows: 200
    })
})
```

ë³´ì‹œë‹¤ì‹œí”¼, ë°ì´í„° ì„¸íŠ¸ëŠ” ì´ë¯¸ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ë¬´ì‘ìœ„ë¡œ ì˜ˆì œë¥¼ ì‚´í´ë³´ë©´ì„œ íŠ¹ì„±ì„ í™•ì¸í•´ë³´ì„¸ìš”.

```py
>>> dataset["train"].features
```

ê° í•„ë“œê°€ ë‚˜íƒ€ë‚´ëŠ” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
* `id`: ì˜ˆì œì˜ id
* `image`: ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•˜ëŠ” PIL.Image.Image ê°ì²´
* `query`: ì§ˆë¬¸ ë¬¸ìì—´ - ì—¬ëŸ¬ ì–¸ì–´ì˜ ìì—°ì–´ë¡œ ëœ ì§ˆë¬¸
* `answers`: ì‚¬ëŒì´ ì£¼ì„ì„ ë‹¨ ì •ë‹µ ë¦¬ìŠ¤íŠ¸
* `words` and `bounding_boxes`: OCRì˜ ê²°ê³¼ê°’ë“¤ì´ë©° ì´ ê°€ì´ë“œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì„ ì˜ˆì •
* `answer`: ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ëŠ” ë‹µë³€ì´ë©° ì´ ê°€ì´ë“œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì„ ì˜ˆì •

ì˜ì–´ë¡œ ëœ ì§ˆë¬¸ë§Œ ë‚¨ê¸°ê³  ë‹¤ë¥¸ ëª¨ë¸ì— ëŒ€í•œ ì˜ˆì¸¡ì„ í¬í•¨í•˜ëŠ” `answer` íŠ¹ì„±ì„ ì‚­ì œí•˜ê² ìŠµë‹ˆë‹¤.
ê·¸ë¦¬ê³  ì£¼ì„ ì‘ì„±ìê°€ ì œê³µí•œ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ë‹µë³€ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ë˜ëŠ” ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œì„ ì¶”ì¶œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

```py
>>> updated_dataset = dataset.map(lambda example: {"question": example["query"]["en"]}, remove_columns=["query"])
>>> updated_dataset = updated_dataset.map(
...     lambda example: {"answer": example["answers"][0]}, remove_columns=["answer", "answers"]
... )
```

ì´ ê°€ì´ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” LayoutLMv2 ì²´í¬í¬ì¸íŠ¸ëŠ” `max_position_embeddings = 512`ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤(ì´ ì •ë³´ëŠ” [ì²´í¬í¬ì¸íŠ¸ì˜ `config.json` íŒŒì¼](https://huggingface.co/microsoft/layoutlmv2-base-uncased/blob/main/config.json#L18)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤).
ë°”ë¡œ ì˜ˆì œë¥¼ ì˜ë¼ë‚¼ ìˆ˜ë„ ìˆì§€ë§Œ, ê¸´ ë¬¸ì„œì˜ ëì— ë‹µë³€ì´ ìˆì–´ ì˜ë¦¬ëŠ” ìƒí™©ì„ í”¼í•˜ê¸° ìœ„í•´ ì—¬ê¸°ì„œëŠ” ì„ë² ë”©ì´ 512ë³´ë‹¤ ê¸¸ì–´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ëª‡ ê°€ì§€ ì˜ˆì œë¥¼ ì œê±°í•˜ê² ìŠµë‹ˆë‹¤.
ë°ì´í„° ì„¸íŠ¸ì— ìˆëŠ” ëŒ€ë¶€ë¶„ì˜ ë¬¸ì„œê°€ ê¸´ ê²½ìš° ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ - ìì„¸í•œ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ì‹¶ìœ¼ë©´ ì´ [ë…¸íŠ¸ë¶](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb)ì„ í™•ì¸í•˜ì„¸ìš”.

```py
>>> updated_dataset = updated_dataset.filter(lambda x: len(x["words"]) + len(x["question"].split()) < 512)
```

ì´ ì‹œì ì—ì„œ ì´ ë°ì´í„° ì„¸íŠ¸ì˜ OCR íŠ¹ì„±ë„ ì œê±°í•´ ë³´ê² ìŠµë‹ˆë‹¤. OCR íŠ¹ì„±ì€ ë‹¤ë¥¸ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ê¸° ìœ„í•œ ê²ƒìœ¼ë¡œ, ì´ ê°€ì´ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì˜ ì…ë ¥ ìš”êµ¬ ì‚¬í•­ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì´ íŠ¹ì„±ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì¼ë¶€ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
ëŒ€ì‹ , ì›ë³¸ ë°ì´í„°ì— [`LayoutLMv2Processor`]ë¥¼ ì‚¬ìš©í•˜ì—¬ OCR ë° í† í°í™”ë¥¼ ëª¨ë‘ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ì…ë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ë¯¸ì§€ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë ¤ë©´, [`LayoutLMv2` model documentation](../model_doc/layoutlmv2)ì—ì„œ ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ì…ë ¥ í¬ë§·ì„ í™•ì¸í•´ë³´ì„¸ìš”.

```py
>>> updated_dataset = updated_dataset.remove_columns("words")
>>> updated_dataset = updated_dataset.remove_columns("bounding_boxes")
```

ë§ˆì§€ë§‰ìœ¼ë¡œ, ë°ì´í„° íƒìƒ‰ì„ ì™„ë£Œí•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ ì˜ˆì‹œë¥¼ ì‚´í´ë´…ì‹œë‹¤.

```py
>>> updated_dataset["train"][11]["image"]
```

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/docvqa_example.jpg" alt="DocVQA Image Example"/>
 </div>

## ë°ì´í„° ì „ì²˜ë¦¬ [[preprocess-the-data]]


ë¬¸ì„œ ì§ˆì˜ ì‘ë‹µ íƒœìŠ¤í¬ëŠ” ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬ì´ë©°, ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ì…ë ¥ì´ ëª¨ë¸ì˜ ìš”êµ¬ì— ë§ê²Œ ì „ì²˜ë¦¬ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œì™€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¸ì½”ë”©í•  ìˆ˜ ìˆëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ê²°í•©í•œ [`LayoutLMv2Processor`]ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒë¶€í„° ì‹œì‘í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained(model_checkpoint)
```

### ë¬¸ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ [[preprocessing-document-images]]

ë¨¼ì €, í”„ë¡œì„¸ì„œì˜ `image_processor`ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì— ëŒ€í•œ ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„í•´ ë³´ê² ìŠµë‹ˆë‹¤.
ê¸°ë³¸ê°’ìœ¼ë¡œ, ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œëŠ” ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 224x224ë¡œ ì¡°ì •í•˜ê³  ìƒ‰ìƒ ì±„ë„ì˜ ìˆœì„œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•œ í›„ ë‹¨ì–´ì™€ ì •ê·œí™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì–»ê¸° ìœ„í•´ í…Œì„œë™íŠ¸ë¥¼ ì‚¬ìš©í•´ OCRë¥¼ ì ìš©í•©ë‹ˆë‹¤.
ì´ íŠœí† ë¦¬ì–¼ì—ì„œ ìš°ë¦¬ê°€ í•„ìš”í•œ ê²ƒê³¼ ê¸°ë³¸ê°’ì€ ì™„ì „íˆ ë™ì¼í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ë°°ì¹˜ì— ê¸°ë³¸ ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ì ìš©í•˜ê³  OCRì˜ ê²°ê³¼ë¥¼ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

```py
>>> image_processor = processor.image_processor


>>> def get_ocr_words_and_boxes(examples):
...     images = [image.convert("RGB") for image in examples["image"]]
...     encoded_inputs = image_processor(images)

...     examples["image"] = encoded_inputs.pixel_values
...     examples["words"] = encoded_inputs.words
...     examples["boxes"] = encoded_inputs.boxes

...     return examples
```

ì´ ì „ì²˜ë¦¬ë¥¼ ë°ì´í„° ì„¸íŠ¸ ì „ì²´ì— ë¹ ë¥´ê²Œ ì ìš©í•˜ë ¤ë©´ [`~datasets.Dataset.map`]ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

```py
>>> dataset_with_ocr = updated_dataset.map(get_ocr_words_and_boxes, batched=True, batch_size=2)
```

### í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ [[preprocessing-text-data]]

ì´ë¯¸ì§€ì— OCRì„ ì ìš©í–ˆìœ¼ë©´ ë°ì´í„° ì„¸íŠ¸ì˜ í…ìŠ¤íŠ¸ ë¶€ë¶„ì„ ëª¨ë¸ì— ë§ê²Œ ì¸ì½”ë”©í•´ì•¼ í•©ë‹ˆë‹¤.
ì´ ì¸ì½”ë”©ì—ëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ê°€ì ¸ì˜¨ ë‹¨ì–´ì™€ ë°•ìŠ¤ë¥¼ í† í° ìˆ˜ì¤€ì˜ `input_ids`, `attention_mask`, `token_type_ids` ë° `bbox`ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì´ í¬í•¨ë©ë‹ˆë‹¤.
í…ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ë ¤ë©´ í”„ë¡œì„¸ì„œì˜ `tokenizer`ê°€ í•„ìš”í•©ë‹ˆë‹¤.

```py
>>> tokenizer = processor.tokenizer
```

ìœ„ì—ì„œ ì–¸ê¸‰í•œ ì „ì²˜ë¦¬ ì™¸ì—ë„ ëª¨ë¸ì„ ìœ„í•´ ë ˆì´ë¸”ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ğŸ¤— Transformersì˜ `xxxForQuestionAnswering` ëª¨ë¸ì˜ ê²½ìš°, ë ˆì´ë¸”ì€ `start_positions`ì™€ `end_positions`ë¡œ êµ¬ì„±ë˜ë©° ì–´ë–¤ í† í°ì´ ë‹µë³€ì˜ ì‹œì‘ê³¼ ëì— ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

ë ˆì´ë¸” ì¶”ê°€ë¥¼ ìœ„í•´ì„œ, ë¨¼ì € ë” í° ë¦¬ìŠ¤íŠ¸(ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸)ì—ì„œ í•˜ìœ„ ë¦¬ìŠ¤íŠ¸(ë‹¨ì–´ë¡œ ë¶„í• ëœ ë‹µë³€)ì„ ì°¾ì„ ìˆ˜ ìˆëŠ” í—¬í¼ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

ì´ í•¨ìˆ˜ëŠ” `words_list`ì™€ `answer_list`, ì´ë ‡ê²Œ ë‘ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.
ê·¸ëŸ° ë‹¤ìŒ `words_list`ë¥¼ ë°˜ë³µí•˜ì—¬ `words_list`ì˜ í˜„ì¬ ë‹¨ì–´(words_list[i])ê°€ `answer_list`ì˜ ì²« ë²ˆì§¸ ë‹¨ì–´(answer_list[0])ì™€ ê°™ì€ì§€,
í˜„ì¬ ë‹¨ì–´ì—ì„œ ì‹œì‘í•´ `answer_list`ì™€ ê°™ì€ ê¸¸ì´ë§Œí¼ì˜ `words_list`ì˜ í•˜ìœ„ ë¦¬ìŠ¤íŠ¸ê°€ `answer_list`ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
ì´ ì¡°ê±´ì´ ì°¸ì´ë¼ë©´ ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ë°œê²¬í–ˆìŒì„ ì˜ë¯¸í•˜ë©°, í•¨ìˆ˜ëŠ” ì¼ì¹˜ í•­ëª©, ì‹œì‘ ì¸ë±ìŠ¤(idx) ë° ì¢…ë£Œ ì¸ë±ìŠ¤(idx + len(answer_list) - 1)ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤. ì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ë‘ ê°œ ì´ìƒ ë°œê²¬ë˜ë©´ í•¨ìˆ˜ëŠ” ì²« ë²ˆì§¸ í•­ëª©ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤. ì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ì—†ë‹¤ë©´ í•¨ìˆ˜ëŠ” (`None`, 0, 0)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

```py
>>> def subfinder(words_list, answer_list):
...     matches = []
...     start_indices = []
...     end_indices = []
...     for idx, i in enumerate(range(len(words_list))):
...         if words_list[i] == answer_list[0] and words_list[i : i + len(answer_list)] == answer_list:
...             matches.append(answer_list)
...             start_indices.append(idx)
...             end_indices.append(idx + len(answer_list) - 1)
...     if matches:
...         return matches[0], start_indices[0], end_indices[0]
...     else:
...         return None, 0, 0
```

ì´ í•¨ìˆ˜ê°€ ì–´ë–»ê²Œ ì •ë‹µì˜ ìœ„ì¹˜ë¥¼ ì°¾ëŠ”ì§€ ì„¤ëª…í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ì˜ˆì œì—ì„œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```py
>>> example = dataset_with_ocr["train"][1]
>>> words = [word.lower() for word in example["words"]]
>>> match, word_idx_start, word_idx_end = subfinder(words, example["answer"].lower().split())
>>> print("Question: ", example["question"])
>>> print("Words:", words)
>>> print("Answer: ", example["answer"])
>>> print("start_index", word_idx_start)
>>> print("end_index", word_idx_end)
Question:  Who is in  cc in this letter?
Words: ['wie', 'baw', 'brown', '&', 'williamson', 'tobacco', 'corporation', 'research', '&', 'development', 'internal', 'correspondence', 'to:', 'r.', 'h.', 'honeycutt', 'ce:', 't.f.', 'riehl', 'from:', '.', 'c.j.', 'cook', 'date:', 'may', '8,', '1995', 'subject:', 'review', 'of', 'existing', 'brainstorming', 'ideas/483', 'the', 'major', 'function', 'of', 'the', 'product', 'innovation', 'graup', 'is', 'to', 'develop', 'marketable', 'nove!', 'products', 'that', 'would', 'be', 'profitable', 'to', 'manufacture', 'and', 'sell.', 'novel', 'is', 'defined', 'as:', 'of', 'a', 'new', 'kind,', 'or', 'different', 'from', 'anything', 'seen', 'or', 'known', 'before.', 'innovation', 'is', 'defined', 'as:', 'something', 'new', 'or', 'different', 'introduced;', 'act', 'of', 'innovating;', 'introduction', 'of', 'new', 'things', 'or', 'methods.', 'the', 'products', 'may', 'incorporate', 'the', 'latest', 'technologies,', 'materials', 'and', 'know-how', 'available', 'to', 'give', 'then', 'a', 'unique', 'taste', 'or', 'look.', 'the', 'first', 'task', 'of', 'the', 'product', 'innovation', 'group', 'was', 'to', 'assemble,', 'review', 'and', 'categorize', 'a', 'list', 'of', 'existing', 'brainstorming', 'ideas.', 'ideas', 'were', 'grouped', 'into', 'two', 'major', 'categories', 'labeled', 'appearance', 'and', 'taste/aroma.', 'these', 'categories', 'are', 'used', 'for', 'novel', 'products', 'that', 'may', 'differ', 'from', 'a', 'visual', 'and/or', 'taste/aroma', 'point', 'of', 'view', 'compared', 'to', 'canventional', 'cigarettes.', 'other', 'categories', 'include', 'a', 'combination', 'of', 'the', 'above,', 'filters,', 'packaging', 'and', 'brand', 'extensions.', 'appearance', 'this', 'category', 'is', 'used', 'for', 'novel', 'cigarette', 'constructions', 'that', 'yield', 'visually', 'different', 'products', 'with', 'minimal', 'changes', 'in', 'smoke', 'chemistry', 'two', 'cigarettes', 'in', 'cne.', 'emulti-plug', 'te', 'build', 'yaur', 'awn', 'cigarette.', 'eswitchable', 'menthol', 'or', 'non', 'menthol', 'cigarette.', '*cigarettes', 'with', 'interspaced', 'perforations', 'to', 'enable', 'smoker', 'to', 'separate', 'unburned', 'section', 'for', 'future', 'smoking.', 'Â«short', 'cigarette,', 'tobacco', 'section', '30', 'mm.', 'Â«extremely', 'fast', 'buming', 'cigarette.', 'Â«novel', 'cigarette', 'constructions', 'that', 'permit', 'a', 'significant', 'reduction', 'iretobacco', 'weight', 'while', 'maintaining', 'smoking', 'mechanics', 'and', 'visual', 'characteristics.', 'higher', 'basis', 'weight', 'paper:', 'potential', 'reduction', 'in', 'tobacco', 'weight.', 'Â«more', 'rigid', 'tobacco', 'column;', 'stiffing', 'agent', 'for', 'tobacco;', 'e.g.', 'starch', '*colored', 'tow', 'and', 'cigarette', 'papers;', 'seasonal', 'promotions,', 'e.g.', 'pastel', 'colored', 'cigarettes', 'for', 'easter', 'or', 'in', 'an', 'ebony', 'and', 'ivory', 'brand', 'containing', 'a', 'mixture', 'of', 'all', 'black', '(black', 'paper', 'and', 'tow)', 'and', 'ail', 'white', 'cigarettes.', '499150498']
Answer:  T.F. Riehl
start_index 17
end_index 18
```

í•œí¸, ìœ„ ì˜ˆì œê°€ ì¸ì½”ë”©ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œë©ë‹ˆë‹¤:

```py
>>> encoding = tokenizer(example["question"], example["words"], example["boxes"])
>>> tokenizer.decode(encoding["input_ids"])
[CLS] who is in cc in this letter? [SEP] wie baw brown & williamson tobacco corporation research & development ...
```

ì´ì œ ì¸ì½”ë”©ëœ ì…ë ¥ì—ì„œ ì •ë‹µì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
* `token_type_ids`ëŠ” ì–´ë–¤ í† í°ì´ ì§ˆë¬¸ì— ì†í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ í† í°ì´ ë¬¸ì„œì˜ ë‹¨ì–´ì— í¬í•¨ë˜ëŠ”ì§€ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.
* `tokenizer.cls_token_id` ì…ë ¥ì˜ ì‹œì‘ ë¶€ë¶„ì— ìˆëŠ” íŠ¹ìˆ˜ í† í°ì„ ì°¾ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
* `word_ids`ëŠ” ì›ë³¸ `words`ì—ì„œ ì°¾ì€ ë‹µë³€ì„ ì „ì²´ ì¸ì½”ë”©ëœ ì…ë ¥ì˜ ë™ì¼í•œ ë‹µê³¼ ì¼ì¹˜ì‹œí‚¤ê³  ì¸ì½”ë”©ëœ ì…ë ¥ì—ì„œ ë‹µë³€ì˜ ì‹œì‘/ë ìœ„ì¹˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

ìœ„ ë‚´ìš©ë“¤ì„ ì—¼ë‘ì— ë‘ê³  ë°ì´í„° ì„¸íŠ¸ ì˜ˆì œì˜ ë°°ì¹˜ë¥¼ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤:

```py
>>> def encode_dataset(examples, max_length=512):
...     questions = examples["question"]
...     words = examples["words"]
...     boxes = examples["boxes"]
...     answers = examples["answer"]

...     # ì˜ˆì œ ë°°ì¹˜ë¥¼ ì¸ì½”ë”©í•˜ê³  start_positionsì™€ end_positionsë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
...     encoding = tokenizer(questions, words, boxes, max_length=max_length, padding="max_length", truncation=True)
...     start_positions = []
...     end_positions = []

...     # ë°°ì¹˜ì˜ ì˜ˆì œë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤
...     for i in range(len(questions)):
...         cls_index = encoding["input_ids"][i].index(tokenizer.cls_token_id)

...         # ì˜ˆì œì˜ wordsì—ì„œ ë‹µë³€ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤
...         words_example = [word.lower() for word in words[i]]
...         answer = answers[i]
...         match, word_idx_start, word_idx_end = subfinder(words_example, answer.lower().split())

...         if match:
...             # ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ë°œê²¬í•˜ë©´, `token_type_ids`ë¥¼ ì‚¬ìš©í•´ ì¸ì½”ë”©ì—ì„œ ë‹¨ì–´ê°€ ì‹œì‘í•˜ëŠ” ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤
...             token_type_ids = encoding["token_type_ids"][i]
...             token_start_index = 0
...             while token_type_ids[token_start_index] != 1:
...                 token_start_index += 1

...             token_end_index = len(encoding["input_ids"][i]) - 1
...             while token_type_ids[token_end_index] != 1:
...                 token_end_index -= 1

...             word_ids = encoding.word_ids(i)[token_start_index : token_end_index + 1]
...             start_position = cls_index
...             end_position = cls_index

...             # wordsì˜ ë‹µë³€ ìœ„ì¹˜ì™€ ì¼ì¹˜í•  ë•Œê¹Œì§€ word_idsë¥¼ ë°˜ë³µí•˜ê³  `token_start_index`ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤
...             # ì¼ì¹˜í•˜ë©´ `token_start_index`ë¥¼ ì¸ì½”ë”©ì—ì„œ ë‹µë³€ì˜ `start_position`ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤
...             for id in word_ids:
...                 if id == word_idx_start:
...                     start_position = token_start_index
...                 else:
...                     token_start_index += 1

...             # ë¹„ìŠ·í•˜ê²Œ, ëì—ì„œ ì‹œì‘í•´ `word_ids`ë¥¼ ë°˜ë³µí•˜ë©° ë‹µë³€ì˜ `end_position`ì„ ì°¾ìŠµë‹ˆë‹¤
...             for id in word_ids[::-1]:
...                 if id == word_idx_end:
...                     end_position = token_end_index
...                 else:
...                     token_end_index -= 1

...             start_positions.append(start_position)
...             end_positions.append(end_position)

...         else:
...             start_positions.append(cls_index)
...             end_positions.append(cls_index)

...     encoding["image"] = examples["image"]
...     encoding["start_positions"] = start_positions
...     encoding["end_positions"] = end_positions

...     return encoding
```

ì´ì œ ì´ ì „ì²˜ë¦¬ í•¨ìˆ˜ê°€ ìˆìœ¼ë‹ˆ ì „ì²´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì¸ì½”ë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
>>> encoded_train_dataset = dataset_with_ocr["train"].map(
...     encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr["train"].column_names
... )
>>> encoded_test_dataset = dataset_with_ocr["test"].map(
...     encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr["test"].column_names
... )
```

ì¸ì½”ë”©ëœ ë°ì´í„° ì„¸íŠ¸ì˜ íŠ¹ì„±ì´ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```py
>>> encoded_train_dataset.features
{'image': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='uint8', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),
 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),
 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),
 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),
 'bbox': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),
 'start_positions': Value(dtype='int64', id=None),
 'end_positions': Value(dtype='int64', id=None)}
```

## í‰ê°€ [[evaluation]]

ë¬¸ì„œ ì§ˆì˜ ì‘ë‹µì„ í‰ê°€í•˜ë ¤ë©´ ìƒë‹¹í•œ ì–‘ì˜ í›„ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‹œê°„ì´ ë„ˆë¬´ ë§ì´ ê±¸ë¦¬ì§€ ì•Šë„ë¡ ì´ ê°€ì´ë“œì—ì„œëŠ” í‰ê°€ ë‹¨ê³„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.
[`Trainer`]ê°€ í›ˆë ¨ ê³¼ì •ì—ì„œ í‰ê°€ ì†ì‹¤(evaluation loss)ì„ ê³„ì† ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ëŒ€ëµì ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì¶”ì¶œì (Extractive) ì§ˆì˜ ì‘ë‹µì€ ë³´í†µ F1/exact match ë°©ë²•ì„ ì‚¬ìš©í•´ í‰ê°€ë©ë‹ˆë‹¤.
ì§ì ‘ êµ¬í˜„í•´ë³´ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´, Hugging Face courseì˜ [Question Answering chapter](https://huggingface.co/course/chapter7/7?fw=pt#postprocessing)ì„ ì°¸ê³ í•˜ì„¸ìš”.

## í›ˆë ¨ [[train]]

ì¶•í•˜í•©ë‹ˆë‹¤! ì´ ê°€ì´ë“œì˜ ê°€ì¥ ì–´ë ¤ìš´ ë¶€ë¶„ì„ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìœ¼ë‹ˆ ì´ì œ ë‚˜ë§Œì˜ ëª¨ë¸ì„ í›ˆë ¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.
í›ˆë ¨ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤:
* ì „ì²˜ë¦¬ì—ì„œì˜ ë™ì¼í•œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ [`AutoModelForDocumentQuestionAnswering`]ìœ¼ë¡œ ëª¨ë¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
* [`TrainingArguments`]ë¡œ í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •í•©ë‹ˆë‹¤.
* ì˜ˆì œë¥¼ ë°°ì¹˜ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” [`DefaultDataCollator`]ê°€ ì ë‹¹í•©ë‹ˆë‹¤.
* ëª¨ë¸, ë°ì´í„° ì„¸íŠ¸, ë°ì´í„° ì½œë ˆì´í„°(Data collator)ì™€ í•¨ê»˜ [`Trainer`]ì— í›ˆë ¨ ì¸ìˆ˜ë“¤ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
* [`~Trainer.train`]ì„ í˜¸ì¶œí•´ì„œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.

```py
>>> from transformers import AutoModelForDocumentQuestionAnswering

>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained(model_checkpoint)
```

[`TrainingArguments`]ì—ì„œ `output_dir`ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì €ì¥í•  ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ê³ , ì ì ˆí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
ëª¨ë¸ì„ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•˜ë ¤ë©´ `push_to_hub`ë¥¼ `True`ë¡œ ì„¤ì •í•˜ì„¸ìš” (ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ë ¤ë©´ Hugging Faceì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤).
ì´ ê²½ìš° `output_dir`ì€ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ í‘¸ì‹œí•  ë ˆí¬ì§€í† ë¦¬ì˜ ì´ë¦„ì´ ë©ë‹ˆë‹¤.

```py
>>> from transformers import TrainingArguments

>>> # ë³¸ì¸ì˜ ë ˆí¬ì§€í† ë¦¬ IDë¡œ ë°”ê¾¸ì„¸ìš”
>>> repo_id = "MariaK/layoutlmv2-base-uncased_finetuned_docvqa"

>>> training_args = TrainingArguments(
...     output_dir=repo_id,
...     per_device_train_batch_size=4,
...     num_train_epochs=20,
...     save_steps=200,
...     logging_steps=50,
...     eval_strategy="steps",
...     learning_rate=5e-5,
...     save_total_limit=2,
...     remove_unused_columns=False,
...     push_to_hub=True,
... )
```

ê°„ë‹¨í•œ ë°ì´í„° ì½œë ˆì´í„°ë¥¼ ì •ì˜í•˜ì—¬ ì˜ˆì œë¥¼ í•¨ê»˜ ë°°ì¹˜í•©ë‹ˆë‹¤.

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator()
```

ë§ˆì§€ë§‰ìœ¼ë¡œ, ëª¨ë“  ê²ƒì„ í•œ ê³³ì— ëª¨ì•„ [`~Trainer.train`]ì„ í˜¸ì¶œí•©ë‹ˆë‹¤:

```py
>>> from transformers import Trainer

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     data_collator=data_collator,
...     train_dataset=encoded_train_dataset,
...     eval_dataset=encoded_test_dataset,
...     processing_class=processor,
... )

>>> trainer.train()
```

ìµœì¢… ëª¨ë¸ì„ ğŸ¤— Hubì— ì¶”ê°€í•˜ë ¤ë©´, ëª¨ë¸ ì¹´ë“œë¥¼ ìƒì„±í•˜ê³  `push_to_hub`ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤:

```py
>>> trainer.create_model_card()
>>> trainer.push_to_hub()
```

## ì¶”ë¡  [[inference]]

ì´ì œ LayoutLMv2 ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ê³  ğŸ¤— Hubì— ì—…ë¡œë“œí–ˆìœ¼ë‹ˆ ì¶”ë¡ ì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì¶”ë¡ ì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³´ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ [`Pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒ ì…ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤:
```py
>>> example = dataset["test"][2]
>>> question = example["query"]["en"]
>>> image = example["image"]
>>> print(question)
>>> print(example["answers"])
'Who is â€˜presidingâ€™ TRRF GENERAL SESSION (PART 1)?'
['TRRF Vice President', 'lee a. waller']
```

ê·¸ ë‹¤ìŒ, ëª¨ë¸ë¡œ ë¬¸ì„œ ì§ˆì˜ ì‘ë‹µì„ í•˜ê¸° ìœ„í•´ íŒŒì´í”„ë¼ì¸ì„ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ê³  ì´ë¯¸ì§€ + ì§ˆë¬¸ ì¡°í•©ì„ ì „ë‹¬í•©ë‹ˆë‹¤.

```py
>>> from transformers import pipeline

>>> qa_pipeline = pipeline("document-question-answering", model="MariaK/layoutlmv2-base-uncased_finetuned_docvqa")
>>> qa_pipeline(image, question)
[{'score': 0.9949808120727539,
  'answer': 'Lee A. Waller',
  'start': 55,
  'end': 57}]
```

ì›í•œë‹¤ë©´ íŒŒì´í”„ë¼ì¸ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:
1. ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ê°€ì ¸ì™€ ëª¨ë¸ì˜ í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì— ë§ê²Œ ì¤€ë¹„í•©ë‹ˆë‹¤.
2. ëª¨ë¸ì„ í†µí•´ ê²°ê³¼ ë˜ëŠ” ì „ì²˜ë¦¬ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
3. ëª¨ë¸ì€ ì–´ë–¤ í† í°ì´ ë‹µë³€ì˜ ì‹œì‘ì— ìˆëŠ”ì§€, ì–´ë–¤ í† í°ì´ ë‹µë³€ì´ ëì— ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” `start_logits`ì™€ `end_logits`ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ë‘˜ ë‹¤ (batch_size, sequence_length) í˜•íƒœë¥¼ ê°–ìŠµë‹ˆë‹¤.
4. `start_logits`ì™€ `end_logits`ì˜ ë§ˆì§€ë§‰ ì°¨ì›ì„ ìµœëŒ€ë¡œ ë§Œë“œëŠ” ê°’ì„ ì°¾ì•„ ì˜ˆìƒ `start_idx`ì™€ `end_idx`ë¥¼ ì–»ìŠµë‹ˆë‹¤.
5. í† í¬ë‚˜ì´ì €ë¡œ ë‹µë³€ì„ ë””ì½”ë”©í•©ë‹ˆë‹¤.

```py
>>> import torch
>>> from transformers import AutoProcessor
>>> from transformers import AutoModelForDocumentQuestionAnswering

>>> processor = AutoProcessor.from_pretrained("MariaK/layoutlmv2-base-uncased_finetuned_docvqa")
>>> model = AutoModelForDocumentQuestionAnswering.from_pretrained("MariaK/layoutlmv2-base-uncased_finetuned_docvqa")

>>> with torch.no_grad():
...     encoding = processor(image.convert("RGB"), question, return_tensors="pt")
...     outputs = model(**encoding)
...     start_logits = outputs.start_logits
...     end_logits = outputs.end_logits
...     predicted_start_idx = start_logits.argmax(-1).item()
...     predicted_end_idx = end_logits.argmax(-1).item()

>>> processor.tokenizer.decode(encoding.input_ids.squeeze()[predicted_start_idx : predicted_end_idx + 1])
'lee a. waller'
```
