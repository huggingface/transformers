<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Image-to-Image ì‘ì—… ê°€ì´ë“œ [[image-to-image-task-guide]]

[[open-in-colab]]

Image-to-Image ì‘ì—…ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ë˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì´ë¯¸ì§€ í–¥ìƒ(ì´ˆê³ í•´ìƒë„, ì €ì¡°ë„ í–¥ìƒ, ë¹—ì¤„ê¸° ì œê±° ë“±), ì´ë¯¸ì§€ ë³µì› ë“± ë‹¤ì–‘í•œ í•˜ìœ„ ì‘ì—…ì´ í¬í•¨ë©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œì—ì„œëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- ì´ˆê³ í•´ìƒë„ ì‘ì—…ì„ ìœ„í•œ image-to-image íŒŒì´í”„ë¼ì¸ ì‚¬ìš©,
- íŒŒì´í”„ë¼ì¸ ì—†ì´ ë™ì¼í•œ ì‘ì—…ì„ ìœ„í•œ image-to-image ëª¨ë¸ ì‹¤í–‰

ì´ ê°€ì´ë“œê°€ ë°œí‘œëœ ì‹œì ì—ì„œëŠ”, `image-to-image` íŒŒì´í”„ë¼ì¸ì€ ì´ˆê³ í•´ìƒë„ ì‘ì—…ë§Œ ì§€ì›í•œë‹¤ëŠ” ì ì„ ìœ ì˜í•˜ì„¸ìš”.

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.

```bash
pip install transformers
```

ì´ì œ [Swin2SR ëª¨ë¸](https://huggingface.co/caidas/swin2SR-lightweight-x2-64)ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ë¯¸ì§€ì™€ í•¨ê»˜ í˜¸ì¶œí•˜ì—¬ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì´ íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” [Swin2SR ëª¨ë¸](https://huggingface.co/caidas/swin2SR-lightweight-x2-64)ë§Œ ì§€ì›ë©ë‹ˆë‹¤.

```python
from transformers import pipeline

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
pipe = pipeline(task="image-to-image", model="caidas/swin2SR-lightweight-x2-64", device=device)
```

ì´ì œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì™€ ë´…ì‹œë‹¤.

```python
from PIL import Image
import requests

url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg"
image = Image.open(requests.get(url, stream=True).raw)

print(image.size)
```
```bash
# (532, 432)
```
<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg" alt="Photo of a cat"/>
</div>

ì´ì œ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê³ ì–‘ì´ ì´ë¯¸ì§€ì˜ ì—…ìŠ¤ì¼€ì¼ëœ ë²„ì „ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
upscaled = pipe(image)
print(upscaled.size)
```
```bash
# (1072, 880)
```

íŒŒì´í”„ë¼ì¸ ì—†ì´ ì§ì ‘ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ë ¤ë©´ Transformersì˜ `Swin2SRForImageSuperResolution` ë° `Swin2SRImageProcessor` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë™ì¼í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ì´ˆê¸°í™”í•´ ë³´ê² ìŠµë‹ˆë‹¤. 

```python
from transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor 

model = Swin2SRForImageSuperResolution.from_pretrained("caidas/swin2SR-lightweight-x2-64").to(device)
processor = Swin2SRImageProcessor("caidas/swin2SR-lightweight-x2-64")
```

`pipeline` ìš°ë¦¬ê°€ ì§ì ‘ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ” ì „ì²˜ë¦¬ì™€ í›„ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì¶”ìƒí™”í•˜ë¯€ë¡œ, ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ í”„ë¡œì„¸ì„œì— ì „ë‹¬í•œ ë‹¤ìŒ í”½ì…€ê°’ì„ GPUë¡œ ì´ë™ì‹œí‚¤ê² ìŠµë‹ˆë‹¤. 

```python
pixel_values = processor(image, return_tensors="pt").pixel_values
print(pixel_values.shape)

pixel_values = pixel_values.to(device)
```

ì´ì œ í”½ì…€ê°’ì„ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
import torch

with torch.no_grad():
  outputs = model(pixel_values)
```
ì¶œë ¥ì€ ì•„ë˜ì™€ ê°™ì€ `ImageSuperResolutionOutput` ìœ í˜•ì˜ ê°ì²´ì…ë‹ˆë‹¤ ğŸ‘‡ 

```
(loss=None, reconstruction=tensor([[[[0.8270, 0.8269, 0.8275,  ..., 0.7463, 0.7446, 0.7453],
          [0.8287, 0.8278, 0.8283,  ..., 0.7451, 0.7448, 0.7457],
          [0.8280, 0.8273, 0.8269,  ..., 0.7447, 0.7446, 0.7452],
          ...,
          [0.5923, 0.5933, 0.5924,  ..., 0.0697, 0.0695, 0.0706],
          [0.5926, 0.5932, 0.5926,  ..., 0.0673, 0.0687, 0.0705],
          [0.5927, 0.5914, 0.5922,  ..., 0.0664, 0.0694, 0.0718]]]],
       device='cuda:0'), hidden_states=None, attentions=None)
```
`reconstruction`ë¥¼ ê°€ì ¸ì™€ ì‹œê°í™”ë¥¼ ìœ„í•´ í›„ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤. ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ ì‚´í´ë´…ì‹œë‹¤.

```python
outputs.reconstruction.data.shape
# torch.Size([1, 3, 880, 1072])
```

ì¶œë ¥ í…ì„œì˜ ì°¨ì›ì„ ì¶•ì†Œí•˜ê³  0ë²ˆì§¸ ì¶•ì„ ì œê±°í•œ ë‹¤ìŒ, ê°’ì„ í´ë¦¬í•‘í•˜ê³  NumPy ë¶€ë™ì†Œìˆ˜ì  ë°°ì—´ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ [1072, 880] ëª¨ì–‘ì„ ê°–ë„ë¡ ì¶•ì„ ì¬ì •ë ¬í•˜ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ì¶œë ¥ì„ 0ê³¼ 255 ì‚¬ì´ì˜ ê°’ì„ ê°–ë„ë¡ ë˜ëŒë¦½ë‹ˆë‹¤.

```python
import numpy as np

# í¬ê¸°ë¥¼ ì¤„ì´ê³ , CPUë¡œ ì´ë™í•˜ê³ , ê°’ì„ í´ë¦¬í•‘
output = outputs.reconstruction.data.squeeze().cpu().clamp_(0, 1).numpy()
# ì¶•ì„ ì¬ì •ë ¬
output = np.moveaxis(output, source=0, destination=-1)
# ê°’ì„ í”½ì…€ê°’ ë²”ìœ„ë¡œ ë˜ëŒë¦¬ê¸°
output = (output * 255.0).round().astype(np.uint8)
Image.fromarray(output)
```
<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat_upscaled.png" alt="Upscaled photo of a cat"/>
</div>
