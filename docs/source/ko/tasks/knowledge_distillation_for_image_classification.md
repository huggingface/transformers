<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->
# ì»´í“¨í„° ë¹„ì „ì„ ìœ„í•œ ì§€ì‹ ì¦ë¥˜[[Knowledge-Distillation-for-Computer-Vision]]

[[open-in-colab]]

ì§€ì‹ ì¦ë¥˜(Knowledge distillation)ëŠ” ë” í¬ê³  ë³µì¡í•œ ëª¨ë¸(êµì‚¬)ì—ì„œ ë” ì‘ê³  ê°„ë‹¨í•œ ëª¨ë¸(í•™ìƒ)ë¡œ ì§€ì‹ì„ ì „ë‹¬í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. í•œ ëª¨ë¸ì—ì„œ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì§€ì‹ì„ ì¦ë¥˜í•˜ê¸° ìœ„í•´, íŠ¹ì • ì‘ì—…(ì´ ê²½ìš° ì´ë¯¸ì§€ ë¶„ë¥˜)ì— ëŒ€í•´ í•™ìŠµëœ ì‚¬ì „ í›ˆë ¨ëœ êµì‚¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , ëœë¤ìœ¼ë¡œ ì´ˆê¸°í™”ëœ í•™ìƒ ëª¨ë¸ì„ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì— ëŒ€í•´ í•™ìŠµí•©ë‹ˆë‹¤. ê·¸ë‹¤ìŒ, í•™ìƒ ëª¨ë¸ì´ êµì‚¬ ëª¨ë¸ì˜ ì¶œë ¥ì„ ëª¨ë°©í•˜ì—¬ ë‘ ëª¨ë¸ì˜ ì¶œë ¥ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ ê¸°ë²•ì€ Hinton ë“± ì—°êµ¬ì§„ì˜ [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)ì—ì„œ ì²˜ìŒ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œëŠ” íŠ¹ì • ì‘ì—…ì— ë§ì¶˜ ì§€ì‹ ì¦ë¥˜ë¥¼ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤. ì´ë²ˆì—ëŠ” [beans dataset](https://huggingface.co/datasets/beans)ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.

ì´ ê°€ì´ë“œëŠ” [ë¯¸ì„¸ ì¡°ì •ëœ ViT ëª¨ë¸](https://huggingface.co/merve/vit-mobilenet-beans-224) (êµì‚¬ ëª¨ë¸)ì„ [MobileNet](https://huggingface.co/google/mobilenet_v2_1.4_224) (í•™ìƒ ëª¨ë¸)ìœ¼ë¡œ ì¦ë¥˜í•˜ëŠ” ë°©ë²•ì„ ğŸ¤— Transformersì˜ [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer) ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì¦ë¥˜ì™€ ê³¼ì • í‰ê°€ë¥¼ ìœ„í•´ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ ë´…ì‹œë‹¤.


```bash
pip install transformers datasets accelerate tensorboard evaluate --upgrade
```

ì´ ì˜ˆì œì—ì„œëŠ” `merve/beans-vit-224` ëª¨ë¸ì„ êµì‚¬ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ beans ë°ì´í„°ì…‹ì—ì„œ íŒŒì¸ íŠœë‹ëœ `google/vit-base-patch16-224-in21k` ê¸°ë°˜ì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì„ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ëœ MobileNetV2ë¡œ ì¦ë¥˜í•´ë³¼ ê²ƒì…ë‹ˆë‹¤.

ì´ì œ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê² ìŠµë‹ˆë‹¤.

```python
from datasets import load_dataset

dataset = load_dataset("beans")
```

ì´ ê²½ìš° ë‘ ëª¨ë¸ì˜ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œê°€ ë™ì¼í•œ í•´ìƒë„ë¡œ ë™ì¼í•œ ì¶œë ¥ì„ ë°˜í™˜í•˜ê¸° ë•Œë¬¸ì—, ë‘ê°€ì§€ë¥¼ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì˜ ëª¨ë“  ë¶„í• ë§ˆë‹¤ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ `dataset`ì˜ `map()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•  ê²ƒ ì…ë‹ˆë‹¤.


```python
from transformers import AutoImageProcessor
teacher_processor = AutoImageProcessor.from_pretrained("merve/beans-vit-224")

def process(examples):
    processed_inputs = teacher_processor(examples["image"])
    return processed_inputs

processed_datasets = dataset.map(process, batched=True)
```

í•™ìƒ ëª¨ë¸(ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ëœ MobileNet)ì´ êµì‚¬ ëª¨ë¸(íŒŒì¸ íŠœë‹ëœ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸)ì„ ëª¨ë°©í•˜ë„ë¡ í•  ê²ƒ ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë¨¼ì € êµì‚¬ì™€ í•™ìƒ ëª¨ë¸ì˜ ë¡œì§“ ì¶œë ¥ê°’ì„ êµ¬í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ê° ì¶œë ¥ê°’ì„ ë§¤ê°œë³€ìˆ˜ `temperature` ê°’ìœ¼ë¡œ ë‚˜ëˆ„ëŠ”ë°, ì´ ë§¤ê°œë³€ìˆ˜ëŠ” ê° ì†Œí”„íŠ¸ íƒ€ê²Ÿì˜ ì¤‘ìš”ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ë§¤ê°œë³€ìˆ˜ `lambda` ëŠ” ì¦ë¥˜ ì†ì‹¤ì˜ ì¤‘ìš”ë„ì— ê°€ì¤‘ì¹˜ë¥¼ ì¤ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” `temperature=5`ì™€ `lambda=0.5`ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. í•™ìƒê³¼ êµì‚¬ ê°„ì˜ ë°œì‚°ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ Kullback-Leibler Divergence ì†ì‹¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‘ ë°ì´í„° Pì™€ Qê°€ ì£¼ì–´ì¡Œì„ ë•Œ, KL DivergenceëŠ” Që¥¼ ì‚¬ìš©í•˜ì—¬ Pë¥¼ í‘œí˜„í•˜ëŠ” ë° ì–¼ë§Œí¼ì˜ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œì§€ë¥¼ ë§í•´ì¤ë‹ˆë‹¤. ë‘ ë°ì´í„°ê°€ ë™ì¼í•˜ë‹¤ë©´, KL DivergenceëŠ” 0ì´ë©°, Që¡œ Pë¥¼ ì„¤ëª…í•˜ëŠ” ë° ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì§€ ì•ŠìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì§€ì‹ ì¦ë¥˜ì˜ ë§¥ë½ì—ì„œ KL DivergenceëŠ” ìœ ìš©í•©ë‹ˆë‹¤.


```python
from transformers import TrainingArguments, Trainer
import torch
import torch.nn as nn
import torch.nn.functional as F


class ImageDistilTrainer(Trainer):
    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None,  *args, **kwargs):
        super().__init__(model=student_model, *args, **kwargs)
        self.teacher = teacher_model
        self.student = student_model
        self.loss_function = nn.KLDivLoss(reduction="batchmean")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.teacher.to(device)
        self.teacher.eval()
        self.temperature = temperature
        self.lambda_param = lambda_param

    def compute_loss(self, student, inputs, return_outputs=False):
        student_output = self.student(**inputs)

        with torch.no_grad():
          teacher_output = self.teacher(**inputs)

        # Compute soft targets for teacher and student
        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)
        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)

        # Compute the loss
        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)

        # Compute the true label loss
        student_target_loss = student_output.loss

        # Calculate final loss
        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss
        return (loss, student_output) if return_outputs else loss
```

ì´ì œ Hugging Face Hubì— ë¡œê·¸ì¸í•˜ì—¬ `Trainer`ë¥¼ í†µí•´ Hugging Face Hubì— ëª¨ë¸ì„ í‘¸ì‹œí•  ìˆ˜ ìˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


```python
from huggingface_hub import notebook_login

notebook_login()
```

ì´ì œ `TrainingArguments`, êµì‚¬ ëª¨ë¸ê³¼ í•™ìƒ ëª¨ë¸ì„ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification

training_args = TrainingArguments(
    output_dir="my-awesome-model",
    num_train_epochs=30,
    fp16=True,
    logging_dir=f"{repo_name}/logs",
    logging_strategy="epoch",
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="tensorboard",
    push_to_hub=True,
    hub_strategy="every_save",
    hub_model_id=repo_name,
    )

num_labels = len(processed_datasets["train"].features["labels"].names)

# ëª¨ë¸ ì´ˆê¸°í™”
teacher_model = AutoModelForImageClassification.from_pretrained(
    "merve/beans-vit-224",
    num_labels=num_labels,
    ignore_mismatched_sizes=True
)

# MobileNetV2 ë°‘ë°”ë‹¥ë¶€í„° í•™ìŠµ
student_config = MobileNetV2Config()
student_config.num_labels = num_labels
student_model = MobileNetV2ForImageClassification(student_config)
```

`compute_metrics` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” í›ˆë ¨ ê³¼ì •ì—ì„œ ëª¨ë¸ì˜ `accuracy`ì™€ `f1`ì„ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.


```python
import evaluate
import numpy as np

accuracy = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))
    return {"accuracy": acc["accuracy"]}
```

ì •ì˜í•œ í›ˆë ¨ ì¸ìˆ˜ë¡œ `Trainer`ë¥¼ ì´ˆê¸°í™”í•´ë´…ì‹œë‹¤. ë˜í•œ ë°ì´í„° ì½œë ˆì´í„°(data collator)ë¥¼ ì´ˆê¸°í™”í•˜ê² ìŠµë‹ˆë‹¤.

```python
from transformers import DefaultDataCollator

data_collator = DefaultDataCollator()
trainer = ImageDistilTrainer(
    student_model=student_model,
    teacher_model=teacher_model,
    training_args=training_args,
    train_dataset=processed_datasets["train"],
    eval_dataset=processed_datasets["validation"],
    data_collator=data_collator,
    tokenizer=teacher_processor,
    compute_metrics=compute_metrics,
    temperature=5,
    lambda_param=0.5
)
```

ì´ì œ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
trainer.train()
```

ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
trainer.evaluate(processed_datasets["test"])
```


í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì •í™•ë„ëŠ” 72%ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì¦ë¥˜ì˜ íš¨ìœ¨ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ beans ë°ì´í„°ì…‹ì—ì„œ MobileNetì„ ì²˜ìŒë¶€í„° í›ˆë ¨í•˜ì˜€ê³ , í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œì˜ ì •í™•ë„ëŠ” 63% ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‚¬ì „ í›ˆë ¨ëœ êµì‚¬ ëª¨ë¸, í•™ìƒ êµ¬ì¡°, ì¦ë¥˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‹œë„í•´ë³´ì‹œê³  ê²°ê³¼ë¥¼ ë³´ê³ í•˜ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤. ì¦ë¥˜ëœ ëª¨ë¸ì˜ í›ˆë ¨ ë¡œê·¸ì™€ ì²´í¬í¬ì¸íŠ¸ëŠ” [ì´ ì €ì¥ì†Œ](https://huggingface.co/merve/vit-mobilenet-beans-224)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìœ¼ë©°, ì²˜ìŒë¶€í„° í›ˆë ¨ëœ MobileNetV2ëŠ” ì´ [ì €ì¥ì†Œ](https://huggingface.co/merve/resnet-mobilenet-beans-5)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
