<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# BART[[bart]]

<div class="flex flex-wrap space-x-1">
<a href="https://huggingface.co/models?filter=bart">
<img alt="Models" src="https://img.shields.io/badge/All_model_pages-bart-blueviolet">
</a>
<a href="https://huggingface.co/spaces/docs-demos/bart-large-mnli">
<img alt="Spaces" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue">
</a>
</div>

## ê°œìš” [[overview]]

Bart ëª¨ë¸ì€ 2019ë…„ 10ì›” 29ì¼ Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyerê°€ ë°œí‘œí•œ [BART: ìì—°ì–´ ìƒì„±, ë²ˆì—­, ì´í•´ë¥¼ ìœ„í•œ ì¡ìŒ ì œê±° seq2seq ì‚¬ì „ í›ˆë ¨](https://arxiv.org/abs/1910.13461)ì´ë¼ëŠ” ë…¼ë¬¸ì—ì„œ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤.

ë…¼ë¬¸ì˜ ì´ˆë¡ì— ë”°ë¥´ë©´,

- BartëŠ” ì–‘ë°©í–¥ ì¸ì½”ë”(BERTì™€ ìœ ì‚¬)ì™€ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë””ì½”ë”©í•˜ëŠ” ë””ì½”ë”(GPTì™€ ìœ ì‚¬)ë¥¼ ì‚¬ìš©í•˜ëŠ” í‘œì¤€ seq2seq/ê¸°ê³„ ë²ˆì—­ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì€ ì›ë˜ ë¬¸ì¥ì˜ ìˆœì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ê³ , í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ êµ¬ê°„ì„ ë‹¨ì¼ ë§ˆìŠ¤í¬ í† í°ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ìƒˆë¡œìš´ ì¸í•„ë§(in-filling) ë°©ì‹ì„ í¬í•¨í•©ë‹ˆë‹¤.
- BARTëŠ” íŠ¹íˆ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ë¯¸ì„¸ ì¡°ì •ì— íš¨ê³¼ì ì´ì§€ë§Œ ì´í•´ ì‘ì—…ì—ë„ ì˜ ì‘ë™í•©ë‹ˆë‹¤. GLUEì™€ SQuADì—ì„œ ë¹„ìŠ·í•œ í›ˆë ¨ ë¦¬ì†ŒìŠ¤ë¡œ RoBERTaì˜ ì„±ëŠ¥ê³¼ ì¼ì¹˜í•˜ë©°, ì¶”ìƒì  ëŒ€í™”, ì§ˆì˜ì‘ë‹µ, ìš”ì•½ ì‘ì—… ë“±ì—ì„œ ìµœëŒ€ 6 ROUGE ì ìˆ˜ì˜ í–¥ìƒì„ ë³´ì´ë©° ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

ì´ ëª¨ë¸ì€ [sshleifer](https://huggingface.co/sshleifer)ì— ì˜í•´ ê¸°ì—¬ ë˜ì—ˆìŠµë‹ˆë‹¤. ì €ìì˜ ì½”ë“œëŠ” [ì´ê³³](https://github.com/pytorch/fairseq/tree/master/examples/bart)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì‚¬ìš© íŒ:[[usage-tips]]

- BARTëŠ” ì ˆëŒ€ ìœ„ì¹˜ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì´ë¯€ë¡œ ì¼ë°˜ì ìœ¼ë¡œ ì…ë ¥ì„ ì™¼ìª½ë³´ë‹¤ëŠ” ì˜¤ë¥¸ìª½ì— íŒ¨ë”©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì¸ì½”ë”ì™€ ë””ì½”ë”ê°€ ìˆëŠ” seq2seq ëª¨ë¸ì…ë‹ˆë‹¤. ì¸ì½”ë”ì—ëŠ” ì†ìƒëœ í† í°ì´(corrupted tokens) ì…ë ¥ë˜ê³ , ë””ì½”ë”ì—ëŠ” ì›ë˜ í† í°ì´ ì…ë ¥ë©ë‹ˆë‹¤(ë‹¨, ì¼ë°˜ì ì¸ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”ì²˜ëŸ¼ ë¯¸ë˜ ë‹¨ì–´ë¥¼ ìˆ¨ê¸°ëŠ” ë§ˆìŠ¤í¬ê°€ ìˆìŠµë‹ˆë‹¤). ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì—ì„œ ì¸ì½”ë”ì— ì ìš©ë˜ëŠ” ë³€í™˜ë“¤ì˜ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì—ì„œ ì¸ì½”ë”ì— ì ìš©ë˜ëŠ” ë³€í™˜ë“¤ì˜ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

  * ë¬´ì‘ìœ„ í† í° ë§ˆìŠ¤í‚¹ (BERT ì²˜ëŸ¼)
  * ë¬´ì‘ìœ„ í† í° ì‚­ì œ
  * kê°œ í† í°ì˜ ë²”ìœ„ë¥¼ ë‹¨ì¼ ë§ˆìŠ¤í¬ í† í°ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ (0ê°œ í† í°ì˜ ë²”ìœ„ëŠ” ë§ˆìŠ¤í¬ í† í°ì˜ ì‚½ì…ì„ ì˜ë¯¸)
  * ë¬¸ì¥ ìˆœì„œ ë’¤ì„ê¸°
  * íŠ¹ì • í† í°ì—ì„œ ì‹œì‘í•˜ë„ë¡ ë¬¸ì„œ íšŒì „

## êµ¬í˜„ ë…¸íŠ¸[[implementation-notes]]

- BartëŠ” ì‹œí€€ìŠ¤ ë¶„ë¥˜ì— `token_type_ids`ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì ì ˆí•˜ê²Œ ë‚˜ëˆ„ê¸° ìœ„í•´ì„œ [`BartTokenizer`]ë‚˜
  [`~BartTokenizer.encode`]ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- [`BartModel`]ì˜ ì •ë°©í–¥ ì „ë‹¬ì€ `decoder_input_ids`ê°€ ì „ë‹¬ë˜ì§€ ì•Šìœ¼ë©´ `decoder_input_ids`ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ë‹¤ë¥¸ ì¼ë¶€ ëª¨ë¸ë§ APIì™€ ë‹¤ë¥¸ ì ì…ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì˜ ì¼ë°˜ì ì¸ ì‚¬ìš© ì‚¬ë¡€ëŠ” ë§ˆìŠ¤í¬ ì±„ìš°ê¸°(mask filling)ì…ë‹ˆë‹¤.
-  ëª¨ë¸ ì˜ˆì¸¡ì€ `forced_bos_token_id=0`ì¼ ë•Œ ê¸°ì¡´ êµ¬í˜„ê³¼ ë™ì¼í•˜ê²Œ ì‘ë™í•˜ë„ë¡ ì˜ë„ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, [`fairseq.encode`]ì— ì „ë‹¬í•˜ëŠ” ë¬¸ìì—´ì´ ê³µë°±ìœ¼ë¡œ ì‹œì‘í•  ë•Œë§Œ ì´ ê¸°ëŠ¥ì´ ì‘ë™í•©ë‹ˆë‹¤.
- [`~generation.GenerationMixin.generate`]ëŠ” ìš”ì•½ê³¼ ê°™ì€ ì¡°ê±´ë¶€ ìƒì„± ì‘ì—…ì— ì‚¬ìš©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ í•´ë‹¹ ë¬¸ì„œì˜ ì˜ˆì œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
- *facebook/bart-large-cnn* ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ëŠ” ëª¨ë¸ì€ `mask_token_id`ê°€ ì—†ê±°ë‚˜, ë§ˆìŠ¤í¬ ì±„ìš°ê¸° ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

## ë§ˆìŠ¤í¬ ì±„ìš°ê¸°[[mask-filling]]

`facebook/bart-base`ì™€ `facebook/bart-large` ì²´í¬í¬ì¸íŠ¸ëŠ” ë©€í‹° í† í° ë§ˆìŠ¤í¬ë¥¼ ì±„ìš°ëŠ”ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from transformers import BartForConditionalGeneration, BartTokenizer

model = BartForConditionalGeneration.from_pretrained("facebook/bart-large", forced_bos_token_id=0)
tok = BartTokenizer.from_pretrained("facebook/bart-large")
example_english_phrase = "UN Chief Says There Is No <mask> in Syria"
batch = tok(example_english_phrase, return_tensors="pt")
generated_ids = model.generate(batch["input_ids"])
assert tok.batch_decode(generated_ids, skip_special_tokens=True) == [
    "UN Chief Says There Is No Plan to Stop Chemical Weapons in Syria"
]
```

## ìë£Œ[[resources]]

BARTë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©ë¡(ğŸŒë¡œ í‘œì‹œë¨) ì…ë‹ˆë‹¤. ì—¬ê¸°ì— í¬í•¨ë  ìë£Œë¥¼ ì œì¶œí•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ PR(Pull Request)ë¥¼ ì—´ì–´ì£¼ì„¸ìš”. ë¦¬ë·° í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ìë£ŒëŠ” ê¸°ì¡´ ìë£Œë¥¼ ë³µì œí•˜ëŠ” ëŒ€ì‹  ìƒˆë¡œìš´ ë‚´ìš©ì„ ë‹´ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

<PipelineTag pipeline="summarization"/>

- [ë¶„ì‚°í˜• í•™ìŠµ: ğŸ¤— Transformersì™€ Amazon SageMakerë¥¼ ì´ìš©í•˜ì—¬ ìš”ì•½í•˜ê¸° ìœ„í•œ BART/T5 í•™ìŠµ](https://huggingface.co/blog/sagemaker-distributed-training-seq2seq)ì— ëŒ€í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸.
- [blurrë¥¼ ì´ìš©í•˜ì—¬ fastaië¡œ ìš”ì•½í•˜ê¸° ìœ„í•œ BARTë¥¼ ë¯¸ì„¸ ì¡°ì •](https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb)í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ë…¸íŠ¸ë¶. ğŸŒ
- [Trainer í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°€ì§€ ì–¸ì–´ë¡œ ìš”ì•½í•˜ê¸° ìœ„í•œ BART ë¯¸ì„¸ ì¡°ì •](https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb)í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ë…¸íŠ¸ë¶. ğŸŒ
- ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)ì—ì„œëŠ”  [`BartForConditionalGeneration`]ì´ ì§€ì›ë©ë‹ˆë‹¤.
- [`TFBartForConditionalGeneration`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)ì—ì„œ ì§€ì›ë©ë‹ˆë‹¤.
- ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ì—ì„œëŠ”](https://github.com/huggingface/transformers/tree/main/examples/flax/summarization)[`FlaxBartForConditionalGeneration`]ì´ ì§€ì›ë©ë‹ˆë‹¤.
- Hugging Face `datasets` ê°ì²´ë¥¼ í™œìš©í•˜ì—¬ [`BartForConditionalGeneration`]ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì˜ ì˜ˆëŠ” ì´ [í¬ëŸ¼ í† ë¡ ](https://discuss.huggingface.co/t/train-bart-for-conditional-generation-e-g-summarization/1904)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ğŸ¤— Hugging Face ì½”ìŠ¤ì˜ [ìš”ì•½](https://huggingface.co/course/chapter7/5?fw=pt#summarization)ì¥.
- [ìš”ì•½ ì‘ì—… ê°€ì´ë“œ](../tasks/summarization)

<PipelineTag pipeline="fill-mask"/>

- [`BartForConditionalGeneration`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling#robertabertdistilbert-and-masked-language-modeling)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)ì„ ì°¸ê³ í•˜ì„¸ìš”.
- [`TFBartForConditionalGeneration`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/language-modeling#run_mlmpy)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)ì„ ì°¸ê³ í•˜ì„¸ìš”.
- [`FlaxBartForConditionalGeneration`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#masked-language-modeling)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/masked_language_modeling_flax.ipynb)ì„ ì°¸ê³  í•˜ì„¸ìš”.
- ğŸ¤— Hugging Face ì½”ìŠ¤ì˜ [ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§](https://huggingface.co/course/chapter7/3?fw=pt) ì±•í„°.
- [ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ ì‘ì—… ê°€ì´ë“œ](../tasks/masked_language_modeling)

<PipelineTag pipeline="translation"/>

- [Seq2SeqTrainerë¥¼ ì´ìš©í•˜ì—¬ ì¸ë„ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” mBARTë¥¼ ë¯¸ì„¸ ì¡°ì •](https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb)í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ê°€ì´ë“œ. ğŸŒ
- [`BartForConditionalGeneration`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/pytorch/translation)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)ì„ ì°¸ê³ í•˜ì„¸ìš”.
- [`TFBartForConditionalGeneration`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/translation)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)ì„ ì°¸ê³  í•˜ì„¸ìš”.
- [ë²ˆì—­ ì‘ì—… ê°€ì´ë“œ](../tasks/translation)

ì¶”ê°€ì ìœ¼ë¡œ ë³¼ ê²ƒë“¤:
- [í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‘ì—… ê°€ì´ë“œ](../tasks/sequence_classification)
- [ì§ˆë¬¸ ë‹µë³€ ì‘ì—… ê°€ì´ë“œ](../tasks/question_answering)
- [ì¸ê³¼ì  ì–¸ì–´ ëª¨ë¸ë§ ì‘ì—… ê°€ì´ë“œ](../tasks/language_modeling)
- ì´ [ë…¼ë¬¸](https://arxiv.org/abs/2010.13002)ì€ [ì¦ë¥˜ëœ ì²´í¬í¬ì¸íŠ¸](https://huggingface.co/models?search=distilbart)ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

## BartConfig[[transformers.BartConfig]]

[[autodoc]] BartConfig
    - all

## BartTokenizer[[transformers.BartTokenizer]]

[[autodoc]] BartTokenizer
    - all

## BartTokenizerFast[[transformers.BartTokenizerFast]]

[[autodoc]] BartTokenizerFast
    - all


<frameworkcontent>
<pt>

## BartModel[[transformers.BartModel]]

[[autodoc]] BartModel
    - forward

## BartForConditionalGeneration[[transformers.BartForConditionalGeneration]]

[[autodoc]] BartForConditionalGeneration
    - forward

## BartForSequenceClassification[[transformers.BartForSequenceClassification]]

[[autodoc]] BartForSequenceClassification
    - forward

## BartForQuestionAnswering[[transformers.BartForQuestionAnswering]]

[[autodoc]] BartForQuestionAnswering
    - forward

## BartForCausalLM[[transformers.BartForCausalLM]]

[[autodoc]] BartForCausalLM
    - forward

</pt>
<tf>

## TFBartModel[[transformers.TFBartModel]]

[[autodoc]] TFBartModel
    - call

## TFBartForConditionalGeneration[[transformers.TFBartForConditionalGeneration]]

[[autodoc]] TFBartForConditionalGeneration
    - call

## TFBartForSequenceClassification[[transformers.TFBartForSequenceClassification]]

[[autodoc]] TFBartForSequenceClassification
    - call

</tf>
<jax>

## FlaxBartModel[[transformers.FlaxBartModel]]

[[autodoc]] FlaxBartModel
    - __call__
    - encode
    - decode

## FlaxBartForConditionalGeneration[[transformers.FlaxBartForConditionalGeneration]]

[[autodoc]] FlaxBartForConditionalGeneration
    - __call__
    - encode
    - decode

## FlaxBartForSequenceClassification[[transformers.FlaxBartForSequenceClassification]]

[[autodoc]] FlaxBartForSequenceClassification
    - __call__
    - encode
    - decode

## FlaxBartForQuestionAnswering[[transformers.FlaxBartForQuestionAnswering]]

[[autodoc]] FlaxBartForQuestionAnswering
    - __call__
    - encode
    - decode

## FlaxBartForCausalLM[[transformers.FlaxBartForCausalLM]]

[[autodoc]] FlaxBartForCausalLM
    - __call__
</jax>
</frameworkcontent>



