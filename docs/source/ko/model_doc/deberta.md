<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# DeBERTa[[deberta]]

## ê°œìš”[[overview]]


DeBERTa ëª¨ë¸ì€ Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chenì´ ì‘ì„±í•œ [DeBERTa: ë¶„ë¦¬ëœ ì–´í…ì…˜ì„ í™œìš©í•œ ë””ì½”ë”© ê°•í™” BERT](https://arxiv.org/abs/2006.03654)ì´ë¼ëŠ” ë…¼ë¬¸ì—ì„œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 2018ë…„ Googleì´ ë°œí‘œí•œ BERT ëª¨ë¸ê³¼ 2019ë…„ Facebookì´ ë°œí‘œí•œ RoBERTa ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.
DeBERTaëŠ” RoBERTaì—ì„œ ì‚¬ìš©ëœ ë°ì´í„°ì˜ ì ˆë°˜ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¦¬ëœ(disentangled) ì–´í…ì…˜ê³¼ í–¥ìƒëœ ë§ˆìŠ¤í¬ ë””ì½”ë” í•™ìŠµì„ í†µí•´ RoBERTaë¥¼ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

ë…¼ë¬¸ì˜ ì´ˆë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

*ì‚¬ì „ í•™ìŠµëœ ì‹ ê²½ë§ ì–¸ì–´ ëª¨ë¸ì˜ ìµœê·¼ ë°œì „ì€ ë§ì€ ìì—°ì–´ ì²˜ë¦¬(NLP) ì‘ì—…ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‘ ê°€ì§€ ìƒˆë¡œìš´ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ BERTì™€ RoBERTa ëª¨ë¸ì„ ê°œì„ í•œ ìƒˆë¡œìš´ ëª¨ë¸ êµ¬ì¡°ì¸ DeBERTaë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ë¶„ë¦¬ëœ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ, ê° ë‹¨ì–´ê°€ ë‚´ìš©ê³¼ ìœ„ì¹˜ë¥¼ ê°ê° ì¸ì½”ë”©í•˜ëŠ” ë‘ ê°œì˜ ë²¡í„°ë¡œ í‘œí˜„ë˜ë©°, ë‹¨ì–´ë“¤ ê°„ì˜ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ëŠ” ë‚´ìš©ê³¼ ìƒëŒ€ì  ìœ„ì¹˜ì— ëŒ€í•œ ë¶„ë¦¬ëœ í–‰ë ¬ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ, ëª¨ë¸ ì‚¬ì „ í•™ìŠµì„ ìœ„í•´ ë§ˆìŠ¤í‚¹ëœ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” ì¶œë ¥ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì¸µì„ ëŒ€ì²´í•˜ëŠ” í–¥ìƒëœ ë§ˆìŠ¤í¬ ë””ì½”ë”ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ ë‘ ê°€ì§€ ê¸°ìˆ ì´ ëª¨ë¸ ì‚¬ì „ í•™ìŠµì˜ íš¨ìœ¨ì„±ê³¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. RoBERTa-Largeì™€ ë¹„êµí–ˆì„ ë•Œ, ì ˆë°˜ì˜ í•™ìŠµ ë°ì´í„°ë¡œ í•™ìŠµëœ DeBERTa ëª¨ë¸ì€ ê´‘ë²”ìœ„í•œ NLP ì‘ì—…ì—ì„œ ì¼ê´€ë˜ê²Œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, MNLIì—ì„œ +0.9%(90.2% vs 91.1%), SQuAD v2.0ì—ì„œ +2.3%(88.4% vs 90.7%), RACEì—ì„œ +3.6%(83.2% vs 86.8%)ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. DeBERTa ì½”ë“œì™€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì€ https://github.com/microsoft/DeBERTa ì—ì„œ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.*

[DeBERTa](https://huggingface.co/DeBERTa) ëª¨ë¸ì˜ í…ì„œí”Œë¡œ 2.0 êµ¬í˜„ì€ [kamalkraj](https://huggingface.co/kamalkraj)ê°€ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ì½”ë“œëŠ” [ì´ê³³](https://github.com/microsoft/DeBERTa)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë¦¬ì†ŒìŠ¤[[resources]]


DeBERTaë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©ë¡(ğŸŒë¡œ í‘œì‹œë¨) ì…ë‹ˆë‹¤. ì—¬ê¸°ì— í¬í•¨ë  ìë£Œë¥¼ ì œì¶œí•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ PR(Pull Request)ë¥¼ ì—´ì–´ì£¼ì„¸ìš”. ë¦¬ë·°í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ìë£ŒëŠ” ê¸°ì¡´ ìë£Œë¥¼ ë³µì œí•˜ëŠ” ëŒ€ì‹  ìƒˆë¡œìš´ ë‚´ìš©ì„ ë‹´ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.


<PipelineTag pipeline="text-classification"/>

- DeBERTaì™€ [DeepSpeedë¥¼ ì´ìš©í•´ì„œ ëŒ€í˜• ëª¨ë¸ í•™ìŠµì„ ê°€ì†ì‹œí‚¤ëŠ”](https://huggingface.co/blog/accelerate-deepspeed) ë°©ë²•ì— ëŒ€í•œ í¬ìŠ¤íŠ¸.
- DeBERTaì™€ [ë¨¸ì‹ ëŸ¬ë‹ìœ¼ë¡œ í•œì¸µ í–¥ìƒëœ ê³ ê° ì„œë¹„ìŠ¤](https://huggingface.co/blog/supercharge-customer-service-with-machine-learning)ì— ëŒ€í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸.
- [`DebertaForSequenceClassification`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)ì—ì„œ ì§€ì›ë©ë‹ˆë‹¤.
- [`TFDebertaForSequenceClassification`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/text-classification)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)ì—ì„œ ì§€ì›ë©ë‹ˆë‹¤.
- [í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‘ì—… ê°€ì´ë“œ](../tasks/sequence_classification)

<PipelineTag pipeline="token-classification" />

- [`DebertaForTokenClassification`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤.
- [`TFDebertaForTokenClassification`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/token-classification)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤.
- ğŸ¤— Hugging Face ì½”ìŠ¤ì˜ [í† í° ë¶„ë¥˜](https://huggingface.co/course/chapter7/2?fw=pt) ì¥.
- ğŸ¤— Hugging Face ì½”ìŠ¤ì˜ [BPE(Byte-Pair Encoding) í† í°í™”](https://huggingface.co/course/chapter6/5?fw=pt) ì¥.
- [í† í° ë¶„ë¥˜ ì‘ì—… ê°€ì´ë“œ](../tasks/token_classification)

<PipelineTag pipeline="fill-mask"/>

- [`DebertaForMaskedLM`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling#robertabertdistilbert-and-masked-language-modeling)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤.
- [`TFDebertaForMaskedLM`]ì€ ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/language-modeling#run_mlmpy)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤.
- ğŸ¤— Hugging Face ì½”ìŠ¤ì˜ [ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§](https://huggingface.co/course/chapter7/3?fw=pt) ì¥.
- [ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ ì‘ì—… ê°€ì´ë“œ](../tasks/masked_language_modeling)

<PipelineTag pipeline="question-answering"/>

- [`DebertaForQuestionAnswering`]ì€ ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤.
- [`TFDebertaForQuestionAnswering`]ëŠ” ì´ [ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/question-answering)ì™€ [ë…¸íŠ¸ë¶](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤.
- ğŸ¤— Hugging Face ì½”ìŠ¤ì˜ [ì§ˆì˜ì‘ë‹µ(Question answering)](https://huggingface.co/course/chapter7/7?fw=pt) ì¥.
- [ì§ˆì˜ì‘ë‹µ ì‘ì—… ê°€ì´ë“œ](../tasks/question_answering)

## DebertaConfig[[transformers.DebertaConfig]]

[[autodoc]] DebertaConfig

## DebertaTokenizer[[transformers.DebertaTokenizer]]

[[autodoc]] DebertaTokenizer
    - build_inputs_with_special_tokens
    - get_special_tokens_mask
    - create_token_type_ids_from_sequences
    - save_vocabulary

## DebertaTokenizerFast[[transformers.DebertaTokenizerFast]]

[[autodoc]] DebertaTokenizerFast
    - build_inputs_with_special_tokens
    - create_token_type_ids_from_sequences

<frameworkcontent>
<pt>

## DebertaModel[[transformers.DebertaModel]]

[[autodoc]] DebertaModel
    - forward

## DebertaPreTrainedModel[[transformers.DebertaPreTrainedModel]]

[[autodoc]] DebertaPreTrainedModel

## DebertaForMaskedLM[[transformers.DebertaForMaskedLM]]

[[autodoc]] DebertaForMaskedLM
    - forward

## DebertaForSequenceClassification[[transformers.DebertaForSequenceClassification]]

[[autodoc]] DebertaForSequenceClassification
    - forward

## DebertaForTokenClassification[[transformers.DebertaForTokenClassification]]

[[autodoc]] DebertaForTokenClassification
    - forward

## DebertaForQuestionAnswering[[transformers.DebertaForQuestionAnswering]]

[[autodoc]] DebertaForQuestionAnswering
    - forward

</pt>
<tf>

## TFDebertaModel[[transformers.TFDebertaModel]]

[[autodoc]] TFDebertaModel
    - call

## TFDebertaPreTrainedModel[[transformers.TFDebertaPreTrainedModel]]

[[autodoc]] TFDebertaPreTrainedModel
    - call

## TFDebertaForMaskedLM[[transformers.TFDebertaForMaskedLM]]

[[autodoc]] TFDebertaForMaskedLM
    - call

## TFDebertaForSequenceClassification[[transformers.TFDebertaForSequenceClassification]]

[[autodoc]] TFDebertaForSequenceClassification
    - call

## TFDebertaForTokenClassification[[transformers.TFDebertaForTokenClassification]]

[[autodoc]] TFDebertaForTokenClassification
    - call

## TFDebertaForQuestionAnswering[[transformers.TFDebertaForQuestionAnswering]]

[[autodoc]] TFDebertaForQuestionAnswering
    - call

</tf>
</frameworkcontent>

