<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ì–´ë–»ê²Œ ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•˜ë‚˜ìš”? [[how-to-create-a-custom-pipeline]]

ì´ ê°€ì´ë“œì—ì„œëŠ” ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ì„ ì–´ë–»ê²Œ ìƒì„±í•˜ê³  [í—ˆë¸Œ](https://hf.co/models)ì— ê³µìœ í•˜ê±°ë‚˜ ğŸ¤— Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

ë¨¼ì € íŒŒì´í”„ë¼ì¸ì´ ìˆ˜ìš©í•  ìˆ˜ ìˆëŠ” ì›ì‹œ ì…ë ¥ì„ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.
ë¬¸ìì—´, ì›ì‹œ ë°”ì´íŠ¸, ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ê°€ì¥ ì›í•˜ëŠ” ì…ë ¥ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²ƒì´ë©´ ë¬´ì—‡ì´ë“  ê°€ëŠ¥í•©ë‹ˆë‹¤.
ì´ ì…ë ¥ì„ ê°€ëŠ¥í•œ í•œ ìˆœìˆ˜í•œ Python í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•´ì•¼ (JSONì„ í†µí•´ ë‹¤ë¥¸ ì–¸ì–´ì™€ë„) í˜¸í™˜ì„±ì´ ì¢‹ì•„ì§‘ë‹ˆë‹¤.
ì´ê²ƒì´ ì „ì²˜ë¦¬(`preprocess`) íŒŒì´í”„ë¼ì¸ì˜ ì…ë ¥(`inputs`)ì´ ë  ê²ƒì…ë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ `outputs`ë¥¼ ì •ì˜í•˜ì„¸ìš”.
`inputs`ì™€ ê°™ì€ ì •ì±…ì„ ë”°ë¥´ê³ , ê°„ë‹¨í• ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.
ì´ê²ƒì´ í›„ì²˜ë¦¬(`postprocess`) ë©”ì†Œë“œì˜ ì¶œë ¥ì´ ë  ê²ƒì…ë‹ˆë‹¤.

ë¨¼ì € 4ê°œì˜ ë©”ì†Œë“œ(`preprocess`, `_forward`, `postprocess` ë° `_sanitize_parameters`)ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ ê¸°ë³¸ í´ë˜ìŠ¤ `Pipeline`ì„ ìƒì†í•˜ì—¬ ì‹œì‘í•©ë‹ˆë‹¤.


```python
from transformers import Pipeline


class MyPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "maybe_arg" in kwargs:
            preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, inputs, maybe_arg=2):
        model_input = Tensor(inputs["input_ids"])
        return {"model_input": model_input}

    def _forward(self, model_inputs):
        # model_inputs == {"model_input": model_input}
        outputs = self.model(**model_inputs)
        # Maybe {"logits": Tensor(...)}
        return outputs

    def postprocess(self, model_outputs):
        best_class = model_outputs["logits"].softmax(-1)
        return best_class
```

ì´ ë¶„í•  êµ¬ì¡°ëŠ” CPU/GPUì— ëŒ€í•œ ë¹„êµì  ì›í™œí•œ ì§€ì›ì„ ì œê³µí•˜ëŠ” ë™ì‹œì—, ë‹¤ë¥¸ ìŠ¤ë ˆë“œì—ì„œ CPUì— ëŒ€í•œ ì‚¬ì „/ì‚¬í›„ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ì§€ì›í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

`preprocess`ëŠ” ì›ë˜ ì •ì˜ëœ ì…ë ¥ì„ ê°€ì ¸ì™€ ëª¨ë¸ì— ê³µê¸‰í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
ë” ë§ì€ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë©° ì¼ë°˜ì ìœ¼ë¡œ `Dict` í˜•íƒœì…ë‹ˆë‹¤.

`_forward`ëŠ” êµ¬í˜„ ì„¸ë¶€ ì‚¬í•­ì´ë©° ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
`forward`ëŠ” ì˜ˆìƒ ì¥ì¹˜ì—ì„œ ëª¨ë“  ê²ƒì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ì•ˆì „ì¥ì¹˜ê°€ í¬í•¨ë˜ì–´ ìˆì–´ ì„ í˜¸ë˜ëŠ” í˜¸ì¶œ ë©”ì†Œë“œì…ë‹ˆë‹¤.
ì‹¤ì œ ëª¨ë¸ê³¼ ê´€ë ¨ëœ ê²ƒì€ `_forward` ë©”ì†Œë“œì— ì†í•˜ë©°, ë‚˜ë¨¸ì§€ëŠ” ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ê³¼ì •ì— ìˆìŠµë‹ˆë‹¤.

`postprocess` ë©”ì†Œë“œëŠ” `_forward`ì˜ ì¶œë ¥ì„ ê°€ì ¸ì™€ ì´ì „ì— ê²°ì •í•œ ìµœì¢… ì¶œë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

`_sanitize_parameters`ëŠ” ì´ˆê¸°í™” ì‹œê°„ì— `pipeline(...., maybe_arg=4)`ì´ë‚˜ í˜¸ì¶œ ì‹œê°„ì— `pipe = pipeline(...); output = pipe(...., maybe_arg=4)`ê³¼ ê°™ì´, ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²½ìš° ì–¸ì œë“ ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•©ë‹ˆë‹¤.

`_sanitize_parameters`ì˜ ë°˜í™˜ ê°’ì€ `preprocess`, `_forward`, `postprocess`ì— ì§ì ‘ ì „ë‹¬ë˜ëŠ” 3ê°œì˜ kwargs ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
í˜¸ì¶œìê°€ ì¶”ê°€ ë§¤ê°œë³€ìˆ˜ë¡œ í˜¸ì¶œí•˜ì§€ ì•Šì•˜ë‹¤ë©´ ì•„ë¬´ê²ƒë„ ì±„ìš°ì§€ ë§ˆì‹­ì‹œì˜¤.
ì´ë ‡ê²Œ í•˜ë©´ í•­ìƒ ë” "ìì—°ìŠ¤ëŸ¬ìš´" í•¨ìˆ˜ ì •ì˜ì˜ ê¸°ë³¸ ì¸ìˆ˜ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë¶„ë¥˜ ì‘ì—…ì—ì„œ `top_k` ë§¤ê°œë³€ìˆ˜ê°€ ëŒ€í‘œì ì¸ ì˜ˆì…ë‹ˆë‹¤.

```python
>>> pipe = pipeline("my-new-task")
>>> pipe("This is a test")
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}, {"label": "3-star", "score": 0.05}
{"label": "4-star", "score": 0.025}, {"label": "5-star", "score": 0.025}]

>>> pipe("This is a test", top_k=2)
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}]
```

ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” `postprocess` ë©”ì†Œë“œë¥¼ ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ì¸ `5`ë¡œ ì—…ë°ì´íŠ¸í•˜ê³  `_sanitize_parameters`ë¥¼ ìˆ˜ì •í•˜ì—¬ ì´ ìƒˆ ë§¤ê°œë³€ìˆ˜ë¥¼ í—ˆìš©í•©ë‹ˆë‹¤.


```python
def postprocess(self, model_outputs, top_k=5):
    best_class = model_outputs["logits"].softmax(-1)
    # top_kë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¡œì§ ì¶”ê°€
    return best_class


def _sanitize_parameters(self, **kwargs):
    preprocess_kwargs = {}
    if "maybe_arg" in kwargs:
        preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]

    postprocess_kwargs = {}
    if "top_k" in kwargs:
        postprocess_kwargs["top_k"] = kwargs["top_k"]
    return preprocess_kwargs, {}, postprocess_kwargs
```

ì…/ì¶œë ¥ì„ ê°€ëŠ¥í•œ í•œ ê°„ë‹¨í•˜ê³  ì™„ì „íˆ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•˜ë ¤ê³  ë…¸ë ¥í•˜ì‹­ì‹œì˜¤.
ì´ë ‡ê²Œ í•˜ë©´ ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ì¢…ë¥˜ì˜ ê°œì²´ë¥¼ ì´í•´í•˜ì§€ ì•Šê³ ë„ íŒŒì´í”„ë¼ì¸ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë˜í•œ ì‚¬ìš© ìš©ì´ì„±ì„ ìœ„í•´ ì—¬ëŸ¬ ê°€ì§€ ìœ í˜•ì˜ ì¸ìˆ˜(ì˜¤ë””ì˜¤ íŒŒì¼ì€ íŒŒì¼ ì´ë¦„, URL ë˜ëŠ” ìˆœìˆ˜í•œ ë°”ì´íŠ¸ì¼ ìˆ˜ ìˆìŒ)ë¥¼ ì§€ì›í•˜ëŠ” ê²ƒì´ ë¹„êµì  ì¼ë°˜ì ì…ë‹ˆë‹¤.



## ì§€ì›ë˜ëŠ” ì‘ì—… ëª©ë¡ì— ì¶”ê°€í•˜ê¸° [[adding-it-to-the-list-of-supported-tasks]]

`new-task`ë¥¼ ì§€ì›ë˜ëŠ” ì‘ì—… ëª©ë¡ì— ë“±ë¡í•˜ë ¤ë©´ `PIPELINE_REGISTRY`ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:

```python
from transformers.pipelines import PIPELINE_REGISTRY

PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
)
```

ì›í•˜ëŠ” ê²½ìš° ê¸°ë³¸ ëª¨ë¸ì„ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë©°, ì´ ê²½ìš° íŠ¹ì • ê°œì •(ë¶„ê¸° ì´ë¦„ ë˜ëŠ” ì»¤ë°‹ í•´ì‹œì¼ ìˆ˜ ìˆìŒ, ì—¬ê¸°ì„œëŠ” "abcdef")ê³¼ íƒ€ì…ì„ í•¨ê»˜ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤:

```python
PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
    default={"pt": ("user/awesome_model", "abcdef")},
    type="text",  # í˜„ì¬ ì§€ì› ìœ í˜•: text, audio, image, multimodal
)
```

## Hubì— íŒŒì´í”„ë¼ì¸ ê³µìœ í•˜ê¸° [[share-your-pipeline-on-the-hub]]

Hubì— ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ì„ ê³µìœ í•˜ë ¤ë©´ `Pipeline` í•˜ìœ„ í´ë˜ìŠ¤ì˜ ì‚¬ìš©ì ì •ì˜ ì½”ë“œë¥¼ Python íŒŒì¼ì— ì €ì¥í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì´ ë¬¸ì¥ ìŒ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```py
import numpy as np

from transformers import Pipeline


def softmax(outputs):
    maxes = np.max(outputs, axis=-1, keepdims=True)
    shifted_exp = np.exp(outputs - maxes)
    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)


class PairClassificationPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "second_text" in kwargs:
            preprocess_kwargs["second_text"] = kwargs["second_text"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, text, second_text=None):
        return self.tokenizer(text, text_pair=second_text, return_tensors=self.framework)

    def _forward(self, model_inputs):
        return self.model(**model_inputs)

    def postprocess(self, model_outputs):
        logits = model_outputs.logits[0].numpy()
        probabilities = softmax(logits)

        best_class = np.argmax(probabilities)
        label = self.model.config.id2label[best_class]
        score = probabilities[best_class].item()
        logits = logits.tolist()
        return {"label": label, "score": score, "logits": logits}
```

êµ¬í˜„ì€ í”„ë ˆì„ì›Œí¬ì— êµ¬ì• ë°›ì§€ ì•Šìœ¼ë©°, PyTorchì™€ TensorFlow ëª¨ë¸ì— ëŒ€í•´ ì‘ë™í•©ë‹ˆë‹¤.
ì´ë¥¼ `pair_classification.py`ë¼ëŠ” íŒŒì¼ì— ì €ì¥í•œ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì´ ê°€ì ¸ì˜¤ê³  ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
from pair_classification import PairClassificationPipeline
from transformers.pipelines import PIPELINE_REGISTRY
from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification

PIPELINE_REGISTRY.register_pipeline(
    "pair-classification",
    pipeline_class=PairClassificationPipeline,
    pt_model=AutoModelForSequenceClassification,
    tf_model=TFAutoModelForSequenceClassification,
)
```

ì´ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ì‚¬ì „í›ˆë ¨ëœ ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, `sgugger/finetuned-bert-mrpc`ì€ MRPC ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë¯¸ì„¸ ì¡°ì •ë˜ì–´ ë¬¸ì¥ ìŒì„ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆì¸ì§€ ì•„ë‹Œì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

```py
from transformers import pipeline

classifier = pipeline("pair-classification", model="sgugger/finetuned-bert-mrpc")
```

ê·¸ëŸ° ë‹¤ìŒ `Repository`ì˜ `save_pretrained` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í—ˆë¸Œì— ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
from huggingface_hub import Repository

repo = Repository("test-dynamic-pipeline", clone_from="{your_username}/test-dynamic-pipeline")
classifier.save_pretrained("test-dynamic-pipeline")
repo.push_to_hub()
```

ì´ë ‡ê²Œ í•˜ë©´ "test-dynamic-pipeline" í´ë” ë‚´ì— `PairClassificationPipeline`ì„ ì •ì˜í•œ íŒŒì¼ì´ ë³µì‚¬ë˜ë©°, íŒŒì´í”„ë¼ì¸ì˜ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë„ ì €ì¥í•œ í›„, `{your_username}/test-dynamic-pipeline` ì €ì¥ì†Œì— ìˆëŠ” ëª¨ë“  ê²ƒì„ í‘¸ì‹œí•©ë‹ˆë‹¤.
ì´í›„ì—ëŠ” `trust_remote_code=True` ì˜µì…˜ë§Œ ì œê³µí•˜ë©´ ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
from transformers import pipeline

classifier = pipeline(model="{your_username}/test-dynamic-pipeline", trust_remote_code=True)
```

## ğŸ¤— Transformersì— íŒŒì´í”„ë¼ì¸ ì¶”ê°€í•˜ê¸° [[add-the-pipeline-to-transformers]]

ğŸ¤— Transformersì— ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ì„ ê¸°ì—¬í•˜ë ¤ë©´, `pipelines` í•˜ìœ„ ëª¨ë“ˆì— ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ ì½”ë“œì™€ í•¨ê»˜ ìƒˆ ëª¨ë“ˆì„ ì¶”ê°€í•œ ë‹¤ìŒ, `pipelines/__init__.py`ì—ì„œ ì •ì˜ëœ ì‘ì—… ëª©ë¡ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ í…ŒìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
`tests/test_pipelines_MY_PIPELINE.py`ë¼ëŠ” ìƒˆ íŒŒì¼ì„ ë§Œë“¤ê³  ë‹¤ë¥¸ í…ŒìŠ¤íŠ¸ì™€ ì˜ˆì œë¥¼ í•¨ê»˜ ì‘ì„±í•©ë‹ˆë‹¤.

`run_pipeline_test` í•¨ìˆ˜ëŠ” ë§¤ìš° ì¼ë°˜ì ì´ë©°, `model_mapping` ë° `tf_model_mapping`ì—ì„œ ì •ì˜ëœ ê°€ëŠ¥í•œ ëª¨ë“  ì•„í‚¤í…ì²˜ì˜ ì‘ì€ ë¬´ì‘ìœ„ ëª¨ë¸ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

ì´ëŠ” í–¥í›„ í˜¸í™˜ì„±ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•˜ë©°, ëˆ„êµ°ê°€ `XXXForQuestionAnswering`ì„ ìœ„í•œ ìƒˆ ëª¨ë¸ì„ ì¶”ê°€í•˜ë©´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ê°€ í•´ë‹¹ ëª¨ë¸ì—ì„œ ì‹¤í–‰ì„ ì‹œë„í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
ëª¨ë¸ì´ ë¬´ì‘ìœ„ì´ê¸° ë•Œë¬¸ì— ì‹¤ì œ ê°’ì„ í™•ì¸í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ë‹¨ìˆœíˆ íŒŒì´í”„ë¼ì¸ ì¶œë ¥ `TYPE`ê³¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•œ ë„ìš°ë¯¸ `ANY`ê°€ ìˆìŠµë‹ˆë‹¤.

ë˜í•œ 2ê°œ(ì´ìƒì ìœ¼ë¡œëŠ” 4ê°œ)ì˜ í…ŒìŠ¤íŠ¸ë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.

- `test_small_model_pt`: ì´ íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ ì‘ì€ ëª¨ë¸ 1ê°œë¥¼ ì •ì˜(ê²°ê³¼ê°€ ì˜ë¯¸ ì—†ì–´ë„ ìƒê´€ì—†ìŒ)í•˜ê³  íŒŒì´í”„ë¼ì¸ ì¶œë ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” `test_small_model_tf`ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.
- `test_small_model_tf`: ì´ íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ ì‘ì€ ëª¨ë¸ 1ê°œë¥¼ ì •ì˜(ê²°ê³¼ê°€ ì˜ë¯¸ ì—†ì–´ë„ ìƒê´€ì—†ìŒ)í•˜ê³  íŒŒì´í”„ë¼ì¸ ì¶œë ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” `test_small_model_pt`ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.
- `test_large_model_pt`(`ì„ íƒì‚¬í•­`): ê²°ê³¼ê°€ ì˜ë¯¸ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì‹¤ì œ íŒŒì´í”„ë¼ì¸ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ëŠ” ì†ë„ê°€ ëŠë¦¬ë¯€ë¡œ ì´ë¥¼ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
ì—¬ê¸°ì„œì˜ ëª©í‘œëŠ” íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì£¼ê³  í–¥í›„ ë¦´ë¦¬ì¦ˆì—ì„œì˜ ë³€í™”ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
- `test_large_model_tf`(`ì„ íƒì‚¬í•­`): ê²°ê³¼ê°€ ì˜ë¯¸ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì‹¤ì œ íŒŒì´í”„ë¼ì¸ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ëŠ” ì†ë„ê°€ ëŠë¦¬ë¯€ë¡œ ì´ë¥¼ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
ì—¬ê¸°ì„œì˜ ëª©í‘œëŠ” íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì£¼ê³  í–¥í›„ ë¦´ë¦¬ì¦ˆì—ì„œì˜ ë³€í™”ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
