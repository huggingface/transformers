<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ì„ ì–´ë–»ê²Œ ìƒì„±í•˜ë‚˜ìš”? [[how-to-create-a-custom-pipeline]]

ì´ ê°€ì´ë“œì—ì„œëŠ” ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ì„ ì–´ë–»ê²Œ ìƒì„±í•˜ê³  [í—ˆë¸Œ](hf.co/models)ì— ê³µìœ í•˜ê±°ë‚˜ ğŸ¤— Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

ë¨¼ì €, íŒŒì´í”„ë¼ì¸ì´ ìˆ˜ìš©í•  ìˆ˜ ìˆëŠ” ì›ì‹œ ì—”íŠ¸ë¦¬ë¥¼ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.
ë¬¸ìì—´, ë°”ì´íŠ¸, ì‚¬ì „ ë˜ëŠ” ê°€ì¥ ì›í•˜ëŠ” ì…ë ¥ì— ê°€ì¥ ì í•©í•œ ê²ƒì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ ì…ë ¥ì„ ê°€ëŠ¥í•œ í•œ ìˆœìˆ˜í•œ Python í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
ì´ë ‡ê²Œ í•˜ë©´ í˜¸í™˜ì„±ì´ ì‰¬ì›Œì§‘ë‹ˆë‹¤(ë‹¤ë¥¸ ì–¸ì–´ë¥¼ í†µí•œ JSONì„ í†µí•´ ê°€ëŠ¥).
ì´ëŸ¬í•œ ê²ƒë“¤ì€ íŒŒì´í”„ë¼ì¸ì˜ `inputs`(ì „ì²˜ë¦¬)ì´ ë  ê²ƒì…ë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ `outputs`ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
`inputs`ì™€ ê°™ì€ ì •ì±…ì„ ë”°ë¦…ë‹ˆë‹¤.
ê°„ë‹¨í• ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.
ì´ê²ƒë“¤ì€ `postprocess` ë©”ì„œë“œì˜ ì¶œë ¥ì´ ë  ê²ƒì…ë‹ˆë‹¤.

ë¨¼ì € 4ê°œì˜ ë©”ì„œë“œ(`preprocess`, `_forward`, `postprocess` ë° `_sanitize_parameters`)ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ ê¸°ë³¸ í´ë˜ìŠ¤ `Pipeline`ì„ ìƒì†í•˜ì—¬ ì‹œì‘í•©ë‹ˆë‹¤.


```python
from transformers import Pipeline


class MyPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "maybe_arg" in kwargs:
            preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, inputs, maybe_arg=2):
        model_input = Tensor(inputs["input_ids"])
        return {"model_input": model_input}

    def _forward(self, model_inputs):
        # model_inputs == {"model_input": model_input}
        outputs = self.model(**model_inputs)
        # Maybe {"logits": Tensor(...)}
        return outputs

    def postprocess(self, model_outputs):
        best_class = model_outputs["logits"].softmax(-1)
        return best_class
```

ì´ ë¶„í•´ êµ¬ì¡°ì˜ ëª©ì ì€ CPU/GPUì— ëŒ€í•œ ë¹„êµì  ì›í™œí•œ ì§€ì›ì„ ì œê³µí•˜ë©´ì„œ, CPUì—ì„œ ë‹¤ë¥¸ ìŠ¤ë ˆë“œì—ì„œ ì‚¬ì „/í›„ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì§€ì›ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

`preprocess`ëŠ” ìµœì´ˆì— ì •ì˜ëœ ì…ë ¥ì„ ê°€ì ¸ì™€ ëª¨ë¸ì— í”¼ë“œí•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
ë” ë§ì€ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë©° ì¼ë°˜ì ìœ¼ë¡œ `Dict` í˜•íƒœì…ë‹ˆë‹¤.

`_forward`ëŠ” êµ¬í˜„ ì„¸ë¶€ ì‚¬í•­ì´ë©° ì§ì ‘ í˜¸ì¶œë˜ì§€ ì•Šë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 
`forward`ê°€ í˜¸ì¶œë  ë•Œ ëª¨ë“  ê²ƒì´ ì˜ˆìƒëœ ì¥ì¹˜ì—ì„œ ì‘ë™ë˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ë³´í˜¸ ì¥ì¹˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
ì‹¤ì œ ëª¨ë¸ê³¼ ê´€ë ¨ëœ ê²ƒì€ `_forward` ë©”ì„œë“œì— ì†í•˜ë©°, ë‚˜ë¨¸ì§€ëŠ” ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ì— ì†í•©ë‹ˆë‹¤.

`postprocess` ë©”ì„œë“œëŠ” `_forward`ì˜ ì¶œë ¥ì„ ê°€ì ¸ì™€ ì´ì „ì— ê²°ì •í•œ ìµœì¢… ì¶œë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

`_sanitize_parameters`ëŠ” ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²½ìš° ì–¸ì œë“ ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•©ë‹ˆë‹¤. ì´ˆê¸°í™” ì‹œê°„ì— `pipeline(...., maybe_arg=4)`ì´ë‚˜ í˜¸ì¶œ ì‹œê°„ì— `pipe = pipeline(...); output = pipe(...., maybe_arg=4)`ê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

`_sanitize_parameters`ì˜ ë°˜í™˜ ê°’ì€ `preprocess`, `_forward`, `postprocess`ì— ì§ì ‘ ì „ë‹¬ë˜ëŠ” 3ê°œì˜ kwargs ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
í˜¸ì¶œìê°€ ì¶”ê°€ ë§¤ê°œë³€ìˆ˜ë¡œ í˜¸ì¶œí•˜ì§€ ì•Šì•˜ë‹¤ë©´ ì•„ë¬´ê²ƒë„ ì±„ìš°ì§€ ë§ˆì‹­ì‹œì˜¤.
ì´ë ‡ê²Œ í•˜ë©´ í•¨ìˆ˜ ì •ì˜ì˜ ê¸°ë³¸ ì¸ìˆ˜ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ê²ƒì´ í•­ìƒ ë” "ìì—°ìŠ¤ëŸ¬ìš´" ê²ƒì…ë‹ˆë‹¤.

ë¶„ë¥˜ ì‘ì—…ì—ì„œ `top_k` ë§¤ê°œë³€ìˆ˜ê°€ ëŒ€í‘œì ì¸ ì˜ˆì…ë‹ˆë‹¤.

```python
>>> pipe = pipeline("my-new-task")
>>> pipe("This is a test")
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}, {"label": "3-star", "score": 0.05}
{"label": "4-star", "score": 0.025}, {"label": "5-star", "score": 0.025}]

>>> pipe("This is a test", top_k=2)
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}]
```

ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” `postprocess` ë©”ì„œë“œë¥¼ ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ì¸ `5`ë¡œ ì—…ë°ì´íŠ¸í•˜ê³  `_sanitize_parameters`ë¥¼ ìˆ˜ì •í•˜ì—¬ ì´ ìƒˆ ë§¤ê°œë³€ìˆ˜ë¥¼ í—ˆìš©í•©ë‹ˆë‹¤.


```python
def postprocess(self, model_outputs, top_k=5):
    best_class = model_outputs["logits"].softmax(-1)
    # Add logic to handle top_k
    return best_class


def _sanitize_parameters(self, **kwargs):
    preprocess_kwargs = {}
    if "maybe_arg" in kwargs:
        preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]

    postprocess_kwargs = {}
    if "top_k" in kwargs:
        postprocess_kwargs["top_k"] = kwargs["top_k"]
    return preprocess_kwargs, {}, postprocess_kwargs
```

ì…ë ¥/ì¶œë ¥ì„ ê°€ëŠ¥í•œí•œ ê°„ë‹¨í•˜ê³  ì´ìƒì ìœ¼ë¡œ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•˜ë ¤ê³  ë…¸ë ¥í•˜ì‹­ì‹œì˜¤.
ì´ë ‡ê²Œ í•˜ë©´ ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ì¢…ë¥˜ì˜ ê°œì²´ë¥¼ ì´í•´í•˜ì§€ ì•Šê³ ë„ íŒŒì´í”„ë¼ì¸ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë˜í•œ ì‚¬ìš© ìš©ì´ì„±ì„ ìœ„í•´ ì—¬ëŸ¬ ê°€ì§€ ìœ í˜•ì˜ ì¸ìˆ˜ë¥¼ ì§€ì›í•˜ëŠ” ê²ƒì´ ìƒëŒ€ì ìœ¼ë¡œ í”í•œ ë°©ë²•ì…ë‹ˆë‹¤(ì˜¤ë””ì˜¤ íŒŒì¼ì€ íŒŒì¼ ì´ë¦„, URL ë˜ëŠ” ìˆœìˆ˜í•œ ë°”ì´íŠ¸ì¼ ìˆ˜ ìˆìŒ).



## ì§€ì›ë˜ëŠ” ì‘ì—… ëª©ë¡ì— ì¶”ê°€í•˜ê¸° [[adding-it-to-the-list-of-supported-tasks]]

`new-task`ë¥¼ ì§€ì›ë˜ëŠ” ì‘ì—… ëª©ë¡ì— ë“±ë¡í•˜ë ¤ë©´ `PIPELINE_REGISTRY`ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:

```python
from transformers.pipelines import PIPELINE_REGISTRY

PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
)
```

ì›í•˜ëŠ” ê²½ìš° ê¸°ë³¸ ëª¨ë¸ì„ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë©°, ì´ ê²½ìš° íŠ¹ì • ë¦¬ë¹„ì „(ë¶„ê¸° ì´ë¦„ ë˜ëŠ” ì»¤ë°‹ í•´ì‹œì¼ ìˆ˜ ìˆìŒ, ì—¬ê¸°ì„œëŠ” "abcdef")ê³¼ ìœ í˜•ì„ í•¨ê»˜ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤:

```python
PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
    default={"pt": ("user/awesome_model", "abcdef")},
    type="text",  # current support type: text, audio, image, multimodal
)
```

## í—ˆë¸Œì— íŒŒì´í”„ë¼ì¸ ê³µìœ í•˜ê¸° [[share-your-pipeline-on-the-hub]]

í—ˆë¸Œì— ì‚¬ìš©ì ì§€ì • íŒŒì´í”„ë¼ì¸ì„ ê³µìœ í•˜ë ¤ë©´ `Pipeline` í•˜ìœ„ í´ë˜ìŠ¤ì˜ ì‚¬ìš©ì ì§€ì • ì½”ë“œë¥¼ Python íŒŒì¼ì— ì €ì¥í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì´ ë¬¸ì¥ ìŒ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš°:

```py
import numpy as np

from transformers import Pipeline


def softmax(outputs):
    maxes = np.max(outputs, axis=-1, keepdims=True)
    shifted_exp = np.exp(outputs - maxes)
    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)


class PairClassificationPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "second_text" in kwargs:
            preprocess_kwargs["second_text"] = kwargs["second_text"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, text, second_text=None):
        return self.tokenizer(text, text_pair=second_text, return_tensors=self.framework)

    def _forward(self, model_inputs):
        return self.model(**model_inputs)

    def postprocess(self, model_outputs):
        logits = model_outputs.logits[0].numpy()
        probabilities = softmax(logits)

        best_class = np.argmax(probabilities)
        label = self.model.config.id2label[best_class]
        score = probabilities[best_class].item()
        logits = logits.tolist()
        return {"label": label, "score": score, "logits": logits}
```

êµ¬í˜„ì€ í”„ë ˆì„ì›Œí¬ì— ë…ë¦½ì ì´ë©° PyTorchì™€ TensorFlow ëª¨ë¸ ëª¨ë‘ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤.
ì´ë¥¼ `pair_classification.py`ë¼ëŠ” íŒŒì¼ì— ì €ì¥í•œ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ê°€ì ¸ì˜¤ê³  ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
from pair_classification import PairClassificationPipeline
from transformers.pipelines import PIPELINE_REGISTRY
from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification

PIPELINE_REGISTRY.register_pipeline(
    "pair-classification",
    pipeline_class=PairClassificationPipeline,
    pt_model=AutoModelForSequenceClassification,
    tf_model=TFAutoModelForSequenceClassification,
)
```

ì´ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, `sgugger/finetuned-bert-mrpc`ì€ MRPC ë°ì´í„°ì…‹ì—ì„œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ë¡œ ë¬¸ì¥ ìŒì„ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

```py
from transformers import pipeline

classifier = pipeline("pair-classification", model="sgugger/finetuned-bert-mrpc")
```

ê·¸ëŸ° ë‹¤ìŒ `Repository`ì˜ `save_pretrained` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í—ˆë¸Œì— ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
from huggingface_hub import Repository

repo = Repository("test-dynamic-pipeline", clone_from="{your_username}/test-dynamic-pipeline")
classifier.save_pretrained("test-dynamic-pipeline")
repo.push_to_hub()
```

ì´ë ‡ê²Œ í•˜ë©´ "test-dynamic-pipeline" í´ë” ë‚´ì— `PairClassificationPipeline`ì„ ì •ì˜í•œ íŒŒì¼ì´ ë³µì‚¬ë˜ë©°, íŒŒì´í”„ë¼ì¸ì˜ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë„ ì €ì¥ëœ ë‹¤ìŒ ëª¨ë‘ ë¦¬í¬ì§€í† ë¦¬ `{your_username}/test-dynamic-pipeline`ì— í‘¸ì‹œë©ë‹ˆë‹¤.
ì´í›„ì—ëŠ” ëˆ„êµ¬ë‚˜ `trust_remote_code=True` ì˜µì…˜ì„ ì œê³µí•˜ëŠ” í•œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
from transformers import pipeline

classifier = pipeline(model="{your_username}/test-dynamic-pipeline", trust_remote_code=True)
```

## íŒŒì´í”„ë¼ì¸ì„ ğŸ¤— Transformersì— ì¶”ê°€í•˜ê¸° [[add-the-pipeline-to-transformers]]

ì‚¬ìš©ì ì •ì˜ íŒŒì´í”„ë¼ì¸ì„ ğŸ¤— Transformersì— ê¸°ì—¬í•˜ë ¤ë©´ `pipelines` í•˜ìœ„ ëª¨ë“ˆì— ìƒˆ ëª¨ë“ˆì„ ì¶”ê°€í•œ ë‹¤ìŒ, `pipelines/__init__.py`ì—ì„œ ì •ì˜ëœ ì‘ì—… ëª©ë¡ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ í…ŒìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
`tests/test_pipelines_MY_PIPELINE.py`ë¼ëŠ” ìƒˆ íŒŒì¼ì„ ë§Œë“¤ê³  ë‹¤ë¥¸ í…ŒìŠ¤íŠ¸ì™€ ì˜ˆì œë¥¼ í•¨ê»˜ ì‘ì„±í•©ë‹ˆë‹¤.

`run_pipeline_test` í•¨ìˆ˜ëŠ” ë§¤ìš° ì¼ë°˜ì ì´ë©°, `model_mapping` ë° `tf_model_mapping`ì—ì„œ ì •ì˜í•œ ëª¨ë“  ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ì—ì„œ ì‘ì€ ë¬´ì‘ìœ„ ëª¨ë¸ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

ì´ëŠ” ë¯¸ë˜ í˜¸í™˜ì„±ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
ì¦‰, ëˆ„êµ°ê°€ê°€ `XXXForQuestionAnswering`ì„ ìœ„í•œ ìƒˆ ëª¨ë¸ì„ ì¶”ê°€í•˜ë©´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ëŠ” í•´ë‹¹ ëª¨ë¸ì—ì„œ ì‹¤í–‰í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.
ëª¨ë¸ì´ ë¬´ì‘ìœ„ì´ê¸° ë•Œë¬¸ì— ì‹¤ì œ ê°’ì„ í™•ì¸í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì¶œë ¥ í˜•ì‹ì„ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•œ ë„ìš°ë¯¸ `ANY`ê°€ ìˆìŠµë‹ˆë‹¤.

ë˜í•œ 2ê°œ(ì´ìƒí•˜ê²Œ 4ê°œ)ì˜ í…ŒìŠ¤íŠ¸ë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.

- `test_small_model_pt`: ì´ íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ ì‘ì€ ëª¨ë¸ 1ê°œë¥¼ ì •ì˜(ê²°ê³¼ê°€ ì˜ë¯¸ ì—†ë”ë¼ë„ ìƒê´€ì—†ìŒ)í•˜ê³  íŒŒì´í”„ë¼ì¸ ì¶œë ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” `test_small_model_tf`ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.
- `test_small_model_tf`: ì´ íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ ì‘ì€ ëª¨ë¸ 1ê°œë¥¼ ì •ì˜(ê²°ê³¼ê°€ ì˜ë¯¸ ì—†ë”ë¼ë„ ìƒê´€ì—†ìŒ)í•˜ê³  íŒŒì´í”„ë¼ì¸ ì¶œë ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” `test_small_model_pt`ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.
- `test_large_model_pt`(`ì„ íƒì‚¬í•­`): ê²°ê³¼ê°€ ì˜ë¯¸ ìˆëŠ” ì‹¤ì œ íŒŒì´í”„ë¼ì¸ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ëŠ” ëŠë¦¬ë©° ê·¸ë ‡ê²Œ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ì—¬ê¸°ì„œì˜ ëª©í‘œëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‡¼ì¼€ì´ìŠ¤í•˜ê³  ë¯¸ë˜ ë¦´ë¦¬ìŠ¤ì—ì„œì˜ ë³€í™”ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
- `test_large_model_tf`(`ì„ íƒì‚¬í•­`): ê²°ê³¼ê°€ ì˜ë¯¸ ìˆëŠ” ì‹¤ì œ íŒŒì´í”„ë¼ì¸ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ëŠ” ëŠë¦¬ë©° ê·¸ë ‡ê²Œ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ì—¬ê¸°ì„œì˜ ëª©í‘œëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‡¼ì¼€ì´ìŠ¤í•˜ê³  ë¯¸ë˜ ë¦´ë¦¬ìŠ¤ì—ì„œì˜ ë³€í™”ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
