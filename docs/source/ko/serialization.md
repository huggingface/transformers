<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ONNXë¡œ ë‚´ë³´ë‚´ê¸° [[export-to-onnx]]

ğŸ¤— Transformers ëª¨ë¸ì„ ì œí’ˆ í™˜ê²½ì—ì„œ ë°°í¬í•˜ê¸° ìœ„í•´ì„œëŠ” ëª¨ë¸ì„ ì§ë ¬í™”ëœ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê³  íŠ¹ì • ëŸ°íƒ€ì„ê³¼ í•˜ë“œì›¨ì–´ì—ì„œ ë¡œë“œí•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìœ¼ë©´ ìœ ìš©í•©ë‹ˆë‹¤.

ğŸ¤— Optimumì€ Transformersì˜ í™•ì¥ìœ¼ë¡œ, PyTorch ë˜ëŠ” TensorFlowì—ì„œ ëª¨ë¸ì„ ONNXì™€ TFLiteì™€ ê°™ì€ ì§ë ¬í™”ëœ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” `exporters` ëª¨ë“ˆì„ í†µí•´ ì œê³µë©ë‹ˆë‹¤. ğŸ¤— Optimumì€ ë˜í•œ ì„±ëŠ¥ ìµœì í™” ë„êµ¬ ì„¸íŠ¸ë¥¼ ì œê³µí•˜ì—¬ íŠ¹ì • í•˜ë“œì›¨ì–´ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ì‹¤í–‰í•  ë•Œ ìµœëŒ€ íš¨ìœ¨ì„±ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ì•ˆë‚´ì„œëŠ” ğŸ¤— Optimumì„ ì‚¬ìš©í•˜ì—¬ ğŸ¤— Transformers ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. TFLiteë¡œ ëª¨ë¸ì„ ë‚´ë³´ë‚´ëŠ” ì•ˆë‚´ì„œëŠ” [TFLiteë¡œ ë‚´ë³´ë‚´ê¸° í˜ì´ì§€](tflite)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ONNXë¡œ ë‚´ë³´ë‚´ê¸° [[export-to-onnx]]

[ONNX (Open Neural Network eXchange)](http://onnx.ai)ëŠ” PyTorchì™€ TensorFlowë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ì—ì„œ ì‹¬ì¸µ í•™ìŠµ ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê³µí†µ ì—°ì‚°ì ì„¸íŠ¸ì™€ ê³µí†µ íŒŒì¼ í˜•ì‹ì„ ì •ì˜í•˜ëŠ” ì˜¤í”ˆ í‘œì¤€ì…ë‹ˆë‹¤. ëª¨ë¸ì´ ONNX í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ì§€ë©´ ì´ëŸ¬í•œ ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ê²½ë§ì„ í†µí•´ ë°ì´í„°ê°€ íë¥´ëŠ” íë¦„ì„ ë‚˜íƒ€ë‚´ëŠ” ê³„ì‚° ê·¸ë˜í”„(ì¼ë°˜ì ìœ¼ë¡œ _ì¤‘ê°„ í‘œí˜„_ì´ë¼ê³  í•¨)ê°€ êµ¬ì„±ë©ë‹ˆë‹¤.

í‘œì¤€í™”ëœ ì—°ì‚°ìì™€ ë°ì´í„° ìœ í˜•ì„ ê°€ì§„ ê·¸ë˜í”„ë¥¼ ë…¸ì¶œí•¨ìœ¼ë¡œì¨, ONNXëŠ” í”„ë ˆì„ì›Œí¬ ê°„ì— ì‰½ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, PyTorchì—ì„œ í›ˆë ¨ëœ ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê³  TensorFlowì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤(ê·¸ ë°˜ëŒ€ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤).

ONNX í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚¸ ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- [ê·¸ë˜í”„ ìµœì í™”](https://huggingface.co/docs/optimum/onnxruntime/usage_guides/optimization) ë° [ì–‘ìí™”](https://huggingface.co/docs/optimum/onnxruntime/usage_guides/quantization)ì™€ ê°™ì€ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìœ„í•´ ìµœì í™”ë©ë‹ˆë‹¤.
- ONNX Runtimeì„ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [`ORTModelForXXX` í´ë˜ìŠ¤ë“¤](https://huggingface.co/docs/optimum/onnxruntime/package_reference/modeling_ort)ì„ í†µí•´ ë™ì¼í•œ `AutoModel` APIë¥¼ ë”°ë¦…ë‹ˆë‹¤. ì´ APIëŠ” ğŸ¤— Transformersì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤.
- [ìµœì í™”ëœ ì¶”ë¡  íŒŒì´í”„ë¼ì¸](https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/pipelines)ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ğŸ¤— Transformersì˜ [`pipeline`] í•¨ìˆ˜ì™€ ë™ì¼í•œ APIë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ¤— Optimumì€ êµ¬ì„± ê°ì²´ë¥¼ í™œìš©í•˜ì—¬ ONNX ë‚´ë³´ë‚´ê¸°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì„± ê°ì²´ëŠ” ì—¬ëŸ¬ ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ëŒ€í•´ ë¯¸ë¦¬ ì¤€ë¹„ë˜ì–´ ìˆìœ¼ë©° ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ì— ì‰½ê²Œ í™•ì¥í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

ë¯¸ë¦¬ ì¤€ë¹„ëœ êµ¬ì„± ëª©ë¡ì€ [ğŸ¤— Optimum ë¬¸ì„œ](https://huggingface.co/docs/optimum/exporters/onnx/overview)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

ğŸ¤— Transformers ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ë‘ ê°€ì§€ ë°©ë²•ì„ ëª¨ë‘ ë³´ì—¬ì¤ë‹ˆë‹¤:

- ğŸ¤— Optimumì„ ì‚¬ìš©í•˜ì—¬ CLIë¡œ ë‚´ë³´ë‚´ê¸°
- `optimum.onnxruntime`ì„ ì‚¬ìš©í•˜ì—¬ ğŸ¤— Optimumìœ¼ë¡œ ONNXë¡œ ë‚´ë³´ë‚´ê¸°

### CLIë¥¼ ì‚¬ìš©í•˜ì—¬ ğŸ¤— Transformers ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ê¸° [[exporting-a-transformers-model-to-onnx-with-cli]]

ğŸ¤— Transformers ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ë ¤ë©´ ë¨¼ì € ì¶”ê°€ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”:

```bash
pip install optimum[exporters]
```

ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì¸ìˆ˜ë¥¼ í™•ì¸í•˜ë ¤ë©´ [ğŸ¤— Optimum ë¬¸ì„œ](https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli)ë¥¼ ì°¸ì¡°í•˜ê±°ë‚˜ ëª…ë ¹ì¤„ì—ì„œ ë„ì›€ë§ì„ ë³´ì„¸ìš”.

```bash
optimum-cli export onnx --help
```

ì˜ˆë¥¼ ë“¤ì–´, ğŸ¤— Hubì—ì„œ `distilbert-base-uncased-distilled-squad`ì™€ ê°™ì€ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‚´ë³´ë‚´ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:

```bash
optimum-cli export onnx --model distilbert-base-uncased-distilled-squad distilbert_base_uncased_squad_onnx/
```

ìœ„ì™€ ê°™ì´ ì§„í–‰ ìƒí™©ì„ ë‚˜íƒ€ë‚´ëŠ” ë¡œê·¸ê°€ í‘œì‹œë˜ê³  ê²°ê³¼ì¸ `model.onnx`ê°€ ì €ì¥ëœ ìœ„ì¹˜ê°€ í‘œì‹œë©ë‹ˆë‹¤.

```bash
Validating ONNX model distilbert_base_uncased_squad_onnx/model.onnx...
	-[âœ“] ONNX model output names match reference model (start_logits, end_logits)
	- Validating ONNX Model output "start_logits":
		-[âœ“] (2, 16) matches (2, 16)
		-[âœ“] all values close (atol: 0.0001)
	- Validating ONNX Model output "end_logits":
		-[âœ“] (2, 16) matches (2, 16)
		-[âœ“] all values close (atol: 0.0001)
The ONNX export succeeded and the exported model was saved at: distilbert_base_uncased_squad_onnx
```

ìœ„ì˜ ì˜ˆì œëŠ” ğŸ¤— Hubì—ì„œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‚´ë³´ë‚´ëŠ” ê²ƒì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë¡œì»¬ ëª¨ë¸ì„ ë‚´ë³´ë‚¼ ë•Œì—ëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ì™€ í† í¬ë‚˜ì´ì € íŒŒì¼ì„ ë™ì¼í•œ ë””ë ‰í† ë¦¬(`local_path`)ì— ì €ì¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. CLIë¥¼ ì‚¬ìš©í•  ë•Œì—ëŠ” ğŸ¤— Hubì˜ ì²´í¬í¬ì¸íŠ¸ ì´ë¦„ ëŒ€ì‹  `model` ì¸ìˆ˜ì— `local_path`ë¥¼ ì „ë‹¬í•˜ê³  `--task` ì¸ìˆ˜ë¥¼ ì œê³µí•˜ì„¸ìš”. ì§€ì›ë˜ëŠ” ì‘ì—…ì˜ ëª©ë¡ì€ [ğŸ¤— Optimum ë¬¸ì„œ](https://huggingface.co/docs/optimum/exporters/task_manager)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. `task` ì¸ìˆ˜ê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ì‘ì—…ì— íŠ¹í™”ëœ í—¤ë“œ ì—†ì´ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¡œ ê¸°ë³¸ ì„¤ì •ë©ë‹ˆë‹¤.

```bash
optimum-cli export onnx --model local_path --task question-answering distilbert_base_uncased_squad_onnx/
```

ê·¸ ê²°ê³¼ë¡œ ìƒì„±ëœ `model.onnx` íŒŒì¼ì€ ONNX í‘œì¤€ì„ ì§€ì›í•˜ëŠ” ë§ì€ [ê°€ì†ê¸°](https://onnx.ai/supported-tools.html#deployModel) ì¤‘ í•˜ë‚˜ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [ONNX Runtime](https://onnxruntime.ai/)ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
>>> from transformers import AutoTokenizer
>>> from optimum.onnxruntime import ORTModelForQuestionAnswering

>>> tokenizer = AutoTokenizer.from_pretrained("distilbert_base_uncased_squad_onnx")
>>> model = ORTModelForQuestionAnswering.from_pretrained("distilbert_base_uncased_squad_onnx")
>>> inputs = tokenizer("What am I using?", "Using DistilBERT with ONNX Runtime!", return_tensors="pt")
>>> outputs = model(**inputs)
```

Hubì˜ TensorFlow ì²´í¬í¬ì¸íŠ¸ì— ëŒ€í•´ì„œë„ ë™ì¼í•œ í”„ë¡œì„¸ìŠ¤ê°€ ì ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [Keras organization](https://huggingface.co/keras-io)ì—ì„œ ìˆœìˆ˜í•œ TensorFlow ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‚´ë³´ë‚´ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```bash
optimum-cli export onnx --model keras-io/transformers-qa distilbert_base_cased_squad_onnx/
```

### `optimum.onnxruntime`ì„ ì‚¬ìš©í•˜ì—¬ ğŸ¤— Transformers ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ê¸° [[exporting-a-transformers-model-to-onnx-with-optimumonnxruntime]]

CLI ëŒ€ì‹ ì— `optimum.onnxruntime`ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ğŸ¤— Transformers ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•˜ì„¸ìš”:

```python
>>> from optimum.onnxruntime import ORTModelForSequenceClassification
>>> from transformers import AutoTokenizer

>>> model_checkpoint = "distilbert_base_uncased_squad"
>>> save_directory = "onnx/"

>>> # Load a model from transformers and export it to ONNX
>>> ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)
>>> tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)

>>> # Save the onnx model and tokenizer
>>> ort_model.save_pretrained(save_directory)
>>> tokenizer.save_pretrained(save_directory)
```

### ì§€ì›ë˜ì§€ ì•ŠëŠ” ì•„í‚¤í…ì²˜ì˜ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° [[exporting-a-model-for-an-unsupported-architecture]]

í˜„ì¬ ë‚´ë³´ë‚¼ ìˆ˜ ì—†ëŠ” ëª¨ë¸ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ê¸°ì—¬í•˜ë ¤ë©´, ë¨¼ì € [`optimum.exporters.onnx`](https://huggingface.co/docs/optimum/exporters/onnx/overview)ì—ì„œ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸í•œ í›„ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” [ğŸ¤— Optimumì— ê¸°ì—¬](https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/contribute)í•˜ì„¸ìš”.

### `transformers.onnx`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° [[exporting-a-model-with-transformersonnx]]

<Tip warning={true}>

`tranformers.onnx`ëŠ” ë” ì´ìƒ ìœ ì§€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì„¤ëª…í•œ ëŒ€ë¡œ ğŸ¤— Optimumì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë‚´ë³´ë‚´ì„¸ìš”. ì´ ì„¹ì…˜ì€ í–¥í›„ ë²„ì „ì—ì„œ ì œê±°ë  ì˜ˆì •ì…ë‹ˆë‹¤.

</Tip>

ğŸ¤— Transformers ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ë ¤ë©´ ì¶”ê°€ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”:

```bash
pip install transformers[onnx]
```

`transformers.onnx` íŒ¨í‚¤ì§€ë¥¼ Python ëª¨ë“ˆë¡œ ì‚¬ìš©í•˜ì—¬ ì¤€ë¹„ëœ êµ¬ì„±ì„ ì‚¬ìš©í•˜ì—¬ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‚´ë³´ëƒ…ë‹ˆë‹¤:

```bash
python -m transformers.onnx --model=distilbert-base-uncased onnx/
```

ì´ë ‡ê²Œ í•˜ë©´ `--model` ì¸ìˆ˜ì— ì •ì˜ëœ ì²´í¬í¬ì¸íŠ¸ì˜ ONNX ê·¸ë˜í”„ê°€ ë‚´ë³´ë‚´ì§‘ë‹ˆë‹¤. ğŸ¤— Hubì—ì„œ ì œê³µí•˜ëŠ” ì²´í¬í¬ì¸íŠ¸ë‚˜ ë¡œì»¬ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ë¡œ ìƒì„±ëœ `model.onnx` íŒŒì¼ì€ ONNX í‘œì¤€ì„ ì§€ì›í•˜ëŠ” ë§ì€ ê°€ì†ê¸° ì¤‘ í•˜ë‚˜ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì´ ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
>>> from transformers import AutoTokenizer
>>> from onnxruntime import InferenceSession

>>> tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
>>> session = InferenceSession("onnx/model.onnx")
>>> # ONNX Runtime expects NumPy arrays as input
>>> inputs = tokenizer("Using DistilBERT with ONNX Runtime!", return_tensors="np")
>>> outputs = session.run(output_names=["last_hidden_state"], input_feed=dict(inputs))
```

í•„ìš”í•œ ì¶œë ¥ ì´ë¦„(ì˜ˆ: `["last_hidden_state"]`)ì€ ê° ëª¨ë¸ì˜ ONNX êµ¬ì„±ì„ í™•ì¸í•˜ì—¬ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, DistilBERTì˜ ê²½ìš° ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```python
>>> from transformers.models.distilbert import DistilBertConfig, DistilBertOnnxConfig

>>> config = DistilBertConfig()
>>> onnx_config = DistilBertOnnxConfig(config)
>>> print(list(onnx_config.outputs.keys()))
["last_hidden_state"]
```

Hubì˜ TensorFlow ì²´í¬í¬ì¸íŠ¸ì— ëŒ€í•´ì„œë„ ë™ì¼í•œ í”„ë¡œì„¸ìŠ¤ê°€ ì ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì´ ìˆœìˆ˜í•œ TensorFlow ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‚´ë³´ëƒ…ë‹ˆë‹¤:

```bash
python -m transformers.onnx --model=keras-io/transformers-qa onnx/
```

ë¡œì»¬ì— ì €ì¥ëœ ëª¨ë¸ì„ ë‚´ë³´ë‚´ë ¤ë©´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ íŒŒì¼ê³¼ í† í¬ë‚˜ì´ì € íŒŒì¼ì„ ë™ì¼í•œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•œ ë‹¤ìŒ, transformers.onnx íŒ¨í‚¤ì§€ì˜ --model ì¸ìˆ˜ë¥¼ ì›í•˜ëŠ” ë””ë ‰í† ë¦¬ë¡œ ì§€ì •í•˜ì—¬ ONNXë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤:

```bash
python -m transformers.onnx --model=local-pt-checkpoint onnx/
```