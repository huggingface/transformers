<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ì¶”ë¡ ì„ ìœ„í•œ Pipeline[[pipelines-for-inference]]

[`pipeline`]ì„ ì‚¬ìš©í•˜ë©´ ì–¸ì–´, ì»´í“¨í„° ë¹„ì „, ì˜¤ë””ì˜¤ ë° ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬ì— ëŒ€í•œ ì¶”ë¡ ì„ ìœ„í•´ [Hub](https://huggingface.co/models)ì˜ ì–´ë–¤ ëª¨ë¸ì´ë“  ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. íŠ¹ì • ë¶„ì•¼ì— ëŒ€í•œ ê²½í—˜ì´ ì—†ê±°ë‚˜, ëª¨ë¸ì„ ì´ë£¨ëŠ” ì½”ë“œê°€ ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš°ì—ë„ [`pipeline`]ì„ ì‚¬ìš©í•´ì„œ ì¶”ë¡ í•  ìˆ˜ ìžˆì–´ìš”! ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë‹¤ìŒì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤.

* ì¶”ë¡ ì„ ìœ„í•´ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
* íŠ¹ì • í† í¬ë‚˜ì´ì € ë˜ëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
* ì–¸ì–´, ì»´í“¨í„° ë¹„ì „, ì˜¤ë””ì˜¤ ë° ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬ì—ì„œ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•

> [!TIP]
> ì§€ì›í•˜ëŠ” ëª¨ë“  íƒœìŠ¤í¬ì™€ ì“¸ ìˆ˜ ìžˆëŠ” ë§¤ê°œë³€ìˆ˜ë¥¼ ë‹´ì€ ëª©ë¡ì€ [`pipeline`] ì„¤ëª…ì„œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

## Pipeline ì‚¬ìš©í•˜ê¸°[[pipeline-usage]]

ê° íƒœìŠ¤í¬ë§ˆë‹¤ ê³ ìœ ì˜ [`pipeline`]ì´ ìžˆì§€ë§Œ, ê°œë³„ íŒŒì´í”„ë¼ì¸ì„ ë‹´ê³ ìžˆëŠ” ì¶”ìƒí™”ëœ [`pipeline`]ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ê°„ë‹¨í•©ë‹ˆë‹¤. [`pipeline`]ì€ íƒœìŠ¤í¬ì— ì•Œë§žê²Œ ì¶”ë¡ ì´ ê°€ëŠ¥í•œ ê¸°ë³¸ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ í´ëž˜ìŠ¤ë¥¼ ìžë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.

1. ë¨¼ì € [`pipeline`]ì„ ìƒì„±í•˜ê³  íƒœìŠ¤í¬ë¥¼ ì§€ì •í•˜ì„¸ìš”.

```py
>>> from transformers import pipeline

>>> generator = pipeline(task="automatic-speech-recognition")
```

2. ê·¸ë¦¬ê³  [`pipeline`]ì— ìž…ë ¥ì„ ë„£ì–´ì£¼ì„¸ìš”.

```py
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}
```

ê¸°ëŒ€í–ˆë˜ ê²°ê³¼ê°€ ì•„ë‹Œê°€ìš”? Hubì—ì„œ [ê°€ìž¥ ë§Žì´ ë‹¤ìš´ë¡œë“œëœ ìžë™ ìŒì„± ì¸ì‹ ëª¨ë¸](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads)ë¡œ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìžˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.
ë‹¤ìŒì€ [openai/whisper-large](https://huggingface.co/openai/whisper-large)ë¡œ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤.

```py
>>> generator = pipeline(model="openai/whisper-large")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

í›¨ì”¬ ë” ë‚˜ì•„ì¡Œêµ°ìš”!
Hubì˜ ëª¨ë¸ë“¤ì€ ì—¬ëŸ¬ ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ì „ë¬¸ë¶„ì•¼ë¥¼ ì•„ìš°ë¥´ê¸° ë•Œë¬¸ì— ê¼­ ìžì‹ ì˜ ì–¸ì–´ë‚˜ ë¶„ì•¼ì— íŠ¹í™”ëœ ëª¨ë¸ì„ ì°¾ì•„ë³´ì‹œê¸° ë°”ëžë‹ˆë‹¤.
ë¸Œë¼ìš°ì €ë¥¼ ë²—ì–´ë‚  í•„ìš”ì—†ì´ Hubì—ì„œ ì§ì ‘ ëª¨ë¸ì˜ ì¶œë ¥ì„ í™•ì¸í•˜ê³  ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµí•´ì„œ ìžì‹ ì˜ ìƒí™©ì— ë” ì í•©í•œì§€, ì• ë§¤í•œ ìž…ë ¥ì„ ë” ìž˜ ì²˜ë¦¬í•˜ëŠ”ì§€ë„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
ë§Œì•½ ìƒí™©ì— ì•Œë§žëŠ” ëª¨ë¸ì„ ì—†ë‹¤ë©´ ì–¸ì œë‚˜ ì§ì ‘ [í›ˆë ¨](training)ì‹œí‚¬ ìˆ˜ ìžˆìŠµë‹ˆë‹¤!

ìž…ë ¥ì´ ì—¬ëŸ¬ ê°œ ìžˆëŠ” ê²½ìš°, ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì „ë‹¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

```py
generator(
    [
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac",
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac",
    ]
)
```

ì „ì²´ ë°ì´í„°ì„¸íŠ¸ì„ ìˆœíšŒí•˜ê±°ë‚˜ ì›¹ì„œë²„ì— ì˜¬ë ¤ë‘ì–´ ì¶”ë¡ ì— ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´, ê° ìƒì„¸ íŽ˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

[ë°ì´í„°ì„¸íŠ¸ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°](#using-pipelines-on-a-dataset)

[ì›¹ì„œë²„ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°](./pipeline_webserver)

## ë§¤ê°œë³€ìˆ˜[[parameters]]

[`pipeline`]ì€ ë§Žì€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. íŠ¹ì • íƒœìŠ¤í¬ìš©ì¸ ê²ƒë„ ìžˆê³ , ë²”ìš©ì¸ ê²ƒë„ ìžˆìŠµë‹ˆë‹¤.
ì¼ë°˜ì ìœ¼ë¡œ ì›í•˜ëŠ” ìœ„ì¹˜ì— ì–´ë””ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ë„£ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

```py
generator(model="openai/whisper-large", my_parameter=1)
out = generate(...)  # This will use `my_parameter=1`.
out = generate(..., my_parameter=2)  # This will override and use `my_parameter=2`.
out = generate(...)  # This will go back to using `my_parameter=1`.
```

ì¤‘ìš”í•œ 3ê°€ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚´íŽ´ë³´ê² ìŠµë‹ˆë‹¤.

### ê¸°ê¸°(device)[[device]]

`device=n`ì²˜ëŸ¼ ê¸°ê¸°ë¥¼ ì§€ì •í•˜ë©´ íŒŒì´í”„ë¼ì¸ì´ ìžë™ìœ¼ë¡œ í•´ë‹¹ ê¸°ê¸°ì— ëª¨ë¸ì„ ë°°ì¹˜í•©ë‹ˆë‹¤.
íŒŒì´í† ì¹˜ì—ì„œë‚˜ í…ì„œí”Œë¡œìš°ì—ì„œë„ ëª¨ë‘ ìž‘ë™í•©ë‹ˆë‹¤.

```py
generator(model="openai/whisper-large", device=0)
```

ëª¨ë¸ì´ GPU í•˜ë‚˜ì— ëŒì•„ê°€ê¸° ë²„ê²ë‹¤ë©´, `device_map="auto"`ë¥¼ ì§€ì •í•´ì„œ ðŸ¤— [Accelerate](https://huggingface.co/docs/accelerate)ê°€ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ë¡œë“œí•˜ê³  ì €ìž¥í• ì§€ ìžë™ìœ¼ë¡œ ê²°ì •í•˜ë„ë¡ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

```py
#!pip install accelerate
generator(model="openai/whisper-large", device_map="auto")
```

### ë°°ì¹˜ ì‚¬ì´ì¦ˆ[[batch-size]]

ê¸°ë³¸ì ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ì€ [ì—¬ê¸°](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)ì— ë‚˜ì˜¨ ì´ìœ ë¡œ ì¶”ë¡ ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê°„ë‹¨ížˆ ì„¤ëª…í•˜ìžë©´ ì¼ê´„ ì²˜ë¦¬ê°€ ë°˜ë“œì‹œ ë” ë¹ ë¥´ì§€ ì•Šê³  ì˜¤ížˆë ¤ ë” ëŠë ¤ì§ˆ ìˆ˜ë„ ìžˆê¸° ë•Œë¬¸ìž…ë‹ˆë‹¤.

í•˜ì§€ë§Œ ìžì‹ ì˜ ìƒí™©ì— ì í•©í•˜ë‹¤ë©´, ì´ë ‡ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.

```py
generator(model="openai/whisper-large", device=0, batch_size=2)
audio_filenames = [f"audio_{i}.flac" for i in range(10)]
texts = generator(audio_filenames)
```

íŒŒì´í”„ë¼ì¸ ìœ„ ì œê³µëœ 10ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì¶”ê°€ë¡œ ì²˜ë¦¬í•˜ëŠ” ì½”ë“œ ì—†ì´ (ì¼ê´„ ì²˜ë¦¬ì— ë³´ë‹¤ íš¨ê³¼ì ì¸ GPU ìœ„) ëª¨ë¸ì— 2ê°œì”© ì „ë‹¬í•©ë‹ˆë‹¤.
ì¶œë ¥ì€ ì¼ê´„ ì²˜ë¦¬í•˜ì§€ ì•Šì•˜ì„ ë•Œì™€ ë˜‘ê°™ì•„ì•¼ í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì—ì„œ ì†ë„ë¥¼ ë” ë‚¼ ìˆ˜ë„ ìžˆëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ì¼ ë¿ìž…ë‹ˆë‹¤.

íŒŒì´í”„ë¼ì¸ì€ ì¼ê´„ ì²˜ë¦¬ì˜ ë³µìž¡í•œ ë¶€ë¶„ì„ ì¤„ì—¬ì£¼ê¸°ë„ í•©ë‹ˆë‹¤. (ì˜ˆë¥¼ ë“¤ì–´ ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì²˜ëŸ¼) ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ ì•¼ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìžˆëŠ” ê²ƒì„ [*chunk batching*](./main_classes/pipelines#pipeline-chunk-batching)ì´ë¼ê³  í•˜ëŠ”ë°, íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ë©´ ìžë™ìœ¼ë¡œ ë‚˜ëˆ ì¤ë‹ˆë‹¤.

### íŠ¹ì • íƒœìŠ¤í¬ìš© ë§¤ê°œë³€ìˆ˜[[task-specific-parameters]]

ê° íƒœìŠ¤í¬ë§ˆë‹¤ êµ¬í˜„í•  ë•Œ ìœ ì—°ì„±ê³¼ ì˜µì…˜ì„ ì œê³µí•˜ê¸° ìœ„í•´ íƒœìŠ¤í¬ìš© ë§¤ê°œë³€ìˆ˜ê°€ ìžˆìŠµë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´ [`transformers.AutomaticSpeechRecognitionPipeline.__call__`] ë©”ì„œë“œì—ëŠ” ë™ì˜ìƒì˜ ìžë§‰ì„ ë„£ì„ ë•Œ ìœ ìš©í•  ê²ƒ ê°™ì€ `return_timestamps` ë§¤ê°œë³€ìˆ˜ê°€ ìžˆìŠµë‹ˆë‹¤. 

```py
>>> # Not using whisper, as it cannot provide timestamps.
>>> generator = pipeline(model="facebook/wav2vec2-large-960h-lv60-self", return_timestamps="word")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP AND LIVE OUT THE TRUE MEANING OF ITS CREED', 'chunks': [{'text': 'I', 'timestamp': (1.22, 1.24)}, {'text': 'HAVE', 'timestamp': (1.42, 1.58)}, {'text': 'A', 'timestamp': (1.66, 1.68)}, {'text': 'DREAM', 'timestamp': (1.76, 2.14)}, {'text': 'BUT', 'timestamp': (3.68, 3.8)}, {'text': 'ONE', 'timestamp': (3.94, 4.06)}, {'text': 'DAY', 'timestamp': (4.16, 4.3)}, {'text': 'THIS', 'timestamp': (6.36, 6.54)}, {'text': 'NATION', 'timestamp': (6.68, 7.1)}, {'text': 'WILL', 'timestamp': (7.32, 7.56)}, {'text': 'RISE', 'timestamp': (7.8, 8.26)}, {'text': 'UP', 'timestamp': (8.38, 8.48)}, {'text': 'AND', 'timestamp': (10.08, 10.18)}, {'text': 'LIVE', 'timestamp': (10.26, 10.48)}, {'text': 'OUT', 'timestamp': (10.58, 10.7)}, {'text': 'THE', 'timestamp': (10.82, 10.9)}, {'text': 'TRUE', 'timestamp': (10.98, 11.18)}, {'text': 'MEANING', 'timestamp': (11.26, 11.58)}, {'text': 'OF', 'timestamp': (11.66, 11.7)}, {'text': 'ITS', 'timestamp': (11.76, 11.88)}, {'text': 'CREED', 'timestamp': (12.0, 12.38)}]}
```

ë³´ì‹œë‹¤ì‹œí”¼ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ë¡ í•  ë¿ë§Œ ì•„ë‹ˆë¼ ê° ë‹¨ì–´ë¥¼ ë§í•œ ì‹œì ê¹Œì§€ë„ ì¶œë ¥í–ˆìŠµë‹ˆë‹¤.

íƒœìŠ¤í¬ë§ˆë‹¤ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìžˆëŠ”ë°ìš”. ì›í•˜ëŠ” íƒœìŠ¤í¬ì˜ APIë¥¼ ì°¸ì¡°í•´ì„œ ë°”ê¿”ë³¼ ìˆ˜ ìžˆëŠ” ì—¬ëŸ¬ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚´íŽ´ë³´ì„¸ìš”!
ì§€ê¸ˆê¹Œì§€ ë‹¤ë¤„ë³¸ [`~transformers.AutomaticSpeechRecognitionPipeline`]ì—ëŠ” `chunk_length_s` ë§¤ê°œë³€ìˆ˜ê°€ ìžˆìŠµë‹ˆë‹¤. ì˜í™”ë‚˜ 1ì‹œê°„ ë¶„ëŸ‰ì˜ ë™ì˜ìƒì˜ ìžë§‰ ìž‘ì—…ì„ í•  ë•Œì²˜ëŸ¼, ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë¸ì´ ìžì²´ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ë§¤ìš° ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•  ë•Œ ìœ ìš©í•˜ì£ .


ë„ì›€ì´ ë  ë§Œí•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ì–¸ì œë“ ì§€ [ìš”ì²­](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)í•´ì£¼ì„¸ìš”!


## ë°ì´í„°ì„¸íŠ¸ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°[[using-pipelines-on-a-dataset]]

íŒŒì´í”„ë¼ì¸ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì„¸íŠ¸ì—ì„œë„ ì¶”ë¡  ìž‘ì—…ì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë•Œ ì´í„°ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê±¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.

```py
def data():
    for i in range(1000):
        yield f"My example {i}"


pipe = pipe(model="openai-community/gpt2", device=0)
generated_characters = 0
for out in pipe(data()):
    generated_characters += len(out["generated_text"])
```

ì´í„°ë ˆì´í„° `data()`ëŠ” ê° ê²°ê³¼ë¥¼ í˜¸ì¶œë§ˆë‹¤ ìƒì„±í•˜ê³ , íŒŒì´í”„ë¼ì¸ì€ ìž…ë ¥ì´ ìˆœíšŒí•  ìˆ˜ ìžˆëŠ” ìžë£Œêµ¬ì¡°ìž„ì„ ìžë™ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ GPUì—ì„œ ê¸°ì¡´ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ëŠ” ë™ì•ˆ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ì‹œìž‘í•©ë‹ˆë‹¤.(ì´ë•Œ ë‚´ë¶€ì ìœ¼ë¡œ [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ë¥¼ ì‚¬ìš©í•´ìš”.) ì´ ê³¼ì •ì€ ì „ì²´ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë©”ëª¨ë¦¬ì— ì ìž¬í•˜ì§€ ì•Šê³ ë„ GPUì— ìµœëŒ€í•œ ë¹ ë¥´ê²Œ ìƒˆë¡œìš´ ìž‘ì—…ì„ ê³µê¸‰í•  ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•©ë‹ˆë‹¤.

ê·¸ë¦¬ê³  ì¼ê´„ ì²˜ë¦¬ê°€ ë” ë¹ ë¥¼ ìˆ˜ ìžˆê¸° ë•Œë¬¸ì—, `batch_size` ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•´ë´ë„ ì¢‹ì•„ìš”.

ë°ì´í„°ì„¸íŠ¸ë¥¼ ìˆœíšŒí•˜ëŠ” ê°€ìž¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ðŸ¤— [Datasets](https://github.com/huggingface/datasets/)ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì¸ë°ìš”.

```py
# KeyDataset is a util that will just output the item we're interested in.
from transformers.pipelines.pt_utils import KeyDataset

pipe = pipeline(model="hf-internal-testing/tiny-random-wav2vec2", device=0)
dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation[:10]")

for out in pipe(KeyDataset(dataset["audio"])):
    print(out)
```


## ì›¹ì„œë²„ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°[[using-pipelines-for-a-webserver]]

> [!TIP]
> ì¶”ë¡  ì—”ì§„ì„ ë§Œë“œëŠ” ê³¼ì •ì€ ë”°ë¡œ íŽ˜ì´ì§€ë¥¼ ìž‘ì„±í• ë§Œí•œ ë³µìž¡í•œ ì£¼ì œìž…ë‹ˆë‹¤.

[Link](./pipeline_webserver)

## ë¹„ì „ Pipeline[[vision-pipeline]]

ë¹„ì „ íƒœìŠ¤í¬ë¥¼ ìœ„í•´ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ì¼ì€ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤.

íƒœìŠ¤í¬ë¥¼ ì§€ì •í•˜ê³  ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ê¸°ì— ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” ì¸í„°ë„· ë§í¬ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œì˜ í˜•íƒœë¡œ ì „ë‹¬í•´ì£¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ ì•„ëž˜ì— í‘œì‹œëœ ê³ ì–‘ì´ëŠ” ì–´ë–¤ ì¢…ì¸ê°€ìš”?

![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)

```py
>>> from transformers import pipeline

>>> vision_classifier = pipeline(model="google/vit-base-patch16-224")
>>> preds = vision_classifier(
...     images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]
```

### í…ìŠ¤íŠ¸ Pipeline[[text-pipeline]]

NLP íƒœìŠ¤í¬ë¥¼ ìœ„í•´ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ì¼ë„ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤.

```py
>>> from transformers import pipeline

>>> # This model is a `zero-shot-classification` model.
>>> # It will classify text, except you are free to choose any label you might imagine
>>> classifier = pipeline(model="facebook/bart-large-mnli")
>>> classifier(
...     "I have a problem with my iphone that needs to be resolved asap!!",
...     candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
... )
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

### ë©€í‹°ëª¨ë‹¬ Pipeline[[multimodal-pipeline]]

[`pipeline`]ì€ ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°(ì—­ì£¼: ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤, í…ìŠ¤íŠ¸ì™€ ê°™ì€ ë°ì´í„° í˜•íƒœ)ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì˜ˆì‹œë¡œ ì‹œê°ì  ì§ˆì˜ì‘ë‹µ(VQA; Visual Question Answering) íƒœìŠ¤í¬ëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ ì–´ë–¤ ì´ë¯¸ì§€ ë§í¬ë‚˜ ë¬»ê³  ì‹¶ì€ ì§ˆë¬¸ë„ ìžìœ ë¡­ê²Œ ì „ë‹¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” URL ë˜ëŠ” ë¡œì»¬ ê²½ë¡œì˜ í˜•íƒœë¡œ ì „ë‹¬í•´ì£¼ì„¸ìš”.

ì˜ˆë¥¼ ë“¤ì–´ ì´ [ê±°ëž˜ëª…ì„¸ì„œ ì‚¬ì§„](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)ì—ì„œ ê±°ëž˜ëª…ì„¸ì„œ ë²ˆí˜¸ë¥¼ ë¬»ê³  ì‹¶ë‹¤ë©´,

```py
>>> from transformers import pipeline

>>> vqa = pipeline(model="impira/layoutlm-document-qa")
>>> vqa(
...     image="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png",
...     question="What is the invoice number?",
... )
[{'score': 0.42514941096305847, 'answer': 'us-001', 'start': 16, 'end': 16}]
```
