<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ì¶”ë¡ ì„ ìœ„í•œ Pipeline[[pipelines-for-inference]]

[`pipeline`]ì„ ì‚¬ìš©í•˜ë©´ ì–¸ì–´, ì»´í“¨í„° ë¹„ì „, ì˜¤ë””ì˜¤ ë° ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬ì— ëŒ€í•œ ì¶”ë¡ ì„ ìœ„í•´ [Hub](https://huggingface.co/models)ì˜ ì–´ë–¤ ëª¨ë¸ì´ë“  ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹ì • ë¶„ì•¼ì— ëŒ€í•œ ê²½í—˜ì´ ì—†ê±°ë‚˜, ëª¨ë¸ì„ ì´ë£¨ëŠ” ì½”ë“œê°€ ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš°ì—ë„ [`pipeline`]ì„ ì‚¬ìš©í•´ì„œ ì¶”ë¡ í•  ìˆ˜ ìˆì–´ìš”! ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë‹¤ìŒì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤.

* ì¶”ë¡ ì„ ìœ„í•´ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
* íŠ¹ì • í† í¬ë‚˜ì´ì € ë˜ëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
* ì–¸ì–´, ì»´í“¨í„° ë¹„ì „, ì˜¤ë””ì˜¤ ë° ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬ì—ì„œ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•

<Tip>

ì§€ì›í•˜ëŠ” ëª¨ë“  íƒœìŠ¤í¬ì™€ ì“¸ ìˆ˜ ìˆëŠ” ë§¤ê°œë³€ìˆ˜ë¥¼ ë‹´ì€ ëª©ë¡ì€ [`pipeline`] ì„¤ëª…ì„œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

</Tip>

## Pipeline ì‚¬ìš©í•˜ê¸°[[pipeline-usage]]

ê° íƒœìŠ¤í¬ë§ˆë‹¤ ê³ ìœ ì˜ [`pipeline`]ì´ ìˆì§€ë§Œ, ê°œë³„ íŒŒì´í”„ë¼ì¸ì„ ë‹´ê³ ìˆëŠ” ì¶”ìƒí™”ëœ [`pipeline`]ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ê°„ë‹¨í•©ë‹ˆë‹¤. [`pipeline`]ì€ íƒœìŠ¤í¬ì— ì•Œë§ê²Œ ì¶”ë¡ ì´ ê°€ëŠ¥í•œ ê¸°ë³¸ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.

1. ë¨¼ì € [`pipeline`]ì„ ìƒì„±í•˜ê³  íƒœìŠ¤í¬ë¥¼ ì§€ì •í•˜ì„¸ìš”.

```py
>>> from transformers import pipeline

>>> generator = pipeline(task="automatic-speech-recognition")
```

2. ê·¸ë¦¬ê³  [`pipeline`]ì— ì…ë ¥ì„ ë„£ì–´ì£¼ì„¸ìš”.

```py
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}
```

ê¸°ëŒ€í–ˆë˜ ê²°ê³¼ê°€ ì•„ë‹Œê°€ìš”? Hubì—ì„œ [ê°€ì¥ ë§ì´ ë‹¤ìš´ë¡œë“œëœ ìë™ ìŒì„± ì¸ì‹ ëª¨ë¸](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads)ë¡œ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.
ë‹¤ìŒì€ [openai/whisper-large](https://huggingface.co/openai/whisper-large)ë¡œ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤.

```py
>>> generator = pipeline(model="openai/whisper-large")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

í›¨ì”¬ ë” ë‚˜ì•„ì¡Œêµ°ìš”!
Hubì˜ ëª¨ë¸ë“¤ì€ ì—¬ëŸ¬ ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ì „ë¬¸ë¶„ì•¼ë¥¼ ì•„ìš°ë¥´ê¸° ë•Œë¬¸ì— ê¼­ ìì‹ ì˜ ì–¸ì–´ë‚˜ ë¶„ì•¼ì— íŠ¹í™”ëœ ëª¨ë¸ì„ ì°¾ì•„ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.
ë¸Œë¼ìš°ì €ë¥¼ ë²—ì–´ë‚  í•„ìš”ì—†ì´ Hubì—ì„œ ì§ì ‘ ëª¨ë¸ì˜ ì¶œë ¥ì„ í™•ì¸í•˜ê³  ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµí•´ì„œ ìì‹ ì˜ ìƒí™©ì— ë” ì í•©í•œì§€, ì• ë§¤í•œ ì…ë ¥ì„ ë” ì˜ ì²˜ë¦¬í•˜ëŠ”ì§€ë„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë§Œì•½ ìƒí™©ì— ì•Œë§ëŠ” ëª¨ë¸ì„ ì—†ë‹¤ë©´ ì–¸ì œë‚˜ ì§ì ‘ [í›ˆë ¨](training)ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

ì…ë ¥ì´ ì—¬ëŸ¬ ê°œ ìˆëŠ” ê²½ìš°, ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
generator(
    [
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac",
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac",
    ]
)
```

ì „ì²´ ë°ì´í„°ì„¸íŠ¸ì„ ìˆœíšŒí•˜ê±°ë‚˜ ì›¹ì„œë²„ì— ì˜¬ë ¤ë‘ì–´ ì¶”ë¡ ì— ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´, ê° ìƒì„¸ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

[ë°ì´í„°ì„¸íŠ¸ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°](#using-pipelines-on-a-dataset)

[ì›¹ì„œë²„ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°](./pipeline_webserver)

## ë§¤ê°œë³€ìˆ˜[[parameters]]

[`pipeline`]ì€ ë§ì€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. íŠ¹ì • íƒœìŠ¤í¬ìš©ì¸ ê²ƒë„ ìˆê³ , ë²”ìš©ì¸ ê²ƒë„ ìˆìŠµë‹ˆë‹¤.
ì¼ë°˜ì ìœ¼ë¡œ ì›í•˜ëŠ” ìœ„ì¹˜ì— ì–´ë””ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
generator(model="openai/whisper-large", my_parameter=1)
out = generate(...)  # This will use `my_parameter=1`.
out = generate(..., my_parameter=2)  # This will override and use `my_parameter=2`.
out = generate(...)  # This will go back to using `my_parameter=1`.
```

ì¤‘ìš”í•œ 3ê°€ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

### ê¸°ê¸°(device)[[device]]

`device=n`ì²˜ëŸ¼ ê¸°ê¸°ë¥¼ ì§€ì •í•˜ë©´ íŒŒì´í”„ë¼ì¸ì´ ìë™ìœ¼ë¡œ í•´ë‹¹ ê¸°ê¸°ì— ëª¨ë¸ì„ ë°°ì¹˜í•©ë‹ˆë‹¤.
íŒŒì´í† ì¹˜ì—ì„œë‚˜ í…ì„œí”Œë¡œìš°ì—ì„œë„ ëª¨ë‘ ì‘ë™í•©ë‹ˆë‹¤.

```py
generator(model="openai/whisper-large", device=0)
```

ëª¨ë¸ì´ GPU í•˜ë‚˜ì— ëŒì•„ê°€ê¸° ë²„ê²ë‹¤ë©´, `device_map="auto"`ë¥¼ ì§€ì •í•´ì„œ ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate)ê°€ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ë¡œë“œí•˜ê³  ì €ì¥í• ì§€ ìë™ìœ¼ë¡œ ê²°ì •í•˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
#!pip install accelerate
generator(model="openai/whisper-large", device_map="auto")
```

### ë°°ì¹˜ ì‚¬ì´ì¦ˆ[[batch-size]]

ê¸°ë³¸ì ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ì€ [ì—¬ê¸°](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)ì— ë‚˜ì˜¨ ì´ìœ ë¡œ ì¶”ë¡ ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê°„ë‹¨íˆ ì„¤ëª…í•˜ìë©´ ì¼ê´„ ì²˜ë¦¬ê°€ ë°˜ë“œì‹œ ë” ë¹ ë¥´ì§€ ì•Šê³  ì˜¤íˆë ¤ ë” ëŠë ¤ì§ˆ ìˆ˜ë„ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ ìì‹ ì˜ ìƒí™©ì— ì í•©í•˜ë‹¤ë©´, ì´ë ‡ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.

```py
generator(model="openai/whisper-large", device=0, batch_size=2)
audio_filenames = [f"audio_{i}.flac" for i in range(10)]
texts = generator(audio_filenames)
```

íŒŒì´í”„ë¼ì¸ ìœ„ ì œê³µëœ 10ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì¶”ê°€ë¡œ ì²˜ë¦¬í•˜ëŠ” ì½”ë“œ ì—†ì´ (ì¼ê´„ ì²˜ë¦¬ì— ë³´ë‹¤ íš¨ê³¼ì ì¸ GPU ìœ„) ëª¨ë¸ì— 2ê°œì”© ì „ë‹¬í•©ë‹ˆë‹¤.
ì¶œë ¥ì€ ì¼ê´„ ì²˜ë¦¬í•˜ì§€ ì•Šì•˜ì„ ë•Œì™€ ë˜‘ê°™ì•„ì•¼ í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì—ì„œ ì†ë„ë¥¼ ë” ë‚¼ ìˆ˜ë„ ìˆëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ì¼ ë¿ì…ë‹ˆë‹¤.

íŒŒì´í”„ë¼ì¸ì€ ì¼ê´„ ì²˜ë¦¬ì˜ ë³µì¡í•œ ë¶€ë¶„ì„ ì¤„ì—¬ì£¼ê¸°ë„ í•©ë‹ˆë‹¤. (ì˜ˆë¥¼ ë“¤ì–´ ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì²˜ëŸ¼) ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ ì•¼ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê²ƒì„ [*chunk batching*](./main_classes/pipelines#pipeline-chunk-batching)ì´ë¼ê³  í•˜ëŠ”ë°, íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ë‚˜ëˆ ì¤ë‹ˆë‹¤.

### íŠ¹ì • íƒœìŠ¤í¬ìš© ë§¤ê°œë³€ìˆ˜[[task-specific-parameters]]

ê° íƒœìŠ¤í¬ë§ˆë‹¤ êµ¬í˜„í•  ë•Œ ìœ ì—°ì„±ê³¼ ì˜µì…˜ì„ ì œê³µí•˜ê¸° ìœ„í•´ íƒœìŠ¤í¬ìš© ë§¤ê°œë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´ [`transformers.AutomaticSpeechRecognitionPipeline.__call__`] ë©”ì„œë“œì—ëŠ” ë™ì˜ìƒì˜ ìë§‰ì„ ë„£ì„ ë•Œ ìœ ìš©í•  ê²ƒ ê°™ì€ `return_timestamps` ë§¤ê°œë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤. 

```py
>>> # Not using whisper, as it cannot provide timestamps.
>>> generator = pipeline(model="facebook/wav2vec2-large-960h-lv60-self", return_timestamps="word")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP AND LIVE OUT THE TRUE MEANING OF ITS CREED', 'chunks': [{'text': 'I', 'timestamp': (1.22, 1.24)}, {'text': 'HAVE', 'timestamp': (1.42, 1.58)}, {'text': 'A', 'timestamp': (1.66, 1.68)}, {'text': 'DREAM', 'timestamp': (1.76, 2.14)}, {'text': 'BUT', 'timestamp': (3.68, 3.8)}, {'text': 'ONE', 'timestamp': (3.94, 4.06)}, {'text': 'DAY', 'timestamp': (4.16, 4.3)}, {'text': 'THIS', 'timestamp': (6.36, 6.54)}, {'text': 'NATION', 'timestamp': (6.68, 7.1)}, {'text': 'WILL', 'timestamp': (7.32, 7.56)}, {'text': 'RISE', 'timestamp': (7.8, 8.26)}, {'text': 'UP', 'timestamp': (8.38, 8.48)}, {'text': 'AND', 'timestamp': (10.08, 10.18)}, {'text': 'LIVE', 'timestamp': (10.26, 10.48)}, {'text': 'OUT', 'timestamp': (10.58, 10.7)}, {'text': 'THE', 'timestamp': (10.82, 10.9)}, {'text': 'TRUE', 'timestamp': (10.98, 11.18)}, {'text': 'MEANING', 'timestamp': (11.26, 11.58)}, {'text': 'OF', 'timestamp': (11.66, 11.7)}, {'text': 'ITS', 'timestamp': (11.76, 11.88)}, {'text': 'CREED', 'timestamp': (12.0, 12.38)}]}
```

ë³´ì‹œë‹¤ì‹œí”¼ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ë¡ í•  ë¿ë§Œ ì•„ë‹ˆë¼ ê° ë‹¨ì–´ë¥¼ ë§í•œ ì‹œì ê¹Œì§€ë„ ì¶œë ¥í–ˆìŠµë‹ˆë‹¤.

íƒœìŠ¤í¬ë§ˆë‹¤ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë°ìš”. ì›í•˜ëŠ” íƒœìŠ¤í¬ì˜ APIë¥¼ ì°¸ì¡°í•´ì„œ ë°”ê¿”ë³¼ ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚´í´ë³´ì„¸ìš”!
ì§€ê¸ˆê¹Œì§€ ë‹¤ë¤„ë³¸ [`~transformers.AutomaticSpeechRecognitionPipeline`]ì—ëŠ” `chunk_length_s` ë§¤ê°œë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜í™”ë‚˜ 1ì‹œê°„ ë¶„ëŸ‰ì˜ ë™ì˜ìƒì˜ ìë§‰ ì‘ì—…ì„ í•  ë•Œì²˜ëŸ¼, ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë¸ì´ ìì²´ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ë§¤ìš° ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•  ë•Œ ìœ ìš©í•˜ì£ .


ë„ì›€ì´ ë  ë§Œí•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ì–¸ì œë“ ì§€ [ìš”ì²­](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)í•´ì£¼ì„¸ìš”!


## ë°ì´í„°ì„¸íŠ¸ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°[[using-pipelines-on-a-dataset]]

íŒŒì´í”„ë¼ì¸ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì„¸íŠ¸ì—ì„œë„ ì¶”ë¡  ì‘ì—…ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ ì´í„°ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê±¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.

```py
def data():
    for i in range(1000):
        yield f"My example {i}"


pipe = pipe(model="gpt2", device=0)
generated_characters = 0
for out in pipe(data()):
    generated_characters += len(out["generated_text"])
```

ì´í„°ë ˆì´í„° `data()`ëŠ” ê° ê²°ê³¼ë¥¼ í˜¸ì¶œë§ˆë‹¤ ìƒì„±í•˜ê³ , íŒŒì´í”„ë¼ì¸ì€ ì…ë ¥ì´ ìˆœíšŒí•  ìˆ˜ ìˆëŠ” ìë£Œêµ¬ì¡°ì„ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ GPUì—ì„œ ê¸°ì¡´ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ëŠ” ë™ì•ˆ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ì‹œì‘í•©ë‹ˆë‹¤.(ì´ë•Œ ë‚´ë¶€ì ìœ¼ë¡œ [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ë¥¼ ì‚¬ìš©í•´ìš”.) ì´ ê³¼ì •ì€ ì „ì²´ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë©”ëª¨ë¦¬ì— ì ì¬í•˜ì§€ ì•Šê³ ë„ GPUì— ìµœëŒ€í•œ ë¹ ë¥´ê²Œ ìƒˆë¡œìš´ ì‘ì—…ì„ ê³µê¸‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•©ë‹ˆë‹¤.

ê·¸ë¦¬ê³  ì¼ê´„ ì²˜ë¦¬ê°€ ë” ë¹ ë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, `batch_size` ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•´ë´ë„ ì¢‹ì•„ìš”.

ë°ì´í„°ì„¸íŠ¸ë¥¼ ìˆœíšŒí•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ğŸ¤— [Datasets](https://github.com/huggingface/datasets/)ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì¸ë°ìš”.

```py
# KeyDataset is a util that will just output the item we're interested in.
from transformers.pipelines.pt_utils import KeyDataset

pipe = pipeline(model="hf-internal-testing/tiny-random-wav2vec2", device=0)
dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation[:10]")

for out in pipe(KeyDataset(dataset["audio"])):
    print(out)
```


## ì›¹ì„œë²„ì—ì„œ Pipeline ì‚¬ìš©í•˜ê¸°[[using-pipelines-for-a-webserver]]

<Tip>
ì¶”ë¡  ì—”ì§„ì„ ë§Œë“œëŠ” ê³¼ì •ì€ ë”°ë¡œ í˜ì´ì§€ë¥¼ ì‘ì„±í• ë§Œí•œ ë³µì¡í•œ ì£¼ì œì…ë‹ˆë‹¤.
</Tip>

[Link](./pipeline_webserver)

## ë¹„ì „ Pipeline[[vision-pipeline]]

ë¹„ì „ íƒœìŠ¤í¬ë¥¼ ìœ„í•´ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ì¼ì€ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤.

íƒœìŠ¤í¬ë¥¼ ì§€ì •í•˜ê³  ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ê¸°ì— ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” ì¸í„°ë„· ë§í¬ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œì˜ í˜•íƒœë¡œ ì „ë‹¬í•´ì£¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ ì•„ë˜ì— í‘œì‹œëœ ê³ ì–‘ì´ëŠ” ì–´ë–¤ ì¢…ì¸ê°€ìš”?

![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)

```py
>>> from transformers import pipeline

>>> vision_classifier = pipeline(model="google/vit-base-patch16-224")
>>> preds = vision_classifier(
...     images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]
```

### í…ìŠ¤íŠ¸ Pipeline[[text-pipeline]]

NLP íƒœìŠ¤í¬ë¥¼ ìœ„í•´ [`pipeline`]ì„ ì‚¬ìš©í•˜ëŠ” ì¼ë„ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤.

```py
>>> from transformers import pipeline

>>> # This model is a `zero-shot-classification` model.
>>> # It will classify text, except you are free to choose any label you might imagine
>>> classifier = pipeline(model="facebook/bart-large-mnli")
>>> classifier(
...     "I have a problem with my iphone that needs to be resolved asap!!",
...     candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
... )
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

### ë©€í‹°ëª¨ë‹¬ Pipeline[[multimodal-pipeline]]

[`pipeline`]ì€ ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°(ì—­ì£¼: ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤, í…ìŠ¤íŠ¸ì™€ ê°™ì€ ë°ì´í„° í˜•íƒœ)ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì˜ˆì‹œë¡œ ì‹œê°ì  ì§ˆì˜ì‘ë‹µ(VQA; Visual Question Answering) íƒœìŠ¤í¬ëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ ì–´ë–¤ ì´ë¯¸ì§€ ë§í¬ë‚˜ ë¬»ê³  ì‹¶ì€ ì§ˆë¬¸ë„ ììœ ë¡­ê²Œ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” URL ë˜ëŠ” ë¡œì»¬ ê²½ë¡œì˜ í˜•íƒœë¡œ ì „ë‹¬í•´ì£¼ì„¸ìš”.

ì˜ˆë¥¼ ë“¤ì–´ ì´ [ê±°ë˜ëª…ì„¸ì„œ ì‚¬ì§„](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)ì—ì„œ ê±°ë˜ëª…ì„¸ì„œ ë²ˆí˜¸ë¥¼ ë¬»ê³  ì‹¶ë‹¤ë©´,

```py
>>> from transformers import pipeline

>>> vqa = pipeline(model="impira/layoutlm-document-qa")
>>> vqa(
...     image="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png",
...     question="What is the invoice number?",
... )
[{'score': 0.42514941096305847, 'answer': 'us-001', 'start': 16, 'end': 16}]
```
