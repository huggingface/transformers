<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# ë‹¤êµ­ì–´ ëª¨ë¸ ì¶”ë¡ í•˜ê¸°[[multilingual-models-for-inference]]

[[open-in-colab]]

ğŸ¤— Transformersì—ëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë‹¤êµ­ì–´(multilingual) ëª¨ë¸ì´ ìˆìœ¼ë©°, ë‹¨ì¼ ì–¸ì–´(monolingual) ëª¨ë¸ê³¼ ì¶”ë¡  ì‹œ ì‚¬ìš©ë²•ì´ ë‹¤ë¦…ë‹ˆë‹¤.
ê·¸ë ‡ë‹¤ê³  í•´ì„œ *ëª¨ë“ * ë‹¤êµ­ì–´ ëª¨ë¸ì˜ ì‚¬ìš©ë²•ì´ ë‹¤ë¥¸ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.

[bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased)ì™€ ê°™ì€ ëª‡ëª‡ ëª¨ë¸ì€ ë‹¨ì¼ ì–¸ì–´ ëª¨ë¸ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ë²ˆ ê°€ì´ë“œì—ì„œ ë‹¤êµ­ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ì‹œ ì‚¬ìš© ë°©ë²•ì„ ì•Œì•„ë³¼ ê²ƒì…ë‹ˆë‹¤.

## XLM[[xlm]]

XLMì—ëŠ” 10ê°€ì§€ ì²´í¬í¬ì¸íŠ¸(checkpoint)ê°€ ìˆëŠ”ë°, ì´ ì¤‘ í•˜ë‚˜ë§Œ ë‹¨ì¼ ì–¸ì–´ì…ë‹ˆë‹¤. 
ë‚˜ë¨¸ì§€ ì²´í¬í¬ì¸íŠ¸ 9ê°œëŠ” ì–¸ì–´ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” ì²´í¬í¬ì¸íŠ¸ì™€ ê·¸ë ‡ì§€ ì•Šì€ ì²´í¬í¬ì¸íŠ¸ì˜ ë‘ ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì–¸ì–´ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” XLM[[xlm-with-language-embeddings]]

ë‹¤ìŒ XLM ëª¨ë¸ì€ ì¶”ë¡  ì‹œì— ì–¸ì–´ ì„ë² ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

- `xlm-mlm-ende-1024` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, ì˜ì–´-ë…ì¼ì–´)
- `xlm-mlm-enfr-1024` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, ì˜ì–´-í”„ë‘ìŠ¤ì–´)
- `xlm-mlm-enro-1024` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, ì˜ì–´-ë£¨ë§ˆë‹ˆì•„ì–´)
- `xlm-mlm-xnli15-1024` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, XNLI ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì œê³µí•˜ëŠ” 15ê°œ êµ­ì–´)
- `xlm-mlm-tlm-xnli15-1024` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§ + ë²ˆì—­, XNLI ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì œê³µí•˜ëŠ” 15ê°œ êµ­ì–´)
- `xlm-clm-enfr-1024` (Causal language modeling, ì˜ì–´-í”„ë‘ìŠ¤ì–´)
- `xlm-clm-ende-1024` (Causal language modeling, ì˜ì–´-ë…ì¼ì–´)

ì–¸ì–´ ì„ë² ë”©ì€ ëª¨ë¸ì— ì „ë‹¬ëœ `input_ids`ì™€ ë™ì¼í•œ shapeì˜ í…ì„œë¡œ í‘œí˜„ë©ë‹ˆë‹¤.
ì´ëŸ¬í•œ í…ì„œì˜ ê°’ì€ ì‚¬ìš©ëœ ì–¸ì–´ì— ë”°ë¼ ë‹¤ë¥´ë©° í† í¬ë‚˜ì´ì €ì˜ `lang2id` ë° `id2lang` ì†ì„±ì— ì˜í•´ ì‹ë³„ë©ë‹ˆë‹¤.

ë‹¤ìŒ ì˜ˆì œì—ì„œëŠ” `xlm-clm-enfr-1024` ì²´í¬í¬ì¸íŠ¸(ì½”ì˜ ì–¸ì–´ ëª¨ë¸ë§(causal language modeling), ì˜ì–´-í”„ë‘ìŠ¤ì–´)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤:

```py
>>> import torch
>>> from transformers import XLMTokenizer, XLMWithLMHeadModel

>>> tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
>>> model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")
```

í† í¬ë‚˜ì´ì €ì˜ `lang2id` ì†ì„±ì€ ëª¨ë¸ì˜ ì–¸ì–´ì™€ í•´ë‹¹ IDë¥¼ í‘œì‹œí•©ë‹ˆë‹¤:

```py
>>> print(tokenizer.lang2id)
{'en': 0, 'fr': 1}
```

ë‹¤ìŒìœ¼ë¡œ, ì˜ˆì œ ì…ë ¥ì„ ë§Œë“­ë‹ˆë‹¤:

```py
>>> input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # ë°°ì¹˜ í¬ê¸°ëŠ” 1ì…ë‹ˆë‹¤
```

ì–¸ì–´ IDë¥¼ `"en"`ìœ¼ë¡œ ì„¤ì •í•´ ì–¸ì–´ ì„ë² ë”©ì„ ì •ì˜í•©ë‹ˆë‹¤. 
ì–¸ì–´ ì„ë² ë”©ì€ ì˜ì–´ì˜ ì–¸ì–´ IDì¸ `0`ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œì…ë‹ˆë‹¤.
ì´ í…ì„œëŠ” `input_ids`ì™€ ê°™ì€ í¬ê¸°ì—¬ì•¼ í•©ë‹ˆë‹¤. 

```py
>>> language_id = tokenizer.lang2id["en"]  # 0
>>> langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])

>>> # (batch_size, sequence_length) shapeì˜ í…ì„œê°€ ë˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.
>>> langs = langs.view(1, -1)  # ì´ì œ [1, sequence_length] shapeì´ ë˜ì—ˆìŠµë‹ˆë‹¤(ë°°ì¹˜ í¬ê¸°ëŠ” 1ì…ë‹ˆë‹¤)
```

ì´ì œ `input_ids`ì™€ ì–¸ì–´ ì„ë² ë”©ì„ ëª¨ë¸ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤:

```py
>>> outputs = model(input_ids, langs=langs)
```

[run_generation.py](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py) ìŠ¤í¬ë¦½íŠ¸ë¡œ `xlm-clm` ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ì™€ ì–¸ì–´ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì–¸ì–´ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” XLM[[xlm-without-language-embeddings]]

ë‹¤ìŒ XLM ëª¨ë¸ì€ ì¶”ë¡  ì‹œì— ì–¸ì–´ ì„ë² ë”©ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:

- `xlm-mlm-17-1280` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, 17ê°œ êµ­ì–´)
- `xlm-mlm-100-1280` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, 100ê°œ êµ­ì–´)

ì´ì „ì˜ XLM ì²´í¬í¬ì¸íŠ¸ì™€ ë‹¬ë¦¬ ì´ ëª¨ë¸ì€ ì¼ë°˜ ë¬¸ì¥ í‘œí˜„ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

## BERT[[bert]]

ë‹¤ìŒ BERT ëª¨ë¸ì€ ë‹¤êµ­ì–´ íƒœìŠ¤í¬ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- `bert-base-multilingual-uncased` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§ + ë‹¤ìŒ ë¬¸ì¥ ì˜ˆì¸¡, 102ê°œ êµ­ì–´)
- `bert-base-multilingual-cased` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§ + ë‹¤ìŒ ë¬¸ì¥ ì˜ˆì¸¡, 104ê°œ êµ­ì–´)

ì´ëŸ¬í•œ ëª¨ë¸ì€ ì¶”ë¡  ì‹œì— ì–¸ì–´ ì„ë² ë”©ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 
ë¬¸ë§¥ì—ì„œ ì–¸ì–´ë¥¼ ì‹ë³„í•˜ê³ , ì‹ë³„ëœ ì–¸ì–´ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤.

## XLM-RoBERTa[[xlmroberta]]

ë‹¤ìŒ XLM-RoBERTa ë˜í•œ ë‹¤êµ­ì–´ ë‹¤êµ­ì–´ íƒœìŠ¤í¬ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- `xlm-roberta-base` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, 100ê°œ êµ­ì–´)
- `xlm-roberta-large` (ë§ˆìŠ¤í‚¹ëœ ì–¸ì–´ ëª¨ë¸ë§, 100ê°œ êµ­ì–´)

XLM-RoBERTaëŠ” 100ê°œ êµ­ì–´ì— ëŒ€í•´ ìƒˆë¡œ ìƒì„±ë˜ê³  ì •ì œëœ 2.5TB ê·œëª¨ì˜ CommonCrawl ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.
ì´ì „ì— ê³µê°œëœ mBERTë‚˜ XLMê³¼ ê°™ì€ ë‹¤êµ­ì–´ ëª¨ë¸ì— ë¹„í•´ ë¶„ë¥˜, ì‹œí€€ìŠ¤ ë¼ë²¨ë§, ì§ˆì˜ ì‘ë‹µê³¼ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼(downstream) ì‘ì—…ì—ì„œ ì´ì ì´ ìˆìŠµë‹ˆë‹¤.

## M2M100[[m2m100]]

ë‹¤ìŒ M2M100 ëª¨ë¸ ë˜í•œ ë‹¤êµ­ì–´ ë‹¤êµ­ì–´ íƒœìŠ¤í¬ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- `facebook/m2m100_418M` (ë²ˆì—­)
- `facebook/m2m100_1.2B` (ë²ˆì—­)

ì´ ì˜ˆì œì—ì„œëŠ” `facebook/m2m100_418M` ì²´í¬í¬ì¸íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ì¤‘êµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤. 
í† í¬ë‚˜ì´ì €ì—ì„œ ë²ˆì—­ ëŒ€ìƒ ì–¸ì–´(source language)ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
>>> from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

>>> en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
>>> chinese_text = "ä¸è¦æ’æ‰‹å·«å¸«çš„äº‹å‹™, å› ç‚ºä»–å€‘æ˜¯å¾®å¦™çš„, å¾ˆå¿«å°±æœƒç™¼æ€’."

>>> tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M", src_lang="zh")
>>> model = M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")
```

ë¬¸ì¥ì„ í† í°í™”í•©ë‹ˆë‹¤:

```py
>>> encoded_zh = tokenizer(chinese_text, return_tensors="pt")
```

M2M100ì€ ë²ˆì—­ì„ ì§„í–‰í•˜ê¸° ìœ„í•´ ì²« ë²ˆì§¸ë¡œ ìƒì„±ë˜ëŠ” í† í°ì€ ë²ˆì—­í•  ì–¸ì–´(target language) IDë¡œ ê°•ì œ ì§€ì •í•©ë‹ˆë‹¤.
ì˜ì–´ë¡œ ë²ˆì—­í•˜ê¸° ìœ„í•´ `generate` ë©”ì†Œë“œì—ì„œ `forced_bos_token_id`ë¥¼ `en`ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤:

```py
>>> generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id("en"))
>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
'Do not interfere with the matters of the witches, because they are delicate and will soon be angry.'
```

## MBart[[mbart]]

ë‹¤ìŒ MBart ëª¨ë¸ ë˜í•œ ë‹¤êµ­ì–´ íƒœìŠ¤í¬ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- `facebook/mbart-large-50-one-to-many-mmt` (ì¼ëŒ€ë‹¤ ë‹¤êµ­ì–´ ë²ˆì—­, 50ê°œ êµ­ì–´)
- `facebook/mbart-large-50-many-to-many-mmt` (ë‹¤ëŒ€ë‹¤ ë‹¤êµ­ì–´ ë²ˆì—­, 50ê°œ êµ­ì–´)
- `facebook/mbart-large-50-many-to-one-mmt` (ë‹¤ëŒ€ì¼ ë‹¤êµ­ì–´ ë²ˆì—­, 50ê°œ êµ­ì–´)
- `facebook/mbart-large-50` (ë‹¤êµ­ì–´ ë²ˆì—­, 50ê°œ êµ­ì–´)
- `facebook/mbart-large-cc25`

ì´ ì˜ˆì œì—ì„œëŠ” í•€ë€ë“œì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ê¸° ìœ„í•´ `facebook/mbart-large-50-many-to-many-mmt` ì²´í¬í¬ì¸íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. 
í† í¬ë‚˜ì´ì €ì—ì„œ ë²ˆì—­ ëŒ€ìƒ ì–¸ì–´(source language)ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
>>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

>>> en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
>>> fi_text = "Ã„lÃ¤ sekaannu velhojen asioihin, sillÃ¤ ne ovat hienovaraisia ja nopeasti vihaisia."

>>> tokenizer = AutoTokenizer.from_pretrained("facebook/mbart-large-50-many-to-many-mmt", src_lang="fi_FI")
>>> model = AutoModelForSeq2SeqLM.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")
```

ë¬¸ì¥ì„ í† í°í™”í•©ë‹ˆë‹¤:

```py
>>> encoded_en = tokenizer(en_text, return_tensors="pt")
```

MBartëŠ” ë²ˆì—­ì„ ì§„í–‰í•˜ê¸° ìœ„í•´ ì²« ë²ˆì§¸ë¡œ ìƒì„±ë˜ëŠ” í† í°ì€ ë²ˆì—­í•  ì–¸ì–´(target language) IDë¡œ ê°•ì œ ì§€ì •í•©ë‹ˆë‹¤.
ì˜ì–´ë¡œ ë²ˆì—­í•˜ê¸° ìœ„í•´ `generate` ë©”ì†Œë“œì—ì„œ `forced_bos_token_id`ë¥¼ `en`ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤:

```py
>>> generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id("en_XX"))
>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
"Don't interfere with the wizard's affairs, because they are subtle, will soon get angry."
```

`facebook/mbart-large-50-many-to-one-mmt` ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤ë©´, ì²« ë²ˆì§¸ë¡œ ìƒì„±ë˜ëŠ” í† í°ì„ ë²ˆì—­í•  ì–¸ì–´(target language) IDë¡œ ê°•ì œ ì§€ì •í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.
