<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Usa los tokenizadores de ü§ó Tokenizers

[`PreTrainedTokenizerFast`] depende de la librer√≠a [ü§ó Tokenizers](https://huggingface.co/docs/tokenizers). Los tokenizadores obtenidos desde la librer√≠a ü§ó Tokenizers pueden ser 
cargados muy simplemente a ü§ó Transformers.

Antes de entrar en los detalles, podemos crear un tokenizador dummy en unas cuantas l√≠neas:

```python
>>> from tokenizers import Tokenizer
>>> from tokenizers.models import BPE
>>> from tokenizers.trainers import BpeTrainer
>>> from tokenizers.pre_tokenizers import Whitespace

>>> tokenizer = Tokenizer(BPE(unk_token="[UNK]"))
>>> trainer = BpeTrainer(special_tokens=["[UNK]", "[CLS]", "[SEP]", "[PAD]", "[MASK]"])

>>> tokenizer.pre_tokenizer = Whitespace()
>>> files = [...]
>>> tokenizer.train(files, trainer)
```

Ahora tenemos un tokenizador entrenado con los archivos (files en el c√≥digo) que fueron definidos. Lo podemos seguir utilizando en ese entorno de ejecuci√≥n (runtime en ingl√©s), o se lo puede guardar
en un archivo JSON para reutilizarlo en un futuro.

## Cargando directamente desde el objeto tokenizador 

Veamos como utilizar este objeto tokenizador en la librer√≠a ü§ó Transformers. La clase
[`PreTrainedTokenizerFast`] permite una instanciaci√≥n simple, al aceptar el objeto
*tokenizer* instanciado como argumento:

```python
>>> from transformers import PreTrainedTokenizerFast

>>> fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)
```

Este objeto ya puede ser utilizado con todos los m√©todos compartidos por los tokenizadores de ü§ó Transformers! Visita la [p√°gina sobre tokenizadores
](main_classes/tokenizer) para m√°s informaci√≥n.

## Cargando desde un archivo JSON

Para cargar un tokenizador desde un archivo JSON, comencemos por guardar nuestro tokenizador:

```python
>>> tokenizer.save("tokenizer.json")
```

La localizaci√≥n (path en ingl√©s) donde este archivo es guardado puede ser incluida en el m√©todo de inicializaci√≥n de [`PreTrainedTokenizerFast`]
utilizando el par√°metro `tokenizer_file`:

```python
>>> from transformers import PreTrainedTokenizerFast

>>> fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file="tokenizer.json")
```

Este objeto ya puede ser utilizado con todos los m√©todos compartidos por los tokenizadores de ü§ó Transformers! Visita la [p√°gina sobre tokenizadores
](main_classes/tokenizer) para m√°s informaci√≥n.
