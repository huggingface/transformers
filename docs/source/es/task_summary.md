<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

丘멆잺 Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Lo que 游뱅 Transformers puede hacer

游뱅 Transformers es una biblioteca de modelos preentrenados de 칰ltima generaci칩n para procesamiento del lenguaje natural (NLP, por sus siglas en ingl칠s), visi칩n por computadora y tareas de procesamiento de audio y voz. No solo contiene modelos Transformer, sino tambi칠n modelos no Transformer como redes convolucionales modernas para tareas de visi칩n por computadora. Si observas algunos de los productos de consumo m치s populares hoy en d칤a, como tel칠fonos inteligentes, aplicaciones y televisores, es probable que haya alguna tecnolog칤a de aprendizaje profundo detr치s. 쯈uieres quitar un objeto de fondo de una foto tomada por tu tel칠fono inteligente? Este es un ejemplo de una tarea de segmentaci칩n pan칩ptica (no te preocupes si a칰n no sabes qu칠 significa, 춰lo describiremos en las siguientes secciones!).

Esta p치gina proporciona una descripci칩n general de las diferentes tareas de procesamiento de audio y voz, visi칩n por computadora y NLP que se pueden resolver con la biblioteca 游뱅 Transformers en solo tres l칤neas de c칩digo.

## Audio

Las tareas de procesamiento de audio y voz son un poco diferentes de las otras modalidades principalmente porque el audio como entrada es una se침al continua. A diferencia del texto, una forma de onda de audio cruda no se puede dividir ordenadamente en fragmentos discretos de la misma manera en que una oraci칩n puede dividirse en palabras. Para superar esto, la se침al de audio cruda generalmente se muestrea a intervalos regulares. Si tomas m치s muestras dentro de un intervalo, la tasa de muestreo es mayor y el audio se asemeja m치s a la fuente de audio original.

Enfoques anteriores preprocesaban el audio para extraer caracter칤sticas 칰tiles. Ahora es m치s com칰n comenzar las tareas de procesamiento de audio y voz alimentando directamente la forma de onda de audio cruda a un codificador de caracter칤sticas para extraer una representaci칩n de audio. Esto simplifica el paso de preprocesamiento y permite que el modelo aprenda las caracter칤sticas m치s esenciales.

### Clasificaci칩n de audio

La clasificaci칩n de audio es una tarea que etiqueta datos de audio con un conjunto predefinido de clases. Es una categor칤a amplia con muchas aplicaciones espec칤ficas, algunas de las cuales incluyen:

* clasificaci칩n de escena ac칰stica: etiquetar audio con una etiqueta de escena ("oficina", "playa", "estadio")
* detecci칩n de eventos ac칰sticos: etiquetar audio con una etiqueta de evento de sonido ("bocina de autom칩vil", "llamada de ballena", "cristal rompi칠ndose")
* etiquetado: etiquetar audio que contiene varios sonidos (canto de p치jaros, identificaci칩n de altavoces en una reuni칩n)
* clasificaci칩n de m칰sica: etiquetar m칰sica con una etiqueta de g칠nero ("metal", "hip-hop", "country")

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="audio-classification", model="superb/hubert-base-superb-er")
>>> preds = classifier("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4532, 'label': 'hap'},
 {'score': 0.3622, 'label': 'sad'},
 {'score': 0.0943, 'label': 'neu'},
 {'score': 0.0903, 'label': 'ang'}]
```

### Reconocimiento autom치tico del habla

El reconocimiento autom치tico del habla (ASR, por sus siglas en ingl칠s) transcribe el habla a texto. Es una de las tareas de audio m치s comunes, en parte debido a que el habla es una forma natural de comunicaci칩n humana. Hoy en d칤a, los sistemas ASR est치n integrados en productos de tecnolog칤a "inteligente" como altavoces, tel칠fonos y autom칩viles. Podemos pedirle a nuestros asistentes virtuales que reproduzcan m칰sica, establezcan recordatorios y nos informen sobre el clima.

Pero uno de los desaf칤os clave que las arquitecturas Transformer han ayudado a superar es en los idiomas con recursos limitados. Al preentrenar con grandes cantidades de datos de habla, afinar el modelo solo con una hora de datos de habla etiquetados en un idioma con recursos limitados a칰n puede producir resultados de alta calidad en comparaci칩n con los sistemas ASR anteriores entrenados con 100 veces m치s datos etiquetados.

```py
>>> from transformers import pipeline

>>> transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-small")
>>> transcriber("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

## Visi칩n por computadora

Una de las primeras y exitosas tareas de visi칩n por computadora fue reconocer im치genes de n칰meros de c칩digo postal utilizando una [red neuronal convolucional](glossary#convolution) (CNN, por sus siglas en ingl칠s). Una imagen est치 compuesta por p칤xeles, y cada p칤xel tiene un valor num칠rico. Esto facilita representar una imagen como una matriz de valores de p칤xeles. Cada combinaci칩n particular de valores de p칤xeles describe los colores de una imagen.

Dos formas generales en las que se pueden resolver las tareas de visi칩n por computadora son:

1. Utilizar convoluciones para aprender las caracter칤sticas jer치rquicas de una imagen, desde caracter칤sticas de bajo nivel hasta cosas abstractas de alto nivel.
2. Dividir una imagen en parches y utilizar un Transformer para aprender gradualmente c칩mo cada parche de imagen se relaciona entre s칤 para formar una imagen. A diferencia del enfoque ascendente preferido por una CNN, esto es como comenzar con una imagen borrosa y luego enfocarla gradualmente.

### Clasificaci칩n de im치genes

La clasificaci칩n de im치genes etiqueta una imagen completa con un conjunto predefinido de clases. Como la mayor칤a de las tareas de clasificaci칩n, hay muchos casos pr치cticos para la clasificaci칩n de im치genes, algunos de los cuales incluyen:

* salud: etiquetar im치genes m칠dicas para detectar enfermedades o monitorear la salud del paciente
* medio ambiente: etiquetar im치genes de sat칠lite para monitorear la deforestaci칩n, informar la gesti칩n de 치reas silvestres o detectar incendios forestales
* agricultura: etiquetar im치genes de cultivos para monitorear la salud de las plantas o im치genes de sat칠lite para el monitoreo del uso del suelo
* ecolog칤a: etiquetar im치genes de especies animales o vegetales para monitorear poblaciones de vida silvestre o rastrear especies en peligro de extinci칩n

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="image-classification")
>>> preds = classifier(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> print(*preds, sep="\n")
{'score': 0.4335, 'label': 'lynx, catamount'}
{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}
{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}
{'score': 0.0239, 'label': 'Egyptian cat'}
{'score': 0.0229, 'label': 'tiger cat'}
```

### Detecci칩n de objetos

A diferencia de la clasificaci칩n de im치genes, la detecci칩n de objetos identifica m칰ltiples objetos dentro de una imagen y las posiciones de los objetos en la imagen (definidas por el cuadro delimitador). Algunas aplicaciones ejemplares de la detecci칩n de objetos incluyen:

* veh칤culos aut칩nomos: detectar objetos de tr치fico cotidianos como otros veh칤culos, peatones y sem치foros
* teledetecci칩n: monitoreo de desastres, planificaci칩n urbana y pron칩stico del tiempo
* detecci칩n de defectos: detectar grietas o da침os estructurales en edificios y defectos de fabricaci칩n

```py
>>> from transformers import pipeline

>>> detector = pipeline(task="object-detection")
>>> preds = detector(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"], "box": pred["box"]} for pred in preds]
>>> preds
[{'score': 0.9865,
  'label': 'cat',
  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]
```

### Segmentaci칩n de im치genes

La segmentaci칩n de im치genes es una tarea a nivel de p칤xeles que asigna cada p칤xel en una imagen a una clase. A diferencia de la detecci칩n de objetos, que utiliza cuadros delimitadores para etiquetar y predecir objetos en una imagen, la segmentaci칩n es m치s granular. La segmentaci칩n puede detectar objetos a nivel de p칤xeles. Hay varios tipos de segmentaci칩n de im치genes:

* segmentaci칩n de instancias: adem치s de etiquetar la clase de un objeto, tambi칠n etiqueta cada instancia distinta de un objeto ("perro-1", "perro-2")
* segmentaci칩n pan칩ptica: una combinaci칩n de segmentaci칩n sem치ntica y de instancias; etiqueta cada p칤xel con una clase sem치ntica **y** cada instancia distinta de un objeto

Las tareas de segmentaci칩n son 칰tiles en veh칤culos aut칩nomos para crear un mapa a nivel de p칤xeles del mundo que los rodea para que puedan navegar de manera segura alrededor de peatones y otros veh칤culos. Tambi칠n es 칰til en im치genes m칠dicas, donde la mayor granularidad de la tarea puede ayudar a identificar c칠lulas anormales o caracter칤sticas de 칩rganos. La segmentaci칩n de im치genes tambi칠n se puede utilizar en comercio electr칩nico para probar virtualmente la ropa o crear experiencias de realidad aumentada superponiendo objetos en el mundo real a trav칠s de tu c치mara.

```py
>>> from transformers import pipeline

>>> segmenter = pipeline(task="image-segmentation")
>>> preds = segmenter(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> print(*preds, sep="\n")
{'score': 0.9879, 'label': 'LABEL_184'}
{'score': 0.9973, 'label': 'snow'}
{'score': 0.9972, 'label': 'cat'}
```

### Estimaci칩n de profundidad

La estimaci칩n de profundidad predice la distancia de cada p칤xel en una imagen desde la c치mara. Esta tarea de visi칩n por computadora es especialmente importante para la comprensi칩n y reconstrucci칩n de escenas. Por ejemplo, en los veh칤culos aut칩nomos, es necesario entender qu칠 tan lejos est치n los objetos como peatones, se침ales de tr치fico y otros veh칤culos para evitar obst치culos y colisiones. La informaci칩n de profundidad tambi칠n es 칰til para construir representaciones 3D a partir de im치genes 2D y se puede utilizar para crear representaciones 3D de alta calidad de estructuras biol칩gicas o edificios.

Hay dos enfoques para la estimaci칩n de profundidad:

* est칠reo: las profundidades se estiman comparando dos im치genes de la misma escena desde 치ngulos ligeramente diferentes
* monocular: las profundidades se estiman a partir de una sola imagen

```py
>>> from transformers import pipeline

>>> depth_estimator = pipeline(task="depth-estimation")
>>> preds = depth_estimator(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
```

## Procesamiento del lenguaje natural

Las tareas de procesamiento del lenguaje natural (NLP, por sus siglas en ingl칠s) est치n entre los tipos de tareas m치s comunes porque el texto es una forma natural de comunicaci칩n para nosotros. Para convertir el texto en un formato reconocido por un modelo, es necesario tokenizarlo. Esto significa dividir una secuencia de texto en palabras o subpalabras separadas (tokens) y luego convertir estos tokens en n칰meros. Como resultado, puedes representar una secuencia de texto como una secuencia de n칰meros, y una vez que tienes una secuencia de n칰meros, se puede ingresar a un modelo para resolver todo tipo de tareas de NLP.

### Clasificaci칩n de texto

Al igual que las tareas de clasificaci칩n en cualquier modalidad, la clasificaci칩n de texto etiqueta una secuencia de texto (puede ser a nivel de oraci칩n, p치rrafo o documento) de un conjunto predefinido de clases. Hay muchas aplicaciones pr치cticas para la clasificaci칩n de texto, algunas de las cuales incluyen:

* an치lisis de sentimientos: etiquetar texto seg칰n alguna polaridad como `positivo` o `negativo`, lo que puede informar y respaldar la toma de decisiones en campos como pol칤tica, finanzas y marketing
* clasificaci칩n de contenido: etiquetar texto seg칰n alg칰n tema para ayudar a organizar y filtrar informaci칩n en noticias y feeds de redes sociales (`clima`, `deportes`, `finanzas`, etc.)

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="sentiment-analysis")
>>> preds = classifier("Hugging Face is the best thing since sliced bread!")
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.9991, 'label': 'POSITIVE'}]
```

### Clasificaci칩n de tokens

En cualquier tarea de NLP, el texto se procesa separando la secuencia de texto en palabras o subpalabras individuales. Estas se conocen como [tokens](glossary#token). La clasificaci칩n de tokens asigna a cada token una etiqueta de un conjunto predefinido de clases.

Dos tipos comunes de clasificaci칩n de tokens son:

* reconocimiento de entidades nombradas (NER, por sus siglas en ingl칠s): etiquetar un token seg칰n una categor칤a de entidad como organizaci칩n, persona, ubicaci칩n o fecha. NER es especialmente popular en entornos biom칠dicos, donde puede etiquetar genes, prote칤nas y nombres de medicamentos
* etiquetado de partes del discurso (POS, por sus siglas en ingl칠s): etiquetar un token seg칰n su parte del discurso, como sustantivo, verbo o adjetivo. POS es 칰til para ayudar a los sistemas de traducci칩n a comprender c칩mo dos palabras id칠nticas son gramaticalmente diferentes (por ejemplo, "corte" como sustantivo versus "corte" como verbo)

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="ner")
>>> preds = classifier("Hugging Face is a French company based in New York City.")
>>> preds = [
...     {
...         "entity": pred["entity"],
...         "score": round(pred["score"], 4),
...         "index": pred["index"],
...         "word": pred["word"],
...         "start": pred["start"],
...         "end": pred["end"],
...     }
...     for pred in preds
... ]
>>> print(*preds, sep="\n")
{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}
{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}
{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}
{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}
{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}
{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}
{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}
```

### Respuestas a preguntas

Responder preguntas es otra tarea a nivel de tokens que devuelve una respuesta a una pregunta, a veces con contexto (dominio abierto) y otras veces sin contexto (dominio cerrado). Esta tarea ocurre cuando le preguntamos algo a un asistente virtual, como si un restaurante est치 abierto. Tambi칠n puede proporcionar soporte al cliente o t칠cnico y ayudar a los motores de b칰squeda a recuperar la informaci칩n relevante que est치s buscando.

Hay dos tipos comunes de respuestas a preguntas:

* extractivas: dada una pregunta y alg칰n contexto, la respuesta es un fragmento de texto del contexto que el modelo debe extraer
* abstractivas: dada una pregunta y alg칰n contexto, la respuesta se genera a partir del contexto; este enfoque lo maneja la [`Text2TextGenerationPipeline`] en lugar del [`QuestionAnsweringPipeline`] que se muestra a continuaci칩n

```py
>>> from transformers import pipeline

>>> question_answerer = pipeline(task="question-answering")
>>> preds = question_answerer(
...     question="What is the name of the repository?",
...     context="The name of the repository is huggingface/transformers",
... )
>>> print(
...     f"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}"
... )
score: 0.9327, start: 30, end: 54, answer: huggingface/transformers
```

### Resumir

Al resumir se crea una versi칩n m치s corta de un texto m치s largo mientras intenta preservar la mayor parte del significado del documento original. Resumir es una tarea de secuencia a secuencia; produce una secuencia de texto m치s corta que la entrada. Hay muchos documentos de formato largo que se pueden resumir para ayudar a los lectores a comprender r치pidamente los puntos principales. Proyectos de ley legislativos, documentos legales y financieros, patentes y art칤culos cient칤ficos son algunos ejemplos de documentos que podr칤an resumirse para ahorrar tiempo a los lectores y servir como ayuda para la lectura.

Al igual que en las respuestas a preguntas, hay dos tipos de resumen:

* extractiva: identifica y extrae las oraciones m치s importantes del texto original
* abstractiva: genera el resumen objetivo (que puede incluir nuevas palabras no presentes en el documento de entrada) a partir del texto original; el [`SummarizationPipeline`] utiliza el enfoque abstractivo

```py
>>> from transformers import pipeline

>>> summarizer = pipeline(task="summarization")
>>> summarizer(
...     "In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles."
... )
[{'summary_text': ' The Transformer is the first sequence transduction model based entirely on attention . It replaces the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention . For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers .'}]
```

### Traducci칩n

La traducci칩n convierte una secuencia de texto en un idioma a otro. Es importante para ayudar a personas de diferentes or칤genes a comunicarse entre s칤, traducir contenido para llegar a audiencias m치s amplias e incluso ser una herramienta de aprendizaje para ayudar a las personas a aprender un nuevo idioma. Al igual que resumir, la traducci칩n es una tarea de secuencia a secuencia, lo que significa que el modelo recibe una secuencia de entrada y devuelve una secuencia de salida objetivo.

En sus primeros d칤as, los modelos de traducci칩n eran principalmente monoling칲es, pero recientemente ha habido un creciente inter칠s en modelos multiling칲es que pueden traducir entre muchas combinaciones de idiomas.

```py
>>> from transformers import pipeline

>>> text = "translate English to French: Hugging Face is a community-based open-source platform for machine learning."
>>> translator = pipeline(task="translation", model="t5-small")
>>> translator(text)
[{'translation_text': "Hugging Face est une tribune communautaire de l'apprentissage des machines."}]
```

### Modelado de lenguaje

El modelado de lenguaje es una tarea que predice una palabra en una secuencia de texto. Se ha vuelto una tarea de NLP muy popular porque un modelo de lenguaje preentrenado puede ser afinado para muchas otras tareas secundarias. 칔ltimamente, ha habido mucho inter칠s en modelos de lenguaje grandes (LLM, por sus siglas en ingl칠s) que demuestran aprendizaje de cero o con pocas muestras (zero- or few-shot learning). 춰Esto significa que el modelo puede resolver tareas para las cuales no fue entrenado expl칤citamente! Los modelos de lenguaje se pueden utilizar para generar texto fluido y convincente, aunque debes tener cuidado, ya que el texto no siempre puede ser preciso.

Hay dos tipos de modelado de lenguaje:

* causal: el objetivo del modelo es predecir el pr칩ximo token en una secuencia, y los tokens futuros est치n enmascarados

    ```py
    >>> from transformers import pipeline

    >>> prompt = "Hugging Face is a community-based open-source platform for machine learning."
    >>> generator = pipeline(task="text-generation")
    >>> generator(prompt)  # doctest: +SKIP
    ```

* enmascarado: el objetivo del modelo es predecir un token enmascarado en una secuencia con acceso completo a los tokens en la secuencia

    ```py
    >>> text = "Hugging Face is a community-based open-source <mask> for machine learning."
    >>> fill_mask = pipeline(task="fill-mask")
    >>> preds = fill_mask(text, top_k=1)
    >>> preds = [
    ...     {
    ...         "score": round(pred["score"], 4),
    ...         "token": pred["token"],
    ...         "token_str": pred["token_str"],
    ...         "sequence": pred["sequence"],
    ...     }
    ...     for pred in preds
    ... ]
    >>> preds
    [{'score': 0.2236,
      'token': 1761,
      'token_str': ' platform',
      'sequence': 'Hugging Face is a community-based open-source platform for machine learning.'}]
    ```

## Multimodal

Las tareas multimodales requieren que un modelo procese m칰ltiples modalidades de datos (texto, imagen, audio, video) para resolver un problema particular. La descripci칩n de im치genes es un ejemplo de una tarea multimodal en la que el modelo toma una imagen como entrada y produce una secuencia de texto que describe la imagen o algunas propiedades de la imagen.

Aunque los modelos multimodales trabajan con diferentes tipos de datos o modalidades, internamente, los pasos de preprocesamiento ayudan al modelo a convertir todos los tipos de datos en embeddings (vectores o listas de n칰meros que contienen informaci칩n significativa sobre los datos). Para una tarea como la descripci칩n de im치genes, el modelo aprende las relaciones entre los embeddings de im치genes y los embeddings de texto.

### Respuestas a preguntas de documentos

Las respuestas a preguntas de documentos es una tarea que responde preguntas en lenguaje natural a partir de un documento. A diferencia de una tarea de respuestas a preguntas a nivel de token que toma texto como entrada, las respuestas a preguntas de documentos toman una imagen de un documento como entrada junto con una pregunta sobre el documento y devuelven una respuesta. Las respuestas a preguntas de documentos pueden usarse para analizar documentos estructurados y extraer informaci칩n clave de ellos. En el ejemplo a continuaci칩n, el monto total y el cambio debido se pueden extraer de un recibo.

```py
>>> from transformers import pipeline
>>> from PIL import Image
>>> import requests

>>> url = "https://datasets-server.huggingface.co/assets/hf-internal-testing/example-documents/--/hf-internal-testing--example-documents/test/2/image/image.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> doc_question_answerer = pipeline("document-question-answering", model="magorshunov/layoutlm-invoices")
>>> preds = doc_question_answerer(
...     question="What is the total amount?",
...     image=image,
... )
>>> preds
[{'score': 0.8531, 'answer': '17,000', 'start': 4, 'end': 4}]
```

Con suerte, esta p치gina te ha proporcionado m치s informaci칩n de fondo sobre todos los tipos de tareas en cada modalidad y la importancia pr치ctica de cada una. En la pr칩xima [secci칩n](tasks_explained), aprender치s **c칩mo** 游뱅 Transformers trabaja para resolver estas tareas.
