<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

‚ö†Ô∏è Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Ein Modell teilen

Die letzten beiden Tutorials haben gezeigt, wie man ein Modell mit PyTorch, Keras und ü§ó Accelerate f√ºr verteilte Setups feinabstimmen kann. Der n√§chste Schritt besteht darin, Ihr Modell mit der Community zu teilen! Bei Hugging Face glauben wir an den offenen Austausch von Wissen und Ressourcen, um k√ºnstliche Intelligenz f√ºr alle zu demokratisieren. Wir ermutigen Sie, Ihr Modell mit der Community zu teilen, um anderen zu helfen, Zeit und Ressourcen zu sparen.

In diesem Tutorial lernen Sie zwei Methoden kennen, wie Sie ein trainiertes oder verfeinertes Modell auf dem [Model Hub](https://huggingface.co/models) teilen k√∂nnen:

- Programmgesteuertes √úbertragen Ihrer Dateien auf den Hub.
- Ziehen Sie Ihre Dateien per Drag-and-Drop √ºber die Weboberfl√§che in den Hub.

<iframe width="560" height="315" src="https://www.youtube.com/embed/XvSGPZFEjDY" title="YouTube video player"
frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;
picture-in-picture" allowfullscreen></iframe>

<Tip>

Um ein Modell mit der √ñffentlichkeit zu teilen, ben√∂tigen Sie ein Konto auf [huggingface.co](https://huggingface.co/join). Sie k√∂nnen auch einer bestehenden Organisation beitreten oder eine neue Organisation gr√ºnden.

</Tip>

## Repository-Funktionen

Jedes Repository im Model Hub verh√§lt sich wie ein typisches GitHub-Repository. Unsere Repositorys bieten Versionierung, Commit-Historie und die M√∂glichkeit, Unterschiede zu visualisieren.

Die integrierte Versionierung des Model Hub basiert auf Git und [git-lfs](https://git-lfs.github.com/). Mit anderen Worten: Sie k√∂nnen ein Modell als ein Repository behandeln, was eine bessere Zugriffskontrolle und Skalierbarkeit erm√∂glicht. Die Versionskontrolle erm√∂glicht *Revisionen*, eine Methode zum Anheften einer bestimmten Version eines Modells mit einem Commit-Hash, Tag oder Branch.

Folglich k√∂nnen Sie eine bestimmte Modellversion mit dem Parameter "Revision" laden:

```py
>>> model = AutoModel.from_pretrained(
...     "julien-c/EsperBERTo-small", revision="v2.0.1"  # tag name, or branch name, or commit hash
... )
```

Dateien lassen sich auch in einem Repository leicht bearbeiten, und Sie k√∂nnen die Commit-Historie sowie die Unterschiede einsehen:

![vis_diff](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vis_diff.png)

## Einrichtung

Bevor Sie ein Modell f√ºr den Hub freigeben, ben√∂tigen Sie Ihre Hugging Face-Anmeldedaten. Wenn Sie Zugang zu einem Terminal haben, f√ºhren Sie den folgenden Befehl in der virtuellen Umgebung aus, in der ü§ó Transformers installiert ist. Dadurch werden Ihre Zugangsdaten in Ihrem Hugging Face-Cache-Ordner (standardm√§√üig `~/.cache/`) gespeichert:

```bash
huggingface-cli login
```

Wenn Sie ein Notebook wie Jupyter oder Colaboratory verwenden, stellen Sie sicher, dass Sie die [`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library) Bibliothek installiert haben. Diese Bibliothek erm√∂glicht Ihnen die programmatische Interaktion mit dem Hub.

```bash
pip install huggingface_hub
```

Verwenden Sie dann `notebook_login`, um sich beim Hub anzumelden, und folgen Sie dem Link [hier](https://huggingface.co/settings/token), um ein Token f√ºr die Anmeldung zu generieren:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## Ein Modell f√ºr alle Frameworks konvertieren

Um sicherzustellen, dass Ihr Modell von jemandem verwendet werden kann, der mit einem anderen Framework arbeitet, empfehlen wir Ihnen, Ihr Modell sowohl mit PyTorch- als auch mit TensorFlow-Checkpoints zu konvertieren und hochzuladen. W√§hrend Benutzer immer noch in der Lage sind, Ihr Modell von einem anderen Framework zu laden, wenn Sie diesen Schritt √ºberspringen, wird es langsamer sein, weil ü§ó Transformers den Checkpoint on-the-fly konvertieren m√ºssen.

Die Konvertierung eines Checkpoints f√ºr ein anderes Framework ist einfach. Stellen Sie sicher, dass Sie PyTorch und TensorFlow installiert haben (siehe [hier](installation) f√ºr Installationsanweisungen), und finden Sie dann das spezifische Modell f√ºr Ihre Aufgabe in dem anderen Framework. 

<frameworkcontent>
<pt>
Geben Sie `from_tf=True` an, um einen Pr√ºfpunkt von TensorFlow nach PyTorch zu konvertieren:

```py
>>> pt_model = DistilBertForSequenceClassification.from_pretrained("path/to/awesome-name-you-picked", from_tf=True)
>>> pt_model.save_pretrained("path/to/awesome-name-you-picked")
```
</pt>
<tf>
Geben Sie `from_pt=True` an, um einen Pr√ºfpunkt von PyTorch nach TensorFlow zu konvertieren:

```py
>>> tf_model = TFDistilBertForSequenceClassification.from_pretrained("path/to/awesome-name-you-picked", from_pt=True)
```

Dann k√∂nnen Sie Ihr neues TensorFlow-Modell mit seinem neuen Checkpoint speichern:

```py
>>> tf_model.save_pretrained("path/to/awesome-name-you-picked")
```
</tf>
<jax>
Wenn ein Modell in Flax verf√ºgbar ist, k√∂nnen Sie auch einen Kontrollpunkt von PyTorch nach Flax konvertieren:

```py
>>> flax_model = FlaxDistilBertForSequenceClassification.from_pretrained(
...     "path/to/awesome-name-you-picked", from_pt=True
... )
```
</jax>
</frameworkcontent>

## Ein Modell w√§hrend des Trainings hochladen

<frameworkcontent>
<pt>
<Youtube id="Z1-XMy-GNLQ"/>

Die Weitergabe eines Modells an den Hub ist so einfach wie das Hinzuf√ºgen eines zus√§tzlichen Parameters oder R√ºckrufs. Erinnern Sie sich an das [Feinabstimmungs-Tutorial](training), in der Klasse [`TrainingArguments`] geben Sie Hyperparameter und zus√§tzliche Trainingsoptionen an. Eine dieser Trainingsoptionen beinhaltet die M√∂glichkeit, ein Modell direkt an den Hub zu pushen. Setzen Sie `push_to_hub=True` in Ihrer [`TrainingArguments`]:

```py
>>> training_args = TrainingArguments(output_dir="my-awesome-model", push_to_hub=True)
```

√úbergeben Sie Ihre Trainingsargumente wie gewohnt an [`Trainer`]:

```py
>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=small_train_dataset,
...     eval_dataset=small_eval_dataset,
...     compute_metrics=compute_metrics,
... )
```

Nach der Feinabstimmung Ihres Modells rufen Sie [`~transformers.Trainer.push_to_hub`] auf [`Trainer`] auf, um das trainierte Modell an den Hub zu √ºbertragen. Transformers f√ºgt sogar automatisch Trainings-Hyperparameter, Trainingsergebnisse und Framework-Versionen zu Ihrer Modellkarte hinzu!

```py
>>> trainer.push_to_hub()
```
</pt>
<tf>
Geben Sie ein Modell mit [`PushToHubCallback`] an den Hub weiter. In der [`PushToHubCallback`] Funktion, f√ºgen Sie hinzu:

- Ein Ausgabeverzeichnis f√ºr Ihr Modell.
- Einen Tokenizer.
- Die `hub_model_id`, die Ihr Hub-Benutzername und Modellname ist.

```py
>>> from transformers import PushToHubCallback

>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="./your_model_save_path", tokenizer=tokenizer, hub_model_id="your-username/my-awesome-model"
... )
```

F√ºgen Sie den Callback zu [`fit`](https://keras.io/api/models/model_training_apis/) hinzu, und ü§ó Transformers wird das trainierte Modell an den Hub weiterleiten:

```py
>>> model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3, callbacks=push_to_hub_callback)
```
</tf>
</frameworkcontent>

## Verwenden Sie die Funktion `push_to_hub`.

Sie k√∂nnen `push_to_hub` auch direkt f√ºr Ihr Modell aufrufen, um es in den Hub hochzuladen.

Geben Sie den Namen Ihres Modells in "push_to_hub" an:

```py
>>> pt_model.push_to_hub("my-awesome-model")
```

Dadurch wird ein Repository unter Ihrem Benutzernamen mit dem Modellnamen `my-awesome-model` erstellt. Benutzer k√∂nnen nun Ihr Modell mit der Funktion `from_pretrained` laden:

```py
>>> from transformers import AutoModel

>>> model = AutoModel.from_pretrained("your_username/my-awesome-model")
```

Wenn Sie zu einer Organisation geh√∂ren und Ihr Modell stattdessen unter dem Namen der Organisation pushen wollen, f√ºgen Sie diesen einfach zur `repo_id` hinzu:

```py
>>> pt_model.push_to_hub("my-awesome-org/my-awesome-model")
```

Die Funktion "push_to_hub" kann auch verwendet werden, um andere Dateien zu einem Modell-Repository hinzuzuf√ºgen. Zum Beispiel kann man einen Tokenizer zu einem Modell-Repository hinzuf√ºgen:

```py
>>> tokenizer.push_to_hub("my-awesome-model")
```

Oder vielleicht m√∂chten Sie die TensorFlow-Version Ihres fein abgestimmten PyTorch-Modells hinzuf√ºgen:

```py
>>> tf_model.push_to_hub("my-awesome-model")
```

Wenn Sie nun zu Ihrem Hugging Face-Profil navigieren, sollten Sie Ihr neu erstelltes Modell-Repository sehen. Wenn Sie auf die Registerkarte **Dateien** klicken, werden alle Dateien angezeigt, die Sie in das Repository hochgeladen haben.

Weitere Einzelheiten zum Erstellen und Hochladen von Dateien in ein Repository finden Sie in der Hub-Dokumentation [hier](https://huggingface.co/docs/hub/how-to-upstream).

## Hochladen mit der Weboberfl√§che

Benutzer, die einen no-code Ansatz bevorzugen, k√∂nnen ein Modell √ºber das Webinterface des Hubs hochladen. Besuchen Sie [huggingface.co/new](https://huggingface.co/new) um ein neues Repository zu erstellen:

![new_model_repo](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/new_model_repo.png)

F√ºgen Sie von hier aus einige Informationen √ºber Ihr Modell hinzu:

- W√§hlen Sie den **Besitzer** des Repositorys. Dies k√∂nnen Sie selbst oder eine der Organisationen sein, denen Sie angeh√∂ren.
- W√§hlen Sie einen Namen f√ºr Ihr Modell, der auch der Name des Repositorys sein wird.
- W√§hlen Sie, ob Ihr Modell √∂ffentlich oder privat ist.
- Geben Sie die Lizenzverwendung f√ºr Ihr Modell an.

Klicken Sie nun auf die Registerkarte **Dateien** und klicken Sie auf die Schaltfl√§che **Datei hinzuf√ºgen**, um eine neue Datei in Ihr Repository hochzuladen. Ziehen Sie dann eine Datei per Drag-and-Drop hoch und f√ºgen Sie eine √úbergabemeldung hinzu.

![upload_file](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/upload_file.png)

## Hinzuf√ºgen einer Modellkarte

Um sicherzustellen, dass die Benutzer die F√§higkeiten, Grenzen, m√∂glichen Verzerrungen und ethischen Aspekte Ihres Modells verstehen, f√ºgen Sie bitte eine Modellkarte zu Ihrem Repository hinzu. Die Modellkarte wird in der Datei `README.md` definiert. Sie k√∂nnen eine Modellkarte hinzuf√ºgen, indem Sie:

* Manuelles Erstellen und Hochladen einer "README.md"-Datei.
* Klicken Sie auf die Schaltfl√§che **Modellkarte bearbeiten** in Ihrem Modell-Repository.

Werfen Sie einen Blick auf die DistilBert [model card](https://huggingface.co/distilbert-base-uncased) als gutes Beispiel f√ºr die Art von Informationen, die eine Modellkarte enthalten sollte. Weitere Details √ºber andere Optionen, die Sie in der Datei "README.md" einstellen k√∂nnen, wie z.B. den Kohlenstoff-Fu√üabdruck eines Modells oder Beispiele f√ºr Widgets, finden Sie in der Dokumentation [hier](https://huggingface.co/docs/hub/models-cards).