<!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

‚ö†Ô∏è Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# √úberpr√ºfungen bei einer Pull-Anfrage

Wenn Sie eine Pull-Anfrage f√ºr ü§ó Transformers √∂ffnen, wird eine ganze Reihe von Pr√ºfungen durchgef√ºhrt, um sicherzustellen, dass der Patch, den Sie hinzuf√ºgen, nichts Bestehendes zerst√∂rt. Es gibt vier Arten von Pr√ºfungen:
- regul√§re Tests
- Erstellung der Dokumentation
- Stil von Code und Dokumentation
- allgemeine Konsistenz des Repository

In diesem Dokument werden wir versuchen zu erkl√§ren, worum es sich bei diesen verschiedenen Pr√ºfungen handelt und wie Sie sie lokal debuggen k√∂nnen, wenn eine der Pr√ºfungen in Ihrer PR fehlschl√§gt.

Beachten Sie, dass Sie im Idealfall eine Dev-Installation ben√∂tigen:

```bash
pip install transformers[dev]
```

oder f√ºr eine bearbeitbare Installation:

```bash
pip install -e .[dev]
```

innerhalb des Transformers Repo. Da die Anzahl der optionalen Abh√§ngigkeiten von Transformers stark zugenommen hat, ist es m√∂glich, dass Sie nicht alle davon bekommen k√∂nnen. Wenn die Dev-Installation fehlschl√§gt, stellen Sie sicher, dass Sie das Deep Learning-Framework, mit dem Sie arbeiten, installieren (PyTorch, TensorFlow und/oder Flax).

```bash
pip install transformers[quality]
```

oder f√ºr eine bearbeitbare Installation:

```bash
pip install -e .[quality]
```


## Tests

Alle Jobs, die mit `ci/circleci: run_tests_` beginnen, f√ºhren Teile der Transformers-Testsuite aus. Jeder dieser Jobs konzentriert sich auf einen Teil der Bibliothek in einer bestimmten Umgebung: `ci/circleci: run_tests_pipelines_tf` zum Beispiel f√ºhrt den Pipelines-Test in einer Umgebung aus, in der nur TensorFlow installiert ist.

Beachten Sie, dass nur ein Teil der Testsuite jedes Mal ausgef√ºhrt wird, um zu vermeiden, dass Tests ausgef√ºhrt werden, wenn es keine wirkliche √Ñnderung in den Modulen gibt, die sie testen: ein Dienstprogramm wird ausgef√ºhrt, um die Unterschiede in der Bibliothek zwischen vor und nach dem PR zu ermitteln (was GitHub Ihnen auf der Registerkarte "Files changes" anzeigt) und die Tests auszuw√§hlen, die von diesem Unterschied betroffen sind. Dieses Dienstprogramm kann lokal mit ausgef√ºhrt werden:

```bash
python utils/tests_fetcher.py
```

aus dem Stammverzeichnis des Transformers-Repositoriums. Es wird:

1. √úberpr√ºfen Sie f√ºr jede Datei im Diff, ob die √Ñnderungen im Code oder nur in Kommentaren oder Docstrings enthalten sind. Nur die Dateien mit echten Code√§nderungen werden beibehalten.
2. Erstellen Sie eine interne Map, die f√ºr jede Datei des Quellcodes der Bibliothek alle Dateien angibt, auf die sie rekursiv Einfluss nimmt. Von Modul A wird gesagt, dass es sich auf Modul B auswirkt, wenn Modul B Modul A importiert. F√ºr die rekursive Auswirkung ben√∂tigen wir eine Kette von Modulen, die von Modul A zu Modul B f√ºhrt und in der jedes Modul das vorherige importiert.
3. Wenden Sie diese Zuordnung auf die in Schritt 1 gesammelten Dateien an. So erhalten wir die Liste der Modelldateien, die von der PR betroffen sind.
4. Ordnen Sie jede dieser Dateien der/den entsprechenden Testdatei(en) zu und erhalten Sie die Liste der auszuf√ºhrenden Tests.

Wenn Sie das Skript lokal ausf√ºhren, sollten Sie die Ergebnisse von Schritt 1, 3 und 4 ausgegeben bekommen und somit wissen, welche Tests ausgef√ºhrt werden. Das Skript erstellt au√üerdem eine Datei namens `test_list.txt`, die die Liste der auszuf√ºhrenden Tests enth√§lt, die Sie mit dem folgenden Befehl lokal ausf√ºhren k√∂nnen:

```bash
python -m pytest -n 8 --dist=loadfile -rA -s $(cat test_list.txt)
```

F√ºr den Fall, dass Ihnen etwas entgangen ist, wird die komplette Testreihe ebenfalls t√§glich ausgef√ºhrt.

## Dokumentation erstellen

Der Job `build_pr_documentation` erstellt und generiert eine Vorschau der Dokumentation, um sicherzustellen, dass alles in Ordnung ist, wenn Ihr PR zusammengef√ºhrt wird. Ein Bot f√ºgt einen Link zur Vorschau der Dokumentation zu Ihrem PR hinzu. Alle √Ñnderungen, die Sie an dem PR vornehmen, werden automatisch in der Vorschau aktualisiert. Wenn die Dokumentation nicht erstellt werden kann, klicken Sie auf **Details** neben dem fehlgeschlagenen Auftrag, um zu sehen, wo der Fehler liegt. Oft ist der Fehler so einfach wie eine fehlende Datei im `toctree`.

Wenn Sie daran interessiert sind, die Dokumentation lokal zu erstellen oder in der Vorschau anzusehen, werfen Sie einen Blick in die [`README.md`](https://github.com/huggingface/transformers/tree/main/docs) im Ordner docs.

## Code und Dokumentationsstil

Die Formatierung des Codes erfolgt f√ºr alle Quelldateien, die Beispiele und die Tests mit `black` und `ruff`. Wir haben auch ein benutzerdefiniertes Tool, das sich um die Formatierung von docstrings und `rst`-Dateien k√ºmmert (`utils/style_doc.py`), sowie um die Reihenfolge der Lazy-Importe, die in den Transformers `__init__.py`-Dateien durchgef√ºhrt werden (`utils/custom_init_isort.py`). All dies k√∂nnen Sie starten, indem Sie Folgendes ausf√ºhren

```bash
make style
```

Das CI pr√ºft, ob diese innerhalb der Pr√ºfung `ci/circleci: check_code_quality` angewendet wurden. Es f√ºhrt auch `ruff` aus, das einen grundlegenden Blick auf Ihren Code wirft und sich beschwert, wenn es eine undefinierte Variable findet oder eine, die nicht verwendet wird. Um diese Pr√ºfung lokal auszuf√ºhren, verwenden Sie

```bash
make quality
```

Dies kann sehr viel Zeit in Anspruch nehmen. Um dasselbe nur f√ºr die Dateien zu tun, die Sie im aktuellen Zweig ge√§ndert haben, f√ºhren Sie

```bash
make fixup
```

Dieser letzte Befehl f√ºhrt auch alle zus√§tzlichen Pr√ºfungen f√ºr die Konsistenz des Repositorys durch. Schauen wir uns diese an.

## Repository-Konsistenz

Dies fasst alle Tests zusammen, die sicherstellen, dass Ihr PR das Repository in einem guten Zustand verl√§sst. Sie k√∂nnen diese Pr√ºfung lokal durchf√ºhren, indem Sie Folgendes ausf√ºhren:

```bash
make repo-consistency
```

Dies √ºberpr√ºft, ob:

- Alle zum Init hinzugef√ºgten Objekte sind dokumentiert (ausgef√ºhrt von `utils/check_repo.py`)
- Alle `__init__.py`-Dateien haben in ihren beiden Abschnitten den gleichen Inhalt (ausgef√ºhrt von `utils/check_inits.py`)
- Der gesamte Code, der als Kopie eines anderen Moduls identifiziert wurde, stimmt mit dem Original √ºberein (ausgef√ºhrt von `utils/check_copies.py`)
- Alle Konfigurationsklassen haben mindestens einen g√ºltigen Pr√ºfpunkt, der in ihren Dokumentationen erw√§hnt wird (ausgef√ºhrt von `utils/check_config_docstrings.py`)
- Alle Konfigurationsklassen enthalten nur Attribute, die in den entsprechenden Modellierungsdateien verwendet werden (ausgef√ºhrt von `utils/check_config_attributes.py`)
- Die √úbersetzungen der READMEs und der Index des Dokuments haben die gleiche Modellliste wie die Haupt-README (durchgef√ºhrt von `utils/check_copies.py`)
- Die automatisch generierten Tabellen in der Dokumentation sind auf dem neuesten Stand (ausgef√ºhrt von `utils/check_table.py`)
- Die Bibliothek verf√ºgt √ºber alle Objekte, auch wenn nicht alle optionalen Abh√§ngigkeiten installiert sind (ausgef√ºhrt von `utils/check_dummies.py`)

Sollte diese Pr√ºfung fehlschlagen, m√ºssen die ersten beiden Punkte manuell korrigiert werden, die letzten vier k√∂nnen automatisch f√ºr Sie korrigiert werden, indem Sie den Befehl

```bash
make fix-copies
```

Zus√§tzliche Pr√ºfungen betreffen PRs, die neue Modelle hinzuf√ºgen, vor allem, dass:

- Alle hinzugef√ºgten Modelle befinden sich in einer Auto-Zuordnung (durchgef√ºhrt von `utils/check_repo.py`)
<!-- TODO Sylvain, add a check that makes sure the common tests are implemented.-->
- Alle Modelle werden ordnungsgem√§√ü getestet (ausgef√ºhrt von `utils/check_repo.py`)

<!-- TODO Sylvain, add the following
- All models are added to the main README, inside the main doc
- All checkpoints used actually exist on the Hub

-->

### Kopien pr√ºfen

Da die Transformers-Bibliothek in Bezug auf den Modellcode sehr eigenwillig ist und jedes Modell vollst√§ndig in einer einzigen Datei implementiert sein sollte, ohne sich auf andere Modelle zu st√ºtzen, haben wir einen Mechanismus hinzugef√ºgt, der √ºberpr√ºft, ob eine Kopie des Codes einer Ebene eines bestimmten Modells mit dem Original √ºbereinstimmt. Auf diese Weise k√∂nnen wir bei einer Fehlerbehebung alle anderen betroffenen Modelle sehen und entscheiden, ob wir die √Ñnderung weitergeben oder die Kopie zerst√∂ren.

> [!TIP]
> Wenn eine Datei eine vollst√§ndige Kopie einer anderen Datei ist, sollten Sie sie in der Konstante `FULL_COPIES` von `utils/check_copies.py` registrieren.

Dieser Mechanismus st√ºtzt sich auf Kommentare der Form `# Kopiert von xxx`. Das `xxx` sollte den gesamten Pfad zu der Klasse der Funktion enthalten, die darunter kopiert wird. Zum Beispiel ist `RobertaSelfOutput` eine direkte Kopie der Klasse `BertSelfOutput`. Sie k√∂nnen also [hier](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L289) sehen, dass sie einen Kommentar hat:

```py
# Copied from transformers.models.bert.modeling_bert.BertSelfOutput
```

Beachten Sie, dass Sie dies nicht auf eine ganze Klasse anwenden, sondern auf die entsprechenden Methoden, von denen kopiert wird. Zum Beispiel [hier](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L598) k√∂nnen Sie sehen, wie `RobertaPreTrainedModel._init_weights` von der gleichen Methode in `BertPreTrainedModel` mit dem Kommentar kopiert wird:

```py
# Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights
```

Manchmal ist die Kopie bis auf die Namen genau gleich: zum Beispiel verwenden wir in `RobertaAttention` `RobertaSelfAttention` anstelle von `BertSelfAttention`, aber ansonsten ist der Code genau derselbe. Aus diesem Grund unterst√ºtzt `#Copied from` einfache String-Ersetzungen mit der folgenden Syntax: `Kopiert von xxx mit foo->bar`. Das bedeutet, dass der Code kopiert wird, wobei alle Instanzen von "foo" durch "bar" ersetzt werden. Sie k√∂nnen sehen, wie es [hier](https://github.com/huggingface/transformers/blob/2bd7a27a671fd1d98059124024f580f8f5c0f3b5/src/transformers/models/roberta/modeling_roberta.py#L304C1-L304C86) in `RobertaAttention` mit dem Kommentar verwendet wird:

```py
# Copied from transformers.models.bert.modeling_bert.BertAttention with Bert->Roberta
```

Beachten Sie, dass um den Pfeil herum keine Leerzeichen stehen sollten (es sei denn, das Leerzeichen ist Teil des zu ersetzenden Musters, nat√ºrlich).

Sie k√∂nnen mehrere Muster durch ein Komma getrennt hinzuf√ºgen. Zum Beispiel ist hier `CamemberForMaskedLM` eine direkte Kopie von `RobertaForMaskedLM` mit zwei Ersetzungen: `Roberta` zu `Camembert` und `ROBERTA` zu `CAMEMBERT`. Sie k√∂nnen [hier](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/camembert/modeling_camembert.py#L929) sehen, wie dies mit dem Kommentar gemacht wird:

```py
# Copied from transformers.models.roberta.modeling_roberta.RobertaForMaskedLM with Roberta->Camembert, ROBERTA->CAMEMBERT
```

Wenn die Reihenfolge eine Rolle spielt (weil eine der Ersetzungen mit einer vorherigen in Konflikt geraten k√∂nnte), werden die Ersetzungen von links nach rechts ausgef√ºhrt.

> [!TIP]
> Wenn die Ersetzungen die Formatierung √§ndern (wenn Sie z.B. einen kurzen Namen durch einen sehr langen Namen ersetzen), wird die Kopie nach Anwendung des automatischen Formats √ºberpr√ºft.

Eine andere M√∂glichkeit, wenn es sich bei den Mustern nur um verschiedene Umschreibungen derselben Ersetzung handelt (mit einer gro√ü- und einer kleingeschriebenen Variante), besteht darin, die Option `all-casing` hinzuzuf√ºgen. [Hier](https://github.com/huggingface/transformers/blob/15082a9dc6950ecae63a0d3e5060b2fc7f15050a/src/transformers/models/mobilebert/modeling_mobilebert.py#L1237) ist ein Beispiel in `MobileBertForSequenceClassification` mit dem Kommentar:

```py
# Copied from transformers.models.bert.modeling_bert.BertForSequenceClassification with Bert->MobileBert all-casing
```

In diesem Fall wird der Code von `BertForSequenceClassification` kopiert, indem er ersetzt wird:
- `Bert` durch `MobileBert` (zum Beispiel bei der Verwendung von `MobileBertModel` in der Init)
- `bert` durch `mobilebert` (zum Beispiel bei der Definition von `self.mobilebert`)
- `BERT` durch `MOBILEBERT` (in der Konstante `MOBILEBERT_INPUTS_DOCSTRING`)
