# üöÄ Project Setup & Problem Verification Guide

This guide walks through setting up the Transformers repository and verifying the reported problems.

## üìã Prerequisites

- **Python 3.13+** (confirmed working)
- **CUDA-capable GPU** (recommended for P-001, optional for P-002)
- **At least 16GB RAM** (for P-001 full reproduction with 7B model)
- **Git** (for repository management)

## üõ†Ô∏è Setup Steps

### 1. Environment Setup
```powershell
# Navigate to the repository
cd "C:\Users\PRATAP S\Documents\GitHub\transformers"

# Install the library in development mode
python -m pip install -e .

# Install additional dependencies
python -m pip install accelerate requests pillow
```

### 2. Verify Installation
```powershell
# Check that transformers imports correctly
python -c "from transformers import AutoModel; print('‚úÖ Transformers ready')"

# Check GPU availability (optional but recommended)
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

## üîç Problem Verification

### P-002: Missing RAG Examples ‚úÖ RESOLVED
```powershell
# Run verification script
python verify_p002.py
```

**Expected Result:** All checks should pass ‚úÖ
- Directory `examples/rag/` exists
- README.md contains comprehensive examples
- Links to working models and documentation

### P-001: LLaVA-OneVision Eager Attention ‚ö†Ô∏è UNRESOLVED
```powershell
# Check environment setup
python verify_p001.py
```

**Expected Results:**
- ‚úÖ Environment ready for testing
- ‚ö†Ô∏è Full reproduction requires downloading 7B model (~13GB)

**To fully reproduce P-001 (when ready):**
```powershell
# WARNING: Downloads large model, requires 14GB+ RAM
python reproduce_p001.py
```

## üìä System Status

| Component | Status | Notes |
|-----------|--------|-------|
| Python 3.13 | ‚úÖ Ready | Confirmed working |
| PyTorch 2.7.1+cu118 | ‚úÖ Ready | CUDA support enabled |
| Transformers 5.0.0.dev0 | ‚úÖ Ready | Development version installed |
| GPU (RTX 4060 Laptop) | ‚úÖ Available | 8.6GB VRAM (sufficient for 0.5B, tight for 7B) |
| P-002 Fix | ‚úÖ Verified | RAG examples directory restored |
| P-001 Setup | ‚úÖ Ready | Environment prepared for testing |

## üéØ Next Steps

### For P-001 (LLaVa-OneVision Issue):
1. **Quick Test**: Use 0.5B model to verify the issue doesn't occur
2. **Full Test**: Load 7B model with eager+fp16 to reproduce garbage output
3. **Apply Fix**: Implement fp32 softmax upcast in Qwen2 eager attention
4. **Verify Fix**: Retest with same configuration

### For P-002 (RAG Examples):
1. **‚úÖ Complete**: Issue is fully resolved
2. **Commit Changes**: Ready to commit the fix
3. **Test Links**: Verify that GitHub links work correctly

## üß™ Testing Commands Reference

```powershell
# Verify both problems
python verify_p002.py  # Should pass
python verify_p001.py  # Should show setup ready

# Project maintenance (when needed)
make fixup  # Apply code style fixes (requires make)
pytest tests/models/llava_onevision/  # Run specific tests

# Git status
git status  # Check what files are modified/added
git add examples/rag/  # Stage RAG fix for commit
```

## ‚ö° Quick Status Check

Run this one-liner to check everything:
```powershell
python -c "
import os, torch
from transformers import AutoProcessor
print('üîß Setup Status:')
print(f'  Transformers: ‚úÖ')
print(f'  PyTorch: {torch.__version__}')
print(f'  CUDA: {\"‚úÖ\" if torch.cuda.is_available() else \"‚ùå\"}')
print(f'  RAG fix: {\"‚úÖ\" if os.path.exists(\"examples/rag/README.md\") else \"‚ùå\"}')
print('üöÄ Ready to proceed!')
"
```

This should output all ‚úÖ marks for a fully working setup.