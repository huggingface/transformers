#!/usr/bin/env python3
"""
Utilities for automatically updating expected outputs in test files.

This module helps update test expectations based on actual outputs captured during test runs.
It works with the patching system in testing_utils.py that captures actual vs expected values.

============================================
OVERVIEW OF THE COMPLETE WORKFLOW
============================================

STEP 1: Run tests with patching enabled (done by testing_utils.py)
    - Patches methods like torch.testing.assert_close() and unittest.TestCase.assertEqual()
    - When assertions fail, captures BOTH actual and expected values
    - Writes formatted information to captured_info.txt

STEP 2: Run this script to update test files
    - Parses captured_info.txt to extract failures
    - For each failure, locates where the expected value is defined in the test file
    - Replaces the old expected value with the new actual value
    - Preserves variable assignments, indentation, and method chaining

============================================
KEY COMPONENTS AND THEIR RESPONSIBILITIES
============================================

1. parse_captured_info()
   - Reads captured_info.txt generated by testing_utils.py
   - Extracts test name, file path, line numbers, and values
   - IMPORTANT: Normalizes file paths to be relative to transformers root
     (handles /transformers/..., /home/user/transformers/..., etc.)
   - Returns list of failure dictionaries with all needed info

2. detect_value_type()
   - Determines if a value is torch_tensor, string, list_of_strings, etc.
   - Helps guide the formatting strategy for replacement

3. find_expected_value_in_code()
   - THE SEARCH FUNCTION - Locates where expected value is defined
   - Searches backward from assertion line looking for variable assignment
   - Handles multi-line definitions via _extract_multiline_expression()
   - LIMITATION: Only searches 50 lines back (may miss module-level constants)

4. _extract_multiline_expression()
   - Handles multi-line expressions like:
       expected_slice = torch.tensor(
           [[1, 2, 3],
            [4, 5, 6]]
       ).to(device)
   - Counts brackets/parens to find where expression ends
   - Returns (start_line, end_line, full_text)

5. update_expected_value_in_file()
   - THE UPDATE FUNCTION - Actually modifies the test file
   - CRITICAL TASKS:
     a) Extract variable assignment (e.g., "expected_slice = ")
     b) Extract method chaining (e.g., ".to(torch_device)")
     c) Determine base indentation from original file
     d) Apply base + relative indentation to new value
     e) Reconstruct: assignment + torch.tensor( + content + ) + method_chain
   - Replaces old lines with new formatted line(s)

============================================
INDENTATION HANDLING (MOST CRITICAL PART)
============================================

The trickiest aspect is handling indentation correctly. Here's how it works:

CAPTURED_INFO provides values with RELATIVE indentation:
    [
        [4.2325, 4.3882],    <- 4 spaces relative to [
    ]

ORIGINAL FILE has absolute indentation:
    "        expected_slice = torch.tensor("  <- 8 spaces base
    "            [[4.2325, 4.3882]]"          <- 12 spaces total

THE GOAL is to combine them:
    "        expected_slice = torch.tensor("  <- 8 spaces (preserved)
    "            ["                            <- 12 spaces (base from original)
    "                [4.2325, 4.3882],"        <- 16 spaces (base + 4 relative)
    "            ]"                            <- 12 spaces (base from original)
    "        ).to(torch_device)"              <- 8 spaces (preserved)

ALGORITHM:
1. Extract base_indent from first line (e.g., 8 spaces before "expected_slice")
2. Extract content_base_indent from second line (e.g., 12 spaces before "[[")
3. For each line in new_value:
   - Calculate relative_indent (spaces in captured_info)
   - Apply: content_base_indent + relative_indent
4. Wrap with assignment prefix and method suffix

============================================
COMMON PITFALLS AND HOW THEY'RE AVOIDED
============================================

PITFALL 1: Losing variable assignment
    BAD:  torch.tensor([...])
    GOOD: expected_slice = torch.tensor([...])
    FIX:  We extract and preserve assignment_prefix

PITFALL 2: Losing method chaining
    BAD:  expected_slice = torch.tensor([...])
    GOOD: expected_slice = torch.tensor([...]).to(torch_device)
    FIX:  We extract and preserve method_chain_suffix

PITFALL 3: Wrong indentation
    BAD:  Applying same indent to all lines
    GOOD: Preserving relative structure from captured_info
    FIX:  We calculate content_base_indent from original and add relative_indent

PITFALL 4: Can't find definition
    SYMPTOM: Returns None from find_expected_value_in_code()
    CAUSES:  - Variable defined > 50 lines before assertion
             - Variable is class/module constant
             - Variable imported from another file
    FIX:  Currently limited; may need to expand search range or add import handling

============================================
USAGE EXAMPLES
============================================

IMPORTANT: Always run this script from the transformers repository root directory!
The script normalizes all paths to be relative to the transformers root.

# Dry-run (see what would change):
cd /path/to/transformers
python update_test_expectations.py captured/path/to/captured_info.txt

# Actually apply changes:
cd /path/to/transformers
python update_test_expectations.py captured/path/to/captured_info.txt --apply

# Programmatic use:
from update_test_expectations import process_captured_failures
changes = process_captured_failures('captured_info.txt', dry_run=False)

============================================
INTEGRATION WITH TESTING_UTILS.PY
============================================

This script depends on specific formatting from testing_utils.py:
- _format_tensor() provides tensors with 0/4 relative indentation
- _format_py_obj() provides other values formatted for copy-paste
- _get_test_info() provides file paths and line numbers
- _parse_call_info() provides variable names and expressions

If testing_utils.py changes its output format, this script may need updates.

============================================
FUTURE ENHANCEMENTS NEEDED
============================================

TODO: Support for more value types (complex dicts, custom objects)
TODO: Handle class-level and module-level constants
TODO: Handle expected values imported from other files
TODO: Better error messages when definition can't be found
TODO: Verify changes don't break syntax before writing
TODO: Create backup files before modification
TODO: Support for updating multiple related files at once
TODO: Handle single-line to multi-line conversions more gracefully
"""

import ast
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any


def normalize_path_to_transformers_root(path: str) -> str:
    """
    Normalize a file path to be relative to the transformers repository root.

    The captured_info.txt files may contain absolute paths like:
    - /transformers/tests/models/clip/test_modeling_clip.py
    - /home/user/workspace/transformers/tests/models/clip/test_modeling_clip.py

    This function extracts the path relative to 'transformers/' directory and makes it
    relative to the current working directory, assuming we're running from the transformers root.

    Args:
        path: File path from captured_info.txt (may be absolute or relative)

    Returns:
        Path relative to current working directory (transformers root)

    Examples:
        /transformers/tests/models/clip/test_modeling_clip.py
        -> tests/models/clip/test_modeling_clip.py

        /home/user/transformers/tests/models/clip/test_modeling_clip.py
        -> tests/models/clip/test_modeling_clip.py

        tests/models/clip/test_modeling_clip.py
        -> tests/models/clip/test_modeling_clip.py
    """
    # Convert to Path object for easier manipulation
    path_obj = Path(path)

    # Convert to string and normalize slashes
    path_str = str(path_obj).replace('\\', '/')

    # Find 'transformers' in the path and extract everything after it
    # This handles cases like:
    # - /transformers/tests/... -> tests/...
    # - /home/user/transformers/tests/... -> tests/...
    # - C:/Users/user/transformers/tests/... -> tests/...

    if '/transformers/' in path_str:
        # Split on '/transformers/' and take everything after it
        relative_path = path_str.split('/transformers/', 1)[1]
    elif path_str.startswith('transformers/'):
        # Already in format transformers/tests/... -> tests/...
        relative_path = path_str.split('transformers/', 1)[1]
    else:
        # Path doesn't contain 'transformers/' - assume it's already relative
        # This handles cases like: tests/models/clip/test_modeling_clip.py
        relative_path = path_str

    return relative_path


def parse_captured_info(captured_info_content: str) -> List[Dict[str, Any]]:
    """
    Parse the captured_info.txt file generated by patched testing methods.

    This function extracts structured information from the captured_info.txt file that is
    generated by the patching system in testing_utils.py (specifically the _get_test_info()
    and _parse_call_info() functions).

    Returns a list of dictionaries, each containing information about a test failure:
    - test_name: full test name (file::class::method)
    - test_file: path to test file
    - test_lineno: line number in test file
    - caller_lineno: line number where assertion was called
    - actual_value: the actual value (as formatted string)
    - expected_value: the expected value (as formatted string)
    - expected_expression: the variable/expression name for expected value
    """
    failures = []

    # The captured_info.txt file contains multiple test failures separated by a line of 120 '=' characters.
    # Each block contains information about one assertion failure.
    # Example structure:
    #   test:
    #   tests/models/vit/test_modeling_vit.py::ViTModelTest::test_something
    #   -------- (80 dashes)
    #   test context: /path/to/file.py:123
    #   ...
    #   ======== (120 equals) <-- This is the separator between blocks
    test_blocks = captured_info_content.split("=" * 120)

    for block in test_blocks:
        # Skip empty blocks (e.g., before the first test or after the last test)
        if not block.strip():
            continue

        failure_info = {}

        # Extract test name (format: file::class::method)
        # Example: "tests/models/vit/test_modeling_vit.py::ViTModelIntegrationTest::test_inference"
        test_match = re.search(r'test:\s*\n\s*([^\n]+)', block)
        if test_match:
            failure_info['test_name'] = test_match.group(1).strip()

        # Extract test context (file path and line number where the test method is defined)
        # Example: "test context: /transformers/tests/models/vit/test_modeling_vit.py:305"
        # We capture both the file path and line number separately
        test_context_match = re.search(r'test context:\s*([^:]+):(\d+)', block)
        if test_context_match:
            raw_path = test_context_match.group(1).strip()
            # Normalize the path to be relative to transformers root
            failure_info['test_file'] = normalize_path_to_transformers_root(raw_path)
            failure_info['test_lineno'] = int(test_context_match.group(2))

        # Extract caller context (line number where the assertion that failed was called)
        # This might be different from test_lineno if the assertion is not the first line of the test
        # Example: "caller context: tests/models/vit/test_modeling_vit.py:312"
        caller_match = re.search(r'caller context:\s*[^:]+:(\d+)', block)
        if caller_match:
            failure_info['caller_lineno'] = int(caller_match.group(1))

        # Extract the ACTUAL value (what the test produced)
        # The patched methods can have different argument names depending on the assertion:
        # - torch.testing.assert_close uses 'actual'
        # - unittest.TestCase.assertEqual uses 'first'
        # - Some tests use 'output_text'
        # We need to match any of these patterns
        #
        # The regex captures:
        # 1. The expression that produced the actual value (e.g., "outputs.logits[0, :3]")
        # 2. The formatted value itself (formatted by _format_tensor or _format_py_obj)
        #
        # The (?=\n\s*-{80}|\Z) is a lookahead to stop at either:
        # - A line of 80 dashes (separator before next argument)
        # - End of string (\Z)
        actual_match = re.search(
            r'argument name: `(?:actual|first|output_text)`\s*\nargument expression: `([^`]+)`\s*\n\s*argument value:\s*\n\s*(.*?)(?=\n\s*-{80}|\Z)',
            block,
            re.DOTALL  # Allow . to match newlines so we can capture multi-line values
        )
        if actual_match:
            failure_info['actual_expression'] = actual_match.group(1).strip()
            failure_info['actual_value'] = actual_match.group(2).strip()

        # Extract the EXPECTED value (what the test was expecting)
        # Similar to actual value extraction, but looking for 'expected', 'second', or 'EXPECTED_TEXT'
        #
        # This value is what we will use to UPDATE the test file - it contains the actual
        # output that should become the new expected value.
        #
        # IMPORTANT: The expected_value here is formatted by _format_tensor() or _format_py_obj()
        # from testing_utils.py, which means it's already nicely formatted and ready to be
        # pasted into source code. It has RELATIVE indentation (e.g., 0 spaces for outer brackets,
        # 4 spaces for content).
        expected_match = re.search(
            r'argument name: `(?:expected|second|EXPECTED_TEXT)`\s*\nargument expression: `([^`]+)`\s*\n\s*argument value:\s*\n\s*(.*?)(?=\n\s*={120}|\Z)',
            block,
            re.DOTALL
        )
        if expected_match:
            failure_info['expected_expression'] = expected_match.group(1).strip()
            failure_info['expected_value'] = expected_match.group(2).strip()

        # Only add this failure to the list if we successfully extracted some information
        if failure_info:
            failures.append(failure_info)

    return failures


def detect_value_type(value_str: str) -> str:
    """
    Detect the type of value from its string representation.

    This is used to determine how to format and replace the value in the test file.
    The value_str comes from the 'actual_value' field in captured_info.txt, which
    is already formatted by _format_tensor() or _format_py_obj() in testing_utils.py.

    Returns: 'torch_tensor', 'string', 'list_of_strings', 'list', 'dict', 'number', 'unknown'

    IMPORTANT PATTERNS:
    - Torch tensors: Start with [ and contain numeric data (can be nested)
    - Strings: Wrapped in quotes (single or double)
    - List of strings: Start with [" or ['
    - Plain lists: Start with [ but not tensors or string lists
    - Dicts: Start with {
    - Numbers: Just digits, optional decimal point and scientific notation
    """
    value_str = value_str.strip()

    # TORCH TENSOR DETECTION
    # Torch tensors start with [ and have comma-separated numbers
    # They can be nested like:
    #   [[-0.15, 0.03], [0.28, 0.11]]  (2D tensor)
    #   [1.0, 2.0, 3.0]  (1D tensor)
    #   [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]  (3D tensor)
    #
    # The challenge is distinguishing tensors from other list types.
    # We use a regex to check if the content contains only:
    # - Square brackets [ ]
    # - Commas ,
    # - Whitespace
    # - Numbers (with optional sign, decimal point, and scientific notation like 1.23e-4)
    if value_str.startswith('[') and value_str.endswith(']'):
        # Try to parse as nested numeric structure
        try:
            # Extract the content between outer brackets
            content = value_str[1:-1].strip()
            # Check if it looks like a tensor (numbers with optional signs and decimals)
            # Pattern explanation:
            # ^ and $ = start and end of string
            # [\[\],\s\-\d.e+]+ = one or more of:
            #   \[\] = square brackets
            #   , = commas
            #   \s = whitespace
            #   \- = minus sign
            #   \d = digits
            #   . = decimal point
            #   e = scientific notation
            #   + = plus sign (for scientific notation)
            if re.match(r'^[\[\],\s\-\d.e+]+$', content):
                return 'torch_tensor'
        except:
            pass

        # LIST OF STRINGS DETECTION
        # Lists of strings look like:
        #   ["string1", "string2"]
        #   ['string1', 'string2']
        # Check if the list starts with a quote after the opening bracket
        if value_str.startswith('["') or value_str.startswith("['"):
            return 'list_of_strings'

        # If it's a list but not a tensor or string list, classify as generic list
        return 'list'

    # STRING DETECTION
    # Strings are wrapped in quotes (either single or double)
    # Examples: "hello", 'world', "multi\nline"
    if (value_str.startswith('"') and value_str.endswith('"')) or \
            (value_str.startswith("'") and value_str.endswith("'")):
        return 'string'

    # NUMBER DETECTION
    # Numbers can be:
    # - Integers: 42, -17
    # - Floats: 3.14, -0.5
    # - Scientific notation: 1.23e-4, -5e+10
    # Pattern explanation:
    # ^-? = optional minus sign at start
    # \d+ = one or more digits
    # \.? = optional decimal point
    # \d* = zero or more digits after decimal
    # (?:[eE][+-]?\d+)? = optional scientific notation (e or E, optional sign, digits)
    # $ = end of string
    if re.match(r'^-?\d+\.?\d*(?:[eE][+-]?\d+)?$', value_str):
        return 'number'

    # DICT DETECTION
    # Dictionaries start with { and end with }
    # Examples: {"key": "value"}, {'a': 1, 'b': 2}
    if value_str.startswith('{') and value_str.endswith('}'):
        return 'dict'

    # If we can't identify the type, mark it as unknown
    # This might happen for complex nested structures or custom object representations
    return 'unknown'


def find_expected_value_in_code(
        file_path: str,
        line_number: int,
        expected_expression: str,
        value_type: str
) -> Optional[Tuple[int, int, str]]:
    """
    Find where the expected value is defined in the test file.

    This is the MOST CRITICAL function - it locates where in the source code the expected
    value variable is actually defined, so we can replace it.

    Args:
        file_path: Path to the test file
        line_number: Line number where the assertion is called (from captured_info)
        expected_expression: Variable name like "expected_slice" or "EXPECTED_TEXT"
        value_type: Type of value (torch_tensor, string, etc.) - helps guide the search

    Returns: (start_line, end_line, original_text) or None if not found
        - start_line: 0-indexed line number where the definition starts
        - end_line: 0-indexed line number where the definition ends
        - original_text: The complete text of the definition (may span multiple lines)

    SEARCH STRATEGY:
    The function looks for the expected value definition by:
    1. Checking lines around the assertion for inline definitions
    2. Looking backwards from the assertion for variable assignments
    3. Handling multi-line definitions (e.g., multi-line tensors)

    CHALLENGES:
    - The expected value might be defined many lines before the assertion
    - It might be a multi-line definition (e.g., torch.tensor with line breaks)
    - It might have method chaining (e.g., .to(device))
    - It might be defined at class level or module level (not handled yet)

    CURRENT LIMITATIONS:
    - Only searches up to 50 lines backwards (might miss class-level constants)
    - Assumes the variable is defined in the same file (doesn't handle imports)
    - May struggle with very complex nested definitions
    """
    with open(file_path, 'r') as f:
        lines = f.readlines()

    # Define the search range
    # We search backwards from the assertion line, up to 50 lines
    # This should be enough for most test patterns, but might miss:
    # - Module-level constants defined at the top of the file
    # - Class-level attributes defined in setUp() methods
    search_start = max(0, line_number - 50)  # Look up to 50 lines back
    search_end = min(len(lines), line_number + 5)  # And a few lines forward (for rare cases)

    # CASE 1: INLINE DEFINITION IN THE ASSERTION
    # Sometimes the expected value is defined inline in the assertion itself:
    # Example:
    #   torch.testing.assert_close(actual, torch.tensor([1, 2, 3]))
    #
    # In this case, there's no separate variable assignment, and we'd need to
    # replace the inline value directly. This is NOT YET FULLY SUPPORTED.
    #
    # For now, we check for this pattern but don't handle it well.
    for i in range(line_number - 1, search_end):
        if i >= len(lines):
            break
        line = lines[i]

        # Check if expected_expression appears to be defined inline
        if value_type == 'torch_tensor':
            # Look for torch.tensor([...]) pattern
            pattern = rf'{re.escape(expected_expression)}\s*=\s*torch\.tensor\s*\('
            match = re.search(pattern, line)
            if match:
                # Found inline definition, need to find the closing parenthesis
                return _extract_multiline_expression(lines, i, match.start())

    # CASE 2: VARIABLE ASSIGNMENT BEFORE THE ASSERTION
    # This is the most common pattern in tests:
    # Example:
    #   expected_slice = torch.tensor([...])
    #   ...
    #   torch.testing.assert_close(actual, expected_slice)
    #
    # We search backwards from the assertion line to find the line that assigns
    # to the expected_expression variable.
    #
    # Pattern explanation:
    # ^\s* = start of line followed by optional whitespace
    # {re.escape(expected_expression)} = the exact variable name (escaped for regex)
    # \s*=\s* = optional whitespace, equals sign, optional whitespace
    pattern = rf'^\s*{re.escape(expected_expression)}\s*=\s*'

    # Search backwards from the assertion line
    for i in range(line_number - 1, search_start - 1, -1):
        if i < 0:
            break
        line = lines[i]

        if re.search(pattern, line):
            # Found the assignment!
            # Now we need to extract the full value, which might span multiple lines
            # Example:
            #   expected_slice = torch.tensor(
            #       [[1, 2, 3],
            #        [4, 5, 6]]
            #   ).to(device)
            # This is 4 lines total, so we need _extract_multiline_expression
            return _extract_multiline_expression(lines, i, 0)

    # CASE 3: NOT FOUND
    # If we reach here, we couldn't find the definition
    # Possible reasons:
    # - Variable defined more than 50 lines ago
    # - Variable is a class attribute or module constant
    # - Variable is imported from another file
    # - Typo in the variable name
    return None


def _extract_multiline_expression(
        lines: List[str],
        start_line: int,
        start_col: int = 0
) -> Tuple[int, int, str]:
    """
    Extract a potentially multi-line expression starting from start_line.

    This function is critical for handling multi-line definitions like:
        expected_slice = torch.tensor(
            [[1, 2, 3],
             [4, 5, 6]]
        ).to(device)

    It works by counting brackets and parentheses to determine where the expression ends.

    Args:
        lines: All lines from the file
        start_line: 0-indexed line number where the expression starts
        start_col: Column position within start_line to begin (0 = start of line)

    Returns: (start_line, end_line, extracted_text)
        - start_line: Same as input (0-indexed)
        - end_line: 0-indexed line number where the expression ends
        - extracted_text: The complete text of the expression (all lines concatenated)

    ALGORITHM:
    We parse the code character by character, tracking:
    1. Bracket count [ ] - for lists and tensors
    2. Parenthesis count ( ) - for function calls and method chains
    3. String state - to ignore brackets/parens inside strings

    The expression ends when:
    - All brackets and parentheses are balanced (counts return to 0)
    - AND we're at a natural boundary (end of line with ), ], or ,)

    EDGE CASES HANDLED:
    - Strings containing brackets/parens: "array[0]" shouldn't affect count
    - Method chaining: ).to(device) needs to include the final )
    - Nested structures: [[[1, 2]], [[3, 4]]]
    - Multi-line with trailing commas

    LIMITATIONS:
    - Doesn't handle escaped quotes in strings perfectly
    - Assumes well-formed Python (mismatched brackets will cause issues)
    - May include too much if there's code on the same line after the expression
    """
    # We'll build the complete text by concatenating line parts
    text = ""

    # Track bracket and parenthesis nesting levels
    # When both are 0, we've closed all opened brackets/parens
    bracket_count = 0  # Counts [ and ]
    paren_count = 0  # Counts ( and )

    # Track whether we're inside a string literal
    # We need this because brackets/parens inside strings don't count
    # Example: "this [is] a string" - the brackets don't affect bracket_count
    in_string = False
    string_char = None  # Will be either ' or " when in a string

    # Process each line starting from start_line
    for line_idx in range(start_line, len(lines)):
        line = lines[line_idx]

        # For the first line, we might need to start from a specific column
        # (e.g., if the assignment starts mid-line)
        # For subsequent lines, use the entire line
        if line_idx == start_line:
            line_part = line[start_col:]
        else:
            line_part = line

        # Add this line to our accumulated text
        text += line_part

        # Parse character by character to update our state
        for char in line_part:
            # STRING HANDLING
            # Check if we're entering or exiting a string
            if char in ('"', "'") and not in_string:
                # Entering a string
                in_string = True
                string_char = char  # Remember which quote type (single or double)
            elif char == string_char and in_string:
                # Exiting a string (found matching quote)
                # NOTE: This doesn't handle escaped quotes like \" perfectly
                # but works for most test code
                in_string = False
                string_char = None

            # BRACKET/PAREN COUNTING
            # Only count brackets and parens when we're NOT inside a string
            elif not in_string:
                if char == '[':
                    bracket_count += 1
                elif char == ']':
                    bracket_count -= 1
                elif char == '(':
                    paren_count += 1
                elif char == ')':
                    paren_count -= 1

        # TERMINATION CHECK
        # After processing this line, check if we should stop

        # First check: Are all brackets and parens balanced?
        line_stripped = line_part.rstrip()
        if bracket_count == 0 and paren_count == 0:
            # Brackets and parens are balanced. But we need to determine if this
            # is truly the end of the expression or if it continues.

            # Strategy 1: Check if line ends with a clear terminator
            # These characters typically indicate the end of an expression:
            # ) - end of function call or method chain
            # ] - end of list or tensor
            # , - end of element in a sequence (unusual but possible)
            if line_stripped.endswith(')') or line_stripped.endswith(']') or \
                    line_stripped.endswith(','):
                # This line clearly ends the expression
                return (start_line, line_idx, text.rstrip())

            # Strategy 2: Check if the next line continues the expression
            # If the next line starts with , ] or ), it's a continuation
            # Otherwise, the expression probably ends here
            if line_idx + 1 < len(lines):
                next_line = lines[line_idx + 1].strip()
                # If next line exists and doesn't start with continuation characters,
                # then the current line is the end
                if next_line and not next_line.startswith((',', ']', ')')):
                    return (start_line, line_idx, text.rstrip())

    # FALLBACK
    # If we've reached the end of the file without finding a clear termination,
    # return everything we've accumulated
    # This shouldn't happen in well-formed code, but prevents crashes
    return (start_line, len(lines) - 1, text.rstrip())


def format_torch_tensor_for_code(value_str: str, indent_level: int = 0) -> str:
    """
    Format a torch tensor value string into proper Python code.

    Input: "[-0.1552, 0.0314, -0.3233]" or multi-line tensor representation
    Output: Properly formatted torch.tensor([...]) code
    """
    # Remove any extra whitespace and normalize
    value_str = value_str.strip()

    # Check if it's already a multi-line format (from captured_info)
    is_multiline = '\n' in value_str

    if is_multiline:
        # The value is already formatted by _format_tensor() from testing_utils
        # It looks like:
        # [
        #     [-0.1552, 0.0314, -0.3233],
        #     [0.2886, 0.1141, -0.5706],
        # ]
        # We need to apply proper indentation
        lines = value_str.split('\n')
        indented_lines = []
        for line in lines:
            stripped = line.lstrip()
            if stripped:
                indented_lines.append(' ' * (indent_level * 4) + stripped)
            else:
                indented_lines.append('')
        return '\n'.join(indented_lines)
    else:
        # Single line tensor - convert to multi-line if it's 2D
        indent = ' ' * (indent_level * 4)

        # Try to parse as nested list and reformat
        try:
            # For 2D tensors like [[1,2,3], [4,5,6]], make it multi-line
            if value_str.startswith('[[') and value_str.endswith(']]'):
                # Extract inner lists
                inner = value_str[1:-1].strip()  # Remove outer []
                # Split by '], [' pattern
                rows = []
                depth = 0
                current_row = ''
                for char in inner:
                    if char == '[':
                        depth += 1
                    elif char == ']':
                        depth -= 1
                        if depth == 0:
                            rows.append('[' + current_row + ']')
                            current_row = ''
                            continue
                    if depth > 0:
                        current_row += char

                # Format as multi-line
                formatted = indent + '[\n'
                for row in rows:
                    formatted += indent + '    ' + row + ',\n'
                formatted += indent + ']'
                return formatted
            else:
                # 1D tensor, keep as single line
                return f"{indent}{value_str}"
        except:
            # Fallback: return as-is with indentation
            return f"{indent}{value_str}"


def update_expected_value_in_file(
        file_path: str,
        start_line: int,
        end_line: int,
        new_value: str,
        value_type: str
) -> bool:
    """
    Update the expected value in the test file.

    Returns True if successful, False otherwise.
    """
    with open(file_path, 'r') as f:
        lines = f.readlines()

    # Get the original text to extract the full pattern
    original_text = ''.join(lines[start_line:end_line + 1])

    # Get the indentation of the original definition (the line with "expected_slice = ")
    original_line = lines[start_line]
    indent_match = re.match(r'^(\s*)', original_line)
    base_indent = indent_match.group(1) if indent_match else ''

    # Extract the variable assignment part (e.g., "expected_slice = ")
    assignment_match = re.match(r'^(\s*)(\w+\s*=\s*)', original_line)
    assignment_prefix = ''
    if assignment_match:
        assignment_prefix = assignment_match.group(2)

    # Extract any method chaining at the end (e.g., ".to(torch_device)")
    method_chain_suffix = ''
    tensor_params = ''  # For parameters inside torch.tensor(..., device=..., dtype=...)
    if value_type == 'torch_tensor':
        # Look for patterns like ).to(...) or ).cuda() etc.
        chain_match = re.search(r'\)\s*(\.\s*\w+\([^)]*\))', original_text)
        if chain_match:
            method_chain_suffix = chain_match.group(1)

        # Extract parameters inside torch.tensor() like device=, dtype=, requires_grad=
        # We need to properly count brackets to find where the tensor array ends
        if 'torch.tensor(' in original_text:
            tensor_start = original_text.find('torch.tensor(')
            if tensor_start >= 0:
                # Start counting from after torch.tensor(
                pos = tensor_start + len('torch.tensor(')

                bracket_count = 0
                paren_count = 0
                in_string = False
                string_char = None

                # Find where the tensor values end (when brackets go back to 0)
                tensor_end = -1
                for i in range(pos, len(original_text)):
                    char = original_text[i]

                    if char in ('"', "'") and not in_string:
                        in_string = True
                        string_char = char
                    elif char == string_char and in_string:
                        in_string = False
                        string_char = None
                    elif not in_string:
                        if char == '[':
                            bracket_count += 1
                        elif char == ']':
                            bracket_count -= 1
                            if bracket_count == 0:
                                # Found the end of the tensor array
                                tensor_end = i
                                break
                        elif char == '(':
                            paren_count += 1
                        elif char == ')':
                            paren_count -= 1

                if tensor_end > 0:
                    # Now check if there's anything between tensor_end and the closing )
                    # Remove the method chain part first if it exists
                    text_to_check = original_text[tensor_end + 1:]
                    if method_chain_suffix:
                        # Remove method chain from the end
                        text_to_check = text_to_check[:text_to_check.rfind(')' + method_chain_suffix)]

                    # Find parameters: should be comma followed by params, then closing )
                    params_match = re.search(r'\s*,\s*(.+?)\s*\)$', text_to_check, re.DOTALL)
                    if params_match:
                        params = params_match.group(1).strip()
                        if '=' in params:
                            tensor_params = ',\n' + params

    # Format the new value appropriately
    if value_type == 'torch_tensor':
        # The captured_info.txt provides tensor with RELATIVE indentation like:
        # [
        #     [4.2325, 4.3882, -6.6678],
        #     [4.5372, 1.8933, -6.7354],
        # ]
        # where the opening [ has 0 indent, and content has 4 spaces

        # Find the base indentation to add (from the second line of original)
        if len(lines) > start_line + 1:
            second_line = lines[start_line + 1]
            content_indent_match = re.match(r'^(\s*)', second_line)
            if content_indent_match:
                content_base_indent = content_indent_match.group(1)
            else:
                content_base_indent = base_indent + '    '
        else:
            content_base_indent = base_indent + '    '

        # Apply indentation while preserving the relative structure from captured_info
        tensor_lines = new_value.split('\n')
        indented_tensor_lines = []
        for line in tensor_lines:
            stripped = line.lstrip()
            if not stripped:
                continue
            # Get the relative indentation from captured_info
            relative_indent = len(line) - len(stripped)
            # Add base indentation + relative indentation
            indented_tensor_lines.append(content_base_indent + ' ' * relative_indent + stripped)

        # Check if this is a single-line tensor (no newlines in original captured value)
        is_single_line = '\n' not in new_value.strip()

        # Check if original was torch.tensor(...) or just [...]
        if 'torch.tensor' in original_text:
            if is_single_line:
                # Single-line format: torch.tensor([...], device=...).to(...)
                formatted_value = f"{base_indent}{assignment_prefix}torch.tensor({new_value.strip()}{tensor_params}){method_chain_suffix}"
            else:
                # Multi-line format with proper indentation
                formatted_tensor = '\n'.join(indented_tensor_lines)
                formatted_value = f"{base_indent}{assignment_prefix}torch.tensor(\n"
                formatted_value += formatted_tensor
                # Add tensor_params with proper indentation if present
                if tensor_params:
                    # tensor_params starts with ',\n' so we need to add indentation after the newline
                    # Split on newline, indent each non-empty line, then rejoin
                    params_lines = tensor_params.split('\n')
                    indented_params = []
                    for i, line in enumerate(params_lines):
                        if i == 0:
                            # First part is just the comma
                            indented_params.append(line)
                        elif line.strip():
                            # Add base indentation + content indentation (match original style)
                            indented_params.append(content_base_indent + line.lstrip())
                        else:
                            indented_params.append(line)
                    formatted_value += '\n'.join(indented_params) + '\n'
                else:
                    formatted_value += '\n'
                formatted_value += f"{base_indent}){method_chain_suffix}"
        else:
            # Just update the tensor values directly
            if is_single_line:
                formatted_value = f"{base_indent}{assignment_prefix}{new_value.strip()}"
            else:
                formatted_tensor = '\n'.join(indented_tensor_lines)
                formatted_value = f"{base_indent}{assignment_prefix}{formatted_tensor}"
    elif value_type == 'string':
        formatted_value = f"{base_indent}{assignment_prefix}{new_value}"
    elif value_type == 'list_of_strings':
        formatted_value = f"{base_indent}{assignment_prefix}{new_value}"
    else:
        formatted_value = f"{base_indent}{assignment_prefix}{new_value}"

    # Replace the lines
    new_lines = lines[:start_line] + [formatted_value + '\n'] + lines[end_line + 1:]

    # Write back to file
    with open(file_path, 'w') as f:
        f.writelines(new_lines)

    return True


def process_captured_failures(
        captured_info_path: str,
        dry_run: bool = True
) -> Dict[str, List[str]]:
    """
    Process all captured test failures and update expected values.

    Args:
        captured_info_path: Path to the captured_info.txt file
        dry_run: If True, only report what would be changed without modifying files

    Returns:
        Dictionary mapping file paths to list of changes made
    """
    with open(captured_info_path, 'r') as f:
        content = f.read()

    failures = parse_captured_info(content)
    changes = {}

    for failure in failures:
        test_file = failure.get('test_file')
        if not test_file:
            continue

        expected_expr = failure.get('expected_expression')
        actual_value = failure.get('actual_value')

        if not expected_expr or not actual_value:
            continue

        # Detect value type
        value_type = detect_value_type(actual_value)

        # Find where expected value is defined
        location = find_expected_value_in_code(
            test_file,
            failure.get('test_lineno', 0),
            expected_expr,
            value_type
        )

        if location:
            start_line, end_line, original_text = location

            change_desc = (
                f"Line {start_line + 1}-{end_line + 1}: "
                f"Update {expected_expr} from:\n{original_text}\nto:\n{actual_value}"
            )

            if test_file not in changes:
                changes[test_file] = []
            changes[test_file].append(change_desc)

            if not dry_run:
                update_expected_value_in_file(
                    test_file,
                    start_line,
                    end_line,
                    actual_value,
                    value_type
                )

    return changes


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Update expected values in test files based on captured failures"
    )
    parser.add_argument(
        "captured_info",
        help="Path to captured_info.txt file"
    )
    parser.add_argument(
        "--apply",
        action="store_true",
        help="Actually apply changes (default is dry-run)"
    )

    args = parser.parse_args()

    changes = process_captured_failures(
        args.captured_info,
        dry_run=not args.apply
    )

    if changes:
        print("Changes to be made:" if not args.apply else "Changes made:")
        for file_path, file_changes in changes.items():
            print(f"\n{file_path}:")
            for change in file_changes:
                print(f"  {change}")
    else:
        print("No changes detected.")